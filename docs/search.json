[{"path":"index.html","id":"section","chapter":"","heading":"","text":"DRAFT.REVIEWING BOOK, PLEASE PROVIDE FEEDBACK PAGE LINK","code":""},{"path":"index.html","id":"about-this-handbook","chapter":"","heading":"About this handbook","text":"free open-access R reference manual applied epidemiologists public health practitioners.book strives :Serve quick reference manual - textbook comprehensive R trainingAddress common epidemiological problems via task-centered examplesBe accessible settings low internet-connectivity via offline version (instructions )challenges book try address?Many epidemiologists transitioning R SAS, STATA, SPSS, Excel, softwareEpidemiologists need spend hours searching online code relevant common epi userEpidemiologists sometimes work low internet-connectivity environments limited supportHow different R books?written epidemiologists, epidemiologists - leveraging experience local, national, academic, emergency settingsIt provides examples epidemic curves, transmission chains, epidemic modeling projections, age sex pyramids standardization, record matching, outbreak detection, survey analysis, causal diagrams, survival analysis, GIS basics, phylogenetic trees, automated reports, etc…","code":""},{"path":"index.html","id":"how-to-read-this-handbook","chapter":"","heading":"How to read this handbook","text":"Online versionSearch via search box Table ContentsClick “copy” icons copy codeSee “Resources” section page resourcesTo download data “follow-along”, see Download book data pageOffline versionTo download offline version, follow step--step instructions Download book data page.LanguagesWe actively seeking translate book languages English. can help, please contact us epiRhandbook@gmail.com.","code":""},{"path":"index.html","id":"edit-or-contribute","chapter":"","heading":"Edit or contribute","text":"Want share use book? Want offer fix addition?\r\nEmail us epiRhandbook@gmail.com. welcome comments suggestions.can also submit issue pull request Github repository, provide structured feedback via Google survey.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"","heading":"Acknowledgements","text":"","code":""},{"path":"index.html","id":"contributors","chapter":"","heading":"Contributors","text":"book produced collaboration epidemiologists around world, drawing upon experiences organizations including local/state/provincial/national health departments ministries, World Health Organization (), MSF (Médecins Sans Frontières / Doctors without Borders), hospital systems, academic institutions.Editor--Chief: Neale BatraCore team: Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay CampbellAuthors: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonny Polonski, Yurie Izawa, Daniel Molling, Sara Hollis, Isha Berry, Wen LinReviewers:Advisers:","code":""},{"path":"index.html","id":"funding-and-programmatic-support","chapter":"","heading":"Funding and programmatic support","text":"handbook approved product specific organization. Although strive accuracy, provide guarantee content book.handbook project received funding via COVID-19 emergency capacity-building grant Training Programs Epidemiology Public Health Interventions Network (TEPHINET). handbook supported Cooperative Agreement number NU2GGH001873, funded Centers Disease Control Prevention TEPHINET, program Task Force Global Health. contents solely responsibility authors necessarily represent official views Centers Disease Control Prevention, Department Health Human Services, Task Force Global Health, Inc. TEPHINET.Programmatic support provided EPIET Alumni Network (EAN) also MSF’s Manson Unit.","code":""},{"path":"index.html","id":"inspiration","chapter":"","heading":"Inspiration","text":"multitude tutorials vignettes provided knowledge development handbook content credited within respective pages.generally, following sources provided inspiration laid groundwork handbook:“R4Epis” project (collaboration MSF RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R MarkdownNetlify hosts website","code":""},{"path":"index.html","id":"image-credits","chapter":"","heading":"Image credits","text":"Images logo (US CDC Public Health Image Library):2013 Yemen looking mosquito breeding sitesEbola virusSurvey Rajasthan","code":""},{"path":"index.html","id":"terms-of-use-and-license","chapter":"","heading":"Terms of Use and License","text":"work licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.","code":""},{"path":"editorial-and-technical-notes.html","id":"editorial-and-technical-notes","chapter":"1 Editorial and technical notes","heading":"1 Editorial and technical notes","text":"page describe philosophical approach, style, specific editorial decisions made creation handbook.","code":""},{"path":"editorial-and-technical-notes.html","id":"approach-and-style","chapter":"1 Editorial and technical notes","heading":"1.1 Approach and style","text":"potential audience book large. surely used people new R, also experienced R users looking best practices tips. must accessible succinct. Therefore, approach provide just enough text explanation someone new R can apply code follow code .points:code reference book accompanied relatively brief examples - thorough textbook R data scienceThis R handbook use within applied epidemiology - manual methods science applied epidemiology","code":""},{"path":"editorial-and-technical-notes.html","id":"packages","chapter":"1 Editorial and technical notes","heading":"Packages","text":"many choicesOne challenging aspects learning R knowing R package use given task. common occurrence struggle task later realize - hey, ’s R package one command line!handbook, try offer least two ways complete task: one tried--true method (probably base R tidyverse) one special R package custom-built purpose. want couple options case can’t download given package otherwise work .choosing packages use, prioritized R packages approaches tested vetted community, minimize number packages used typical work session, stable (changing often), accomplish task simply cleanlyThis handbook generally prioritizes R packages functions tidyverse. Tidyverse collection R packages designed data science share underlying grammar data structures. tidyverse packages can installed loaded via tidyverse package. Read tidyverse website.applicable, also offer code options using base R - packages functions come R installation. recognize book’s audience may reliable internet download extra packages.Linking functions packages explicitlyIt often frustrating R tutorials function shown code, don’t know package ! try avoid situation.narrative text, package names written bold (e.g. dplyr) functions written like : mutate(). strive explicit package function comes , either referencing package nearby text specifying package explicitly code like : dplyr::mutate(). may look redundant, purpose.See page R basics learn packages functions.","code":""},{"path":"editorial-and-technical-notes.html","id":"code-style","chapter":"1 Editorial and technical notes","heading":"Code style","text":"handbook, frequently utilize “new lines”, making code appear “long”. reasons:can write explanatory comments # adjacent little part codeGenerally, longer (vertical) code easier readIt easier read narrow screen (sideways scrolling needed)indentations, can easier know arguments belong functionAs result, code written like :…written like :R code generally affected new lines indentations. writing code, initiate new line comma apply automatic indentation patterns.also use lots spaces (e.g. n = 1 instead n=1) easier read. kind people reading code!","code":"\nlinelist %>% \n  group_by(hospital) %>%  # group rows by hospital\n  slice_max(date, n = 1, with_ties = F) # if there's a tie (of date), take the first row\nlinelist %>% \n  group_by(hospital) %>% # group rows by hospital\n  slice_max(\n    date,                # keep row per group with maximum date value \n    n = 1,               # keep only the single highest row \n    with_ties = F)       # if there's a tie (of date), take the first row"},{"path":"editorial-and-technical-notes.html","id":"notes","chapter":"1 Editorial and technical notes","heading":"Notes","text":"types notes may encounter handbook:NOTE: noteTIP: tip.CAUTION: cautionary note.DANGER: warning.","code":""},{"path":"editorial-and-technical-notes.html","id":"editorial-decisions","chapter":"1 Editorial and technical notes","heading":"1.2 Editorial decisions","text":", track significant editorial decisions around package function choice. disagree want offer new tool consideration, please join/start conversation Github page.Table package, function, editorial decisions","code":""},{"path":"editorial-and-technical-notes.html","id":"session-info-r-rstudio-packages","chapter":"1 Editorial and technical notes","heading":"1.3 Session info (R, RStudio, packages)","text":"information versions R, RStudio, R packages used rendering Handbook.","code":"\nsessioninfo::session_info()## - Session info -----------------------------------------------------------------------------------------------------------------------------------\r\n##  setting  value                       \r\n##  version  R version 4.0.2 (2020-06-22)\r\n##  os       Windows 10 x64              \r\n##  system   x86_64, mingw32             \r\n##  ui       RStudio                     \r\n##  language (EN)                        \r\n##  collate  English_United States.1252  \r\n##  ctype    English_United States.1252  \r\n##  tz       America/New_York            \r\n##  date     2021-03-30                  \r\n## \r\n## - Packages ---------------------------------------------------------------------------------------------------------------------------------------\r\n##  package       * version     date       lib source                            \r\n##  ada             2.0-5       2016-05-13 [1] CRAN (R 4.0.3)                    \r\n##  adagio          0.7.1       2018-05-17 [1] CRAN (R 4.0.3)                    \r\n##  ade4            1.7-16      2020-10-28 [1] CRAN (R 4.0.3)                    \r\n##  apyramid      * 0.1.2       2020-05-08 [1] CRAN (R 4.0.2)                    \r\n##  assertthat      0.2.1       2019-03-21 [1] CRAN (R 4.0.0)                    \r\n##  aweek         * 1.0.2       2021-01-04 [1] CRAN (R 4.0.3)                    \r\n##  backports       1.2.0       2020-11-02 [1] CRAN (R 4.0.3)                    \r\n##  base64enc       0.1-3       2015-07-28 [1] CRAN (R 4.0.0)                    \r\n##  bit           * 4.0.4       2020-08-04 [1] CRAN (R 4.0.3)                    \r\n##  bit64           4.0.5       2020-08-30 [1] CRAN (R 4.0.3)                    \r\n##  blob            1.2.1       2020-01-20 [1] CRAN (R 4.0.2)                    \r\n##  bookdown        0.21.4      2021-01-23 [1] Github (rstudio/bookdown@cc0f6d4) \r\n##  broom           0.7.3       2020-12-16 [1] CRAN (R 4.0.3)                    \r\n##  bslib           0.2.3.9000  2021-01-23 [1] Github (rstudio/bslib@4c5d15d)    \r\n##  cellranger      1.1.0       2016-07-27 [1] CRAN (R 4.0.0)                    \r\n##  class           7.3-17      2020-04-26 [2] CRAN (R 4.0.2)                    \r\n##  cli             2.3.1       2021-02-23 [1] CRAN (R 4.0.4)                    \r\n##  codetools       0.2-16      2018-12-24 [2] CRAN (R 4.0.2)                    \r\n##  colorspace      2.0-0       2020-11-11 [1] CRAN (R 4.0.3)                    \r\n##  crayon          1.4.1       2021-02-08 [1] CRAN (R 4.0.4)                    \r\n##  crosstalk       1.1.1       2021-01-12 [1] CRAN (R 4.0.3)                    \r\n##  curl            4.3         2019-12-02 [1] CRAN (R 4.0.0)                    \r\n##  data.table      1.14.0      2021-02-21 [1] CRAN (R 4.0.4)                    \r\n##  DBI           * 1.1.1       2021-01-15 [1] CRAN (R 4.0.3)                    \r\n##  dbplyr          2.0.0       2020-11-03 [1] CRAN (R 4.0.3)                    \r\n##  DiagrammeR    * 1.0.6.1     2020-05-08 [1] CRAN (R 4.0.3)                    \r\n##  digest          0.6.27      2020-10-24 [1] CRAN (R 4.0.3)                    \r\n##  doParallel      1.0.16      2020-10-16 [1] CRAN (R 4.0.3)                    \r\n##  downlit         0.2.1       2020-11-04 [1] CRAN (R 4.0.3)                    \r\n##  dplyr         * 1.0.5       2021-03-05 [1] CRAN (R 4.0.4)                    \r\n##  DT            * 0.15        2020-08-05 [1] CRAN (R 4.0.2)                    \r\n##  e1071           1.7-4       2020-10-14 [1] CRAN (R 4.0.3)                    \r\n##  ellipsis        0.3.1       2020-05-15 [1] CRAN (R 4.0.2)                    \r\n##  epikit        * 0.1.2       2020-09-07 [1] CRAN (R 4.0.3)                    \r\n##  epitrix         0.2.2       2019-01-15 [1] CRAN (R 4.0.2)                    \r\n##  evaluate        0.14        2019-05-28 [1] CRAN (R 4.0.0)                    \r\n##  evd             2.3-3       2018-04-25 [1] CRAN (R 4.0.3)                    \r\n##  FactoClass      1.2.7       2018-10-01 [1] CRAN (R 4.0.3)                    \r\n##  fansi           0.4.2       2021-01-15 [1] CRAN (R 4.0.3)                    \r\n##  farver          2.1.0       2021-02-28 [1] CRAN (R 4.0.4)                    \r\n##  fastLink      * 0.6.0       2020-04-29 [1] CRAN (R 4.0.3)                    \r\n##  ff            * 4.0.4       2020-10-13 [1] CRAN (R 4.0.3)                    \r\n##  flextable       0.6.2       2021-01-25 [1] CRAN (R 4.0.2)                    \r\n##  forcats       * 0.5.0       2020-03-01 [1] CRAN (R 4.0.0)                    \r\n##  foreach         1.5.1       2020-10-15 [1] CRAN (R 4.0.3)                    \r\n##  foreign         0.8-80      2020-05-24 [2] CRAN (R 4.0.2)                    \r\n##  fs            * 1.5.0       2020-07-31 [1] CRAN (R 4.0.2)                    \r\n##  gdtools         0.2.3       2021-01-06 [1] CRAN (R 4.0.3)                    \r\n##  generics        0.1.0       2020-10-31 [1] CRAN (R 4.0.3)                    \r\n##  ggplot2       * 3.3.3       2020-12-30 [1] CRAN (R 4.0.3)                    \r\n##  ggrepel         0.9.1       2021-01-15 [1] CRAN (R 4.0.3)                    \r\n##  glue            1.4.2       2020-08-27 [1] CRAN (R 4.0.2)                    \r\n##  gtable          0.3.0       2019-03-25 [1] CRAN (R 4.0.0)                    \r\n##  gtools          3.8.2       2020-03-31 [1] CRAN (R 4.0.3)                    \r\n##  haven           2.3.1       2020-06-01 [1] CRAN (R 4.0.2)                    \r\n##  here          * 1.0.1       2020-12-13 [1] CRAN (R 4.0.3)                    \r\n##  highcharter     0.8.2       2020-07-26 [1] CRAN (R 4.0.3)                    \r\n##  highr           0.8         2019-03-20 [1] CRAN (R 4.0.0)                    \r\n##  hms             1.0.0       2021-01-13 [1] CRAN (R 4.0.3)                    \r\n##  htmltools       0.5.1.1     2021-01-22 [1] CRAN (R 4.0.4)                    \r\n##  htmlwidgets     1.5.3       2020-12-10 [1] CRAN (R 4.0.3)                    \r\n##  httr            1.4.2       2020-07-20 [1] CRAN (R 4.0.2)                    \r\n##  igraph          1.2.6       2020-10-06 [1] CRAN (R 4.0.3)                    \r\n##  incidence2      0.2.2       2020-11-12 [1] CRAN (R 4.0.4)                    \r\n##  ipred           0.9-9       2019-04-28 [1] CRAN (R 4.0.2)                    \r\n##  iterators       1.0.13      2020-10-15 [1] CRAN (R 4.0.3)                    \r\n##  janitor       * 2.1.0       2021-01-05 [1] CRAN (R 4.0.3)                    \r\n##  jquerylib       0.1.3       2020-12-17 [1] CRAN (R 4.0.3)                    \r\n##  jsonlite        1.7.2       2020-12-09 [1] CRAN (R 4.0.3)                    \r\n##  kableExtra      1.3.1       2020-10-22 [1] CRAN (R 4.0.3)                    \r\n##  KernSmooth      2.23-17     2020-04-26 [2] CRAN (R 4.0.2)                    \r\n##  knitr           1.31        2021-01-27 [1] CRAN (R 4.0.4)                    \r\n##  labeling        0.4.2       2020-10-20 [1] CRAN (R 4.0.3)                    \r\n##  lattice         0.20-41     2020-04-02 [2] CRAN (R 4.0.2)                    \r\n##  lava            1.6.8.1     2020-11-04 [1] CRAN (R 4.0.3)                    \r\n##  lazyeval        0.2.2       2019-03-15 [1] CRAN (R 4.0.0)                    \r\n##  lifecycle       1.0.0       2021-02-15 [1] CRAN (R 4.0.4)                    \r\n##  linelist      * 0.0.40.9000 2020-09-18 [1] Github (reconhub/linelist@cae034d)\r\n##  lubridate     * 1.7.9.2     2020-11-13 [1] CRAN (R 4.0.3)                    \r\n##  magrittr        2.0.1       2020-11-17 [1] CRAN (R 4.0.3)                    \r\n##  MASS            7.3-51.6    2020-04-26 [2] CRAN (R 4.0.2)                    \r\n##  matchmaker      0.1.1       2020-02-21 [1] CRAN (R 4.0.2)                    \r\n##  Matrix        * 1.2-18      2019-11-27 [2] CRAN (R 4.0.2)                    \r\n##  memoise         1.1.0       2017-04-21 [1] CRAN (R 4.0.2)                    \r\n##  modelr          0.1.8       2020-05-19 [1] CRAN (R 4.0.2)                    \r\n##  munsell         0.5.0       2018-06-12 [1] CRAN (R 4.0.0)                    \r\n##  networkD3     * 0.4         2017-03-18 [1] CRAN (R 4.0.3)                    \r\n##  nnet            7.3-14      2020-04-26 [2] CRAN (R 4.0.2)                    \r\n##  officer         0.3.16      2021-01-04 [1] CRAN (R 4.0.3)                    \r\n##  openxlsx        4.2.3       2020-10-27 [1] CRAN (R 4.0.3)                    \r\n##  pacman          0.5.1       2019-03-11 [1] CRAN (R 4.0.0)                    \r\n##  pillar          1.5.1       2021-03-05 [1] CRAN (R 4.0.4)                    \r\n##  pkgconfig       2.0.3       2019-09-22 [1] CRAN (R 4.0.0)                    \r\n##  plotly        * 4.9.3       2021-01-10 [1] CRAN (R 4.0.3)                    \r\n##  plotrix         3.8-1       2021-01-21 [1] CRAN (R 4.0.3)                    \r\n##  png             0.1-7       2013-12-03 [1] CRAN (R 4.0.0)                    \r\n##  prettyunits     1.1.1       2020-01-24 [1] CRAN (R 4.0.0)                    \r\n##  prodlim         2019.11.13  2019-11-17 [1] CRAN (R 4.0.2)                    \r\n##  progress        1.2.2       2019-05-16 [1] CRAN (R 4.0.0)                    \r\n##  purrr         * 0.3.4       2020-04-17 [1] CRAN (R 4.0.0)                    \r\n##  quantmod        0.4.18      2020-12-09 [1] CRAN (R 4.0.3)                    \r\n##  R6              2.5.0       2020-10-28 [1] CRAN (R 4.0.3)                    \r\n##  rappdirs        0.3.1       2016-03-28 [1] CRAN (R 4.0.3)                    \r\n##  RColorBrewer    1.1-2       2014-12-07 [1] CRAN (R 4.0.0)                    \r\n##  Rcpp            1.0.6       2021-01-15 [1] CRAN (R 4.0.3)                    \r\n##  readr         * 1.4.0       2020-10-05 [1] CRAN (R 4.0.3)                    \r\n##  readxl          1.3.1       2019-03-13 [1] CRAN (R 4.0.0)                    \r\n##  RecordLinkage * 0.4-12.1    2020-08-25 [1] CRAN (R 4.0.3)                    \r\n##  repr            1.1.3       2021-01-21 [1] CRAN (R 4.0.3)                    \r\n##  reprex          0.3.0       2019-05-16 [1] CRAN (R 4.0.0)                    \r\n##  rio           * 0.5.26      2021-03-01 [1] CRAN (R 4.0.4)                    \r\n##  rjson           0.2.20      2018-06-08 [1] CRAN (R 4.0.0)                    \r\n##  rlang           0.4.10      2020-12-30 [1] CRAN (R 4.0.3)                    \r\n##  rlist           0.4.6.1     2016-04-04 [1] CRAN (R 4.0.3)                    \r\n##  rmarkdown       2.7         2021-02-19 [1] CRAN (R 4.0.4)                    \r\n##  rpart           4.1-15      2019-04-12 [2] CRAN (R 4.0.2)                    \r\n##  rprojroot       2.0.2       2020-11-15 [1] CRAN (R 4.0.3)                    \r\n##  RSQLite       * 2.2.3       2021-01-24 [1] CRAN (R 4.0.3)                    \r\n##  rstudioapi      0.13        2020-11-12 [1] CRAN (R 4.0.3)                    \r\n##  rvest           0.3.6       2020-07-25 [1] CRAN (R 4.0.2)                    \r\n##  sass            0.3.0       2021-01-13 [1] CRAN (R 4.0.3)                    \r\n##  scales          1.1.1       2020-05-11 [1] CRAN (R 4.0.2)                    \r\n##  scatterplot3d   0.3-41      2018-03-14 [1] CRAN (R 4.0.3)                    \r\n##  sessioninfo     1.1.1       2018-11-05 [1] CRAN (R 4.0.2)                    \r\n##  skimr           2.1.2       2020-07-06 [1] CRAN (R 4.0.3)                    \r\n##  snakecase       0.11.0      2019-05-25 [1] CRAN (R 4.0.0)                    \r\n##  stringdist    * 0.9.6.3     2020-10-09 [1] CRAN (R 4.0.3)                    \r\n##  stringi         1.5.3       2020-09-09 [1] CRAN (R 4.0.2)                    \r\n##  stringr       * 1.4.0       2019-02-10 [1] CRAN (R 4.0.0)                    \r\n##  survival        3.1-12      2020-04-10 [2] CRAN (R 4.0.2)                    \r\n##  systemfonts     0.3.2       2020-09-29 [1] CRAN (R 4.0.3)                    \r\n##  tibble        * 3.1.0       2021-02-25 [1] CRAN (R 4.0.4)                    \r\n##  tidyr         * 1.1.2       2020-08-27 [1] CRAN (R 4.0.2)                    \r\n##  tidyselect      1.1.0       2020-05-11 [1] CRAN (R 4.0.2)                    \r\n##  tidyverse     * 1.3.0       2019-11-21 [1] CRAN (R 4.0.4)                    \r\n##  TTR             0.24.2      2020-09-01 [1] CRAN (R 4.0.2)                    \r\n##  utf8            1.1.4       2018-05-24 [1] CRAN (R 4.0.4)                    \r\n##  uuid            0.1-4       2020-02-26 [1] CRAN (R 4.0.3)                    \r\n##  vctrs           0.3.6       2020-12-17 [1] CRAN (R 4.0.3)                    \r\n##  viridisLite     0.3.0       2018-02-01 [1] CRAN (R 4.0.0)                    \r\n##  visNetwork      2.0.9       2019-12-06 [1] CRAN (R 4.0.0)                    \r\n##  vistime       * 1.1.0       2020-07-25 [1] CRAN (R 4.0.3)                    \r\n##  webshot         0.5.2       2019-11-22 [1] CRAN (R 4.0.0)                    \r\n##  withr           2.4.1       2021-01-26 [1] CRAN (R 4.0.4)                    \r\n##  xfun            0.22        2021-03-11 [1] CRAN (R 4.0.4)                    \r\n##  xml2            1.3.2       2020-04-23 [1] CRAN (R 4.0.2)                    \r\n##  xtable          1.8-4       2019-04-21 [1] CRAN (R 4.0.0)                    \r\n##  xts             0.12.1      2020-09-09 [1] CRAN (R 4.0.2)                    \r\n##  yaml            2.2.1       2020-02-01 [1] CRAN (R 4.0.0)                    \r\n##  zip             2.1.1       2020-08-27 [1] CRAN (R 4.0.2)                    \r\n##  zoo           * 1.8-8       2020-05-02 [1] CRAN (R 4.0.2)                    \r\n## \r\n## [1] C:/Users/Neale/OneDrive - Neale Batra/Documents/R/win-library/4.0\r\n## [2] C:/Program Files/R/R-4.0.2/library"},{"path":"download-book-and-data.html","id":"download-book-and-data","chapter":"2 Download book and data","heading":"2 Download book and data","text":"","code":""},{"path":"download-book-and-data.html","id":"download-offline-handbook","chapter":"2 Download book and data","heading":"2.1 Download offline handbook","text":"download offline version handbook please follow steps. download HTML file. can view file web browser even internet access.Note: file large (>40MB). open , may take several minutes images Table Contents load/appear. Also, offline handbook displays one long page, please search specific content using Ctrl+f (Cmd-f).Click link go html file Github repository’s “offline_long” folder.Click “Download” button. window open HTML source code.“Save ” webpage, via right-click (windows) Cmd-s (mac) - given option, set file type “Webpage, Complete”","code":""},{"path":"download-book-and-data.html","id":"download-data-to-follow-along","chapter":"2 Download book and data","heading":"2.2 Download data to follow along","text":"data handbook can downloaded “data” folder Github repository. arrive folder, click file want download.“follow along” handbook examples use linelist dataset, download load either “linelist_raw.xlsx” (Cleaning page), “linelist_cleaned.rds” (page).detailed instructions downloading data files Github:","code":""},{"path":"download-book-and-data.html","id":"raw-linelist-.xlsx","chapter":"2 Download book and data","heading":"“Raw” linelist (.xlsx)","text":"Use “linelist_raw.xlsx” follow-along Cleaning data core functions page. download raw linelist (uncleaned, messy data), use following appraoch.Note: Use “linelist_cleaned.rds” follow-along page uses case linelist.Go “data” folder Github repositoryClick “linelist_raw.xlsx”Click “Download” button shown belowSave file computer, import R import() function rio, described page Import export.","code":""},{"path":"download-book-and-data.html","id":"clean-linelist-.rds","chapter":"2 Download book and data","heading":"Clean linelist (.rds)","text":"Use “linelist_cleaned.rds” follow-along page uses case linelist (data cleaning page). .rds file R-specific file type preserves column classes. ensures minimal cleaning importing.Go “data” folder Github repositoryClick “linelist_cleaned.rds”Click “Download” button shown belowSave file computer, import R import() function rio, described page Import export.","code":""},{"path":"download-book-and-data.html","id":"csv-files","chapter":"2 Download book and data","heading":".csv files","text":"easy download relatively small CSV file directly Github R R command.Go “data” folder Github repositoryClick .csv file interestClick “Raw” button (see “raw” csv data, shown )Copy URL (web address)Use URL import() R command, shown belowProvide URL import() rio shown .approach work, can click “Raw” button, right-click webpage “Save ” data .txt file computer. file can imported R import().","code":"\n# Example of importing the country demographics csv file\ncountry_demographics <- import(\"https://raw.githubusercontent.com/nsbatra/Epi_R_handbook/master/data/country_demographics.csv\")\n\n# Example of importing the likert-scale data csv file\nlikert_data <- import(\"https://raw.githubusercontent.com/nsbatra/Epi_R_handbook/master/data/likert_data.csv\")"},{"path":"download-book-and-data.html","id":"shapefiles","chapter":"2 Download book and data","heading":"Shapefiles","text":"Shapefiles many sub-component files, different file extention. One file “.shp” extension, others may “.dbf”, “.prj”, etc.GIS basics page provides links Humanitarian Data Exchange website can download shapefiles directly. example, health facility points can downloaded . Download points shapefile (shp) “.zip” folder. saved computer, “unzip” folder. see several files different extensions (e.g. “.shp”, “.prj”, “.shx”) - must saved folder. described GIS basics page, provide filepath name “.shp” file st_read() sf package.Alternatively, can download shapefiles R Handbook Github “data” folder (see “shp” sub-folder). However, aware need download sub-file individually computer. Github, click file individually download clicking “Download” button. , can see shapefile “sle_adm3” consists many files - must downloaded Github.","code":""},{"path":"download-book-and-data.html","id":"nwk-and-other-files","chapter":"2 Download book and data","heading":"NWK and other files","text":"Click file Gitub “data” folder, use “Download” button, described .xlsx files.","code":""},{"path":"download-book-and-data.html","id":"background-information","chapter":"2 Download book and data","heading":"2.3 Background information","text":"details data:case linelist\r\nsimulated Ebola outbreak, expanded handbook team ebola_sim practice dataset outbreaks package\r\nsimulated Ebola outbreak, expanded handbook team ebola_sim practice dataset outbreaks packageAggregated counts\r\nsimulated dataset malaria counts age, day, facility fictional region, can downloaded data folder noted “district_count_data.xlsx”\r\nsimulated dataset malaria counts age, day, facility fictional region, can downloaded data folder noted “district_count_data.xlsx”Time series outbreak detection\r\nCampylobacter cases reported Germany 2002-2011. Available surveillance package\r\nClimate data (temperature degrees celsius rain fail millimetres) Germany 2002-2011. Downloaded EU Copernicus satellite reanalysis dataset using ecmwfr package explained time series page.\r\nCampylobacter cases reported Germany 2002-2011. Available surveillance packageClimate data (temperature degrees celsius rain fail millimetres) Germany 2002-2011. Downloaded EU Copernicus satellite reanalysis dataset using ecmwfr package explained time series page.GIS page shapefiles\r\nDownloaded Humanitarian Data Exchange (HDX) - see links GIS basics page\r\nDownloaded Humanitarian Data Exchange (HDX) - see links GIS basics pagePhylogenetic tree data\r\nNewick file phylogenetic tree constructed whole genome sequencing 299 Shigella sonnei samples corresponding sample data.\r\nBelgian samples resulting data kindly provided Belgian NRC Salmonella Shigella scope project conducted ECDC EUPHEM Fellow, also published manuscript.\r\ninternational data openly available public databases (ncbi) previously published.\r\nNewick file phylogenetic tree constructed whole genome sequencing 299 Shigella sonnei samples corresponding sample data.Belgian samples resulting data kindly provided Belgian NRC Salmonella Shigella scope project conducted ECDC EUPHEM Fellow, also published manuscript.international data openly available public databases (ncbi) previously published.","code":""},{"path":"r-basics.html","id":"r-basics","chapter":"3 R Basics","heading":"3 R Basics","text":"","code":""},{"path":"r-basics.html","id":"overview","chapter":"3 R Basics","heading":"3.1 Overview","text":"page intended comprehensive “learn R” tutorial. However, cover fundamentals can useful reference refreshing memory. See section recommended training links comprehensive tutorials.Much page adapted permission R Basics section R4Epis project.See page Transition R tips switching R STATA, SAS, Excel.","code":""},{"path":"r-basics.html","id":"why-use-r","chapter":"3 R Basics","heading":"3.2 Why use R?","text":"stated R project website, R programming language environment statistical computing graphics. highly versatile, extensible, community-driven.CostR free use! strong ethic community free open-source material.ReproducibilityConducting data management analysis programming language (compared Excel another primarily point-click/manual tool) enhances reproducibility, makes error-detection easier, eases workload.CommunityThe R community users enormous collaborative. New packages tools address real-life problems developed daily, vetted community users. one example, R-Ladies worldwide organization whose mission promote gender diversity R community, one largest organizations R users. likely chapter near !","code":""},{"path":"r-basics.html","id":"recommended-training","chapter":"3 R Basics","heading":"3.3 Recommended training","text":"","code":""},{"path":"r-basics.html","id":"resources-within-rstudio","chapter":"3 R Basics","heading":"Resources within RStudio","text":"Help documentationSearch RStudio “Help” tab documentation R packages specific functions. within pane also contains Files, Plots, Packages (typically lower-right pane). shortcut, can also type name package function R console question-mark open relevant Help page. example: ?filter ?diagrammeR.Interactive tutorialsRStudio built-interative tutorials via learnr package. package installed, can go tutorials via “Tutorial” tab upper-right RStudio pane (also contains Environment History tabs).","code":""},{"path":"r-basics.html","id":"cheatsheets","chapter":"3 R Basics","heading":"Cheatsheets","text":"many PDF “cheatsheets” available RStudio website, example:Factors forcats packageDates times lubridate packageStrings stringr package“apply” functions purrr packageData import cheatsheetData transformation cheatsheet dplyr packageR MarkdownShinyData visualization ggplot2 packageCartographyleaflet package (interactive maps)Python R (reticulate package)online R resource specifically Excel users","code":""},{"path":"r-basics.html","id":"free-online-resources","chapter":"3 R Basics","heading":"Free online resources","text":"definitive text R Data Science book Garrett Grolemund Hadley WickhamThe R4Epis project website aims “develop standardised data cleaning, analysis reporting tools cover common types outbreaks population-based surveys conducted MSF emergency response setting.” can find R basics training materials, templates RMarkdown reports outbreaks surveys, tutorials help set .","code":""},{"path":"r-basics.html","id":"installation","chapter":"3 R Basics","heading":"3.4 Installation","text":"install RVisit website https://www.r-project.org/ download latest version R suitable computer.install RStudioVisit website https://rstudio.com/products/rstudio/download/ download latest free Desktop version RStudio suitable computer.Permissions\r\nNote install R RStudio drive read write permissions. Otherwise, ability install R packages (frequent occurrence) impacted. encounter problems, try opening RStudio right-clicking icon selecting “Run administrator”. tips can found page R network drives.update R RStudioYour version R printed R Console start-. can also run sessionInfo().update R, go website mentioned re-install R. Alternatively, can use installr package (Windows) running installr::updateR(). open dialog boxes help download latest R version update packages new R version. details can found installr documentation.aware old R version still exist computer. can temporarily run older version (older “installation”) R clicking “Tools” -> “Global Options” RStudio choosing R version. can useful want use package updated work newest version R.update RStudio, can go website re-download RStudio. Another option click “Help” -> “Check Updates” within RStudio, may show latest updates.see versions R, RStudio, packages used Handbook made, see page [Datasets version used].","code":""},{"path":"r-basics.html","id":"other-software-you-may-need-to-install","chapter":"3 R Basics","heading":"Other software you may need to install","text":"TinyTeX (compiling RMarkdown document PDF)Pandoc (compiling RMarkdown documents)RTools (building packages R)phantomjs (saving still images animated networks, transmission chains)","code":""},{"path":"r-basics.html","id":"tinytex","chapter":"3 R Basics","heading":"TinyTex","text":"TinyTex custom LaTeX distribution, useful trying produce PDFs R.\r\nSee https://yihui.org/tinytex/ informaton.install TinyTex R:","code":"\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n# to uninstall TinyTeX, run tinytex::uninstall_tinytex()"},{"path":"r-basics.html","id":"pandoc","chapter":"3 R Basics","heading":"Pandoc","text":"Pandoc document converter, separate software R. comes bundled RStudio need downloaded. helps process converting Rmarkdown documents formats like .pdf adding complex functionality.","code":""},{"path":"r-basics.html","id":"rtools","chapter":"3 R Basics","heading":"RTools","text":"RTools collection software building packages RInstall website: https://cran.r-project.org/bin/windows/Rtools/","code":""},{"path":"r-basics.html","id":"phantomjs","chapter":"3 R Basics","heading":"phantomjs","text":"often used take “screenshots” webpages. example make transmission chain epicontacts package, HTML file produced interactive dynamic. want static image, can useful use webshot package automate process. require external program “phantomjs”. can install phantomjs via webshot package command webshot::install_phantomjs().","code":""},{"path":"r-basics.html","id":"rstudio","chapter":"3 R Basics","heading":"3.5 RStudio","text":"","code":""},{"path":"r-basics.html","id":"rstudio-orientation","chapter":"3 R Basics","heading":"RStudio Orientation","text":"First, open RStudio. icons can look similar, sure opening RStudio R.RStudio work must also R installed computer (see installation instructions).RStudio interface (GUI) easier use R. can think R engine vehicle, crucial work, RStudio body vehicle (seats, accessories, etc.) helps actually use engine move forward!default RStudio displays four rectangle panes.TIP: RStudio displays one left pane scripts open yet.R Console PaneThe R Console, default left lower-left pane R Studio, home R “engine”. commands actually run non-graphic outputs error/warning messages appear. can directly enter run commands R Console, realize commands saved running commands script.familiar Stata, R Console like Command Window also Results Window.Source Pane\r\npane, default upper-left, space edit, run, save scripts, write commands want run. pane can also display datasets (data frames) viewing.Stata users, pane similar -file Data Editor windows.Environment Pane\r\npane, default upper-right, often used see brief summaries objects R Environment current session. objects include imported, modified, created datasets, parameters defined (e.g. specific epi week analysis), vectors lists defined analysis (e.g. names regions). Click arrow next data frame name see variables.Stata, similar Variables Manager window.pane also contains History can see commands can previously. also “Tutorial” tab can complete interactive R tutorials learnr package installed. also “Connections” pane external connections, can “Git” pane choose interface Github.Plots, Viewer, Packages, Help Pane\r\nlower-right pane includes several tabs. Typical plot graphics including maps display Plot pane. Interactive HTML outputs display Viewer pane. Help pane can display documentation help files. Files pane browser can used open delete files. Packages pane allows see, install, update, delete, load/unload R packages, see version package . learn packages see packages section .pane contains Stata equivalents Plots Manager Project Manager windows.","code":""},{"path":"r-basics.html","id":"rstudio-settings","chapter":"3 R Basics","heading":"RStudio settings","text":"Change RStudio settings appearance Tools drop-menu, selecting Global Options. can change default settings, including appearance/background color.RestartIf R freezes, can re-start R going Session menu clicking “Restart R”. avoids hassle closing opening RStudio. Everything R environment removed .","code":""},{"path":"r-basics.html","id":"keyboard-shortcuts","chapter":"3 R Basics","heading":"Keyboard shortcuts","text":"CONSTRUCTION","code":""},{"path":"r-basics.html","id":"functions","chapter":"3 R Basics","heading":"3.6 Functions","text":"Functions core using R. Functions perform tasks operations. Many functions come installed R, many available download packages (explained next section), can even write custom functions!basics section functions explains:function workWhat function arguments areHow get help understanding functionA quick note syntax: handbook, functions written code-text open parentheses, like : filter(). explained packages section, functions downloaded within packages. handbook, package names written bold, like dplyr. Sometimes example code may see function name linked explicitly name package two colons (::) like : dplyr::filter(). purpose linkage explained packages section.learn write functions, see page Writing functions.","code":""},{"path":"r-basics.html","id":"simple-functions","chapter":"3 R Basics","heading":"Simple functions","text":"function like machine receives inputs, action inputs, produces output. output depends function.Functions typically operate upon object placed within function’s parentheses. example, function sqrt() calculates square root number:object provided function also can column dataset. Read objects section detail kinds objects. example, function summary() applied numeric column age dataset linelist, output summary columns’s numeric missing values.NOTE: Behind scenes, function represents complex additional code wrapped user one easy command.","code":"\nsqrt(49)## [1] 7\nsummary(linelist$age)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \r\n##     0.0     6.0    13.0    16.1    23.0    84.0      86"},{"path":"r-basics.html","id":"functions-with-multiple-arguments","chapter":"3 R Basics","heading":"Functions with multiple arguments","text":"Functions often ask several inputs, called arguments, located within parentheses function, usually separated commas.arguments required function work correctly, others optionalOptional arguments default settingsArguments can take character, numeric, logical (TRUE/FALSE), inputsHere fun fictional function, called oven_bake(), example typical function. takes input object (e.g. dataset, example “dough”) performs operations specified additional arguments (minutes = temperature =). output can printed console, saved object using assignment operator <-.realistic example, age_pyramid() command produces age pyramid plot based defined age groups binary split column, gender. function given three arguments within parentheses, separated commas. values supplied arguments establish linelist dataframe use, age_cat5 column count, gender binary column use splitting pyramid color.command can equivalently written , newlines. can easier read write # comments. run command can highlight entire command, just place cursor first line press Ctrl Enter keys simultaneously.first half argument assignment (e.g. data =) need specified arguments written specific order (specified function’s documentation). code produces exact pyramid , function expects argument order: data frame, age_group variable, split_by variable.complex age_pyramid() command might include optional arguments :Show proportions instead counts (set proportional = TRUE default FALSE)Specify two colors use (pal = short “palette” supplied vector two color names. See objects page function c() makes vector)NOTE: arguments specify parts argument (e.g. proportional = TRUE), order among arguments matter.","code":"\n# Create an age pyramid\nage_pyramid(data = linelist, age_group = \"age_cat5\", split_by = \"gender\")\n# Create an age pyramid\nage_pyramid(\n  data = linelist,        # case linelist\n  age_group = \"age_cat5\", # age group column\n  split_by = \"gender\"     # two sides to pyramid\n  )\n# This command will produce the exact same graphic as above\nage_pyramid(linelist, \"age_cat5\", \"gender\")\nage_pyramid(\n  linelist,                    # use case linelist\n  \"age_cat5\",                  # age group column\n  \"gender\",                    # split by gender\n  proportional = TRUE,         # percents instead of counts\n  pal = c(\"orange\", \"purple\")  # colors\n  )"},{"path":"r-basics.html","id":"packages","chapter":"3 R Basics","heading":"3.7 Packages","text":"Packages contain functions.R package shareable bundle code documentation contains pre-defined functions. Users R community develop share packages time, chances likely solution exists ! install use hundreds packages use R.installation, R contains “base” packages functions perform common elementary tasks. many R users create specialized functions, verified R community can download package use. handbook, package names written bold. One challenging aspects R often many functions packages choose complete given task.","code":""},{"path":"r-basics.html","id":"install-and-load","chapter":"3 R Basics","heading":"Install and load","text":"Functions contained within packages can downloaded (“installed”) computer internet. package downloaded, can access functions current R session loading package library() command (base R) beginning R session. handbook, advocate use p_load() instead library(), library() still common approach.Think R personal library: download package, library gains new book functions, time want use function book, must borrow book library.libraryYour “library” actually folder computer, containing folder package installed. Find R installed computer, look folder called “win-library”. example: R\\win-library\\4.0 (4.0 R version - ’ll different library R version ’ve downloaded). last-case measure, can remove package manually deleting (better use remove.packages(\"packagename\")).CRANCRAN (Comprehensive R Archive Network) public warehouse R packages published R community members. often, R users download packages CRAN.Install vs. LoadTo use package, 2 steps must implemented:package must installed (), andThe package must loaded (R session)basic function installing package install.packages(), name package provided quotes. can also accomplished point--click going RStudio “Packages” pane clicking “Install” typing package name. Note case-sensitive.basic function load package use (installed) library(), name package quotes.check whether package installed loaded, can view Packages pane RStudio. package installed, shown version number. box checked, loaded current session.Using pacmanThis handbook emphasizes use package pacman (abbreviation “package manager”), offers useful function p_load(). function combines two steps one - installs /loads packages, depending needed. package yet installed, attempt install CRAN, load ., load three packages often used R basics page:Install githubSometimes, need install package yet available CRAN. perhaps package available CRAN want development version new features. often hosted website Github public code “repository”.download packages, can use p_load_gh() pacman. may also see guidance use remotes devtools packages. background, pacman function utilizes install_github() devtools).install github, provide different information function. must provide Github ID repository owner, name code repository contains package.examples , first name listed quotation marks Github ID repository owner, slash name repository. want install branch main/master branch, add branch name “@” repository name.usual, use package (including pacman) must load first, specify package name function two colons pacman::p_load_gh(). syntax loads package order execute function.Read pacman online vignetteInstall ZIP TARYou install package URL:, download computer zipped file:Option 1: using install_local() remotes packageOption 2: using install.packages() base R, providing file path ZIP file setting type = \"source repos = NULL.","code":"\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\npacman::p_load(tidyverse, rio, here)\n# install/load package from github repository\np_load_gh(\"reconhub/epicontacts\")\n\n# load development version of package which you had downloaded from github repository\np_load_gh(\"reconhub/epicontacts\")\n\n# install development version of package, but not the main branch\np_install_gh(\"reconhub/epicontacts@timeline\")\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\nremotes::install_local(\"~/Downloads/dplyr-master.zip\")\ninstall.packages(\"~/Downloads/dplyr-master.zip\", repos=NULL, type=\"source\")"},{"path":"r-basics.html","id":"code-syntax","chapter":"3 R Basics","heading":"Code syntax","text":"clarity handbook, functions sometimes preceded name package using :: symbol following way: package_name::function_name()package loaded session, explicit style necessary. One can just use function_name(). However writing package name useful function name common may exist multiple packages (e.g. plot()). Writing package name also load package already loaded.","code":"\n# This command uses the package \"rio\" and its function \"import()\" to import a dataset\nlinelist <- rio::import(\"linelist.xlsx\", which = \"Sheet1\")"},{"path":"r-basics.html","id":"function-help","chapter":"3 R Basics","heading":"Function help","text":"read function, can search Help tab lower-right RStudio. can also run command like ?thefunctionname (put name function question mark) Help page appear Help pane. Finally, try searching online resources.","code":""},{"path":"r-basics.html","id":"update-packages","chapter":"3 R Basics","heading":"Update packages","text":"can update packages re-installing . can also click green “Update” button RStudio Packages pane see packages new versions install. aware old code may need updated major revision function works!","code":""},{"path":"r-basics.html","id":"delete-packages","chapter":"3 R Basics","heading":"Delete packages","text":"Use p_delete() pacman, remove.packages() base R. Alternatively, go find folder contains library manually delete folder.","code":""},{"path":"r-basics.html","id":"dependencies","chapter":"3 R Basics","heading":"Dependencies","text":"Packages often depend packages work. called dependencies. dependency fails install, package depending may also fail install.See dependencies package p_depends(), see packages depend p_depends_reverse()","code":""},{"path":"r-basics.html","id":"masked-functions","chapter":"3 R Basics","heading":"Masked functions","text":"uncommon two packages contain function name. example, package dplyr filter() function, package stats. default filter() function depends order packages first loaded R session - later one default command filter().can check order Environment pane R Studio - click drop-“Global Environment” see order packages. Functions packages lower drop-list mask functions name packages appear higher drop-list. first loading package, R warn console masking occurring, can easy miss.ways can fix masking:Specify package name command. example, use dplyr::filter()Re-arrange order packages loaded (e.g. within p_load()), start new R session","code":""},{"path":"r-basics.html","id":"detach-unload","chapter":"3 R Basics","heading":"Detach / unload","text":"detach (unload) package, use command, correct package name one colon. Note may resolve masking.","code":"\ndetach(package:PACKAGE_NAME_HERE, unload=TRUE)"},{"path":"r-basics.html","id":"install-older-version","chapter":"3 R Basics","heading":"Install older version","text":"See guide install older version particular package.","code":""},{"path":"r-basics.html","id":"suggested-packages","chapter":"3 R Basics","heading":"Suggested packages","text":"See page Suggested packages listing packages recommend everyday epidemiology.","code":""},{"path":"r-basics.html","id":"scripts","chapter":"3 R Basics","heading":"3.8 Scripts","text":"Scripts fundamental part programming. documents hold commands (e.g. functions create modify datasets, print visualizations, etc). can save script run later. many advantages storing running commands script (vs. typing commands one--one R console “command line”):Portability - can share work others sending scriptsReproducibility - others know exactly didVersion control - can track changes made colleaguesCommenting/annotation - explain colleagues done","code":""},{"path":"r-basics.html","id":"commenting","chapter":"3 R Basics","heading":"Commenting","text":"script can also annotate (“comment”) around R code. Commenting helpful explain readers . can add comment typing hash symbol (#) writing comment . commented text appear different color R code. code written # run. Therefore, placing # code useful way temporarily run line code (perhaps want run line, also want delete ).","code":""},{"path":"r-basics.html","id":"example","chapter":"3 R Basics","heading":"Example","text":"example short R script. Remember, better succinctly explain code comments, colleagues like !","code":""},{"path":"r-basics.html","id":"r-markdown","chapter":"3 R Basics","heading":"R markdown","text":"R markdown script type R script script becomes output document (PDF, Word, HTML, Powerpoint, etc.). incredibly useful versatile tools often used create dynamic automated reports. Even website handbook produced R markdown scripts!learn , see handbook page R Markdown documents.","code":""},{"path":"r-basics.html","id":"r-notebooks","chapter":"3 R Basics","heading":"R notebooks","text":"difference writing Rmarkdown vs R notebook. However execution document differs slightly. See site details.","code":""},{"path":"r-basics.html","id":"shiny","chapter":"3 R Basics","heading":"Shiny","text":"Shiny apps/websites contained within one script, must named app.R. file three components:user interface (ui)server functionA call shinyApp functionSee handbook page Shiny dashboards, online tutorial: Shiny tutorialIn older times, file split two files (ui.R server.R)","code":""},{"path":"r-basics.html","id":"working-directory","chapter":"3 R Basics","heading":"3.9 Working directory","text":"working directory root folder location used R work - R looks saves files default. default, save new files outputs location, look files import (e.g. datasets) well.working directory appears grey text top RStudio Console pane. can also return current working directory getwd() (leave parentheses empty).See page R projects details recommended approach managing working directory. common, efficient, trouble-free way use R combine 3 elements: R project store files, package locate files, rio package import/export files.","code":""},{"path":"r-basics.html","id":"set-by-command","chapter":"3 R Basics","heading":"Set by command","text":"Although recommend approach circumstances, can use command setwd() desired folder file path quotations, example:","code":"\nsetwd(\"C:/Documents/R Files/My analysis\")"},{"path":"r-basics.html","id":"set-manually","chapter":"3 R Basics","heading":"Set manually","text":"set working directory manually (point--click), click Session drop-menu go “Set Working Directory” “Choose Directory”. set working directory specific R session (using approach, time open RStudio).","code":""},{"path":"r-basics.html","id":"within-an-r-project","chapter":"3 R Basics","heading":"Within an R project","text":"using R project, working directory default R project root folder contains “.rproj” file. apply open RStudio clicking open R project (file “.rproj” extension))","code":""},{"path":"r-basics.html","id":"working-directory-in-an-r-markdown","chapter":"3 R Basics","heading":"Working directory in an R markdown","text":"R markdown script, default working directory folder Rmarkdown file (.Rmd) saved within. using R project package, apply working directory () explained R projects page.want change working directory stand-alone R markdown (R project), use setwd() apply specific code chunk. make change code chunks R markdown, edit setup chunk add root.dir = parameter, :much easier just use R markdown within R project use package.","code":"\nknitr::opts_knit$set(root.dir = 'desired/directorypath')"},{"path":"r-basics.html","id":"providing-file-paths","chapter":"3 R Basics","heading":"Providing file paths","text":"Perhaps common source frustration R beginner (least Windows machine) typing filepath import data. Note following:Slash direction - typing filepath, beware direction slashes. Enter using forward slashes separate components (“data/provincial.csv”). Windows users, default way filepaths displayed copied backslashes (“\\”) - means need change direction slash.use package described R projects slash direction issue.Broken paths -example “absolute” “full address” filepath. likely break used another computer.situations, recommend using “relative” filepaths instead - , path relative root R project. can using package explained R projects page.One possible exception need load data folder locations outside R project. case can still use R project relative file paths scripts outputs, may need use absolute file path import data.","code":"C:/Users/Name/Document/Analytic Software/R/Projects/Analysis2019/data/March2019.csv  "},{"path":"r-basics.html","id":"objects","chapter":"3 R Basics","heading":"3.10 Objects","text":"Everything R object, R “object-oriented” language. sections explain:create objects (<-)Types objects (e.g. data frames, vectors..)access subparts objects (e.g. variables dataset)Classes objects (e.g. numeric, logical, integer, double, character, factor)","code":""},{"path":"r-basics.html","id":"everything-is-an-object","chapter":"3 R Basics","heading":"Everything is an object","text":"section adapted R4Epis project.\r\nEverything store R - datasets, variables, list village names, total population number, even outputs graphs - objects assigned name can referenced later commands.object exists assigned value (see assignment section ). assigned value, object appears Environment (see upper right pane RStudio). can operated upon, manipulated, changed, re-defined.","code":""},{"path":"r-basics.html","id":"defining-objects--","chapter":"3 R Basics","heading":"Defining objects (<-)","text":"Create objects assigning value <- operator.\r\ncan think assignment operator <- words “defined ”. Assignment commands generally follow standard order:object_name <- value (process/calculation produce value)example, may want record current epidemiological reporting week object reference later code. example, object current_week created assigned character value \"2018-W10\" (quote marks make character value). object current_week appear RStudio Environment pane (upper-right) can referenced later commands.See R commands output boxes .NOTE: Note [1] R console output simply indicating viewing first item outputCAUTION: object’s value can -written time running assignment command re-define value. Thus, order commands run important.following command re-define value current_week:Equals signs =also see equals signs R code:double equals sign == two objects values asks logical question: “equal ?”.also see equals signs within functions used specify values function arguments (read sections ), example max(age, na.rm = TRUE).can use single equals sign = place <- create define objects, discouraged. can discouraged .DatasetsDatasets also objects (typically “dataframes”) must assigned names imported. code , object linelist created assigned value CSV file imported rio package import() function.can read importing exporting datasets section Import export.CAUTION: quick note naming objects:Object names must contain spaces, use underscore (_) period (.) instead space.Object names case-sensitive (meaning Dataset_A different dataset_A).Object names must begin letter (begin number like 1, 2 3).OutputsOutputs like tables plots provide example outputs can saved objects, just printed without saved. cross-tabulation gender outcome using base R function table() can printed directly R console (without saved).table can saved named object. , optionally, can printed.ColumnsColumns dataset also objects can defined, -written, created described section Columns.can use assignment operator base R create new column. , new column bmi (Body Mass Index) created, row new value result mathematical operation row’s value wt_kg ht_cm columns.However, handbook, emphasize different approach defining columns, uses function mutate() dplyr package piping pipe operator (%>%). syntax easier read advantages explained page Cleaning data core functions. can read piping Piping section .","code":"\ncurrent_week <- \"2018-W10\"   # this command creates the object current_week by assigning it a value\ncurrent_week                 # this command prints the current value of current_week object in the console## [1] \"2018-W10\"\ncurrent_week <- \"2018-W51\"   # assigns a NEW value to the object current_week\ncurrent_week                 # prints the current value of current_week in the console## [1] \"2018-W51\"\n# linelist is created and assigned the value of the imported CSV file\nlinelist <- import(\"my_linelist.csv\")\n# printed to R console only\ntable(linelist$gender, linelist$outcome)##    \r\n##     Death Recover\r\n##   f  1227     953\r\n##   m  1228     950\n# save\ngen_out_table <- table(linelist$gender, linelist$outcome)\n\n# print\ngen_out_table##    \r\n##     Death Recover\r\n##   f  1227     953\r\n##   m  1228     950\n# create new \"bmi\" column using base R syntax\nlinelist$bmi <- linelist$wt_kg / (linelist$ht_cm/100)^2\n# create new \"bmi\" column using dplyr syntax\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)"},{"path":"r-basics.html","id":"object-structure","chapter":"3 R Basics","heading":"Object structure","text":"Objects can single piece data (e.g. my_number <- 24), can consist structured data.graphic borrowed online R tutorial. shows common data structures names. included image spatial data, discussed GIS basics page.epidemiology (particularly field epidemiology), commonly encounter data frames vectors:Note create vector “stands alone” (part data frame) function c() used combine different elements. example, creating vector colors plot’s color scale:\r\nlist_of_names <- c(\"blue\", \"red2\", \"orange\", \"grey\")","code":""},{"path":"r-basics.html","id":"object-classes","chapter":"3 R Basics","heading":"Object classes","text":"objects stored R class tells R handle object. many possible classes, common ones include:can test class object providing name function class(). Note: can reference specific column within dataset using $ notation separate name dataset name column.Sometimes, column converted different class automatically R. Watch ! example, vector column numbers, character value inserted… entire column change class character.One common example manipulating data frame order print table - make total row try paste/glue together percents cell numbers (e.g. 23 (40%)), entire numeric column convert character can longer used mathematical calculations.Sometimes, need convert objects columns another class.Likewise, base R functions check whether object specific class, .numeric(), .character(), .double(), .factor(), .integer()online material classes data structures R.","code":"\nclass(linelist)         # class should be a data frame## [1] \"data.frame\"\nclass(linelist$age)     # class should be numeric## [1] \"numeric\"\nclass(linelist$gender)  # class should be character## [1] \"character\"\nnum_vector <- c(1,2,3,4,5) # define vector as all numbers\nclass(num_vector)          # vector is numeric class## [1] \"numeric\"\nnum_vector[3] <- \"three\"   # convert the third element to a character\nclass(num_vector)          # vector is now character class## [1] \"character\""},{"path":"r-basics.html","id":"columnsvariables","chapter":"3 R Basics","heading":"Columns/Variables ($)","text":"column data frame technically “vector” (see table ) - series values must class (either character, numeric, logical, etc).vector can exist independent data frame, example vector column names want include explanatory variables model. create “stand alone” vector, use c() function :Columns data frame also vectors can called, referenced, extracted, created using $ symbol. $ symbol connects name column name data frame. handbook, try use word “column” instead “variable”.typing name dataframe followed $ also see drop-menu columns data frame. can scroll using arrow key, select one Enter key, avoid spelling mistakes!ADVANCED TIP: complex objects (e.g. list, epicontacts object) may multiple levels can accessed multiple dollar signs. example epicontacts$linelist$date_onset","code":"\n# define the stand-alone vector of character values\nexplanatory_vars <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n# print the values in this named vector\nexplanatory_vars## [1] \"gender\" \"fever\"  \"chills\" \"cough\"  \"aches\"  \"vomit\"\n# Retrieve the length of the vector age_years\nlength(linelist$age) # (age is a column in the linelist data frame)"},{"path":"r-basics.html","id":"accessindex-with-brackets","chapter":"3 R Basics","heading":"Access/index with brackets ([ ])","text":"may need view parts objects, also called “indexing”, often done using square brackets [ ]. Using $ dataframe access column also type indexing.Square brackets also work return specific parts returned output, output summary() function:Brackets also work data frames view specific rows columns. can using syntax dataframe[rows, columns]:indexing object class list, single brackets always return class list, even single object returned. Double brackets, however, can used access single element return different class list.\r\nBrackets can also written one another, demonstrated .visual explanation lists indexing, pepper shakers humorous helpful.list looks printed console. See two named elements:hospitals, character vectoraddresses, data frame addressesNow extract, using various methods:","code":"\nmy_vector <- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")  # define the vector\nmy_vector[5]                                  # print the 5th element## [1] \"e\"\n# All of the summary\nsummary(linelist$age)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \r\n##     0.0     6.0    13.0    16.1    23.0    84.0      86\n# Just one part of the summary\nsummary(linelist$age)[2]## 1st Qu. \r\n##       6\n# One part without its \"name\"\nsummary(linelist$age)[[2]]## [1] 6\n# View a specific row (2) from dataset, with all columns (don't forget the comma!)\nlinelist[2,]\n\n# View all rows, but just one column\nlinelist[, \"date_onset\"]\n\n# View values from row 2 and columns 5 through 10\nlinelist[2, 5:10] \n\n# View values from row 2 and columns 5 through 10 and 18\nlinelist[2, c(5:10, 18)] \n\n# View rows 2 through 20, and specific columns\nlinelist[2:20, c(\"date_onset\", \"outcome\", \"age\")]\n\n# View rows and columns based on criteria\n# *** Note the dataframe must still be named in the criteria!\nlinelist[linelist$age > 25 , c(\"date_onset\", \"outcome\", \"age\")]\n\n# Use View() to see the outputs in the RStudio Viewer pane (easier to read) \n# *** Note the capital \"V\" in View() function\nView(linelist[2:20, \"date_onset\"])\n\n# Save as a new object\nnew_table <- linelist[2:20, c(\"date_onset\")] \n# define demo list\nmy_list <- list(\n  # First element in the list is a character vector\n  hospitals = c(\"Central\", \"Empire\", \"Santa Anna\"),\n  \n  # second element in the list is a data frame of addresses\n  addresses   = data.frame(\n    street = c(\"145 Medical Way\", \"1048 Brown Ave\", \"999 El Camino\"),\n    city   = c(\"Andover\", \"Hamilton\", \"El Paso\")\n    )\n  )\nmy_list## $hospitals\r\n## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\r\n## \r\n## $addresses\r\n##            street     city\r\n## 1 145 Medical Way  Andover\r\n## 2  1048 Brown Ave Hamilton\r\n## 3   999 El Camino  El Paso\nmy_list[1] # this returns the element in class \"list\" - the element name is still displayed## $hospitals\r\n## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[1]] # this returns only the (unnamed) character vector## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[\"hospitals\"]] # you can also index by name of the list element## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\nmy_list[[1]][3] # this returns the third element of the \"hospitals\" character vector## [1] \"Santa Anna\"\nmy_list[[2]][1] # This returns the first column (\"street\") of the address data frame##            street\r\n## 1 145 Medical Way\r\n## 2  1048 Brown Ave\r\n## 3   999 El Camino"},{"path":"r-basics.html","id":"remove-objects","chapter":"3 R Basics","heading":"Remove objects","text":"can remove individual objects R environment putting name rm() function (quote marks):can remove objects (clear workspace) running:","code":"\nrm(object_name)\nrm(list = ls(all = TRUE))"},{"path":"r-basics.html","id":"piping","chapter":"3 R Basics","heading":"3.11 Piping (%>%)","text":"Two general approaches working objects :Pipes/tidyverse - pipes send object function function - emphasis action, objectDefine intermediate objects - object re-defined - emphasis object","code":""},{"path":"r-basics.html","id":"pipes","chapter":"3 R Basics","heading":"Pipes","text":"Simply explained, pipe operator (%>%) passes intermediate output one function next.\r\ncan think saying “”. Many functions can linked together %>%.Piping emphasizes sequence actions, object actions performed onPipes best sequence actions must performed one objectPipes come package magrittr, automatically included packages dplyr tidyversePipes can make code clean easier read, intuitiveRead approach tidyverse style guideHere fake example comparison, using fictional functions “bake cake”. First, pipe method:another link describing utility pipes.Piping base function. use piping, magrittr package must installed loaded (typically done loading tidyverse dplyr package). can read piping magrittr documentation.Note just like R commands, pipes can used just display result, save/re-save object, depending whether assignment operator <- involved. See :CAUTION: Remember even using piping link functions, assignment operator (<-) present, object left still -written (re-defined) right side.%<>%\r\n“assignment pipe” magritter package, pipes object forward also re-defines object. must first pipe operator chain. shorthand, object %<>% function() %>% function() object <- object %>% function() %>% function().","code":"\n# A fake example of how to bake a care using piping syntax\n\ncake <- flour %>%       # to define cake, start with flour, and then...\n  left_join(eggs) %>%   # add eggs\n  left_join(oil) %>%    # add oil\n  left_join(water) %>%  # add water\n  mix_together(         # mix together\n    utensil = spoon,\n    minutes = 2) %>%    \n  bake(degrees = 350,   # bake\n       system = \"fahrenheit\",\n       minutes = 35) %>%  \n  let_cool()            # let it cool down\n# Create or overwrite object, defining as aggregate counts by age category (not printed)\nlinelist_summary <- linelist %>% \n  count(age_cat)\n# Print the table of counts in the console, but don't save it\nlinelist %>% \n  count(age_cat)"},{"path":"r-basics.html","id":"define-intermediate-objects","chapter":"3 R Basics","heading":"Define intermediate objects","text":"approach changing objects/dataframes may better :need manipulate multiple objectsThere intermediate steps meaningful deserve separate object namesRisks:Creating new objects step means creating lots objects. use wrong one might realize !Naming objects can confusingErrors may easily detectableEither name intermediate object, overwrite original, combine functions together. come risks.fake “cake” example , using style:Combine functions together - difficult read:","code":"\n# a fake example of how to bake a cake using this method (defining intermediate objects)\nbatter_1 <- left_join(flour, eggs)\nbatter_2 <- left_join(batter_1, oil)\nbatter_3 <- left_join(batter_2, water)\n\nbatter_4 <- mix_together(object = batter_3, utensil = spoon, minutes = 2)\n\ncake <- bake(batter_4, degrees = 350, system = \"fahrenheit\", minutes = 35)\n\ncake <- let_cool(cake)\n# an example of combining/nesting mutliple functions together - difficult to read\ncake <- let_cool(bake(mix_together(batter_3, utensil = spoon, minutes = 2), degrees = 350, system = \"fahrenheit\", minutes = 35))"},{"path":"r-basics.html","id":"operators","chapter":"3 R Basics","heading":"3.12 Key operators and functions","text":"section details operators R, :Definitional operatorsRelational operators (less , equal ..)Logical operators (, …)Handling missing valuesMathematical operators functions (+/-, >, sum(), median(), …)%% operator","code":""},{"path":"r-basics.html","id":"assignment-operators","chapter":"3 R Basics","heading":"Assignment operators","text":"<-basic assignment operator R <-. object_name <- value.\r\nassignment operator can also written =. advise use <- general R use.\r\nalso advise surrounding operators spaces, readability.<<-Writing functions, using R interactive way sourced scripts, may need use assignment operator <<- (base R). operator used define object higher ‘parent’ R Environment. See online reference.%<>%“assignment pipe” magrittr package, pipes object forward also re-defines object. must first pipe operator chain. shorthand, shown two equivalent examples:equivalent :%<+%used add data phylogenetic trees ggtree package. See page Phylogenetic trees online resource book.","code":"\nlinelist <- linelist %>% \n  mutate(age_months = age_years * 12)\nlinelist %<>% mutate(age_months = age_years * 12)"},{"path":"r-basics.html","id":"relational-and-logical-operators","chapter":"3 R Basics","heading":"Relational and logical operators","text":"Relational operators compare values often used defining new variables subsets datasets. common relational operators R:Logical operators, , often used connect relational operators create complicated criteria. Complex statements might require parentheses ( ) grouping order application.example, , linelist two variables want use create case definition, hep_e_rdt, test result other_cases_in_hh, tell us cases household. command uses function case_when() create new variable case_def :Note R case-sensitive, “Positive” different “positive”…","code":"\nlinelist_cleaned <- linelist %>%\n  mutate(case_def = case_when(\n    is.na(rdt_result) & is.na(other_case_in_home)            ~ NA_character_,\n    rdt_result == \"Positive\"                                 ~ \"Confirmed\",\n    rdt_result != \"Positive\" & other_cases_in_home == \"Yes\"  ~ \"Probable\",\n    TRUE                                                     ~ \"Suspected\"\n  ))"},{"path":"r-basics.html","id":"missing-values","chapter":"3 R Basics","heading":"Missing values","text":"R, missing values represented special value NA (“reserved” value) (capital letters N - quotation marks). import data records missing data another way (e.g. 99, “Missing”, .), may want re-code values NA. addressed Import export page.test whether value NA, use special function .na(), returns TRUE FALSE.Read missing, infinite, NULL, impossible values page Missing data. Learn convert missing values importing data page Import export.","code":"\nrdt_result <- c(\"Positive\", \"Suspected\", \"Positive\", NA)   # two positive cases, one suspected, and one unknown\nis.na(rdt_result)  # Tests whether the value of rdt_result is NA## [1] FALSE FALSE FALSE  TRUE"},{"path":"r-basics.html","id":"mathematics-and-statistics","chapter":"3 R Basics","heading":"Mathematics and statistics","text":"operators functions page automatically available using base R.","code":""},{"path":"r-basics.html","id":"mathematical-operators","chapter":"3 R Basics","heading":"Mathematical operators","text":"often used perform addition, division, create new columns, etc. common mathematical operators R. Whether put spaces around operators important.","code":""},{"path":"r-basics.html","id":"mathematical-functions","chapter":"3 R Basics","heading":"Mathematical functions","text":"","code":""},{"path":"r-basics.html","id":"scientific-notation","chapter":"3 R Basics","heading":"Scientific notation","text":"turn scientific notation R session, run command:","code":"\noptions(scipen=999)"},{"path":"r-basics.html","id":"rounding","chapter":"3 R Basics","heading":"Rounding","text":"DANGER: round() uses “banker’s rounding” rounds .5 upper number even. Use round_half_up() janitor consistently round halves nearest whole number. See explanation ","code":"\n# use the appropriate rounding function for your work\nround(c(2.5, 3.5))## [1] 2 4\njanitor::round_half_up(c(2.5, 3.5))## [1] 3 4"},{"path":"r-basics.html","id":"statistical-functions","chapter":"3 R Basics","heading":"3.12.0.1 Statistical functions:","text":"CAUTION: functions default include missing values calculations. Missing values result output NA, unless argument na.rm=TRUE specifiedNotes:quantile(): x numeric vector examine, probs = numeric vector probabilities within 0 1.0, e.g c(0.5, 0.8, 0.85)summary(): gives summary numeric vector including mean, median, common percentilesDANGER: providing vector numbers one functions, sure wrap numbers within c() .","code":"\n# If supplying raw numbers to a function, wrap them in c()\nmean(1, 6, 12, 10, 5, 0)    # !!! INCORRECT !!!  ## [1] 1\nmean(c(1, 6, 12, 10, 5, 0)) # CORRECT## [1] 5.67"},{"path":"r-basics.html","id":"other-useful-functions","chapter":"3 R Basics","heading":"3.12.0.2 Other useful functions:","text":"","code":""},{"path":"r-basics.html","id":"in","chapter":"3 R Basics","heading":"%in%","text":"useful operator matching values, quickly assessing value within vector dataframe.ask value %% vector, put exclamation mark (!) front logic statement:%% useful using dplyr function case_when(). can define vector previously, reference later. example:Note: want detect partial string, perhaps using str_detect() stringr, accept character vector like c(\"1\", \"Yes\", \"yes\", \"y\"). Instead, must given regular expression - one condensed string bars, “1|Yes|yes|y”. example, str_detect(hospitalized, \"1|Yes|yes|y\"). See page Characters strings information.can convert character vector named regular expression command:","code":"\nmy_vector <- c(\"a\", \"b\", \"c\", \"d\")\n\"a\" %in% my_vector## [1] TRUE\n\"h\" %in% my_vector## [1] FALSE\n# to negate, put an exclamation in front\n!\"a\" %in% my_vector## [1] FALSE\n!\"h\" %in% my_vector## [1] TRUE\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist <- linelist %>% \n  mutate(child_hospitaled = case_when(\n    hospitalized %in% affirmative & age < 18 ~ \"Hospitalized Child\",\n    TRUE                                      ~ \"Not\"))\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative## [1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\"\n# condense to \naffirmative_str_search <- paste0(affirmative, collapse = \"|\")  # option with base R\naffirmative_str_search <- str_c(affirmative, collapse = \"|\")   # option with stringr package\n\naffirmative_str_search## [1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\""},{"path":"r-basics.html","id":"errors-warnings","chapter":"3 R Basics","heading":"3.13 Errors & warnings","text":"section explains:difference errors warningsGeneral syntax tips writing R codeCode assistsCommon errors warnings troubleshooting tips can found page [Errors warnings].","code":""},{"path":"r-basics.html","id":"error-versus-warning","chapter":"3 R Basics","heading":"Error versus Warning","text":"command run, R Console may show warning error messages red text.warning means R completed command, take additional steps produced unusual output aware .warning means R completed command, take additional steps produced unusual output aware .error means R able complete command.error means R able complete command.Look clues:error/warning message often include line number problem.error/warning message often include line number problem.object “unknown” “found”, perhaps spelled incorrectly, forgot call package library(), forgot re-run script making changes.object “unknown” “found”, perhaps spelled incorrectly, forgot call package library(), forgot re-run script making changes.else fails, copy error message Google along key terms - chances someone else worked already!","code":""},{"path":"r-basics.html","id":"general-syntax-tips","chapter":"3 R Basics","heading":"General syntax tips","text":"things remember writing commands R, avoid errors warnings:Always close parentheses - tip: count number opening “(” closing parentheses “)” code chunkAvoid spaces column object names. Use underscore ( _ ) periods ( . ) insteadKeep track remember separate function’s arguments commasR case-sensitive, meaning Variable_A different variable_A","code":""},{"path":"r-basics.html","id":"code-assists","chapter":"3 R Basics","heading":"Code assists","text":"script (RMarkdown otherwise) give clues made mistake. example, forgot write comma needed, close parentheses, RStudio raise flag line, right side script, warn .","code":""},{"path":"transition-to-r.html","id":"transition-to-r","chapter":"4 Transition to R","heading":"4 Transition to R","text":", provide advice resources transitioning R.","code":""},{"path":"transition-to-r.html","id":"from-excel","chapter":"4 Transition to R","heading":"4.1 From Excel","text":"Transitioning Excel directly R can seem daunting, achievable goal.find using R (another coding language) offers immense benefits time saved, consistent accurate analysis, reproducibility, shareability, faster error-correction. Like new software learning “curve” time must invest become familiar. dividends significant immense scope new possibilities open R.Excel well-known software can easy beginner use produce simple analysis visualizations “point--click”. comparison, can take couple weeks become comfortable R functions interface. However, R evolved recent years become much friendly beginners.Many Excel workflows rely memory repetition - thus, much opportunity error. Furthermore, general Excel use data cleaning, analysis methodology, equations used hidden view. can require substantial time new colleague learn Excel workbook troubleshoot . R, steps explicitly written script can easily viewed, edited, corrected, applied datasets.begin transition Excel R must adjust mindset important ways:","code":""},{"path":"transition-to-r.html","id":"scripts-1","chapter":"4 Transition to R","heading":"Scripts","text":"Instead clicking buttons dragging cells writing every step procedure “script”. script step--step instructions. allows colleague read script easily see steps took. also helps de-bug errors inaccurate calculations. See R Basics section scripts examples.example R script:","code":""},{"path":"transition-to-r.html","id":"tidy-data","chapter":"4 Transition to R","heading":"Tidy data","text":"Use machine-readable “tidy” data instead messy “human-readable” data. three main requirements “tidy” data, explained tutorial “tidy” data R:variable must columnEach observation must rowEach value must cellAn example “tidy” data case linelist used throughout handbook - variable contained within one column, observation (one case) ’s row, every value just one cell. can view first 50 rows linelist:main reason one encounters non-tidy data many Excel spreadsheets designed prioritize easy reading humans, easy reading machines/software.help see difference, fictional examples non-tidy data prioritize human-readability machine-readability:Problems: spreadsheet , merged cells easily digested R. row considered “header” clear. color-based dictionary right side cell values represented colors - also easily interpreted R. Furthermore, different piece information combined one cell (multiple partner organizations working one area, status “TBC” cell “Partner D”).Problems: spreadsheet , numerous extra empty rows columns within dataset - cause cleaning headaches R. Furthermore, GPS coordinates spread across two rows given treatment center. side note - GPS coordinates two different formats!“Tidy” datasets may readable human eye, make data cleaning analysis much easier! Tidy data can stored various formats, example “long” “wide”\"(see page Pivoting data), principles still observed.","code":""},{"path":"transition-to-r.html","id":"excel-to-r-resources","chapter":"4 Transition to R","heading":"Excel-to-R resources","text":"links tutorials help transition R Excel:R vs. ExcelRStudio course R Excel users","code":""},{"path":"transition-to-r.html","id":"from-stata","chapter":"4 Transition to R","heading":"4.2 From Stata","text":"Coming R StataMany epidemiologists first taught use Stata, can seem daunting move R. However, comfortable Stata user jump R certainly manageable might think. key differences Stata R data can created modified, well analysis functions implemented – learning key differences able translate skills.key translations Stata R, may handy review guide.General notesWorking directoryImporting viewing dataBasic data manipulationDescriptive analysisWhile list gives overview basics translating Stata commands R, exhaustive. many great resources Stata users transitioning R interest:https://dss.princeton.edu/training/RStata.pdfhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.htmlhttp://r4stats.com/books/r4stata/","code":""},{"path":"transition-to-r.html","id":"from-sas","chapter":"4 Transition to R","heading":"4.3 From SAS","text":"Coming SAS RSAS commonly used public health agencies academic research fields. Although transitioning new language rarely simple process, understanding key differences SAS R may help start navigate new language using native language.\r\noutlines key translations data management descriptive analysis SAS R.General notesWorking directoryImporting viewing dataReading xslx files done using Proc Import datafile=”filename.xlsx” =work.filename dbms=xlsx; run;\r\nusing Data Step Infile statement|Use import(“filename.xlsx”)\r\nBrowse data new window opening Explorer window select desired library dataset|View dataset RStudio source pane using View(dataset). need specify dataset name function R multiple datasets can held time. Note capital “V” functionBasic data manipulationDescriptive analysisSome useful resources:R SAS SPSS Users (2011)SAS R, Second Edition (2014)","code":""},{"path":"transition-to-r.html","id":"data-interoperability","chapter":"4 Transition to R","heading":"4.4 Data interoperability","text":"See Import export page details R package rio can import export files STATA .dta files, SAS .xpt .sas7bdat files, SPSS .por .sav files, many others.","code":""},{"path":"import-and-export.html","id":"import-and-export","chapter":"5 Import and export","heading":"5 Import and export","text":"page describe ways locate, import, export files:Using rio package import() export() dataThe package locate files computer R projectSpecific import scenarios, \r\nExcel sheets\r\nGoogle sheets\r\nWebsites\r\nSkipping rows\r\nExcel sheetsGoogle sheetsWebsitesSkipping rowsExporting/saving data files","code":""},{"path":"import-and-export.html","id":"overview-1","chapter":"5 Import and export","heading":"5.1 Overview","text":"import “dataset” R, generally creating new data frame object R environment defining imported flat file (Excel, CSV, etc.). learn objects assignment operator, see page R Basics.","code":""},{"path":"import-and-export.html","id":"the-rio-package","chapter":"5 Import and export","heading":"5.2 The rio package","text":"R package recommend : rio. import() function rio utilizes file extension (e.g. .xlsx, .csv, .rds, .tsv) correctly import export file. name “rio” abbreviation “R /O” (input/output).alternative using rio use functions many packages, specific type file. example, read.csv() (base R), read.xlsx() (openxlsx package), write_csv() (readr pacakge), etc. alternatives can difficult remember, whereas using import() export() rio easy.rio’s functions import() export() use appropriate package function given file, based file extension. See end page complete table packages/functions rio uses background. can also used import STATA, SAS, SPSS files, among dozens others.Import/export shapefiles requires packages, detailed page GIS basics.","code":""},{"path":"import-and-export.html","id":"file-paths","chapter":"5 Import and export","heading":"5.3 File paths","text":"importing exporting data, must provide file path. can one three ways:Provide “full” / “absolute” file pathProvide “relative” file path - location relative R project root directoryManual file selection","code":""},{"path":"import-and-export.html","id":"absolute-file-paths","chapter":"5 Import and export","heading":"“Absolute” file paths","text":"example absolute file path, placed within quotes provided import(), saved R data frame object named linelist.\r\nfilepath , “epiproject” home/root folder analysis. sub-folder “data” within subfolder “linelists”, xlsx file.things note absolute file paths:Avoid using absolute file paths usually break script run different computerThey can used must load data shared drive folder distant R script savedUse forward slashes (/) example (default Windows file paths)File paths begin double slashes (e.g. “//…”) likely recognized R produce error. Consider moving “named” “lettered” drive begins letter (e.g. “J:” “C:”). See page Directory interactions details issue.TIP: quickly convert \\ /, highlight code interest, use Ctrl+f (Windows), check option box “selection”, use replace functionality convert .","code":"\nlinelist <- import(\"C:/Users/Pierre/My Documents/epiproject/data/linelists/ebola_linelist.xlsx\")"},{"path":"import-and-export.html","id":"relative-file-paths","chapter":"5 Import and export","heading":"“Relative” file paths","text":"“Relative” file paths consist file path relative particular root folder. allow simple file paths can work different computers (e.g. root folder shared drive sent email)., assume folder “epiproject” root folder R project using package . file path written relative R project root folder “epiproject”. syntax explained .package function () locate files computer relation root directory R project, provide shortcut syntax providing file path function like import(). () works:Ensure working within R project (read R projects page)package first loaded within R project, places small file called “” root-level folder R project “benchmark” “anchor” files project.script, want reference file saved project’s folders, use function () tell R file located relation anchor.() can used importing exporting.unsure “” root set , run function () empty parentheses:can build onto anchor specifying folders, within quotes, separated commas, finally ending filename extension. approach also removes slash direction source error.Running () command folder names file name returns extended file path, can processed import() function.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\n# load the package\npacman::p_load(here)\n\n# return the folder path that \"here\" is set to \nhere()## [1] \"C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook\"\n# the filepath\nhere(\"data\", \"linelist.xlsx\")## [1] \"C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook/data/linelist.xlsx\""},{"path":"import-and-export.html","id":"select-file-manually","chapter":"5 Import and export","heading":"Select file manually","text":"can import data manually via one methods:Environment RStudio Pane, click “Import Dataset”, select type dataClick File / Import Dataset / (select type data)hard-code manual selection, use base R command file.choose() (leaving parentheses empty) trigger appearance pop-window allows user manually select file computer. example:TIP: pop-window may appear BEHIND RStudio window.","code":"\n# Manual selection of a file. When this command is run, a POP-UP window will appear. \n# The file path selected will be supplied to the import() command.\n\nmy_data <- import(file.choose())"},{"path":"import-and-export.html","id":"excel-sheets","chapter":"5 Import and export","heading":"5.4 Excel sheets","text":"want import specific sheet Excel workbook, include sheet name = argument. example:using () method provide relative pathway import(), can still indicate specific sheet adding = argument closing parentheses () function.export dataframe R specific Excel sheet rest Excel workbook remain unchanged, import, edit, export alternative package catered purpose openxlsx. See information page Directory interactions github page.Excel workbook .xlsb (binary format Excel workbook) may able import using rio. Consider re-saving .xlsx, using package like readxlsb built purpose.","code":"\nmy_data <- import(\"my_excel_file.xlsx\", which = \"Sheetname\")# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package\r\nlinelist_raw <- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  "},{"path":"import-and-export.html","id":"missing-values-1","chapter":"5 Import and export","heading":"5.5 Missing values","text":"may want designate value(s) dataset considered missing. explained page Missing data, value R missing data NA, perhaps dataset want import uses 99, “Missing”, just empty character space \"\" instead.Use na = argument import() provide value(s) within quotes (even numbers). can specify multiple values including within vector, using c() shown ., value “99” imported dataset considered missing converted NA R., values “Missing”, \"\" (empty cell), \" \" (single space) imported dataset converted NA R.","code":"\nlinelist <- import(here(\"data\", \"linelist_raw.xlsx\"), na =\"99\")\nlinelist <- import(here(\"data\", \"cleaning_dict.csv\"), na = c(\"Missing\", \"\", \" \"))"},{"path":"import-and-export.html","id":"google-sheets","chapter":"5 Import and export","heading":"5.6 Google sheets","text":"can import data online Google spreadsheet googlesheet4 package authenticating access spreadsheet., demo Google sheet imported saved. command may prompt confirmation authentification Google account. Follow prompts pop-ups internet browser grant Tidyverse API packages permissions edit, create, delete spreadsheets Google Drive.sheet “viewable anyone link” can try import .sheet can also imported using sheet ID, shorter part URL:Another package, googledrive offers useful functions writing, editing, deleting Google sheets. example, using gs4_create() sheet_write() functions found package.helpful online tutorials: basic importing tutorial detail interaction two packages","code":"\npacman::p_load(\"googlesheets4\")\nGsheets_demo <- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\nGsheets_demo <- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")"},{"path":"import-and-export.html","id":"scraping-websites","chapter":"5 Import and export","heading":"5.7 Scraping websites","text":"Scraping data website - TBD - construction","code":""},{"path":"import-and-export.html","id":"skip-rows","chapter":"5 Import and export","heading":"5.8 Skip rows","text":"Sometimes, may want avoid importing row data. can argument skip = using import() rio .xlsx .csv file. Provide number rows want skip.Unfortunately skip = accepts one integer value, range (e.g. “2:10” work). skip import specific rows consecutive top, consider importing multiple times using bind_rows() dplyr. See example skipping row 2.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 1)  # does not import header row"},{"path":"import-and-export.html","id":"remove-second-header-row","chapter":"5 Import and export","heading":"Remove second header row","text":"Sometimes, data may second row want remove, example “data dictionary” row shown . situation can problematic can result columns imported class “character”.example kind dataset (first row data dictionary).solve , likely need import data twice.Import data order store correct column namesImport data , skipping first two rows (header second rows)Bind correct names onto reduced dataframeThe exact argument used bind correct column names depends type data file (.csv, .tsv, .xlsx, etc.). rio using different function different file types (see table ).Excel files: (col_names =)CSV files: (col.names =)Backup option - changing column names separate command","code":"\n# import first time; store the column names\nlinelist_raw_names <- import(\"linelist_raw.xlsx\") %>% names()  # save true column names\n\n# import second time; skip row 2, and assign column names to argument col_names =\nlinelist_raw <- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n# import first time; sotre column names\nlinelist_raw_names <- import(\"linelist_raw.csv\") %>% names() # save true column names\n\n# note argument for csv files is 'col.names = '\nlinelist_raw <- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n# assign/overwrite headers using the base 'colnames()' function\ncolnames(linelist_raw) <- linelist_raw_names"},{"path":"import-and-export.html","id":"make-a-data-dictionary","chapter":"5 Import and export","heading":"Make a data dictionary","text":"Bonus! second row data dictionary, can easily create proper data dictionary . tip adapted post.","code":"\ndict <- linelist_2headers %>%             # begin: linelist with dictionary as first row\n  head(1) %>%                             # keep only column names and first dictionary row                \n  pivot_longer(cols = everything(),       # pivot all columns to long format\n               names_to = \"Column\",       # assign new column names\n               values_to = \"Description\")"},{"path":"import-and-export.html","id":"combine-two-header-rows","chapter":"5 Import and export","heading":"Combine two header rows","text":"cases, may want combine two header rows one. command define column names combination (pasting together) existing column names value underneath first row. Replace “df” name dataset.","code":"\nnames(df) <- paste(names(df), df[1, ], sep = \"_\")"},{"path":"import-and-export.html","id":"multiple-files---import-export-split-combine","chapter":"5 Import and export","heading":"5.9 Multiple files - import, export, split, combine","text":"See page Iteration loops examples import combine multiple files, multiple Excel workbook files. page also examples split data frame parts export one separately, named sheets Excel workbook.","code":""},{"path":"import-and-export.html","id":"import-from-github","chapter":"5 Import and export","heading":"5.10 Import from Github","text":"Importing data directly Github R can easy can require steps - depending file type. approaches:","code":""},{"path":"import-and-export.html","id":"csv-files-1","chapter":"5 Import and export","heading":"CSV files","text":"can easy import .csv file directly Github R R command.Go Github repo, locate file interest, click itClick “Raw” button (see “raw” csv data, shown )Copy URL (web address)Use URL import() R command, shown ","code":""},{"path":"import-and-export.html","id":"xlsx-files","chapter":"5 Import and export","heading":"XLSX files","text":"may able view “Raw” data files (e.g. .xlsx, .rds, .nwk, .shp)Go Github repo, locate file interest, click itClick “Download” button, shown belowSave file computer, import R","code":""},{"path":"import-and-export.html","id":"shapefiles-1","chapter":"5 Import and export","heading":"Shapefiles","text":"Shapefiles many sub-component files, different file extention. One file “.shp” extension, others may “.dbf”, “.prj”, etc. download shapefile Github, need download sub-component files individually, save folder computer. Github, click file individually download clicking “Download” button.saved computer can import shapefile shown GIS basics page using st_read() sf package. need provide filepath name “.shp” file - long related files within folder computer., can see shapefile “sle_adm3” consists many files - must downloaded Github.","code":""},{"path":"import-and-export.html","id":"manual-data-entry","chapter":"5 Import and export","heading":"5.11 Manual data entry","text":"","code":""},{"path":"import-and-export.html","id":"entry-by-rows","chapter":"5 Import and export","heading":"Entry by rows","text":"Use tribble function tibble package tidverse (onlinetibble reference).Note column headers start tilde (~). Also note column must contain one class data (character, numeric, etc.). can use tabs, spacing, new rows make data entry intuitive readable. Spaces matter values, row represented new line code. example:now display new dataset:","code":"\n# create the dataset manually by row\nmanual_entry_rows <- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )"},{"path":"import-and-export.html","id":"entry-by-columns","chapter":"5 Import and export","heading":"Entry by columns","text":"Since data frame consists vectors (vertical columns), base approach manual dataframe creation R expects define column bind together. can counter-intuitive epidemiology, usually think data rows ().CAUTION: vectors must length (number values).vectors can bound together using function data.frame():now display new dataset:","code":"\n# define each vector (vertical column) separately, each with its own name\nPatientID <- c(235, 452, 778, 111)\nTreatment <- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     <- c(1, 0, 1, 0)\n# combine the columns into a data frame, by referencing the vector names\nmanual_entry_cols <- data.frame(PatientID, Treatment, Death)"},{"path":"import-and-export.html","id":"pasting-from-clipboard","chapter":"5 Import and export","heading":"Pasting from clipboard","text":"copy data elsewhere clipboard, can try following function base R convert data R data frame:","code":"\ndf_from_clipboard <- read.table(\n  file = \"clipboard\",  # specify this as \"clipboard\"\n  sep = \"t\",           # separator could be tab, or commas, etc.\n  header=TRUE)         # if there is a header row"},{"path":"import-and-export.html","id":"import-most-recent-file","chapter":"5 Import and export","heading":"Import most recent file","text":"Often may receive daily updates datasets. case want write code imports recent file. present two ways approach :Selecting file based date file nameSelecting file based file metadata (last modification)","code":""},{"path":"import-and-export.html","id":"dates-in-file-name","chapter":"5 Import and export","heading":"Dates in file name","text":"approach depends three premises:trust dates file namesThe dates numeric appear generally format (e.g. year month day)numbers file nameWe explain step, show combined end. First, use dir() base R extract just file names file folder interest. See page Directory interactions details dir(). example, folder interest folder “linelists” within folder “data” within R project.vector names, can extract dates applying str_extract() stringr using regular expression. extracts numbers file name (including characters middle dashes slashes). can read stringr [Strings characters] page.Assuming dates written date general format (e.g. Year Month Day) can use lubridate’s flexible ymd() function (dmy() mdy()) convert dates. functions, dashes, spaces, slashes matter, order numbers. Read Working dates.base R function .max() can used return index position (e.g. 1st, 2nd, 3rd, …) maximum date value. latest file correctly identified 6th file - “case_linelist_2020-10-08.xlsx”.condense commands, complete code look like . Note . last line placeholder piped object point pipe sequence. point value simply number 6. placed double brackets extract 6th element vector file names produced dir().can now use name finish relative file path, ():can now import latest file:","code":"\nlinelist_filenames <- dir(here(\"data\", \"linelists\")) # get file names from folder\nlinelist_filenames                                   # print## [1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\"  \"case_linelist_2020-10-03.csv\"  \"case_linelist_2020-10-04.csv\" \r\n## [5] \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\" \"case_linelist20201006.csv\"\nlinelist_dates_raw <- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print## [1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\" \"20201006\"\nlinelist_dates_clean <- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean## [1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\" \"2020-10-06\"\nindex_latest_file <- which.max(linelist_dates_clean)\nindex_latest_file## [1] 6\n# load packages\npacman::p_load(\n  tidyverse,         # data management\n  stringr,           # work with strings/characters\n  lubridate,         # work with dates\n  rio,               # import / export\n  here,              # relative file paths\n  fs)                # directory interactions\n\n# extract the file name of latest file\nlatest_file <- dir(here(\"data\", \"linelists\")) %>%  # file names from \"linelists\" sub-folder          \n  str_extract(\"[0-9].*[0-9]\") %>%                  # pull out dates (numbers)\n  ymd() %>%                                        # convert numbers to dates (assuming year-month-day format)\n  which.max() %>%                                  # get index of max date (latest file)\n  dir(here(\"data\", \"linelists\"))[[.]]              # return the filename of latest linelist\n\nlatest_file  # print name of latest file## [1] \"case_linelist_2020-10-08.xlsx\"\nhere(\"data\", \"linelists\", latest_file) ## [1] \"C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook/data/linelists/case_linelist_2020-10-08.xlsx\"\n# import\nimport(here(\"data\", \"linelists\", latest_file)) # import "},{"path":"import-and-export.html","id":"use-the-file-info","chapter":"5 Import and export","heading":"Use the file info","text":"files dates names (trust dates), can try extract last modification date file metadata. Use functions package fs examine metadata information file, includes last modification time file path., provide folder interest fs’s dir_info(). case, folder interest sub-folder “linelists” within folder “data” within R project. result data frame one line per file columns modification_time, path, etc. can see visual example page Directory interactions.can sort data frame files column modification_time, keep top/latest row (file) base R’s head(). can extract file path latest file dplyr function pull() column path. Finally can pass file path import(). imported file saved latest_file.","code":"\nlatest_file <- dir_info(here(\"data\", \"linelists\")) %>%  # collect file info on all files in directory\n  arrange(desc(modification_time)) %>%      # sort by modification time\n  head(1) %>%                               # keep only the top (latest) file\n  pull(path) %>%                            # extract only the file path\n  import()                                  # import the file"},{"path":"import-and-export.html","id":"export","chapter":"5 Import and export","heading":"5.12 Export","text":"rio, can use export() function similar way import(). First give name R object want save (e.g. linelist) quote filepath including name file extension. example:save dataframe .csv, folder specified relative pathway:","code":"\nexport(linelist, \"my_linelist.xlsx\") # will save to working directoryexport(linelist, here(\"data\",\"clean\", \"my_linelist.csv\")"},{"path":"import-and-export.html","id":"rds-files","chapter":"5 Import and export","heading":"5.13 RDS files","text":"Along .csv, .xlsx, etc, can also export/save R data frames .rds files. file format specific R, useful know work exported data R.classes columns stored, don’t cleaning imported (Excel even CSV file can headache!).example, work Epi team need send files GIS team mapping, use R well, just send .rds file! column classes retained less work .","code":"export(linelist, here(\"data\",\"clean\", \"my_linelist.rds\")"},{"path":"import-and-export.html","id":"rdata-files","chapter":"5 Import and export","heading":"5.14 Rdata files","text":".Rdata files store R objects, can actually store multiple R objects within one file, example multiple dataframes, model results, lists, etc. can useful consolidate share lot data given project.example, multiple R objects stored within exported file “my_objects.Rdata”:Note: trying import list, use import_list() rio import complete original structure contents.","code":"\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\nrio::import_list(\"my_list.Rdata\")"},{"path":"import-and-export.html","id":"saving-plots","chapter":"5 Import and export","heading":"5.15 Saving plots","text":"save plots, created ggplot() discussed depth ggplot tips page.brief, run ggsave(\"my_plot_filepath_and_name.png\") printing plot. can either provide saved plot object plot = argument, specify destination file path (file extension) save recently-displayed plot. can also control width =, height =, units =, dpi =.save network graph, transmission tree, addressed page Transmission chains.","code":""},{"path":"import-and-export.html","id":"resources","chapter":"5 Import and export","heading":"5.16 Resources","text":"R Data Import/Export ManualR 4 Data Science chapterggsaveBelow table, taken rio online vignette. type data shows: expected file extension, package rio uses import export data, whether functionality included default installed version rio.","code":""},{"path":"r-projects.html","id":"r-projects","chapter":"6 R projects","heading":"6 R projects","text":"R project enables work bundled self-contained folder. Within project, relevant scripts, data files, figures/outputs, history stored sub-folders importantly - working directory project’s root folder.","code":""},{"path":"r-projects.html","id":"suggested-use","chapter":"6 R projects","heading":"6.1 Suggested use","text":"common, efficient, trouble-free way use R combine 3 elements. described sections .R project\r\nself-contained working environment folders data, scripts, outputs, etc.\r\nself-contained working environment folders data, scripts, outputs, etc.package relative filepaths\r\nFilepaths written relative root folder R project - see Import export information\r\nFilepaths written relative root folder R project - see Import export informationThe rio package importing/exporting\r\nimport() export() handle file type extension (e.g. .csv, .xlsx, .png)\r\nimport() export() handle file type extension (e.g. .csv, .xlsx, .png)","code":""},{"path":"r-projects.html","id":"creating-an-r-project","chapter":"6 R projects","heading":"6.2 Creating an R project","text":"create R project, select “New Project” File menu.want create new folder project, select “New directory” indicate want created.want create project within existing folder, click “Existing directory” indicate folder.want clone Github repository, select third option “Version Control” “Git”. See page Collaboration Github details.R project create come form folder containing .Rproj file. file shortcut likely primary way open project. can also open project selecting “Open Project” File menu. Alternatively far upper right side RStudio see R project icon drop-menu available R projects.exit R project, either open new project, close project (File - Close Project).","code":""},{"path":"r-projects.html","id":"switch-projects","chapter":"6 R projects","heading":"Switch projects","text":"switch projects, click R project icon drop-menu top-right RStudio. see options Close Project, Open Project, list recent projects.","code":""},{"path":"r-projects.html","id":"settings","chapter":"6 R projects","heading":"Settings","text":"generally advised start RStudio time “clean slate” - , workspace preserved previous session. mean objects results persist session--session (must re-create running scripts). good, force write better scripts avoid errors long run.set RStudio “clean slate” time start-:Select “Project Options” Tools menu.“General” tab, set RStudio restore .RData workspace startup, save workspace .RData exit.","code":""},{"path":"r-projects.html","id":"organization","chapter":"6 R projects","heading":"Organization","text":"common subfolders project. Consider folders “data”, “scripts”, “figures”, “presentations”. can add folders typical way add new folder computer. Alternatively, see page Directory interactions learn create new folders R commands.","code":""},{"path":"r-projects.html","id":"version-control","chapter":"6 R projects","heading":"Version control","text":"Consider version control system. something simple dates names scripts (e.g. “transmission_analysis_2020-10-03.R”) “archive” folder. Consider also commented header text top script description, tags, authors, change log.complicated method involve using Github similar platform version control. See page Collaboration Github.One tip can search across entire project folder using “Find Files” tool (Edit menu). can search even replace strings across multiple files.","code":""},{"path":"r-projects.html","id":"examples","chapter":"6 R projects","heading":"6.3 Examples","text":"examples import/export/saving using () within R projct. Read using package Import export page.Importing linelist_raw.xlsx “data” folder R projectExporting R object linelist “my_linelist.rds” “clean” folder within “data” folder R project.Saving recently printed plot “epicurve_2021-02-15.png” within “epicurves” folder “outputs” folder R project.","code":"\nlinelist <- import(here(\"data\", \"linelist_raw.xlsx\"))\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))"},{"path":"r-projects.html","id":"resources-1","chapter":"6 R projects","heading":"6.4 Resources","text":"RStudio webpage using R projects","code":""},{"path":"suggested-packages-1.html","id":"suggested-packages-1","chapter":"7 Suggested packages","heading":"7 Suggested packages","text":"long list suggested packages common epidemiological work R. can copy code, run , packages install CRAN load use current R session. package already installed, loaded use .can modify code # symbols exclude packages want.note:Install pacman package first running code. can install.packages(\"pacman\"). handbook emphasize p_load() pacman, installs package necessary loads use current R session. can also load packages already installed library() base R.code , packages included installing/loading another package indicated indent hash. example ggplot2 listed tidyverse.code installs packages available CRAN - GithubIf multiple packages functions name, masking can occur function recently-loaded package takes precedent. Read R Basics page. Consider using package conflicted manage conflicts.See R basics section packages information pacman masking.see versions R, RStudio, R packages used production handbook, see page Editorial technical notes.","code":"\n# List of useful epidemiology R packages  \n\npacman::p_load(\n     \n     # learning R\n     learnr,   # interactive tutorials in RStudio\n        \n     # project and file management\n     here,     # filepaths relative to root project folder\n     rio,      # import/export of many types of data\n     openxlsx, # import/export of Excel workbooks \n     \n     # package install and management\n     pacman,   # package install/load\n     renv,     # managing versions of packages when working in collaborative groups\n     remotes,  # install from github\n     \n     # General data management\n     tidyverse,    # includes many packages for tidy data wrangling and presentation\n          #dplyr,\n          #tidyr,\n          #ggplot2,\n     linelist,     # cleaning linelists\n     lubridate,    # working with dates\n     naniar,       # assessing missing data\n     \n     # statistics  \n     gtsummary,    # making descriptive and statistical tables\n     janitor,      # tables and data cleaning\n     \n     # epidemic modeling\n     epicontacts,  # Analysing transmission networks\n     EpiNow2,      # Rt estimation\n     EpiEstim,     # Rt estimation\n     projections,  # Incidence projections\n     incidence2,   # Make epicurves and handle incidence data\n     i2extras,     #\n     epitrix,      # Useful epi functions\n     distcrete,    # Discrete delay distributions\n     \n     \n     # plots - general\n     #ggplot2,         # included in tidyverse\n     cowplot,          # combining plots\n     RColorBrewer,     # color scales\n     \n     # plots - specific types\n     DiagrammeR,       # diagrams using DOT language\n     incidence,        # epidemic curves\n     gghighlight,      # highlight a subset\n     ggrepel,          # smart labels\n     \n     # gis\n     sf,               # to manage spatial data using a Simple Feature format\n     tmap,             # to produce simple maps, works for both interactive and static maps\n     OpenStreetMap,    # to add OSM basemap in ggplot map\n     \n     # routine reports  \n     rmarkdown,        # produce PDFs, Word Documents, Powerpoints, and HTML files\n     reportfactory,    # Auto-organization of Rmarkdown outputs\n     \n     # tables\n     knitr,            # report generation, kable() for html tables\n     flextable,        # HTML tables\n     DT,               # HTML tables\n     gt,               # HTML tables\n     \n     # phylogenetics  \n     ggtree,           # visualization and annotation of trees\n     ape,              # analysis of phylogenetics and evolution\n     \n     # interactive\n     plotly,           # interactive graphics\n     shiny             # interactive web apps  \n)"},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-data-and-core-functions","chapter":"8 Cleaning data and core functions","heading":"8 Cleaning data and core functions","text":"page demonstrates common steps necessary clean dataset, starting importing raw data demonstrating “pipe chain” cleaning steps. use simulated Ebola case linelist, referenced often handbook.page also explains use many core functions used data management, including:want see functions compare Stata SAS, see page Transition R.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-pipeline","chapter":"8 Cleaning data and core functions","heading":"8.1 Cleaning pipeline","text":"page proceeds typical cleaning steps, adding sequentially cleaning pipe chain.epidemiological analysis data processing, cleaning steps often performed linked together, sequentially. R often manifests cleaning “pipeline”, raw dataset passed “piped” one cleaning step another.chain utilize dplyr “verb” functions magrittr pipe operator %>%. pipe begins “raw” data (“linelist_raw.xlsx”) ends “clean” R data frame (linelist).cleaning pipeline order steps important. Cleaning steps might include:Importing dataColumn names cleaned changedDe-duplicationColumn creation transformation (e.g. re-coding cleaning values)Rows filtered added","code":""},{"path":"cleaning-data-and-core-functions.html","id":"load-packages","chapter":"8 Cleaning data and core functions","heading":"8.2 Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  tidyverse   # data manipulation and visualization\n)"},{"path":"cleaning-data-and-core-functions.html","id":"import-data","chapter":"8 Cleaning data and core functions","heading":"8.3 Import data","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"import","chapter":"8 Cleaning data and core functions","heading":"Import","text":"import raw .xlsx case linelist using import() function package rio, save data frame linelist_raw. want download data follow step--step, see instructions Download book data page.dataset large takes long time import, can useful import command separate pipe chain “raw” saved distinct file. also allows easy comparison original cleaned versions.See page Import export details unusual situations, including:Skipping import certain rowsDealing second row data dictionaryImporting Google sheetsBelow import raw .xlsx file. assume located working directory sub-folders specified filepath.can view first 50 rows original “raw” dataset . can use base R function head(n) view just first n lines console.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\")"},{"path":"cleaning-data-and-core-functions.html","id":"review","chapter":"8 Cleaning data and core functions","heading":"Review","text":"can use function skim() package skimr get overview entire dataframe (see page Descriptive tables info). Columns summarised class (character, numeric, POSIXct - type date class).\r\nTable 8.1: Data summary\r\nVariable type: characterVariable type: numericVariable type: POSIXct","code":"\nskimr::skim(linelist_raw)"},{"path":"cleaning-data-and-core-functions.html","id":"column-names","chapter":"8 Cleaning data and core functions","heading":"8.4 Column names","text":"Column names used often, must “clean” syntax. suggest following:Short namesNo spaces (replace underscores _ )unusual characters (&, #, <, >, …)Similar style nomenclature (e.g. date columns named like date_onset, date_report, date_death…)columns names linelist_raw printed using names() base R. can see initially:names contain spaces (e.g. infection date)Different naming patterns used dates (date onset vs. infection date)must merged header across two last columns .xlsx. know name two merged columns (“merged_header”) applied first one, second column assigned placeholder name “…28”, empty 28th column.NOTE: reference column name include spaces, surround name back-ticks, example: linelist$`infection date`. note keyboard, back-tick (`) different single quotation mark (’).","code":"\nnames(linelist_raw)##  [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"      \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \r\n##  [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"        \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \r\n## [17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"           \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \r\n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\""},{"path":"cleaning-data-and-core-functions.html","id":"automatic-cleaning","chapter":"8 Cleaning data and core functions","heading":"Automatic cleaning","text":"function clean_names() package janitor standardizes column names makes unique following:Converts names consist underscores, numbers, lettersAccented characters transliterated ASCII (e.g. german o umlaut becomes “o”, spanish “enye” becomes “n”)Capitalization preference can specified using case = argument (“snake” default, alternatives include “sentence”, “title”, “small_camel”…)can specify name replacements replace = argument (e.g. replace = c(onset = \"date_of_onset\"))online vignetteBelow, cleaning pipeline begins using clean_names() raw linelist.NOTE: last column name “…28” changed “x28”.","code":"\n# send the dataset through the function clean_names()\nlinelist <- linelist_raw %>% \n  janitor::clean_names()\n\n# see the new names\nnames(linelist)##  [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"      \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \r\n##  [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"        \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \r\n## [17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"           \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \r\n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"manual-name-cleaning","chapter":"8 Cleaning data and core functions","heading":"Manual name cleaning","text":"Re-naming columns manually often necessary, even standardization step . , re-naming performed using rename() function dplyr package, part pipe chain. rename() uses style “NEW = OLD”, new column name given old column name., re-name command added cleaning pipeline:Now can see columns names changed:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \r\n##  [7] \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \r\n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"                \"ht_cm\"               \r\n## [19] \"ct_blood\"             \"fever\"                \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \r\n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"rename-by-column-position","chapter":"8 Cleaning data and core functions","heading":"Rename by column position","text":"can also rename column position, instead column name, example:","code":"\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)"},{"path":"cleaning-data-and-core-functions.html","id":"rename-via-select","chapter":"8 Cleaning data and core functions","heading":"Rename via select()","text":"can also rename columns within dplyr select() function, used retain certain columns (covered later page). approach also uses format new_name = old_name. example:","code":"\nlinelist_raw %>% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)"},{"path":"cleaning-data-and-core-functions.html","id":"other-challenges","chapter":"8 Cleaning data and core functions","heading":"Other challenges","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"empty-excel-column-names","chapter":"8 Cleaning data and core functions","heading":"Empty Excel column names","text":"R dataset columns column names (headers). , import Excel dataset data column headers, R fill-headers names like “…1” “…2”. number represents column number (e.g. 4th column dataset header, R name “..4”).can clean names manually referencing position number (see example ), assigned name (linelist_raw$...1).","code":""},{"path":"cleaning-data-and-core-functions.html","id":"merged-excel-column-names-and-cells","chapter":"8 Cleaning data and core functions","heading":"Merged Excel column names and cells","text":"Merged cells Excel file common occurrence receiving data operational teams. Merged cells can nice human reading data, cause many problems machine reading data. R accommodate merged cells.Remind people data entry human-readable data machine-readable data. Strive train users principles tidy data. possible, try change procedures data arrive tidy format without merged cells.variable must column.observation must row.value must cell.using rio’s import() function, value merged cell assigned first cell subsequent cells empty.One solution deal merged cells import data function readWorkbook() package openxlsx. Set argument fillMergedCells = TRUE. gives value merged cell cells within merge range.DANGER: column names merged readWorkbook(), end duplicate column names, need fix manually - R work well duplicate column names! can re-name referencing position (e.g. column 5), explained section manual column name cleaning..","code":"\nlinelist_raw <- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)"},{"path":"cleaning-data-and-core-functions.html","id":"select-or-re-order-columns","chapter":"8 Cleaning data and core functions","heading":"8.5 Select or re-order columns","text":"Use select() dplyr select columns want retain, specify order data frame.CAUTION: examples , linelist data frame modified select() displayed, saved. demonstration purposes. modified column names printed piping data frame names().column names linelist point cleaning pipe chain:","code":"\nnames(linelist)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \r\n##  [7] \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \r\n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"                \"ht_cm\"               \r\n## [19] \"ct_blood\"             \"fever\"                \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \r\n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"keep-columns","chapter":"8 Cleaning data and core functions","heading":"Keep columns","text":"Select columns want remainPut names select() command, quotation marks. appear data frame order provide. Note include column exist, R return error (see use any_of() want error situation).","code":"\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, fever) %>% \n  names()  # display the column names## [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\" \"fever\""},{"path":"cleaning-data-and-core-functions.html","id":"helper-functions","chapter":"8 Cleaning data and core functions","heading":"Helper functions","text":"Helper functions operators exist make easy specify columns keep discard.example, want re-order columns, everything() useful signify “columns yet mentioned”. command pulls columns date_onset date_hospitalisation beginning, keeps others afterward:helpers functions work within select():everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEstarts_with() - matches specified prefix\r\nexample: select(starts_with(\"date\"))\r\nexample: select(starts_with(\"date\"))ends_with() - matches specified suffix\r\nexample: select(ends_with(\"_end\"))\r\nexample: select(ends_with(\"_end\"))contains() - columns containing character string\r\nexample: select(contains(\"time\"))\r\nexample: select(contains(\"time\"))matches() - apply regular expression (regex)\r\nexample: select(contains(\"[pt]al\"))\r\nexample: select(contains(\"[pt]al\"))num_range() - numerical range like x01, x02, x03any_of() - matches column exists returns error found\r\nexample: select(any_of(date_onset, date_death, cardiac_arrest))\r\nexample: select(any_of(date_onset, date_death, cardiac_arrest))addition, use normal operators c() list several columns, : consecutive columns, ! opposite, & , | .Use () specify logical criteria columns. providing function inside (), include empty parentheses. command selects columns class Numeric.Use contains() select columns column name contains string. ends_with() starts_with() provide nuance.function matches() works similarly contains() can provided regular expression (see page Characters strings), multiple strings separated bars within parentheses:CAUTION: column name specifically provide exist data, can return error stop code. Consider using any_of() cite columns may may exist, especially useful negative (remove) selections.one columns exists, error produced code continues.","code":"\n# move date_onset and date_hospitalisation to beginning\nlinelist %>% \n  select(date_onset, date_hospitalisation, everything()) %>% \n  names()##  [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"              \"generation\"           \"date_infection\"       \"date_outcome\"        \r\n##  [7] \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \r\n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"                \"ht_cm\"               \r\n## [19] \"ct_blood\"             \"fever\"                \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \r\n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\"\n# select columns that are class Numeric\nlinelist %>% \n  select(where(is.numeric)) %>% \n  names()## [1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"      \"ht_cm\"      \"ct_blood\"   \"temp\"\n# select columns containing certain characters\nlinelist %>% \n  select(contains(\"date\")) %>% \n  names()## [1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"\n# searched for multiple character matches\nlinelist %>% \n  select(matches(\"onset|hosp|fev\")) %>%   # note the OR symbol \"|\"\n  names()## [1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"             \"fever\"\nlinelist %>% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %>% \n  names()## [1] \"date_onset\""},{"path":"cleaning-data-and-core-functions.html","id":"remove-columns","chapter":"8 Cleaning data and core functions","heading":"Remove columns","text":"Indicate columns remove placing minus symbol “-” front column name (e.g. select(-outcome)), vector column names (). columns retained.can also remove column using base R defining NULL. example:","code":"\nlinelist %>% \n  select(-c(date_onset, fever:vomit)) %>% # remove onset and all cols from fever to vomit\n  names()##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \r\n##  [7] \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"             \"source\"              \r\n## [13] \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \r\n## [19] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\"\nlinelist$date_onset <- NULL   # deletes column with base R syntax "},{"path":"cleaning-data-and-core-functions.html","id":"standalone","chapter":"8 Cleaning data and core functions","heading":"Standalone","text":"select() can also used independent command (pipe chain). case, first argument original dataframe operated upon.","code":"\n# Create a new linelist with id and age-related columns\nlinelist_age <- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)## [1] \"case_id\"  \"age\"      \"age_unit\""},{"path":"cleaning-data-and-core-functions.html","id":"add-to-the-pipe-chain","chapter":"8 Cleaning data and core functions","heading":"Add to the pipe chain","text":"linelist_raw, columns need: row_num, merged_header, x28. remove select() command cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))"},{"path":"cleaning-data-and-core-functions.html","id":"deduplication","chapter":"8 Cleaning data and core functions","heading":"8.6 Deduplication","text":"See handbook page De-duplication extensive options de-duplicate data. simple row de-duplication example presented .package dplyr offers distinct() function. function examines every row reduce data frame unique rows. , removes rows 100% duplicates.evaluating duplicate rows, takes account range columns - default considers columns. shown de-duplication page, can adjust column range uniqueness rows evaluated regards certain columns.simple example, just add empty command distinct() pipe chain. ensures rows 100% duplicates rows (evaluated across columns).begin 6611 rows linelist.de-duplication 6608 rows. removed rows 100% duplicates rows., distinct() command added cleaning pipe chain:","code":"\nlinelist <- linelist %>% \n  distinct()\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()"},{"path":"cleaning-data-and-core-functions.html","id":"column-creation-and-transformation","chapter":"8 Cleaning data and core functions","heading":"8.7 Column creation and transformation","text":"recommend using dplyr function mutate() add new column, modify existing one.example creating new column mutate(). syntax : mutate(new_column_name = value transformation)Stata, similar command generate, R’s mutate() can also used modify existing column.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"new-columns","chapter":"8 Cleaning data and core functions","heading":"New columns","text":"basic mutate() command create new column might look like . creates new column new_col value every row 10.can also reference values columns, perform calculations. example new column bmi created hold Body Mass Index (BMI) case - calculated using formula BMI = kg/m^2, using column ht_cm column wt_kg.creating multiple new columns, separate comma new line. , examples new columns, including pasting together values columns using str_glue() stringr package (see page Characters strings.Scroll right see new columns added (first 50 rows shown):TIP: variation mutate() function transmute(). function adds new column just like mutate(), also drops/removes columns mention within parentheses.","code":"\nlinelist <- linelist %>% \n  mutate(new_col = 10)\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\nlinelist <- linelist %>%                       \n  mutate(\n    new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n    new_var_static = 7,                   # new column = all values the same\n    new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n    ) "},{"path":"cleaning-data-and-core-functions.html","id":"convert-column-class","chapter":"8 Cleaning data and core functions","heading":"Convert column class","text":"Often need set correct class column. ways set column class import commands, often often cumbersome. See section object classes learn converting class objects, including columns.First, run checks important columns see correct class:Currently, class “age” column character. perform quantitative analyses, need numbers recognized numeric!class “date_onset” column also character! perform analyses, dates must recognized dates!case, use mutate() define column , converted different class. basic example, converting ensuring column age class Numeric:similar way, can use .character(), .double(), .logical().convert class Factor, can use factor() base R as_factor() forcats. Read Factors page.Converting class date must take care. Several methods explained page Working dates. Typically, raw date values must format conversion work correctly (e.g “MM/DD/YYYY”, “DD MM YYYY”). converting class Date, check data visually cross-table confirm value converted correctly.","code":"\nclass(linelist$age)## [1] \"character\"\nclass(linelist$date_onset)## [1] \"character\"\nlinelist <- linelist %>% \n  mutate(age = as.numeric(age))"},{"path":"cleaning-data-and-core-functions.html","id":"grouped-data","chapter":"8 Cleaning data and core functions","heading":"Grouped data","text":"dataframe already grouped (see page Grouping data), mutate() may behave differently dataframe grouped. summarizing functions, like mean(), median(), max(), etc. based grouped rows, rows.Read using mutate grouped dataframes tidyverse mutate documentation.","code":"\n# age normalized to mean of ALL rows\nlinelist %>% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %>% \n  group_by(hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))"},{"path":"cleaning-data-and-core-functions.html","id":"transform-multiple-columns","chapter":"8 Cleaning data and core functions","heading":"Transform multiple columns","text":"Often write concise code want apply transformation multiple columns . transformation can applied multiple columns using across() function package dplyr (also contained within tidyverse package). across() can used dplyr function, commonly select(), mutate(), filter(), summarise(). See applied summarise() page Descriptive tables.specify columns .cols = function(s) .fns. additional arguments provide function can included comma, still within across().","code":""},{"path":"cleaning-data-and-core-functions.html","id":"across-column-selection","chapter":"8 Cleaning data and core functions","heading":"across() column selection","text":"Specify columns argument .cols = - can name individually, use helper functions. Specify function .fns =. Note using function mode demonstrated , function written without parentheses ( ).transformation .character() applied specific columns named within across().helpers available assist specifying columns:everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEstarts_with() - matches specified prefix\r\nexample: across(starts_with(\"date\"))\r\nexample: across(starts_with(\"date\"))ends_with() - matches specified suffix\r\nexample: across(ends_with(\"_end\"))\r\nexample: across(ends_with(\"_end\"))contains() - columns containing character string\r\nexample: across(contains(\"time\"))\r\nexample: across(contains(\"time\"))matches() - apply regular expression (regex)\r\nexample: across(contains(\"[pt]al\"))\r\nexample: across(contains(\"[pt]al\"))num_range() -any_of() - matches column named. Useful name might exist\r\nexample: across(any_of(date_onset, date_death, cardiac_arrest))\r\nexample: across(any_of(date_onset, date_death, cardiac_arrest))example one change columns character class:Columns name contains string “date” (note placement commas parentheses):, want mutate columns class POSIXct (datetime class shows timestamps) - words, function .POSIXct() evaluates TRUE. want apply function .Date() columns convert normal class Date.Note within across() also use function ()Note .POSIXct() package lubridate. similar functions (.character(), .numeric(), .logical()) base R","code":"\nlinelist <- linelist %>% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = everything(), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\nlinelist <- linelist %>% \n  mutate(across(.cols = where(lubridate::is.POSIXct), .fns = as.Date))"},{"path":"cleaning-data-and-core-functions.html","id":"across-functions","chapter":"8 Cleaning data and core functions","heading":"across() functions","text":"can read documentation ?across details provide functions across(). summary points: several ways specify function(s) perform column can even define functions:can provide function name alone (e.g. mean .character)can provide function purrr-style (e.g. ~ mean(.x, na.rm = TRUE))can specify multiple functions providing list (e.g. list(mean = mean, n_miss = ~ sum(.na(.x))).\r\nprovide multiple functions, multiple transformed columns returned unique names (e.g. col_fn). can adjust new columns named .names = argument using glue syntax (see page Characters strings) {.col} {.fn} shorthand column function.\r\nprovide multiple functions, multiple transformed columns returned unique names (e.g. col_fn). can adjust new columns named .names = argument using glue syntax (see page Characters strings) {.col} {.fn} shorthand column function.online resources using across(): creator Hadley Wickham’s thoughts/rationale","code":""},{"path":"cleaning-data-and-core-functions.html","id":"coalesce","chapter":"8 Cleaning data and core functions","heading":"coalesce()","text":"dplyr function finds first non-missing value position.Say two vectors/columns, one village detection another village residence. can use coalesce pick first non-missing value index:works provide data frame columns: row, function assign new column value first non-missing value columns provided (order provided).complicated row-wise calculations, see section Row-wise calculations.","code":"\nvillage_detection <- c(\"a\", \"b\", NA,  NA)\nvillage_residence <- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage <- coalesce(village_detection, village_residence)\nvillage    # print## [1] \"a\" \"b\" \"a\" \"d\"\nlinelist <- linelist %>% \n  mutate(village = coalesce(village_detection, village_residence))"},{"path":"cleaning-data-and-core-functions.html","id":"cumulative-math","chapter":"8 Cleaning data and core functions","heading":"Cumulative math","text":"want column reflect cumulative sum/mean/min/max etc assessed rows dataframe, use following functions:cumsum() returns cumulative sum, shown :can used dataframe making new column. example, calculate cumulative number cases per day outbreak, consider code like :first 10 rows:See page Epidemic curves plot cumulative incidence epicurve.See also:\r\ncumsum(), cummean(), cummin(), cummax(), cumany(), cumall()","code":"\nsum(c(2,4,15,10))     # returns only one number## [1] 31\ncumsum(c(2,4,15,10))  # returns the cumulative sum at each step## [1]  2  6 21 31\ncumulative_case_counts <- linelist %>% \n  count(date_onset) %>%                 # count of rows per day   \n  mutate(cumulative_cases = cumsum(n))  # new column of the cumulative sum at that row\nhead(cumulative_case_counts, 10)##    date_onset n cumulative_cases\r\n## 1  2012-04-15 1                1\r\n## 2  2012-05-05 1                2\r\n## 3  2012-05-08 1                3\r\n## 4  2012-05-31 1                4\r\n## 5  2012-06-02 1                5\r\n## 6  2012-06-07 1                6\r\n## 7  2012-06-14 1                7\r\n## 8  2012-06-21 1                8\r\n## 9  2012-06-24 1                9\r\n## 10 2012-06-25 1               10"},{"path":"cleaning-data-and-core-functions.html","id":"using-base-r","chapter":"8 Cleaning data and core functions","heading":"Using base R","text":"define new column (re-define column) using base R, write name data frame new column (column modified). Use assignment operator <- define new value(s). Remember using base R must specify data frame name column name every time (e.g. dataframe$column). example creating bmi column using base R:","code":"linelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain","chapter":"8 Cleaning data and core functions","heading":"Add to pipe chain","text":", new column added pipe chain classes converted.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>% \n  \n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) "},{"path":"cleaning-data-and-core-functions.html","id":"re-code-values","chapter":"8 Cleaning data and core functions","heading":"8.8 Re-code values","text":"scenarios need re-code (change) values:edit one specific value (e.g. one date incorrect year format)reconcile values spelled sameto create new column categoriesto create new column numeric categories (e.g. age categories)","code":""},{"path":"cleaning-data-and-core-functions.html","id":"specific-values","chapter":"8 Cleaning data and core functions","heading":"Specific values","text":"change values manually can use recode() function within mutate() function.Imagine nonsensical date data (e.g. “2014-14-15”): fix date source data, , write change cleaning pipeline via mutate() recode().mutate() line can read : “mutate column date_onset equal column date_onset re-coded OLD VALUE changed NEW VALUE”. Note pattern (OLD = NEW) recode() opposite R patterns (new = old). R development community working revising .another example re-coding multiple values within one column.linelist values column “hospital” must cleaned. several different spellings many missing values.recode() command re-defines column “hospital” current column “hospital”, specified recode changes. Don’t forget commas !Now see spellings hospital column corrected consolidated:TIP: number spaces equals sign matter. Make code easier read aligning = rows. Also, consider adding hashed comment row clarify future readers side OLD side NEW. TIP: Sometimes blank character value exists dataset (recognized R’s value missing - NA). can reference value two quotation marks space inbetween (\"\").","code":"\n# fix incorrect values                   # old value       # new value\nlinelist <- linelist %>% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\ntable(linelist$hospital, useNA = \"always\")## \r\n##                      Central Hopital                     Central Hospital                           Hospital A                           Hospital B \r\n##                                   11                                  457                                  290                                  289 \r\n##                     Military Hopital                    Military Hospital                     Mitylira Hopital                    Mitylira Hospital \r\n##                                   32                                  798                                    1                                   79 \r\n##                                Other                         Port Hopital                        Port Hospital St. Mark's Maternity Hospital (SMMH) \r\n##                                  907                                   48                                 1756                                  417 \r\n##   St. Marks Maternity Hopital (SMMH)                                 <NA> \r\n##                                   11                                 1512\nlinelist <- linelist %>% \n  mutate(hospital = recode(hospital,\n                      #    reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\ntable(linelist$hospital, useNA = \"always\")## \r\n##                     Central Hospital                           Hospital A                           Hospital B                    Military Hospital \r\n##                                  468                                  290                                  289                                  910 \r\n##                                Other                        Port Hospital St. Mark's Maternity Hospital (SMMH)                                 <NA> \r\n##                                  907                                 1804                                  428                                 1512"},{"path":"cleaning-data-and-core-functions.html","id":"missing-values-2","chapter":"8 Cleaning data and core functions","heading":"Missing values","text":"See page Missing data detailed tips identifying handling missing values. example, .na() function logically tests missingness.dplyr offers two special functions handling missing values context data cleaning:replace_na()change missing values (NA) specific value, “Missing”, use function replace_na() within mutate(). Note used manner recode - name variable must repeated within replace_na().na_if()convert specific value NA, use na_if(). command performs opposite operation replace_na(). example , values “Missing” column hospital converted NA.Note: na_if() used logic criteria (e.g. “values > 99”) - use replace() case_when() :","code":"\nlinelist <- linelist %>% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\nlinelist <- linelist %>% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n# Convert temperatures above 40 to NA \nlinelist <- linelist %>% \n  mutate(temp = replace(temp, temp > 40, NA))\n\n# Convert onset dates earlier than 2000 to missing\nlinelist <- linelist %>% \n  mutate(date_onset = replace(date_onset, date_onset > as.Date(\"2000-01-01\"), NA))"},{"path":"cleaning-data-and-core-functions.html","id":"by-logic","chapter":"8 Cleaning data and core functions","heading":"By logic","text":"demonstrated re-code values column using logic conditions:Using replace(), ifelse() if_else() simple logicUsing case_when() complex logic","code":""},{"path":"cleaning-data-and-core-functions.html","id":"simple-logic","chapter":"8 Cleaning data and core functions","heading":"Simple logic","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"replace","chapter":"8 Cleaning data and core functions","heading":"replace()","text":"re-code simple logical criteria, can use replace() within mutate(). replace() function base R. Use logic condition specify rows change . general syntax :mutate(col_to_change = replace(col_to_change, criteria rows, new value)).One common situation changing just one value one row, using unique row identifier. , gender changed “Female” row column case_id “2195”.equivalent command using base R syntax indexing brackets [ ] . reads “Change value dataframe linelist‘s column gender (rows linelist’s column case_id value ’2195’) ‘Female’”.","code":"# Example: change gender of one specific observation to \"Female\" \r\nlinelist <- linelist %>% \r\n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\")\nlinelist$gender[linelist$case_id == \"2195\"] <- \"Female\""},{"path":"cleaning-data-and-core-functions.html","id":"ifelse-and-if_else","chapter":"8 Cleaning data and core functions","heading":"ifelse() and if_else()","text":"Another tool simple logical re-coding ifelse() partner if_else(). However, cases better use case_when() (clarity).commands simplified versions else programming statement. general syntax :ifelse(condition, value return condition evaluates TRUE, value return condition evaluates FALSE), column source_known defined (re-defined). value given row set “known” row’s value column source missing. value source missing, value source_known set “unknown”.if_else() special version dplyr handles dates. Note ‘true’ value date, ‘false’ value must also qualify date, hence using special character NA_real_ instead just NA.Avoid stringing together many ifelse commands… use case_when() instead! case_when() much easier read ’ll make fewer errors.Outside context data frame, want object used code switch value, consider using switch() base R. See section using switch() page [Interactive console].","code":"\nlinelist <- linelist %>% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n# Create a date of death column, which is NA if patient has not died.\nlinelist <- linelist %>% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))"},{"path":"cleaning-data-and-core-functions.html","id":"complex-logic","chapter":"8 Cleaning data and core functions","heading":"Complex logic","text":"Use dplyr’s case_when() need use complex logic statements re-code values. important differences recode() syntax logic order!case_when() commands Right-Hand Side (RHS) Left-Hand Side (LHS) separated “tilde” ~. logic criteria LHS pursuant value RHS. Statements separated commas. important note :Statements evaluated order written - top--bottom. Thus best write specific criteria first, general last.End TRUE LHS, signifies row value meet previous criteriaThe values RHS must class - either numeric, character, logical, etc.\r\nassign NA, may need use special values NA_character_, NA_real_ (numeric POSIX), .Date(NA)\r\nassign NA, may need use special values NA_character_, NA_real_ (numeric POSIX), .Date(NA)utilize columns age age_unit create column age_years:","code":"\nlinelist <- linelist %>% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # if age is given in years\n            age_unit == \"months\" ~ age/12,    # if age is given in months\n            is.na(age_unit)      ~ age,       # if age unit is missing, assume years\n            TRUE                 ~ NA_real_)) # any other circumstance assign missing"},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-dictionary","chapter":"8 Cleaning data and core functions","heading":"Cleaning dictionary","text":"Use package linelist clean linelist cleaning dictionary.Import cleaning dictionary 3 columns:\r\n“” column (incorrect value)\r\n“” column (correct value)\r\ncolumn specifying column changes applied (“.global” apply columns)\r\n“” column (incorrect value)“” column (correct value)column specifying column changes applied (“.global” apply columns)Store names columns want “protect” changes. must provided clean_data() numeric logical vector, see use names(.) command (dot means dataframe).Run clean_data(), specifying cleaning dictionaryScroll see values changed - particularly gender (lowercase uppercase), symptoms columns transformed yes/1/0.CAUTION: clean_data() linelist package also clean values data unless columns protected - may encounter changes columns dashes “-” .Note column names cleaning dictionary must correspond names point cleaning script. clean_data() also implements column name cleaning function similar clean_names() janitor standardizes column names prior applying dictionary.See online reference linelist package details.","code":"\ncleaning_dict <- import(\"cleaning_dict.csv\")\nprotected_cols <- c(\"case_id\", \"source\")\nlinelist <- linelist %>% \n  linelist::clean_data(\n    wordlists = cleaning_dict,\n    spelling_vars = \"col\",       # dict column containing column names, defaults to 3rd column in dict\n    protect = names(.) %in% protected_cols\n  )"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-1","chapter":"8 Cleaning data and core functions","heading":"Add to pipe chain","text":", new columns column transformations added pipe chain.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n   # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n   ###################################################\n\n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))"},{"path":"cleaning-data-and-core-functions.html","id":"num_cats","chapter":"8 Cleaning data and core functions","heading":"8.9 Numeric categories","text":"describe special approaches creating numeric categories. Common examples include age categories, groups lab values, etc. discuss:age_categories(), epikit packagecut(), base Rcase_when()quantile breaks","code":""},{"path":"cleaning-data-and-core-functions.html","id":"review-distribution","chapter":"8 Cleaning data and core functions","heading":"Review distribution","text":"example create age_cat column using age_years column.First, examine distribution data, make appropriate cut-points. See page Plot continuous data.CAUTION: Sometimes, numeric variables import class “character”. occurs non-numeric characters values, example entry “2 months” age, (depending R locale settings) comma used decimals place (e.g. “4,5” mean four one half years)..","code":"\n#check the class of the linelist variable age\nclass(linelist$age_years)## [1] \"numeric\"\n# examine the distribution\nhist(linelist$age_years)\nsummary(linelist$age_years, na.rm=T)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \r\n##       0       6      13      16      23      84     107"},{"path":"cleaning-data-and-core-functions.html","id":"age_categories","chapter":"8 Cleaning data and core functions","heading":"age_categories()","text":"epikit package, can use age_categories() function easily categorize label numeric columns (note: function can applied non-age numeric variables ). note: output ordered factor.required inputs:numeric vector (column)breakers = - numeric vector break points new groupsFirst, simple example:break values specify default included “higher” group - groups “open” lower/left side. shown , can add 1 break value achieve groups open top/right.can adjust labels displayed separator =. default “-”can adjust upper cut-values allowed included group. Use ceiling =, default FALSE. TRUE, highest break value “ceiling” category “XX+” included. values highest break value upper (defined) categorized NA. example ceiling = TRUE, category XX+ values 70 (highest break value) assigned NA.Alternatively, instead breakers =, can provide lower =, upper =, =:lower = lowest number want considered - default 0upper = highest number want consideredby = number years groupsSee function’s Help page details (enter ?age_categories R console).","code":"\n# Simple example\n################\npacman::p_load(epikit)\n\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years,\n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  <NA> \r\n##  1227  1223  1048   827  1216   597   251    78    27     7   107\n# Include upper ends for the same categories\n############################################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  <NA> \r\n##  1469  1195  1040   770  1149   547   231    70    24     6   107\n# With ceiling set to TRUE\n##########################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  <NA> \r\n##  1227  1223  1048   827  1216   597   251    78    28   113\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  <NA> \r\n##  2450  1875  1216   597   251    78    27     6     1     0     0   107"},{"path":"cleaning-data-and-core-functions.html","id":"cut","chapter":"8 Cleaning data and core functions","heading":"cut()","text":"can also use base R function cut(), creates categories numeric column. differences age_categories() :need install/load another packageYou can specify whether groups open/closed right/leftYou must provide accurate labels yourselfIf want 0 included lowest group must specify thisThe basic syntax within cut() first provide numeric variable cut (age_years), breaks argument, numeric vector (c()) break points. Using cut(), resulting column ordered factor. used within mutate() (dplyr verb) necessary specify dataframe column name (e.g. linelist$age_years).Create new column age categories (age_cat) cutting numeric age_year column specified break points.Specify numeric vector break pointsDefault behavior cut() lower break values excluded category, upper break values included. opposite behavior age_categories() function.Include 0 lowest category adding include.lowest = TRUEAdd vector customized labels using labels = argumentCheck work cross-tabulation numeric category columns - aware missing valuesBelow detailed description behavior using cut() make age_cat column. Key points:Inclusion/exclusion behavior break pointsCustom category labelsHandling missing valuesCheck work!simple example cut() applied age_years make new variable age_cat :default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). default labels use notation “(, B]”, means group include (lower break value), includes B (upper break value). Reverse behavior providing right = TRUE argument.default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). default labels use notation “(, B]”, means group include (lower break value), includes B (upper break value). Reverse behavior providing right = TRUE argument.Thus, default “0” values excluded lowest group, categorized NA. “0” values infants coded age 0. change add argument include.lowest = TRUE. , “0” values included lowest group. automatically-generated label lowest category change “(0,B]” “[0,B]”, signifies 0 values included.Thus, default “0” values excluded lowest group, categorized NA. “0” values infants coded age 0. change add argument include.lowest = TRUE. , “0” values included lowest group. automatically-generated label lowest category change “(0,B]” “[0,B]”, signifies 0 values included.Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 15-20).Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 15-20).Reverse break inclusion behavior cut()Lower break values included category (upper break values excluded) argument right = included set TRUE. applied - note values shifted among categories.NOTE: include include.lowest = TRUE argument right = TRUE, extreme inclusion now apply highest break point value category, lowest.Add labelsAs manually written, careful ensure accurate! Check work using cross-tabulation, described . code , manual labels added.Re-labeling NA values cut()cut() automatically label NA values, may want assign label “Missing”. requires extra steps cut() automatically classified new column age_cat class Factor (rigid class limited defined values).First, convert age_cut Factor Character class, flexibility add new character values (e.g. “Missing”). Otherwise encounter error. , use dplyr verb replace_na() replace NA values character value like “Missing”. steps can combined one step, shown .Note Missing added, order categories now wrong (alphabetical considering numbers characters).fix , re-convert age_cat factor, define order levels correctly.seems cumbersome, consider using age_categories() instead, described .Make breaks labelsFor fast way make breaks labels manually, use something like . See R Basics page references seq() rep().Read cut() Help page entering ?cut R console.","code":"\n# Create new variable, by cutting the numeric age variable\n# by default, upper break is excluded and lower break excluded from each category\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100]     <NA> \r\n##     1469     1195     1040      770     1149      778       94        6      107\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values##                     Categories\r\n## Numeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70] (70,100] <NA>\r\n##   0                    136      0       0       0       0       0       0        0    0\r\n##   0.0833333333333333     1      0       0       0       0       0       0        0    0\r\n##   0.25                   2      0       0       0       0       0       0        0    0\r\n##   0.333333333333333      6      0       0       0       0       0       0        0    0\r\n##   0.416666666666667      1      0       0       0       0       0       0        0    0\r\n##   0.5                    6      0       0       0       0       0       0        0    0\r\n##   0.583333333333333      3      0       0       0       0       0       0        0    0\r\n##   0.666666666666667      3      0       0       0       0       0       0        0    0\r\n##   0.75                   3      0       0       0       0       0       0        0    0\r\n##   0.833333333333333      1      0       0       0       0       0       0        0    0\r\n##   0.916666666666667      1      0       0       0       0       0       0        0    0\r\n##   1                    275      0       0       0       0       0       0        0    0\r\n##   1.5                    2      0       0       0       0       0       0        0    0\r\n##   2                    308      0       0       0       0       0       0        0    0\r\n##   3                    246      0       0       0       0       0       0        0    0\r\n##   4                    233      0       0       0       0       0       0        0    0\r\n##   5                    242      0       0       0       0       0       0        0    0\r\n##   6                      0    241       0       0       0       0       0        0    0\r\n##   7                      0    256       0       0       0       0       0        0    0\r\n##   8                      0    239       0       0       0       0       0        0    0\r\n##   9                      0    245       0       0       0       0       0        0    0\r\n##   10                     0    214       0       0       0       0       0        0    0\r\n##   11                     0      0     220       0       0       0       0        0    0\r\n##   12                     0      0     224       0       0       0       0        0    0\r\n##   13                     0      0     191       0       0       0       0        0    0\r\n##   14                     0      0     199       0       0       0       0        0    0\r\n##   15                     0      0     206       0       0       0       0        0    0\r\n##   16                     0      0       0     186       0       0       0        0    0\r\n##   17                     0      0       0     164       0       0       0        0    0\r\n##   18                     0      0       0     141       0       0       0        0    0\r\n##   19                     0      0       0     130       0       0       0        0    0\r\n##   20                     0      0       0     149       0       0       0        0    0\r\n##   21                     0      0       0       0     158       0       0        0    0\r\n##   22                     0      0       0       0     149       0       0        0    0\r\n##   23                     0      0       0       0     125       0       0        0    0\r\n##   24                     0      0       0       0     144       0       0        0    0\r\n##   25                     0      0       0       0     107       0       0        0    0\r\n##   26                     0      0       0       0     100       0       0        0    0\r\n##   27                     0      0       0       0     117       0       0        0    0\r\n##   28                     0      0       0       0      85       0       0        0    0\r\n##   29                     0      0       0       0      82       0       0        0    0\r\n##   30                     0      0       0       0      82       0       0        0    0\r\n##   31                     0      0       0       0       0      68       0        0    0\r\n##   32                     0      0       0       0       0      84       0        0    0\r\n##   33                     0      0       0       0       0      78       0        0    0\r\n##   34                     0      0       0       0       0      58       0        0    0\r\n##   35                     0      0       0       0       0      58       0        0    0\r\n##   36                     0      0       0       0       0      33       0        0    0\r\n##   37                     0      0       0       0       0      46       0        0    0\r\n##   38                     0      0       0       0       0      45       0        0    0\r\n##   39                     0      0       0       0       0      45       0        0    0\r\n##   40                     0      0       0       0       0      32       0        0    0\r\n##   41                     0      0       0       0       0      34       0        0    0\r\n##   42                     0      0       0       0       0      26       0        0    0\r\n##   43                     0      0       0       0       0      31       0        0    0\r\n##   44                     0      0       0       0       0      24       0        0    0\r\n##   45                     0      0       0       0       0      27       0        0    0\r\n##   46                     0      0       0       0       0      25       0        0    0\r\n##   47                     0      0       0       0       0      16       0        0    0\r\n##   48                     0      0       0       0       0      21       0        0    0\r\n##   49                     0      0       0       0       0      15       0        0    0\r\n##   50                     0      0       0       0       0      12       0        0    0\r\n##   51                     0      0       0       0       0       0      13        0    0\r\n##   52                     0      0       0       0       0       0       7        0    0\r\n##   53                     0      0       0       0       0       0       4        0    0\r\n##   54                     0      0       0       0       0       0       6        0    0\r\n##   55                     0      0       0       0       0       0       9        0    0\r\n##   56                     0      0       0       0       0       0       7        0    0\r\n##   57                     0      0       0       0       0       0       9        0    0\r\n##   58                     0      0       0       0       0       0       6        0    0\r\n##   59                     0      0       0       0       0       0       5        0    0\r\n##   60                     0      0       0       0       0       0       4        0    0\r\n##   61                     0      0       0       0       0       0       2        0    0\r\n##   62                     0      0       0       0       0       0       1        0    0\r\n##   63                     0      0       0       0       0       0       5        0    0\r\n##   64                     0      0       0       0       0       0       1        0    0\r\n##   65                     0      0       0       0       0       0       5        0    0\r\n##   66                     0      0       0       0       0       0       3        0    0\r\n##   67                     0      0       0       0       0       0       2        0    0\r\n##   68                     0      0       0       0       0       0       1        0    0\r\n##   69                     0      0       0       0       0       0       3        0    0\r\n##   70                     0      0       0       0       0       0       1        0    0\r\n##   72                     0      0       0       0       0       0       0        1    0\r\n##   73                     0      0       0       0       0       0       0        3    0\r\n##   76                     0      0       0       0       0       0       0        1    0\r\n##   84                     0      0       0       0       0       0       0        1    0\r\n##   <NA>                   0      0       0       0       0       0       0        0  107\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),  # same breaks as above\n      right = FALSE,                # include each *lower* break point\n      include.lowest = TRUE         # include *highest* value *highest* group\n      ))                                                 \n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    [0,5)   [5,10)  [10,15)  [15,20)  [20,30)  [30,50)  [50,70) [70,100]     <NA> \r\n##     1227     1223     1048      827     1216      848      105        7      107\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),  # same breaks as above\n      right = FALSE,                # include each *lower* break point\n      include.lowest = TRUE,        # include *highest* value *highest* group\n      labels = c(\"0-4\", \"5-9\", \"10-14\",\n                 \"15-19\", \"20-29\", \"30-49\",\n                 \"50-69\", \"70-100\")\n      ))\n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    0-4    5-9  10-14  15-19  20-29  30-49  50-69 70-100   <NA> \r\n##   1227   1223   1048    827   1216    848    105      7    107\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(age_years,\n                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n                          right = FALSE,\n                          include.lowest = TRUE,        \n                          labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\",\n                                     \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n         # convert to class Character, and replace NA with \"Missing\"\n         age_cat = replace_na(as.character(age_cat), \"Missing\"))\n\n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##     0-4   10-14   15-19   20-29   30-49     5-9   50-69  70-100 Missing    <NA> \r\n##    1227    1048     827    1216     848    1223     105       7     107       0\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(age_years,\n                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n                          right = FALSE,\n                          include.lowest = TRUE,        \n                          labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\",\n                                     \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n         # convert to class Character, and replace NA with \"Missing\"\n         age_cat = replace_na(as.character(age_cat), \"Missing\"),\n         \n         # re-classify age_cat as Factor, with correct level order and new \"Missing\" level\n         age_cat = factor(age_cat, levels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\",\n                                              \"30-49\", \"50-69\", \"70-100\", \"Missing\")))    \n  \n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##     0-4     5-9   10-14   15-19   20-29   30-49   50-69  70-100 Missing    <NA> \r\n##    1227    1223    1048     827    1216     848     105       7     107       0\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq+1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)"},{"path":"cleaning-data-and-core-functions.html","id":"quantile-breaks","chapter":"8 Cleaning data and core functions","heading":"Quantile breaks","text":"Make breaks quantile(). stats package comes base R.can use break points age_categories() cut().","code":"\nage_quantiles <- quantile(linelist$age_years, c(0, .25, .50, .75, .90, .95), na.rm=T)\nage_quantiles##  0% 25% 50% 75% 90% 95% \r\n##   0   6  13  23  33  41\n# to return only the numbers use unname()\nage_quantiles <- unname(age_quantiles)\nage_quantiles## [1]  0  6 13 23 33 41"},{"path":"cleaning-data-and-core-functions.html","id":"case_when","chapter":"8 Cleaning data and core functions","heading":"case_when()","text":"dplyr function case_when() can also used create numeric categories.Allows explicit setting break point inclusion/exclusionAllows designation label NA values one stepMore complicated codeAllow flexibility include variables logicIf using case_when() please review proper use described earlier page, logic order assignment important understand avoid errors.CAUTION: case_when() right-hand side values must class. Thus, categories character values (e.g. “20-30 years”) designated outcome NA age values must also character (either “Missing”, special NA_character_ instead NA).need designate column factor (wrapping case_when() function factor()) provide ordering factor levels using levels = argument close case_when() function. using cut(), factor ordering levels done automatically.now view results table new column:","code":"\nlinelist <- linelist %>% \n  mutate(\n    age_cat = factor(case_when(\n      # provide the case_when logic and outcomes\n      age_years >= 0 & age_years < 5     ~ \"0-4\",          \n      age_years >= 5 & age_years < 10    ~ \"5-9\",\n      age_years >= 10 & age_years < 15   ~ \"10-14\",\n      age_years >= 15 & age_years < 20   ~ \"15-19\",\n      age_years >= 20 & age_years < 30   ~ \"20-29\",\n      age_years >= 30 & age_years < 50   ~ \"30-49\",\n      age_years >= 50 & age_years < 70   ~ \"50-69\",\n      age_years >= 45 & age_years <= 100 ~ \"70-100\",\n      is.na(age_years)                   ~ \"Missing\",      # if age_years is missing\n      TRUE                               ~ \"Check value\"), # trigger for review\n      \n      # define the levels order for factor()\n      levels = c(\"0-4\",\"5-9\", \"10-14\",\n                 \"15-19\", \"20-29\", \"30-49\",\n                 \"50-69\", \"70-100\", \"Missing\", \"Check value\")))\ntable(linelist$age_cat, useNA = \"always\")## \r\n##         0-4         5-9       10-14       15-19       20-29       30-49       50-69      70-100     Missing Check value        <NA> \r\n##        1227        1223        1048         827        1216         848         105           7         107           0           0"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-2","chapter":"8 Cleaning data and core functions","heading":"Add to pipe chain","text":", code create two categorical age columns added cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))"},{"path":"cleaning-data-and-core-functions.html","id":"add-rows","chapter":"8 Cleaning data and core functions","heading":"8.10 Add rows","text":"Remember column must contain values one class (either character, numeric, logical, etc.). adding row requires nuance maintain .Use ... place row want add. .= 3 put new row 3rd row. default behavior add row end. Columns specified left empty.new row number may look strange (“…23”) row numbers pre-existing rows changed. using command twice, examine/test insertion carefully.class provide see error like :(inserting row date value, remember wrap date function .Date() like .Date(\"2020-10-10\")).","code":"\nlinelist <- linelist %>% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)Error: Can't combine ..1$infection date <date> and ..2$infection date <character>."},{"path":"cleaning-data-and-core-functions.html","id":"filter-rows","chapter":"8 Cleaning data and core functions","heading":"8.11 Filter rows","text":"typical early cleaning step filter dataframe specific rows using dplyr verb filter(). Within filter(), give logic must TRUE row dataset kept.shown filter rows based simple complex logical conditions, filter/subset rows stand-alone command base R","code":""},{"path":"cleaning-data-and-core-functions.html","id":"simple-filter","chapter":"8 Cleaning data and core functions","heading":"Simple filter()","text":"simple example re-defines dataframe linelist , filtered rows meet logical condition. rows logical statement within parentheses TRUE kept.case, logical statement !.na(case_id), asking whether value column case_id missing (NA). Thus, rows case_id missing kept.filter applied, number rows linelist 6608.filter applied, number rows linelist 6473.","code":"\nlinelist <- linelist %>% \n  filter(!is.na(case_id))  # keep only rows where case_id is not missing"},{"path":"cleaning-data-and-core-functions.html","id":"complex-filter","chapter":"8 Cleaning data and core functions","heading":"Complex filter()","text":"complex example using filter():","code":""},{"path":"cleaning-data-and-core-functions.html","id":"examine-the-data","chapter":"8 Cleaning data and core functions","heading":"Examine the data","text":"simple one-line command create histogram onset dates. See second smaller outbreak 2012-2013 also included raw dataset. analyses, want remove entries earlier outbreak.","code":"\nhist(linelist$date_onset, breaks = 50)"},{"path":"cleaning-data-and-core-functions.html","id":"how-filters-handle-missing-numeric-and-date-values","chapter":"8 Cleaning data and core functions","heading":"How filters handle missing numeric and date values","text":"Can just filter date_onset rows June 2013? Caution! Applying code filter(date_onset > .Date(\"2013-06-01\"))) remove rows later epidemic missing date onset!DANGER: Filtering greater (>) less (<) date number can remove rows missing values (NA)! NA treated infinitely large small.(See page Working dates information working dates package lubridate)","code":""},{"path":"cleaning-data-and-core-functions.html","id":"design-the-filter","chapter":"8 Cleaning data and core functions","heading":"Design the filter","text":"Examine cross-tabulation make sure exclude correct rows:criteria can filter remove first outbreak (2012 & 2013) dataset? see :first epidemic 2012 & 2013 occurred Hospital , Hospital B, also 10 cases Port Hospital.Hospitals & B cases second epidemic, Port Hospital .want exclude:585 rows onset 2012 2013 either hospital , B, Port:\r\nExclude 559 rows onset 2012 2013\r\nExclude 26 rows Hospitals & B missing onset dates\r\nexclude 256 rows missing onset dates.\r\nExclude 559 rows onset 2012 2013Exclude 26 rows Hospitals & B missing onset datesDo exclude 256 rows missing onset dates.start linelist nrow(linelist). filter statement:re-make cross-tabulation, see Hospitals & B removed completely, 10 Port Hospital cases 2012 & 2013 removed, values - just wanted.Multiple statements can included within one filter command (separated commas), can always pipe separate filter() command clarity.Note: readers may notice easier just filter date_hospitalisation 100% complete missing values. true. date_onset used purposes demonstrating complex filter.","code":"\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\r\n## Hospital                               2012 2013 2014 2015 <NA>\r\n##   Central Hospital                        0    0  342   94   18\r\n##   Hospital A                            229   46    0    0   13\r\n##   Hospital B                            227   47    0    0   13\r\n##   Military Hospital                       0    0  666  196   34\r\n##   Missing                                 0    0 1090  308   71\r\n##   Other                                   0    0  668  172   45\r\n##   Port Hospital                           9    1 1348  339   75\r\n##   St. Mark's Maternity Hospital (SMMH)    0    0  318   91   13\r\n##   <NA>                                    0    0    0    0    0\nlinelist <- linelist %>% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)## [1] 5888\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\r\n## Hospital                               2014 2015 <NA>\r\n##   Central Hospital                      342   94   18\r\n##   Military Hospital                     666  196   34\r\n##   Missing                              1090  308   71\r\n##   Other                                 668  172   45\r\n##   Port Hospital                        1348  339   75\r\n##   St. Mark's Maternity Hospital (SMMH)  318   91   13\r\n##   <NA>                                    0    0    0"},{"path":"cleaning-data-and-core-functions.html","id":"standalone-1","chapter":"8 Cleaning data and core functions","heading":"Standalone","text":"Filtering can also done stand-alone command (part pipe chain). Like dplyr verbs, case first argument must dataset .can also use base R subset using square brackets reflect [rows, columns] want retain.TIP: Use bracket-subset syntax View() quickly review records.","code":"\n# dataframe <- filter(dataframe, condition(s) for rows to keep)\n\nlinelist <- filter(linelist, !is.na(case_id))\n# dataframe <- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist <- linelist[!is.na(case_id), ]"},{"path":"cleaning-data-and-core-functions.html","id":"quickly-review-records","chapter":"8 Cleaning data and core functions","heading":"Quickly review records","text":"base R syntax can handy want quickly view subset rows columns. Use base R View() command (note capital “V”) around [ ] subset want see. result appear dataframe RStudio viewer panel. example, want review onset hospitalization dates 3 specific cases:View linelist viewer panel:View specific data three cases:Note: command can also written dplyr verbs filter() select() :","code":"\nView(linelist)\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])\nView(linelist %>%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %>%\n       select(date_onset, date_hospitalisation))"},{"path":"cleaning-data-and-core-functions.html","id":"add-to-pipe-chain-3","chapter":"8 Cleaning data and core functions","heading":"Add to pipe chain","text":"","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))"},{"path":"cleaning-data-and-core-functions.html","id":"row-wise-calculations","chapter":"8 Cleaning data and core functions","heading":"8.12 Row-wise calculations","text":"want perform calculation within row, can use rowwise() dplyr. See vignette row-wise calculationsFor example, code applies rowwise() creates new column sums number symptoms per case:","code":"\nlinelist <- linelist %>%\n  rowwise() %>%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\"))## [1] \"2014-04-17\"## [1] \"2014-04-19\""},{"path":"working-with-dates.html","id":"working-with-dates","chapter":"9 Working with dates","heading":"9 Working with dates","text":"","code":""},{"path":"working-with-dates.html","id":"overview-2","chapter":"9 Working with dates","heading":"9.1 Overview","text":"Working dates R can difficult working object classes. , offer tools example make process less painful. Luckily, dates can wrangled easily practice, set helpful packages.Upon import raw data, R often interprets dates character objects - means used general date operations making time series calculating time intervals. make matters difficult, many ways date can formatted must help R know part date represents (month, day, hour, etc.).Dates R class object - Date class. noted also class stores objects date time. Date time objects formally referred /POSIXt, POSIXct, /POSIXlt classes (difference isn’t important). objects informally referred datetime classes.important make R recognize column contains dates.Dates object class can tricky work .present several ways convert date columns Date class.","code":""},{"path":"working-with-dates.html","id":"preparation","chapter":"9 Working with dates","heading":"9.2 Preparation","text":"","code":""},{"path":"working-with-dates.html","id":"load-packages-1","chapter":"9 Working with dates","heading":"Load packages","text":"code chunk shows loading packages required page. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\n# Checks if package is installed, installs if necessary, and loads package for current session\n\npacman::p_load(\n  lubridate,  # general package for handling and converting dates  \n  linelist,   # has function to \"guess\" messy dates\n  aweek,      # another option for converting dates to weeks, and weeks to dates\n  zoo,        # additional date/time functions\n  tidyverse,  # data management and visualization  \n  rio)        # data import/export"},{"path":"working-with-dates.html","id":"import-data-1","chapter":"9 Working with dates","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow along step--step, see instruction Download book data page.","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"working-with-dates.html","id":"current-date-and-time","chapter":"9 Working with dates","heading":"9.3 Current date and time","text":"can get system date system datetime following base R.lubridate package can also returned today() now(), respectively. date() returns current date time weekday month names.","code":"\n# get the system date - this is a DATE class\nSys.Date()## [1] \"2021-03-30\"\n# get the system time - this is a DATETIME class\nSys.time()## [1] \"2021-03-30 21:14:55 EDT\""},{"path":"working-with-dates.html","id":"convert-to-date-class","chapter":"9 Working with dates","heading":"9.4 Convert to Date class","text":"importing dataset R, date column values may look like “1989/12/30”, “05/06/2014”, “13 Jan 2020”. cases, R likely still treating values Character values. R must told values dates… format date (part Day, Month, Year, etc).told, R converts values class Date. background, R store dates numbers (number days “origin” date 1 Jan 1970). interface date number often, allows R treat dates continuous variables allow special operations calculating distance dates.default, values class Date R displayed YYYY-MM-DD. Later section discuss change display date values.present two approaches converting column character values class Date.TIP: can check current class column base R function class(), like class(linelist$date_onset).","code":""},{"path":"working-with-dates.html","id":"base-r","chapter":"9 Working with dates","heading":"base R","text":".Date() standard, base R function convert object column class Date (note capitalization “D”).Use .Date() requires :specify existing format raw character date origin date suppling dates numbers (see section Excel dates)used character column, date values must format (case, try guess_dates() linelist package)First, check class column class() base R. unsure confused class data (e.g. see “POSIXct”, etc.) can easiest first convert column class Character .character(), convert class Date.Second, within .Date() function, use format = argument tell R current format character date components - characters refer month, day, year, separated. values already one R’s standard date formats (“YYYY-MM-DD” “YYYY/MM/DD”) format = argument necessary.format =, provide character string (quotes) represents current date format using special “strptime” abbreviations . example, character dates currently format “DD/MM/YYYY”, like “24/04/1968”, use format = \"%d/%m/%Y\" convert values dates. Putting format quotation marks necessary. don’t forget slashes dashes!strptime abbreviations listed . can see complete list running ?strptime.%d = Day number month (5, 17, 28, etc.)\r\n%j = Day number year (Julian day 001-366)\r\n%= Abbreviated weekday (Mon, Tue, Wed, etc.)\r\n%= Full weekday (Monday, Tuesday, etc.)\r\n%w = Weekday number (0-6, Sunday 0)\r\n%u = Weekday number (1-7, Monday 1)\r\n%W = Week number (00-53, Monday week start)\r\n%U = Week number (01-53, Sunday week start)\r\n%m = Month number (e.g. 01, 02, 03, 04)\r\n%b = Abbreviated month (Jan, Feb, etc.)\r\n%B = Full month (January, February, etc.)\r\n%y = 2-digit year (e.g. 89)\r\n%Y = 4-digit year (e.g. 1989)\r\n%h = hours (24-hr clock)\r\n%m = minutes\r\n%s = seconds\r\n%z = offset GMT\r\n%Z = Time zone (character)TIP: format = argument telling R format want dates , rather identify date parts run command.TIP: sure format = argument use date-part separator (e.g. /, -, space) present dates.values class Date, R default display standard format, YYYY-MM-DD.","code":"\n# Convert to class date\nlinelist <- linelist %>% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))"},{"path":"working-with-dates.html","id":"lubridate","chapter":"9 Working with dates","heading":"lubridate","text":"Converting character objects dates can made easier using lubridate package. tidyverse package designed make working dates times simple consistent base R. reasons, lubridate often considered gold-standard package dates time, recommended whenever working .lubridate package provides several different helper functions designed convert character objects dates intuitive, lenient way specifying format .Date(). functions specific rough date format, allow variety separators, synonyms dates (e.g. 01 vs Jan vs January) - named abbreviations date formats.ymd() function flexibly converts date values supplied year, month, day.mdy() function flexibly converts date values supplied month, day, year.dmy() function flexibly converts date values supplied day, month, year.using piping tidyverse, converting character column dates lubridate might look like :complete, can run class() verify class columnOnce values class Date, R default display standard format, YYYY-MM-DD.","code":"\n# install/load lubridate \npacman::p_load(lubridate)\n# read date in year-month-day format\nymd(\"2020-10-11\")## [1] \"2020-10-11\"\nymd(\"20201011\")## [1] \"2020-10-11\"\n# read date in month-day-year format\nmdy(\"10/11/2020\")## [1] \"2020-10-11\"\nmdy(\"Oct 11 20\")## [1] \"2020-10-11\"\n# read date in day-month-year format\ndmy(\"11 10 2020\")## [1] \"2020-10-11\"\ndmy(\"11 October 2020\")## [1] \"2020-10-11\"\nlinelist <- linelist %>%\n  mutate(date_onset = lubridate::dmy(date_onset))\n# Check the class of the column\nclass(linelist$date_onset)  "},{"path":"working-with-dates.html","id":"combine-columns","chapter":"9 Working with dates","heading":"Combine columns","text":"can use lubridate functions make_date() make_datetime() combine multiple numeric columns one date column. example numeric columns day, month, year data frame linelist:","code":"\nlinelist <- linelist %>% \n  mutate(date = make_date(year = year, month = month, day = day))"},{"path":"working-with-dates.html","id":"excel-numeric-dates","chapter":"9 Working with dates","heading":"9.5 Excel (numeric) dates","text":"background, software store dates numbers. R stores dates origin 1st January, 1970. Thus, run .numeric(.Date(\"1970-01-01)) get 0.Microsoft Excel stores dates origin either December 30, 1899 (Windows) January 1, 1904 (Mac), depending operating system. See Microsoft guidance information.Excel dates often import R numeric values instead characters. dataset imported Excel shows dates numbers characters like “41369”… use .Date() (lubridate’s as_date() function) convert, instead supplying “format” , supply Excel origin date argument origin =.work Excel date stored R character type, sure ensure date class Numeric Double!NOTE: provide origin date R’s default date format (“YYYY-MM-DD”).","code":"\n# An example of providing the Excel 'origin date' when converting Excel number dates\ndata_cleaned <- data %>% \n  mutate(date_onset = as.Date(as.numeric(date_onset), origin = \"1899-12-30\")) # convert to numeric, then convert to date"},{"path":"working-with-dates.html","id":"messy-dates","chapter":"9 Working with dates","heading":"9.6 Messy dates","text":"function guess_dates() linelist package attempts read “messy” date column containing dates many different formats convert dates standard format. can read online guess_dates(). guess_dates() yet available CRAN R 4.0.2, try install via pacman::p_load_gh(\"reconhub/linelist\").example guess_dates see vector following character dates “03 Jan 2018”, “07/03/1982”, “08/20/85” convert class Date : 2018-01-03, 1982-03-07, 1985-08-20.optional arguments guess_dates() might include :error_tolerance - proportion entries identified dates tolerated (defaults 0.1 10%)last_date - last valid date (defaults current date)first_date - first valid date. Defaults fifty years last_date.","code":"\nlinelist::guess_dates(c(\"03 Jan 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))## [1] \"2018-01-03\" \"1982-03-07\" \"1985-08-20\"# An example using guess_dates on the column dater_onset\r\nlinelist <- linelist %>%                 # the dataset is called linelist\r\n  mutate(\r\n    date_onset = linelist::guess_dates(  # the guess_dates() from package \"linelist\"\r\n      date_onset,\r\n      error_tolerance = 0.1,\r\n      first_date = \"2016-01-01\"\r\n    )"},{"path":"working-with-dates.html","id":"convert-to-datetime-classes","chapter":"9 Working with dates","heading":"9.7 Convert to datetime classes","text":"previously mentioned, R also supports datetime class - column contains date time information. Date class, often need converted character objects datetime objects.","code":""},{"path":"working-with-dates.html","id":"convert-dates-with-times","chapter":"9 Working with dates","heading":"Convert dates with times","text":"standard datetime object formatted date first, followed time component - example 01 Jan 2020, 16:30. dates, many ways can formatted, numerous levels precision (hours, minutes, seconds) can supplied.Luckily, lubridate helper functions also exist help convert strings datetime objects. functions extensions date helper functions, _h (hours supplied), _hm (hours minutes supplied), _hms (hours, minutes, seconds supplied) appended end (e.g. dmy_hms()). can used shown:Convert datetime hours datetime objectConvert datetime hours minutes datetime objectConvert datetime hours, minutes, seconds datetime objectYou can supply time zone ignored. See section later page time zones.working dataframe, time date columns can combined create datetime column using str_glue() stringr package appropriate lubridate function. See page Characters strings details stringr.\r\nexample, linelist data frame column format “hours:minutes”. convert datetime follow steps:Create “clean” time admission column missing values filled-column median. lubridate won’t operate missing values. combine column date_hospitalisation, use function ymd_hm() convert.","code":"\nymd_h(\"2020-01-01 16hrs\")## [1] \"2020-01-01 16:00:00 UTC\"\nymd_h(\"2020-01-01 4PM\")## [1] \"2020-01-01 16:00:00 UTC\"\ndmy_hm(\"Jan 1st 2020 16:20\")## Warning: All formats failed to parse. No formats found.## [1] NA\nmdy_hms(\"01 January 20, 16:20:40\")## Warning: All formats failed to parse. No formats found.## [1] NA\nmdy_hms(\"01 January 20, 16:20:40 PST\")## Warning: All formats failed to parse. No formats found.## [1] NA# packages\r\npacman::p_load(tidyverse, lubridate, stringr)\r\n\r\n# time_admission is a column in hours:minutes\r\nlinelist <- linelist %>%\r\n  \r\n  # when time of admission is not given, assign the median admission time\r\n  mutate(\r\n    time_admission_clean = ifelse(\r\n      is.na(time_admission),\r\n      median(time_admission),\r\n      time_admission\r\n  ) %>%\r\n  \r\n    # use str_glue() to combine two columns to create a character column\r\n    # and then use ymd_hm() to convert to datetime\r\n  mutate(\r\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %>% \r\n      ymd_hm()\r\n  )"},{"path":"working-with-dates.html","id":"convert-times-alone","chapter":"9 Working with dates","heading":"Convert times alone","text":"data contain character time (hours minutes), can convert manipulate times using strptime() base R. example, get difference two times:Note however without date value provided, assumes date today. combine string date string time together see use stringr section just . Read strptime() .","code":"\n# raw character times\ntime1 <- \"13:45\" \ntime2 <- \"15:20\"\n\n# Times converted to a datetime class\ntime1_clean <- strptime(time1, format = \"%H:%M\")\ntime2_clean <- strptime(time2, format = \"%H:%M\")\n\n# Difference is of class \"difftime\" by default, here converted to numeric hours \nas.numeric(time2_clean - time1_clean)   # difference in hours## [1] 1.58"},{"path":"working-with-dates.html","id":"extract-time","chapter":"9 Working with dates","heading":"Extract time","text":"can extract elements time hour(), minute(), second() lubridate.example extracting hour, using classify times. begin column time_admission, class Character format “HH:MM”. First, strptime() used described convert characters datetime class. , hour extracted hour(), returning number 0-24. Finally, column time_period created using logic case_when() classify rows Morning/Afternoon/Evening/Night based hour admission.learn case_when() see page Cleaning data core functions.","code":"\nlinelist <- linelist %>%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %>%\n  mutate(time_period = case_when(\n    hour_admit > 06 & hour_admit < 12 ~ \"Morning\",\n    hour_admit >= 12 & hour_admit < 17 ~ \"Afternoon\",\n    hour_admit >= 17 & hour_admit < 21 ~ \"Evening\",\n    hour_admit >=21 | hour_admit <= 6 ~ \"Night\"))"},{"path":"working-with-dates.html","id":"working-with-dates-1","chapter":"9 Working with dates","heading":"9.8 Working with dates","text":"lubridate can also used variety functions, extracting aspects date/datetime, performing date arithmetic, calculating date intervalsHere define date use examples:can extract common aspects month, day, weekday:can also extract time components datetime object column. can useful want view distribution admission times.several options retrieve weeks. See section Epidemiological weeks .Note seeking display date certain way (e.g. “Jan 2020” “Thursday 20 March” “Week 20, 1977”) can flexibly described section Date display.","code":"\n# create object of class Date\nexample_date <- ymd(\"2020-03-01\")\nmonth(example_date)  # month number## [1] 3\nday(example_date)    # day (number) of the month## [1] 1\nwday(example_date)   # day number of the week (1-7)## [1] 1\nexample_datetime <- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime)     # extract hour\nminute(example_datetime)   # extract minute\nsecond(example_datetime)   # extract second"},{"path":"working-with-dates.html","id":"date-math","chapter":"9 Working with dates","heading":"Date math","text":"can add certain numbers days weeks using respective function lubridate.","code":"\n# add 3 days to this date\nexample_date + days(3)## [1] \"2020-03-04\"\n# add 7 weeks and subtract two days from this date\nexample_date + weeks(7) - days(2)## [1] \"2020-04-17\""},{"path":"working-with-dates.html","id":"date-intervals","chapter":"9 Working with dates","heading":"Date intervals","text":"difference dates can calculated :Ensure dates class dateUse subtraction return “difftime” difference two datesIf necessary, convert result numeric class perform subsequent mathematical calculationsBelow interval two dates calculated displayedYou can find intervals using subtraction “minus” symbol values class Date. Note, however class returned value “difftime” displayed , numeric.subsequent operations “difftime”, convert numeric .numeric().can brought together work data - example:dataframe format (.e. working linelist), either dates missing, operation fail row. result NA instead numeric value. using column calculations, sure set na.rm option TRUE. example:","code":"\n# find the interval between this date and Feb 20 2020 \noutput <- example_date - ymd(\"2020-02-20\")\noutput    # print## Time difference of 10 days\nclass(output)## [1] \"difftime\"\npacman::p_load(lubridate, tidyverse)   # load packages\n\nlinelist <- linelist %>%\n  \n  # convert date of onset from character to date objects by specifying dmy format\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %>%\n  \n  # filter out all cases without onset in march\n  filter(month(date_onset) == 3) %>%\n    \n  # find the difference in days between onset and hospitalisation\n  mutate(onset_to_hosp_days = date_hospitalisation - date_of_onset)\n# add a new column\n# calculating the number of days between symptom onset and patient outcome\nlinelist_delay <- linelist_cleaned %>%\n  mutate(\n    days_onset_to_outcome = as.double(date_of_outcome - date_of_onset)\n  )\n\n# calculate the median number of days to outcome for all cases where data are available\nmed_days_outcome <- median(linelist_delay$dats_onset_to_outcome, na.rm = T)\n\n# often this operation might be done only on a subset of data cases, e.g. those who died\n# this is easy to look at and will be explained later in the handbook"},{"path":"working-with-dates.html","id":"date-display","chapter":"9 Working with dates","heading":"9.9 Date display","text":"dates correct class, often want display differently, example display “Monday 05 January” instead “2018-01-05”. may also want adjust display order group rows date elements displayed - example group month-year.Adjust date display base R function format(). function accepts character string (quotes) specifying desired output format “%” strptime abbreviation (syntax used .Date()). common abbreviations.Note: using format() convert values class Character, generally used towards end analysis display purposes ! can see complete list running ?strptime.%d = Day number month (5, 17, 28, etc.)\r\n%j = Day number year (Julian day 001-366)\r\n%= Abbreviated weekday (Mon, Tue, Wed, etc.)\r\n%= Full weekday (Monday, Tuesday, etc.)\r\n%w = Weekday number (0-6, Sunday 0)\r\n%u = Weekday number (1-7, Monday 1)\r\n%W = Week number (00-53, Monday week start)\r\n%U = Week number (01-53, Sunday week start)\r\n%m = Month number (e.g. 01, 02, 03, 04)\r\n%b = Abbreviated month (Jan, Feb, etc.)\r\n%B = Full month (January, February, etc.)\r\n%y = 2-digit year (e.g. 89)\r\n%Y = 4-digit year (e.g. 1989)\r\n%h = hours (24-hr clock)\r\n%m = minutes\r\n%s = seconds\r\n%z = offset GMT\r\n%Z = Time zone (character)example formatting today’s date:","code":"\n# today's date, with formatting\nformat(Sys.Date(), format = \"%d %B %Y\")## [1] \"30 March 2021\"\n# easy way to get full date and time (no formatting)\ndate()## [1] \"Tue Mar 30 21:14:56 2021\"\n# formatted date, time, and time zone (using paste0() function)\npaste0(\n  format(Sys.Date(), format = \"%A, %B %d %Y, %z  %Z, \"), \n  format(Sys.time(), format = \"%H:%M:%S\")\n)## [1] \"Tuesday, March 30 2021, +0000  UTC, 21:14:56\"\n# Using format to display weeks\nformat(Sys.Date(), \"%Y Week %W\")## [1] \"2021 Week 13\""},{"path":"working-with-dates.html","id":"month-year","chapter":"9 Working with dates","heading":"Month-Year","text":"convert Date column Month-year format, suggest use function .yearmon() zoo package. converts date class “yearmon” retains proper ordering. contract, using format(column, \"%Y %B) convert class Character order values alphabetically., new column yearmon created column date_onset, using .yearmon() function. default ordering resulting values given table.contrast, can see using format() achieve desired display, correct ordering.Note: working within ggplot() want adjust dates displayed , may sufficient provide strptime format date_labels = argument scale_x_date() - can use “%b %Y” “%Y %b”.zoo also offers function .yearqtr(), can use scale_x_yearmon() using ggplot().","code":"\n# create new column \ntest_zoo <- linelist %>% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# print table\ntable(test_zoo$yearmon)## \r\n## Apr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 Dec 2014 Jan 2015 Feb 2015 Mar 2015 Apr 2015 \r\n##        7       64      100      226      528     1070     1112      763      562      431      306      277      186\n# create new column\ntest_format <- linelist %>% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# print table\ntable(test_format$yearmon)## \r\n## Apr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 Mar 2015 May 2014 Nov 2014 Oct 2014 Sep 2014 \r\n##        7      186      528      562      306      431      226      100      277       64      763     1112     1070"},{"path":"working-with-dates.html","id":"epidemiological-weeks","chapter":"9 Working with dates","heading":"9.10 Epidemiological weeks","text":"","code":""},{"path":"working-with-dates.html","id":"lubridate-1","chapter":"9 Working with dates","heading":"lubridate","text":"See page Grouping data examples grouping date. briefly describe grouping data weeks.generally recommend using floor_date() function lubridate, argument unit = \"week\". rounds date “start” week, defined argument week_start =. default week start 1 (Mondays) can specify day week start (e.g. 7 Sundays). floor_date() can also used round time units setting unit = “second”, “minute”, “hour”, “day”, “month”, “year”).returned value start date week, Date class. Date class useful plotting data, easily recognized ordered correctly ggplot().See section Date display tips adjust display dates plot. example, plotting epicurve format date display providing desired strptime “%” nomenclature. example, use “%Y-%W” “%Y-%U” return year week number (given Monday Sunday week start, respectively).","code":""},{"path":"working-with-dates.html","id":"weekly-counts","chapter":"9 Working with dates","heading":"Weekly counts","text":"See page Grouping data thorough explanation grouping data count(), group_by(), summarise(). brief example .Create new ‘week’ column mutate(), using floor_date() `unit = “week”Get counts rows (cases) per week count(); filter cases missing dateFollow-complete() tidyr ensure weeks appear data - even rows/cases.first rows resulting data frame:","code":"\n# Make aggregated dataset of weekly case counts\nweekly_counts <- linelist %>% \n  filter(!is.na(date_onset)) %>%    # remove cases missing onset date\n  mutate(week = floor_date(         # make new column, week of onset\n    date_onset,\n    unit = \"week\")) %>%            \n  count(week) %>%                   # group data by week and count rows per group\n  tidyr::complete(week = seq.Date(  # ensure all weeks are present, even those with no cases reported\n    from = min(week),               \n    to = max(week),\n    by = \"week\"))"},{"path":"working-with-dates.html","id":"epiweek-alternatives","chapter":"9 Working with dates","heading":"Epiweek alternatives","text":"Note lubridate also functions week(), epiweek(), isoweek(), slightly different start dates nuances. Generally speaking though, floor_date() need. Read details functions entering ?week console reading documentation .might consider using package aweek set epidemiological weeks. can read RECON website. functions date2week() week2date() can set week start day week_start = \"Monday\". package easiest want “week”-style outputs (e.g. “2020-W12”). Another advantage aweek date2week() applied date column, returned column (week format) automatically class Factor includes levels weeks time span (avoids extra step complete() described ). However, aweek functionality round dates time units months, years, etc.\r\nAnother alternative time series also works well show “week” format (“2020 W12”) yearweek() package tsibble, demonstrated page Time series outbreak detection.","code":""},{"path":"working-with-dates.html","id":"converting-datestime-zones","chapter":"9 Working with dates","heading":"9.11 Converting dates/time zones","text":"data present different time time zones, can often important standardise data unified time zone. can present challenge, time zone component data must coded manually cases.R, datetime object timezone component. default, datetime objects carry local time zone computer used - generally specific location rather named timezone, time zones often change locations due daylight savings time. possible accurately compensate time zones without time component date, event date column represents attributed specific time, therefore time shifts measured hours reasonably accounted .deal time zones, number helper functions lubridate can used change time zone datetime object local time zone different time zone. Time zones set attributing valid tz database time zone datetime object. list can found - location using data list, nearby large cities time zone available serve purpose.https://en.wikipedia.org/wiki/List_of_tz_database_time_zonesThis may seem largely abstract, often needed user isn’t working across time zones. One simple example implementation :","code":"\n# assign the current time to a column\ntime_now <- Sys.time()\ntime_now## [1] \"2021-03-30 21:14:57 EDT\"\n# use with_tz() to assign a new timezone to the column, while CHANGING the clock time\ntime_london_real <- with_tz(time_now, \"Europe/London\")\n\n# use force_tz() to assign a new timezone to the column, while KEEPING the clock time\ntime_london_local <- force_tz(time_now, \"Europe/London\")\n\n\n# note that as long as the computer that was used to run this code is NOT set to London time, there will be a difference in the times (the number of hours difference from the computers time zone to london)\n\ntime_london_real - time_london_local## Time difference of 5 hours\n# TODO add when time column is here\n# set the time column to time zone for ebola outbreak \n\n# \"Africa/Lubumbashi\" is the time zone for eastern DRC/Kivu Nord"},{"path":"working-with-dates.html","id":"lagging-and-leading-calculations","chapter":"9 Working with dates","heading":"9.12 Lagging and leading calculations","text":"lead() lag() functions dplyr package help find previous (lagged) subsequent (leading) values vector - typically numeric date vector. useful calculations change/difference time units.Let’s say want calculate difference cases current week previous one. data initially provided weekly counts shown . learn aggregate counts daily weekly see page aggregating (LINK).using lag() lead() order rows dataframe important! - pay attention whether dates/numbers ascending descendingFirst, create new column containing value previous (lagged) week.Control number units back/forward n = (must non-negative integer)Use default = define value placed non-existing rows (e.g. first row lagged value). default NA.Use order_by = TRUE reference column orderedNext, create new column difference two cases columns:can read lead() lag() documentation entering ?lag console.","code":"\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)"},{"path":"working-with-dates.html","id":"dates-miscellaneous","chapter":"9 Working with dates","heading":"9.13 Dates miscellaneous","text":"Sys.Date( ) base R returns current date computerSys.Time() base R returns current time computerdate() lubridate returns current date time.","code":""},{"path":"working-with-dates.html","id":"resources-2","chapter":"9 Working with dates","heading":"9.14 Resources","text":"lubridate tidyverse pagelubridate RStudio cheatsheet\r\nR Data Science page dates timesOnline tutorial\r\nDate formats","code":""},{"path":"factors.html","id":"factors","chapter":"10 Factors","heading":"10 Factors","text":"R, factors allow ordered categorical data. column can converted class numeric, categorical, even logical class factor. case, values stored ordered integer levels, can display assigned labels.column class factor:possible values restricted - values already defined levels rejectedvalues ordered, impacts display tables plotsThis page demonstrates use functions package forcats (short name “categorical variables”) base R functions. also touch upon use lubridate aweek special cases related epiweeks.Factors useful statistical modeling, allows integer values 1/0 evaluated categorically continuously.","code":""},{"path":"factors.html","id":"preparation-1","chapter":"10 Factors","heading":"10.1 Preparation","text":"","code":""},{"path":"factors.html","id":"load-packages-2","chapter":"10 Factors","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,           # import/export\n  here,          # filepaths\n  lubridate,     # working with dates\n  forcats,       # factors\n  aweek,         # create epiweeks with automatic factor levels\n  tidyverse      # data mgmt and viz\n  )"},{"path":"factors.html","id":"import-data-2","chapter":"10 Factors","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.","code":"\n# fake import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"factors.html","id":"example-new-categorical-column","chapter":"10 Factors","heading":"10.1.1 Example: new categorical column","text":"demonstration page use common scenario - creation categorical variable.use existing column days_onset_hosp (days symptom onset hospital admission) classify row one several categorical groupings.can use dplyr function case_when() apply logical criteria row, resulting values new column delay","code":"\nlinelist <- linelist %>% \n  mutate(delay = case_when(\n    days_onset_hosp < 2                        ~ \"<2 days\",\n    days_onset_hosp >= 2 & days_onset_hosp < 5 ~ \"2-5 days\",\n    days_onset_hosp >= 5                       ~ \">5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  "},{"path":"factors.html","id":"non-factor-categorical","chapter":"10 Factors","heading":"10.2 Non-factor categorical","text":"column delay (created Preparation section ) categorical column class Character - yet Factor. Thus, frequency table, see values appear default alphabetical order - order make much intuitive sense:Likewise, make bar plot, values also appear order x-axis. order make sense. (see ggplot tips page ggplot2 - common useful visualization package).","code":"\ntable(linelist$delay, useNA = \"always\")## \r\n##  <2 days  >5 days 2-5 days     <NA> \r\n##     2990      602     2040      256\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay))"},{"path":"factors.html","id":"convert-to-factor","chapter":"10 Factors","heading":"10.3 Convert to factor","text":"initially convert character numeric column class Factor, suggest using base R function factor(). data frame linelist modified column delay converted factor. default order values alpha-numeric.Unless specified, levels still alphabetic (numeric) order. Use base R function levels() see levels time_period ordered. Note NA factor level.can specify levels order initial conversion command levels = argument.","code":"\nlinelist <- linelist %>%\n  mutate(delay = factor(delay))\nlevels(linelist$delay)## [1] \"<2 days\"  \">5 days\"  \"2-5 days\"\nlinelist <- linelist %>%\n  mutate(delay = factor(delay, levels = c(\"<2 days\", \"2-5 days\", \">5 days\")))\nlevels(linelist$delay)## [1] \"<2 days\"  \"2-5 days\" \">5 days\""},{"path":"factors.html","id":"adjust-level-order","chapter":"10 Factors","heading":"10.4 Adjust level order","text":"package forcats offers several useful functions easily adjust order factor’s levels:Use fct_relevel() manually adjust orderUse fct_infreq() reorder frequency (highest lowest)Use fct_inorder() reorder order appearance dataUse fct_reorder() reorder another column (e.g. order time_period levels row’s median delay admission)Use fct_rev() reverse existing orderUse fct_reorder2() reorder final values plotted two columnsThese functions can applied outside plot re-define column, within plot affect just one specific plot.","code":""},{"path":"factors.html","id":"examples-1","chapter":"10 Factors","heading":"Examples","text":"fct_relevel()function used manually order factor levels. Within parentheses, first provide factor column, provide levels desired order (character vector within c()). example redefining column delay (already class Factor) specifying desired order levels.want move one level, can specify fct_relevel() alone give number = argument indicate order . example:define level order data frame. Alternatively, can adjust levels within ggplot, re-ordering levels apply within plot. , delay column mapped x-axis plot wrapped within fct_relevel().Note default x-axis label now quite complicated - can overwrite labs() ggplot.fct_infreq()order frequency value appears data, use fct_infreq(). missing values (NA) automatically included end. can reverse order modifying fct_rev().function can used within ggplot(), shown .example within data frame:fct_reorder()Use function order levels another column. example, order boxplots showing delay median CT value delay group.examples , x-axis delay group, y = axis CT value. boxplots also colored delay group.first example, baseline order levels applies (set earlier page) - increase incrementally updward delay.\r\nsecond example, x-axis column wrapped fct_reorder(), column ct_blood second argument. default order delay median ct_value. alternative function can supplied, e.g. “mean”, “max”.Note explicit grouping steps required prior ggplot() - grouping calculations done internally.fct_reorder2()Use function order legend colors vertical order groups “end” plot. example, lines showing case counts hospital time, can apply fct_reorder2() color = argument within aes(), vertical order hospitals appearing legend aligns order lines terminal end plot. Read function documentation.fct_lump()“lump” together many low-frequency levels “” group, can use function. one following:Set n = argument number groups want keep. values combine “”.set prop = argument proportion want keep. values combine “”.can also change label “” using other_level =. , two -frequent hospitals combined “hospitals”.can also use fct_other() manually assign factor levels “” group. , hospital values aside “Port Hospital” “Central Hospital” combined “”.can use arguments keep =, drop =, can change label “” other_label =.","code":"\n# re-define level order\nlinelist <- linelist %>% \n  mutate(delay = fct_relevel(delay, c(\"<2 days\", \"2-5 days\", \">5 days\")))\n# re-define level order\nlinelist <- linelist %>% \n  mutate(delay = fct_relevel(delay, \"<2 days\", after = 1))\n\nlevels(linelist$delay)## [1] \"2-5 days\" \"<2 days\"  \">5 days\"\n# Incorrect order - no adjustment within ggplot\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay))\n\n# Factor level order adjusted within ggplot\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay, c(\"<2 days\", \"2-5 days\", \">5 days\"))))\n# ordered by frequency\nggplot(data = linelist, aes(x = fct_infreq(delay)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\")\n\n# reversed frequency\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\")\nlinelist %>% \n  mutate(delay = fct_infreq(delay),\n         delay = fct_rev(delay))\n# boxplots ordered by original factor levels\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay,\n        y = ct_blood, \n        fill = delay))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by increasing delay (original factor levels)\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n# boxplots ordered by median CT value\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by median CT value in group\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\nlinelist %>%         # begin with the linelist            \n  count(             # summarise so n = counts of rows by epiweek and by hospital\n    epiweek = lubridate::floor_date(date_onset, \"week\"),  # create and group by epiweeks\n    hospital         # also group by hospital\n    ) %>% \n  \n  ggplot()+           # start plot\n  geom_line(          # make lines\n    aes(x = epiweek,  # x-axis epiweek\n        y = n,        # height in number of rows\n        color = fct_reorder2(hospital, epiweek, n)))+ # grouped by hospital and colors ordered by n value at end of plot\n  labs(color = \"Hospital\")  # change legend title\nggplot(data = linelist)+\n  geom_bar(aes(x = fct_lump(hospital,    # column for x-axis\n                            n = 2,       # keep two most-frequent levels\n                            other_level = \"Other hospitals\"))) # label for \"Other\" group\nlinelist %>% \n  mutate(hospital = fct_other(hospital, keep = c(\"Port Hospital\", \"Central Hospital\"))) %>% \n  select(hospital) %>% \n  table()## .\r\n## Central Hospital    Port Hospital            Other \r\n##              454             1762             3672"},{"path":"factors.html","id":"missing-values-3","chapter":"10 Factors","heading":"10.5 Missing values","text":"NA values column, can easily convert named value “Missing” fct_explicit_na(), performed temporarily column delay:","code":"\nlinelist %>% \n  mutate(delay = fct_explicit_na(delay, na_level = \"Missing\")) %>% \n  select(delay) %>% \n  table(useNA = \"always\")## .\r\n## 2-5 days  <2 days  >5 days  Missing     <NA> \r\n##     2040     2990      602      256        0"},{"path":"factors.html","id":"edit-labels","chapter":"10 Factors","heading":"10.6 Edit labels","text":"Adjust factor labels fct_recode(). remember change underlying values, labels.\r\n, labels factor column delay (grouped days onset admission) edited:old labels:Now labels changed, using syntax fct_recode(column, \"new\" = \"old\",\"new\" = \"old\", \"new\" = \"old\"). Remember NA formal level unless changed (e.g. fct_explicit_na() shown ).","code":"\ntable(linelist$delay, useNA = \"always\")## \r\n## 2-5 days  <2 days  >5 days     <NA> \r\n##     2040     2990      602      256\nlinelist <- linelist %>% \n  mutate(delay = fct_recode(delay,\n                            \"Less than 2 days\" = \"<2 days\",\n                            \"2 to 5 days\"      = \"2-5 days\",\n                            \"More than 5 days\" = \">5 days\"))\n\ntable(linelist$delay)## \r\n##      2 to 5 days Less than 2 days More than 5 days \r\n##             2040             2990              602"},{"path":"factors.html","id":"adddrop-levels","chapter":"10 Factors","heading":"10.7 Add/drop levels","text":"factor want add levels (regardless whether rows values), use fct_expand().See classify “hospital” factor, try change values, error returned:Now can add level “University Hospital”:","code":"\nlinelist <- linelist %>% \n  mutate(hospital = factor(hospital))\n\nlevels(linelist$hospital)## [1] \"Central Hospital\"                     \"Military Hospital\"                    \"Missing\"                             \r\n## [4] \"Other\"                                \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\nlinelist <- linelist %>% \n  mutate(hospital = fct_expand(hospital, \"University Hospital\"))\n\nlevels(linelist$hospital)## [1] \"Central Hospital\"                     \"Military Hospital\"                    \"Missing\"                             \r\n## [4] \"Other\"                                \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\r\n## [7] \"University Hospital\""},{"path":"factors.html","id":"epiweeks","chapter":"10 Factors","heading":"Epiweeks","text":"Please see extensive discussion create epidemiological weeks Grouping data page.\r\nPlease also see Working dates page tips create format epi weeks.","code":""},{"path":"factors.html","id":"floor_date","chapter":"10 Factors","heading":"floor_date()","text":"create epiweeks lubridate’s floor_date(), values returned class Date format YYYY-MM-DD. use plot dates naturally order correctly, need worry class Factor. example, ggplot() histogram onset dates .can adjust display dates axis scale_x_date(). See page Epidemic curves information. can specify “strptime” display format date_labels = argument. formats use “%” placeholders covered Working dates page. Use “%Y” represent 4-digit year, either “%W” “%U” represent week number (Monday Sunday weeks respectively).However, purpose factoring plot, may convert epiweek column (YYYY-MM-DD) different display format (YYYY-WWw) within data frame , convert class Factor. Use format() base R convert display, convert class Factor factor().DANGER: use “Www-YYYY” (“%W-%Y”) display format instead, default alpha-numeric level ordering incorrect (e.g. 01-2015 35-2014).","code":"\nlinelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %>%  # create week column\n  ggplot()+                                                  # begin ggplot\n  geom_histogram(mapping = aes(x = epiweek_date))+           # histogram of date of onset\n  scale_x_date(date_labels = \"%Y-W%W\")                       # adjust disply of dates to be YYYY-WWw\nlinelist <- linelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # create epiweeks (YYYY-MM-DD)\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # Convert to display (YYYY-WWw)\n         epiweek_formatted = factor(epiweek_formatted))       # Convert to factor\n\n# Display levels\nlevels(linelist$epiweek_formatted)##  [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\" \"2014-W19\" \"2014-W20\" \"2014-W21\" \"2014-W22\" \"2014-W23\" \"2014-W24\" \"2014-W25\"\r\n## [14] \"2014-W26\" \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\" \"2014-W31\" \"2014-W32\" \"2014-W33\" \"2014-W34\" \"2014-W35\" \"2014-W36\" \"2014-W37\" \"2014-W38\"\r\n## [27] \"2014-W39\" \"2014-W40\" \"2014-W41\" \"2014-W42\" \"2014-W43\" \"2014-W44\" \"2014-W45\" \"2014-W46\" \"2014-W47\" \"2014-W48\" \"2014-W49\" \"2014-W50\" \"2014-W51\"\r\n## [40] \"2015-W00\" \"2015-W01\" \"2015-W02\" \"2015-W03\" \"2015-W04\" \"2015-W05\" \"2015-W06\" \"2015-W07\" \"2015-W08\" \"2015-W09\" \"2015-W10\" \"2015-W11\" \"2015-W12\"\r\n## [53] \"2015-W13\" \"2015-W14\" \"2015-W15\" \"2015-W16\""},{"path":"factors.html","id":"aweek","chapter":"10 Factors","heading":"aweek","text":"alternative method want convert dates epiweeks within data frame use aweek package function date2week(). can set week_start = set factor = TRUE output column ordered factor. bonus, factor includes levels weeks span - even cases week. ensure create table bar plot weeks appear.See Working dates page information aweek. also offers reverse function week2date().","code":"\ndf <- linelist %>% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)"},{"path":"factors.html","id":"resources-3","chapter":"10 Factors","heading":"10.8 Resources","text":"R Data Science page factors.\r\naweek vignette","code":""},{"path":"pivoting-data.html","id":"pivoting-data","chapter":"11 Pivoting data","heading":"11 Pivoting data","text":"manipulating data, pivoting can understood refer one two processes:creation pivot tables, tables “… statistics summarize data extensive table (database, spreadsheet, business intelligence program). summary might include sums, averages, statistics, pivot table groups together meaningful way… arrange rearrange (”pivot“) statistics order draw attention useful information. leads finding figures facts quickly making integral data analysis.” see wiki.conversion table long wide format, vice versa.page, focus latter definition. former crucial step data analysis, covered elsewhere Grouping data Descriptive tables pages.","code":""},{"path":"pivoting-data.html","id":"preparation-2","chapter":"11 Pivoting data","heading":"11.1 Preparation","text":"","code":""},{"path":"pivoting-data.html","id":"load-packages-3","chapter":"11 Pivoting data","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  tidyverse)    # data management + ggplot2 graphics"},{"path":"pivoting-data.html","id":"import-data-3","chapter":"11 Pivoting data","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"pivoting-data.html","id":"wide-to-long","chapter":"11 Pivoting data","heading":"11.2 Wide-to-long","text":"Transforming dataset wide long (image source)","code":""},{"path":"pivoting-data.html","id":"data","chapter":"11 Pivoting data","heading":"Data","text":"Data often entered stored format might useful presentation, analysis. Let us take count_data dataset example, stored “wide” format, means column variable row observation. useful presenting information table entering data (e.g. Excel) case report forms. However, typically needs transformed “long” format order analyse visualise.observation dataset refers malaria counts one 65 facilities given date, ranging 2019-03-18 2019-06-14. facilties located one Province (North) four Districts (Spring, Bolo, Dingo, Barnard). dataset provides overall counts malaria, well age-specific counts three age groups - <4 years, 5-14 years, 15 years older.Visualising overall malaria counts time poses difficulty data ’s current format:However, wanted display relative contributions age group total count? case, need ensure variable interest (age group), appears dataset single column can passed ggplot2’s “aesthetics” (aes()) function.Consider also using common problem whereby data stored dates columns, example dataset tidyr::table4a","code":"\ncount_data <- import(\"facility_count_data.rds\")\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot))\ntidyr::table4a## # A tibble: 3 x 3\r\n##   country     `1999` `2000`\r\n## * <chr>        <int>  <int>\r\n## 1 Afghanistan    745   2666\r\n## 2 Brazil       37737  80488\r\n## 3 China       212258 213766"},{"path":"pivoting-data.html","id":"pivot_longer","chapter":"11 Pivoting data","heading":"pivot_longer()","text":"First, let’s begin loading packages converting count_data tibble easy printing:Next, want use tidyr’s pivot_longer() function convert wide dataset long format, converting four columns data malaria counts two new columns: one captures variable name one captures values cells. Since four variables begin prefix malaria_, can make use handy function starts_with().However, also specified columns position:named range:Notice newly created dataframe (df_long) rows (12,152 vs 3,038); become longer. fact, precisely four times long, row original dataset now represents four rows df_long, one malaria count observations (<4y, 5-14y, 15y+, total).addition becoming longer, new dataset fewer columns (8 vs 10), data previously stored four columns (beginning prefix malaria_) now stored two. two columns given default names name value, can override defaults provide meaningful names, can help remember stored within, using names_to values_to arguments. Let’s use names age_group count:can now pass new dataset ggplot2 display malaria counts age group:look plot - wrong ? encountered common problem - also included total counts malaria_tot column, magnitude bar plot twice high .can handle number ways. simply filter dataset pass ggplot2:Alternatively, excluded variable ran pivot_longer, thereby maintaining dataset separate variable:","code":"\npacman::p_load(tidyverse)\n\n# Convert count_data to `tibble` for better printing\ncount_data <- \n  count_data %>% \n  as_tibble() \n\ncount_data## # A tibble: 3,038 x 10\r\n##    location_name data_date  submitted_date Province District `malaria_rdt_0-4` `malaria_rdt_5-14` malaria_rdt_15 malaria_tot newid\r\n##    <chr>         <date>     <date>         <chr>    <chr>                <int>              <int>          <int>       <int> <int>\r\n##  1 Facility 1    2019-06-13 2019-06-14     North    Spring                  11                 12             23          46     1\r\n##  2 Facility 2    2019-06-13 2019-06-14     North    Bolo                    11                 10              5          26     2\r\n##  3 Facility 3    2019-06-13 2019-06-14     North    Dingo                    8                  5              5          18     3\r\n##  4 Facility 4    2019-06-13 2019-06-14     North    Bolo                    16                 16             17          49     4\r\n##  5 Facility 5    2019-06-13 2019-06-14     North    Bolo                     9                  2              6          17     5\r\n##  6 Facility 6    2019-06-13 2019-06-14     North    Dingo                    3                  1              4           8     6\r\n##  7 Facility 6    2019-06-12 2019-06-14     North    Dingo                    4                  0              3           7     6\r\n##  8 Facility 5    2019-06-12 2019-06-14     North    Bolo                    15                 14             13          42     5\r\n##  9 Facility 5    2019-06-11 2019-06-14     North    Bolo                    11                 11             13          35     5\r\n## 10 Facility 5    2019-06-10 2019-06-14     North    Bolo                    19                 15             15          49     5\r\n## # ... with 3,028 more rows\ndf_long <- \n  count_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )\n\ndf_long## # A tibble: 12,152 x 8\r\n##    location_name data_date  submitted_date Province District newid name             value\r\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>            <int>\r\n##  1 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_0-4     11\r\n##  2 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_5-14    12\r\n##  3 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_15      23\r\n##  4 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_tot         46\r\n##  5 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_0-4     11\r\n##  6 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_5-14    10\r\n##  7 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_15       5\r\n##  8 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_tot         26\r\n##  9 Facility 3    2019-06-13 2019-06-14     North    Dingo        3 malaria_rdt_0-4      8\r\n## 10 Facility 3    2019-06-13 2019-06-14     North    Dingo        3 malaria_rdt_5-14     5\r\n## # ... with 12,142 more rows\ncount_data %>% \n  pivot_longer(\n    cols = 6:9\n  )## # A tibble: 12,152 x 8\r\n##    location_name data_date  submitted_date Province District newid name             value\r\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>            <int>\r\n##  1 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_0-4     11\r\n##  2 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_5-14    12\r\n##  3 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_15      23\r\n##  4 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_tot         46\r\n##  5 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_0-4     11\r\n##  6 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_5-14    10\r\n##  7 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_15       5\r\n##  8 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_tot         26\r\n##  9 Facility 3    2019-06-13 2019-06-14     North    Dingo        3 malaria_rdt_0-4      8\r\n## 10 Facility 3    2019-06-13 2019-06-14     North    Dingo        3 malaria_rdt_5-14     5\r\n## # ... with 12,142 more rows\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )## # A tibble: 12,152 x 8\r\n##    location_name data_date  submitted_date Province District newid name             value\r\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>            <int>\r\n##  1 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_0-4     11\r\n##  2 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_5-14    12\r\n##  3 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_15      23\r\n##  4 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_tot         46\r\n##  5 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_0-4     11\r\n##  6 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_5-14    10\r\n##  7 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_15       5\r\n##  8 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_tot         26\r\n##  9 Facility 3    2019-06-13 2019-06-14     North    Dingo        3 malaria_rdt_0-4      8\r\n## 10 Facility 3    2019-06-13 2019-06-14     North    Dingo        3 malaria_rdt_5-14     5\r\n## # ... with 12,142 more rows\ndf_long <- \n  count_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\"),\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long## # A tibble: 12,152 x 8\r\n##    location_name data_date  submitted_date Province District newid age_group        counts\r\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>             <int>\r\n##  1 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_0-4      11\r\n##  2 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_5-14     12\r\n##  3 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_rdt_15       23\r\n##  4 Facility 1    2019-06-13 2019-06-14     North    Spring       1 malaria_tot          46\r\n##  5 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_0-4      11\r\n##  6 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_5-14     10\r\n##  7 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_rdt_15        5\r\n##  8 Facility 2    2019-06-13 2019-06-14     North    Bolo         2 malaria_tot          26\r\n##  9 Facility 3    2019-06-13 2019-06-14     North    Dingo        3 malaria_rdt_0-4       8\r\n## 10 Facility 3    2019-06-13 2019-06-14     North    Dingo        3 malaria_rdt_5-14      5\r\n## # ... with 12,142 more rows\nggplot(df_long) +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group)\n  )\ndf_long %>% \n  filter(age_group != \"malaria_tot\") %>% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group)\n  )\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  ) %>% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group)\n  )"},{"path":"pivoting-data.html","id":"long-to-wide","chapter":"11 Pivoting data","heading":"11.3 Long-to-wide","text":"Transforming dataset long wide (image source)instances, may wish convert dataset wider format. , can use pivot_wider() function.typical use case want transform results analysis format digestible reader. Typically, transforming dataset observations spread multiple rows one observation occupies single row.introduces useful topic “tidy data”, variable ’s column, observation ’s row, value ’s cell. topic can found https://r4ds..co.nz/tidy-data.html.","code":""},{"path":"pivoting-data.html","id":"data-1","chapter":"11 Pivoting data","heading":"Data","text":"Let us use linelist dataset. Suppose want know counts individuals different age groups, sex:gives us long dataset great visualisation, ideal presentation table:","code":"\nlinelist <- \n  linelist %>% \n  as_tibble()\n  \ndf_wide <- \n  linelist %>% \n  count(age_cat, gender)\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))"},{"path":"pivoting-data.html","id":"pivot-wider","chapter":"11 Pivoting data","heading":"Pivot wider","text":"Therefore, can use pivot_wider() put better format inclusion tables reports. argument names_from specifies column generate new column names, argument values_from specifies column take values populate cells:table much nicer inclusion reports:","code":"\ntable_wide <- \n  df_wide %>% \n  pivot_wider(\n    names_from = gender,\n    values_from = n\n  )\n\ntable_wide## # A tibble: 9 x 4\r\n##   age_cat     f     m  `NA`\r\n##   <fct>   <int> <int> <int>\r\n## 1 0-4       640   416    39\r\n## 2 5-9       641   412    42\r\n## 3 10-14     518   383    40\r\n## 4 15-19     359   364    20\r\n## 5 20-29     468   575    30\r\n## 6 30-49     179   557    18\r\n## 7 50-69       2    91     2\r\n## 8 70+        NA     5     1\r\n## 9 <NA>       NA    NA    86\ntable_wide %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% # adds a total row and column\n  knitr::kable() %>% \n  kableExtra::row_spec(row = 9, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) "},{"path":"pivoting-data.html","id":"fill","chapter":"11 Pivoting data","heading":"11.4 Fill","text":"Filling missing data","code":""},{"path":"pivoting-data.html","id":"data-2","chapter":"11 Pivoting data","heading":"Data","text":"situations pivot, commonly bind, left gaps cells like fill. example, take two datasets, observations measurement number, name facility, case count time. However, second dataset also variable Year. perform bind_rows() join two datasets together, Year variable filled NA rows prior information (.e. first dataset):","code":"\ndf1 <- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 ## # A tibble: 9 x 3\r\n##   Measurement Facility Cases\r\n##         <dbl> <chr>    <dbl>\r\n## 1           1 Hosp 1      66\r\n## 2           2 Hosp 1      26\r\n## 3           3 Hosp 1       8\r\n## 4           1 Hosp 2      71\r\n## 5           2 Hosp 2      62\r\n## 6           3 Hosp 2      70\r\n## 7           1 Hosp 3      47\r\n## 8           2 Hosp 3      70\r\n## 9           3 Hosp 3      38\ndf2 <- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2## # A tibble: 3 x 4\r\n##    Year Measurement Facility Cases\r\n##   <dbl>       <dbl> <chr>    <dbl>\r\n## 1  2000           1 Hosp 4      82\r\n## 2  2001           2 Hosp 4      87\r\n## 3  2002           3 Hosp 4      46\ndf_combined <- \n  bind_rows(df1, df2) %>% \n  arrange(Measurement, Facility)\n\ndf_combined## # A tibble: 12 x 4\r\n##    Measurement Facility Cases  Year\r\n##          <dbl> <chr>    <dbl> <dbl>\r\n##  1           1 Hosp 1      66    NA\r\n##  2           1 Hosp 2      71    NA\r\n##  3           1 Hosp 3      47    NA\r\n##  4           1 Hosp 4      82  2000\r\n##  5           2 Hosp 1      26    NA\r\n##  6           2 Hosp 2      62    NA\r\n##  7           2 Hosp 3      70    NA\r\n##  8           2 Hosp 4      87  2001\r\n##  9           3 Hosp 1       8    NA\r\n## 10           3 Hosp 2      70    NA\r\n## 11           3 Hosp 3      38    NA\r\n## 12           3 Hosp 4      46  2002"},{"path":"pivoting-data.html","id":"fill-1","chapter":"11 Pivoting data","heading":"fill()","text":"case, Year useful variable include, particularly want explore trends time. Therefore, use fill() fill empty cells, specifying column fill direction (case ):can rearrange data need fill downward direction:dataset now useful plotting:less useful presenting table, let’s practice converting long, untidy dataframe wider, tidy dataframe:N.B. case, specify include three variables Facility, Year, Cases additional variable Measurement interfere creation table:","code":"\ndf_combined %>% \n  fill(Year, .direction = \"up\")## # A tibble: 12 x 4\r\n##    Measurement Facility Cases  Year\r\n##          <dbl> <chr>    <dbl> <dbl>\r\n##  1           1 Hosp 1      66  2000\r\n##  2           1 Hosp 2      71  2000\r\n##  3           1 Hosp 3      47  2000\r\n##  4           1 Hosp 4      82  2000\r\n##  5           2 Hosp 1      26  2001\r\n##  6           2 Hosp 2      62  2001\r\n##  7           2 Hosp 3      70  2001\r\n##  8           2 Hosp 4      87  2001\r\n##  9           3 Hosp 1       8  2002\r\n## 10           3 Hosp 2      70  2002\r\n## 11           3 Hosp 3      38  2002\r\n## 12           3 Hosp 4      46  2002\ndf_combined <- \n  df_combined %>% \n  arrange(Measurement, desc(Facility))\n\ndf_combined## # A tibble: 12 x 4\r\n##    Measurement Facility Cases  Year\r\n##          <dbl> <chr>    <dbl> <dbl>\r\n##  1           1 Hosp 4      82  2000\r\n##  2           1 Hosp 3      47    NA\r\n##  3           1 Hosp 2      71    NA\r\n##  4           1 Hosp 1      66    NA\r\n##  5           2 Hosp 4      87  2001\r\n##  6           2 Hosp 3      70    NA\r\n##  7           2 Hosp 2      62    NA\r\n##  8           2 Hosp 1      26    NA\r\n##  9           3 Hosp 4      46  2002\r\n## 10           3 Hosp 3      38    NA\r\n## 11           3 Hosp 2      70    NA\r\n## 12           3 Hosp 1       8    NA\ndf_combined <- \n  df_combined %>% \n  fill(Year, .direction = \"down\")\n\ndf_combined## # A tibble: 12 x 4\r\n##    Measurement Facility Cases  Year\r\n##          <dbl> <chr>    <dbl> <dbl>\r\n##  1           1 Hosp 4      82  2000\r\n##  2           1 Hosp 3      47  2000\r\n##  3           1 Hosp 2      71  2000\r\n##  4           1 Hosp 1      66  2000\r\n##  5           2 Hosp 4      87  2001\r\n##  6           2 Hosp 3      70  2001\r\n##  7           2 Hosp 2      62  2001\r\n##  8           2 Hosp 1      26  2001\r\n##  9           3 Hosp 4      46  2002\r\n## 10           3 Hosp 3      38  2002\r\n## 11           3 Hosp 2      70  2002\r\n## 12           3 Hosp 1       8  2002\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\ndf_combined %>% \n  pivot_wider(\n    id_cols = c(Facility, Year, Cases),\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  arrange(Facility) %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% \n  knitr::kable() %>% \n  kableExtra::row_spec(row = 5, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) \ndf_combined %>% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  knitr::kable()"},{"path":"pivoting-data.html","id":"resources-4","chapter":"11 Pivoting data","heading":"11.5 Resources","text":"helpful tutorial","code":""},{"path":"grouping-data.html","id":"grouping-data","chapter":"12 Grouping data","heading":"12 Grouping data","text":"page reviews group aggregate data descriptive analysis. makes use tidyverse packages common easy--use functions.","code":""},{"path":"grouping-data.html","id":"overview-3","chapter":"12 Grouping data","heading":"12.1 Overview","text":"Grouping data core component data management analysis. Grouped data can plotted, statistically summarised group. Functions dplyr package (part tidyverse) make grouping subsequent operations quite easy.page address following topics:Grouping data group_by() functionUn-group datasummarise() grouped data statisticsThe difference count() tally()arrange() applied grouped datafilter() applied grouped datamutate() applied grouped dataselect() applied grouped dataThe base R aggregate() command alternative","code":""},{"path":"grouping-data.html","id":"preparation-3","chapter":"12 Grouping data","heading":"12.2 Preparation","text":"","code":""},{"path":"grouping-data.html","id":"load-packages-4","chapter":"12 Grouping data","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.Ensure tidyverse package installed loaded (includes dplyr).","code":"\npacman::p_load(\n  rio,       # to import data\n  here,      # to locate files\n  tidyverse, # to clean, handle, and plot the data (includes dplyr)\n  janitor)   # adding total rows and columns"},{"path":"grouping-data.html","id":"import-data-4","chapter":"12 Grouping data","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist:","code":"\nlinelist <- rio::import(here(\"data\", \"linelist_cleaned.xlsx\"))"},{"path":"grouping-data.html","id":"grouping","chapter":"12 Grouping data","heading":"12.3 Grouping","text":"function group_by() dplyr groups rows unique values specified columns. unique value constitutes group (unique combination values, multiple grouping columns specified). Subsequent changes dataset calculations can performed within context unique group.example, command takes linelist groups rows unique values column outcome, saving output new dataframe ll_by_outcome. grouping column name placed inside parentheses function group_by().Note perceptible change dataset group_by(), another dplyr verb mutate() summarise() applied “grouped” dataframe.can however “see” groupings printing dataframe. print grouped dataframe, see transformed tibble class object (LINK) , printed, displays grouping columns applied many groups - written just header row.","code":"\nll_by_outcome <- linelist %>% \n  group_by(outcome)\n# print to see which groups are active\nll_by_outcome## # A tibble: 5,888 x 30\r\n## # Groups:   outcome [3]\r\n##    case_id generation date_infection date_onset date_hospitalisa~ date_outcome outcome gender   age age_unit age_years age_cat age_cat5 hospital    \r\n##    <chr>        <dbl> <date>         <date>     <date>            <date>       <chr>   <chr>  <dbl> <chr>        <dbl> <fct>   <fct>    <chr>       \r\n##  1 5fe599           4 2014-05-08     2014-05-13 2014-05-15        NA           <NA>    m          2 years            2 0-4     0-4      Other       \r\n##  2 8689b7           4 NA             2014-05-13 2014-05-14        2014-05-18   Recover f          3 years            3 0-4     0-4      Missing     \r\n##  3 11f8ea           2 NA             2014-05-16 2014-05-18        2014-05-30   Recover m         56 years           56 50-69   55-59    St. Mark's ~\r\n##  4 b8812a           3 2014-05-04     2014-05-18 2014-05-20        NA           <NA>    f         18 years           18 15-19   15-19    Port Hospit~\r\n##  5 893f25           3 2014-05-18     2014-05-21 2014-05-22        2014-05-29   Recover m          3 years            3 0-4     0-4      Military Ho~\r\n##  6 be99c8           3 2014-05-03     2014-05-22 2014-05-23        2014-05-24   Recover f         16 years           16 15-19   15-19    Port Hospit~\r\n##  7 07e3e8           4 2014-05-22     2014-05-27 2014-05-29        2014-06-01   Recover f         16 years           16 15-19   15-19    Missing     \r\n##  8 369449           4 2014-05-28     2014-06-02 2014-06-03        2014-06-07   Death   f          0 years            0 0-4     0-4      Missing     \r\n##  9 f393b4           4 NA             2014-06-05 2014-06-06        2014-06-18   Recover m         61 years           61 50-69   60-64    Missing     \r\n## 10 1389ca           4 NA             2014-06-05 2014-06-07        2014-06-09   Death   f         27 years           27 20-29   25-29    Missing     \r\n## # ... with 5,878 more rows, and 16 more variables: lon <dbl>, lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>,\r\n## #   fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>, time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>"},{"path":"grouping-data.html","id":"unique-groups","chapter":"12 Grouping data","heading":"Unique groups","text":"groups created reflect unique combination values grouping columns. see groups number rows group, pass grouped data tally(). see just unique groups without counts can pass group_keys().See three unique values grouping column outcome: “Death”, “Recover”, NA. See 2582 deaths, 1983 recoveries, 1323 outcome recorded.can group one column. , dataframe grouped outcome gender, tallied. Note unique combination outcome gender registered group - including missing values either column.","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  tally()## # A tibble: 3 x 2\r\n##   outcome     n\r\n##   <chr>   <int>\r\n## 1 Death    2582\r\n## 2 Recover  1983\r\n## 3 <NA>     1323\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally()## # A tibble: 9 x 3\r\n## # Groups:   outcome [3]\r\n##   outcome gender     n\r\n##   <chr>   <chr>  <int>\r\n## 1 Death   f       1227\r\n## 2 Death   m       1228\r\n## 3 Death   <NA>     127\r\n## 4 Recover f        953\r\n## 5 Recover m        950\r\n## 6 Recover <NA>      80\r\n## 7 <NA>    f        627\r\n## 8 <NA>    m        625\r\n## 9 <NA>    <NA>      71"},{"path":"grouping-data.html","id":"new-columns-1","chapter":"12 Grouping data","heading":"New columns","text":"can also create new grouping column within group_by() statement. equivalent calling mutate() group_by(). quick tabulation style can handy, clarity code consider creating column ’s mutate() step piping group_by().","code":"\n# group dat based on a binary column created *within* the group_by() command\nlinelist %>% \n  group_by(\n    age_class = ifelse(age >= 18, \"adult\", \"child\")) %>% \n  tally(sort = T)## # A tibble: 3 x 2\r\n##   age_class     n\r\n##   <chr>     <int>\r\n## 1 child      3618\r\n## 2 adult      2184\r\n## 3 <NA>         86"},{"path":"grouping-data.html","id":"adddrop-grouping-columns","chapter":"12 Grouping data","heading":"Add/drop grouping columns","text":"default run group_by() data already grouped, old groups removed new one(s) apply. want add new groups existing ones, include argument .add=TRUE.group column class Factor may levels Factor present data. group column, default non-present levels dropped included groups. want change , set .drop = FALSE group_by() command.","code":"\n# Grouped by outcome\nby_outcome <- linelist %>% \n  group_by(outcome)\n\n# Add grouping by gender in addition\nby_outcome_gender <- by_outcome %>% \n  group_by(gender, .add = TRUE)"},{"path":"grouping-data.html","id":"un-group","chapter":"12 Grouping data","heading":"12.4 Un-group","text":"Data grouped remain grouped specifically ungrouped via ungroup(). forget ungroup, can lead incorrect calculations! example removing grouping columns:can also remove grouping specific columns, placing column name inside.NOTE: verb count() automatically ungroups data counting.","code":"\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup()\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup(gender) # remove the grouping by gender, leave grouping by outcome"},{"path":"grouping-data.html","id":"summarise","chapter":"12 Grouping data","heading":"12.5 Summarise","text":"See page Descriptive tables detailed description produce summary tables summarise(). briefly address behavior changes applied grouped data.applying dplyr verb summarise() grouped data, can produce summary tables containing descriptive statistics group. grouping columns always returned new data frame.Within summarise statement, provide name(s) new summary column(s), equals sign, statistical function apply data, shown . example, min(), max(), median(), sd(). Within statistical function, list column operated relevant argument (e.g. na.rm = TRUE). can use sum() count number rows meet logical criteria (use double equals ==).example summarise() applied without grouped data. statistics returned produced entire dataset.contrast, summarise() statement applied grouped data. statistics calculated outcome group.TIP: summarise function works UK US spelling - summarise() summarize() call function.","code":"\n# summary statistics on ungrouped linelist\nlinelist %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males  = sum(gender == \"m\", na.rm=T))##   n_cases mean_age max_age min_age n_males\r\n## 1    5888       16      84       0    2803\n# summary statistics on grouped linelist\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males    = sum(gender == \"m\", na.rm=T))## # A tibble: 3 x 6\r\n##   outcome n_cases mean_age max_age min_age n_males\r\n##   <chr>     <int>    <dbl>   <dbl>   <dbl>   <int>\r\n## 1 Death      2582     15.9      76       0    1228\r\n## 2 Recover    1983     16.1      84       0     950\r\n## 3 <NA>       1323     16.2      69       0     625"},{"path":"grouping-data.html","id":"count-and-tally","chapter":"12 Grouping data","heading":"12.6 Count and tally","text":"count() tally() provide similar functionality different.tally() shorthand summarise(), automatically group data. Thus, achieve grouped tallys must follow group_by() command. can add sort = TRUE see largest groups first.contrast, count() following:applies group_by() specified column(s)applies summarise() returns column n number observations per groupapplies ungroup()Just like group_by() can create new column within count() command:Read distinction tally() count() hereBoth verbs can called multiple times, functionality “rolling ”. example, summarise number genders present outcome, run following. Note, name final column changed default “n” clarity.","code":"\nlinelist %>% \n  tally##      n\r\n## 1 5888\nlinelist %>% \n  group_by(outcome) %>% \n  tally(sort = TRUE)## # A tibble: 3 x 2\r\n##   outcome     n\r\n##   <chr>   <int>\r\n## 1 Death    2582\r\n## 2 Recover  1983\r\n## 3 <NA>     1323\nlinelist %>% \n  count(outcome)##   outcome    n\r\n## 1   Death 2582\r\n## 2 Recover 1983\r\n## 3    <NA> 1323\nlinelist %>% \n  count(age_class = ifelse(age >= 18, \"adult\", \"child\"), sort = T)##   age_class    n\r\n## 1     child 3618\r\n## 2     adult 2184\r\n## 3      <NA>   86\nlinelist %>% \n  # produce counts by outcome-gender groups\n  count(outcome, gender) %>% \n  # produce counts of gender within each outcome group\n  count(outcome, name = \"number of genders per outcome\" ) ##   outcome number of genders per outcome\r\n## 1   Death                             3\r\n## 2 Recover                             3\r\n## 3    <NA>                             3"},{"path":"grouping-data.html","id":"add-totals","chapter":"12 Grouping data","heading":"Add totals","text":"want add total rows column using tally() count(), see page Descriptive tables demonstrations janitor package. package offers functions like tabyl() make cross-tabulations, adorn_totals() adorn_percentages() add totals convert show percentages. brief example:","code":"\nlinelist %>%                                  # case linelist\n  tabyl(age_cat, gender) %>%                  # cross-tabulate counts of two columns\n  adorn_totals(where = \"row\") %>%             # add a total row\n  adorn_percentages(denominator = \"col\") %>%  # convert to proportions with column denominator\n  adorn_pct_formatting() %>%                  # convert proportions to percents\n  adorn_ns(position = \"front\") %>%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                      Gender                           \r\n##  Age Category             f             m          NA_\r\n##           0-4  640  (22.8%)  416  (14.8%)  39  (14.0%)\r\n##           5-9  641  (22.8%)  412  (14.7%)  42  (15.1%)\r\n##         10-14  518  (18.5%)  383  (13.7%)  40  (14.4%)\r\n##         15-19  359  (12.8%)  364  (13.0%)  20   (7.2%)\r\n##         20-29  468  (16.7%)  575  (20.5%)  30  (10.8%)\r\n##         30-49  179   (6.4%)  557  (19.9%)  18   (6.5%)\r\n##         50-69    2   (0.1%)   91   (3.2%)   2   (0.7%)\r\n##           70+    0   (0.0%)    5   (0.2%)   1   (0.4%)\r\n##          <NA>    0   (0.0%)    0   (0.0%)  86  (30.9%)\r\n##         Total 2807 (100.0%) 2803 (100.0%) 278 (100.0%)"},{"path":"grouping-data.html","id":"grouping-by-date","chapter":"12 Grouping data","heading":"12.7 Grouping by date","text":"grouping data date, must create column date unit interest, example “day”, “epiweek”, “month”, etc. can make column using floor_date() lubridate, explained page Working dates (Epidemiological weeks section). column, can use count() group rows achieve aggregate counts.One additional step particular dates use complete() tidyr aggregated date series complete including possible date units within range. Without step, week cases reported might appear data! Within complete() re-define date column sequence dates minimum maximum - thus dates expanded.","code":""},{"path":"grouping-data.html","id":"linelist-cases-into-days","chapter":"12 Grouping data","heading":"Linelist cases into days","text":"example grouping cases days without using complete(). Note first rows skip dates cases.add complete() command ensure every day range represented.","code":"\ndaily_counts <- linelist %>% \n  filter(!is.na(date_onset)) %>%        # remove that were missing date_onset\n  count(date_onset)                     # count number of rows per unique date\ndaily_counts <- linelist %>% \n  filter(!is.na(date_onset)) %>%                  # remove case missing date_onset\n  count(date_onset) %>%                           # count number of rows per unique date\n  complete(date_onset = seq.Date(min(date_onset), # ensure all days appear even if no cases\n                                 max(date_onset),\n                                 by=\"day\")) %>% \n  mutate(n = replace_na(n, 0))                    # replace NA counts with 0"},{"path":"grouping-data.html","id":"linelist-cases-into-weeks","chapter":"12 Grouping data","heading":"Linelist cases into weeks","text":"principle can applied weeks. First create new column week case using floor_date() unit = \"week\". , use count() achieve weekly case counts. Finish complete() ensure weeks represented, even contain cases.first 50 rows resulting dataframe:","code":"\n# Make dataset of weekly case counts\nweekly_counts <- linelist %>% \n  filter(!is.na(date_onset)) %>%                      # remove cases missing date_onset\n  mutate(week = lubridate::floor_date(date_onset, unit = \"week\")) %>%  # new column of week of onset\n  count(week) %>%                                     # group data by week and count rows per group\n  complete(week = seq.Date(from = min(week),          # include all weeks, even if no cases\n                           to = max(week),\n                           by=\"week\")) %>% \n  mutate(n = replace_na(n, 0))                        # fill-in NA values with 0"},{"path":"grouping-data.html","id":"daily-counts-into-weeks","chapter":"12 Grouping data","heading":"Daily counts into weeks","text":"aggregate daily counts weekly counts, use floor_date() . However, use group_by() summarize() instead count() need sum() daily case counts instead just counting number rows per week.","code":""},{"path":"grouping-data.html","id":"linelist-cases-into-months","chapter":"12 Grouping data","heading":"Linelist cases into months","text":"aggregate cases months, use floor_date() lubridate package, argument unit = \"months\". rounds date 1st month. output class Date. Note complete() step also use = \"months\".","code":"\n# Make dataset of monthly case counts\nmonthly_counts <- linelist %>% \n  filter(!is.na(date_onset)) %>% \n  mutate(month = lubridate::floor_date(date_onset, unit = \"months\")) %>%  # new column, 1st of month of onset\n  count(month) %>%                          # count cases by month\n  complete(month = seq.Date(min(month),     # include all months with no cases reported\n                            max(month),\n                            by=\"month\")) %>% \n  mutate(month = replace_na(n, 0))          # replace NA with 0 for months with no cases"},{"path":"grouping-data.html","id":"daily-counts-into-months","chapter":"12 Grouping data","heading":"Daily counts into months","text":"aggregate daily counts months counts, use floor_date() unit = \"month\" . However, use group_by() summarize() instead count() need sum() daily case counts instead just counting number rows per month.","code":""},{"path":"grouping-data.html","id":"arranging-grouped-data","chapter":"12 Grouping data","heading":"12.8 Arranging grouped data","text":"Using dplyr verb arrange() order rows dataframe behaves data grouped, unless set argument .by_group =TRUE. case rows ordered first grouping columns columns specify arrange().","code":""},{"path":"grouping-data.html","id":"filter-on-grouped-data","chapter":"12 Grouping data","heading":"12.9 Filter on grouped data","text":"","code":""},{"path":"grouping-data.html","id":"filter","chapter":"12 Grouping data","heading":"filter()","text":"applied conjunction functions evaluate dataframe (like max(), min(), mean()), functions now applied groups. example, want filter keep rows patients median age, now apply per group - filtering keep rows group’s median age.","code":""},{"path":"grouping-data.html","id":"slice-rows-per-group","chapter":"12 Grouping data","heading":"Slice rows per group","text":"dplyr function slice(), subsets rows based position data, can also applied per group. Remember account sorting data within group get desired “slice”.example, retrieve latest 5 admissions hospital:Group linelist column hospitalArrange records latest earliest date_hospitalisation within hospital groupSlice retrieve first 5 rows hospitalslice_head() - selects n rows topslice_tail() - selects n rows endslice_sample() - randomly selects n rowsslice_min() - selects n rows highest values order_by = column, use with_ties = TRUE keep tiesslice_max() - selects n rows lowest values order_by = column, use with_ties = TRUE keep ties","code":"\nlinelist %>%\n  group_by(hospital) %>%\n  arrange(hospital, date_hospitalisation) %>%\n  slice_head(n = 5) %>% \n  arrange(hospital) %>% \n  select(case_id, hospital, date_hospitalisation)## # A tibble: 30 x 3\r\n## # Groups:   hospital [6]\r\n##    case_id hospital          date_hospitalisation\r\n##    <chr>   <chr>             <date>              \r\n##  1 20b688  Central Hospital  2014-05-06          \r\n##  2 d58402  Central Hospital  2014-05-10          \r\n##  3 b8f2fd  Central Hospital  2014-05-13          \r\n##  4 acf422  Central Hospital  2014-05-28          \r\n##  5 275cc7  Central Hospital  2014-05-28          \r\n##  6 d1fafd  Military Hospital 2014-04-17          \r\n##  7 974bc1  Military Hospital 2014-05-13          \r\n##  8 6a9004  Military Hospital 2014-05-13          \r\n##  9 09e386  Military Hospital 2014-05-14          \r\n## 10 865581  Military Hospital 2014-05-15          \r\n## # ... with 20 more rows"},{"path":"grouping-data.html","id":"filter-on-group-size","chapter":"12 Grouping data","heading":"Filter on group size","text":"function add_count() adds column n original data giving number rows row’s group.Shown simplicity selection two columns linelist data. add_count() applied hospital, values column n reflect number rows row’s hospital group. Note values column n repeated. example , column name n changed using name = within add_count().becomes easy filter case rows hospitalized “small” hospital, say, hospital admitted fewer 500 patients:","code":"\nlinelist %>% \n  select(case_id, hospital) %>% \n  add_count(hospital) %>%          # add \"number of rows admitted to same hospital as this row\" \n  head(10)                         # show just the first 10 rows, for demo purposes##    case_id                             hospital    n\r\n## 1   5fe599                                Other  885\r\n## 2   8689b7                              Missing 1469\r\n## 3   11f8ea St. Mark's Maternity Hospital (SMMH)  422\r\n## 4   b8812a                        Port Hospital 1762\r\n## 5   893f25                    Military Hospital  896\r\n## 6   be99c8                        Port Hospital 1762\r\n## 7   07e3e8                              Missing 1469\r\n## 8   369449                              Missing 1469\r\n## 9   f393b4                              Missing 1469\r\n## 10  1389ca                              Missing 1469\nlinelist %>% \n  select(case_id, hospital) %>% \n  add_count(hospital) %>% \n  filter(n < 500)"},{"path":"grouping-data.html","id":"mutate-on-grouped-data","chapter":"12 Grouping data","heading":"12.10 Mutate on grouped data","text":"retain columns rows (summarize) add new variable containing group statistics, use mutate() instead summarise().useful want group statistics original dataset column present - e.g. calculations comparing one row group.example, code calculates difference row’s delay--admission median delay hospital. steps :Group data hospitalUse column days_onset_hosp (delay hospitalisation) create new column containing mean delay hospital rowCalculate difference two columns","code":"\nlinelist %>% \n  # group data by hospital (no change to linelist yet)\n  group_by(hospital) %>% \n  \n  # new columns\n  mutate(\n    # mean days to admission per hospital (rounded to 1 decimal)\n    group_delay_admit = round(mean(days_onset_hosp, na.rm=T), 1),\n    \n    # difference between row's delay and mean delay at their hospital (rounded to 1 decimal)\n    diff_to_group     = round(days_onset_hosp - group_delay_admit, 1)) %>%\n  \n  # select certain rows only - for demonstration/viewing purposes\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)## # A tibble: 5,888 x 5\r\n## # Groups:   hospital [6]\r\n##    case_id hospital                             days_onset_hosp group_delay_admit diff_to_group\r\n##    <chr>   <chr>                                          <dbl>             <dbl>         <dbl>\r\n##  1 5fe599  Other                                              2               2             0  \r\n##  2 8689b7  Missing                                            1               2.1          -1.1\r\n##  3 11f8ea  St. Mark's Maternity Hospital (SMMH)               2               2.1          -0.1\r\n##  4 b8812a  Port Hospital                                      2               2.1          -0.1\r\n##  5 893f25  Military Hospital                                  1               2.1          -1.1\r\n##  6 be99c8  Port Hospital                                      1               2.1          -1.1\r\n##  7 07e3e8  Missing                                            2               2.1          -0.1\r\n##  8 369449  Missing                                            1               2.1          -1.1\r\n##  9 f393b4  Missing                                            1               2.1          -1.1\r\n## 10 1389ca  Missing                                            2               2.1          -0.1\r\n## # ... with 5,878 more rows"},{"path":"grouping-data.html","id":"select-on-grouped-data","chapter":"12 Grouping data","heading":"12.11 Select on grouped data","text":"verb select() works grouped data, grouping columns always included (even mentioned select()). want grouping columns, use ungroup() first.","code":""},{"path":"grouping-data.html","id":"resources-5","chapter":"12 Grouping data","heading":"12.12 Resources","text":"useful resources information:\r\n* https://github.com/rstudio/cheatsheets/blob/master/data-transformation.pdf\r\n* https://datacarpentry.org/R-genomics/04-dplyr.html\r\n* https://dplyr.tidyverse.org/reference/group_by.html\r\n* https://dplyr.tidyverse.org/articles/grouping.html\r\n* https://itsalocke.com/files/DataManipulationinR.pdfSummarize conditionsYou can perform summary function grouped data; see Cheat Sheet info:\r\nhttps://github.com/rstudio/cheatsheets/blob/master/data-transformation.pdf","code":""},{"path":"joining-data.html","id":"joining-data","chapter":"13 Joining data","heading":"13 Joining data","text":"page describes common “joins” also probabilistic matching dataframes.","code":""},{"path":"joining-data.html","id":"preparation-4","chapter":"13 Joining data","heading":"13.1 Preparation","text":"","code":""},{"path":"joining-data.html","id":"load-packages-5","chapter":"13 Joining data","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.traditional joins (non-probabilistic) can specific, requiring exact string matches, may need cleaning datasets prior join (e.g. change spellings, change case lower upper).","code":"\npacman::p_load(\n  rio,            # import/export\n  here,           # relative filepaths\n  tidyverse,      # data management/viz\n  RecordLinkage,  # probabilistic matches\n  fastLink        # probabilistic matches\n)"},{"path":"joining-data.html","id":"import-data-5","chapter":"13 Joining data","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"joining-data.html","id":"datasets","chapter":"13 Joining data","heading":"13.1.1 Datasets","text":"joining examples, ’ll use following datasets:“miniature” version linelist, containing columns case_id, date_onset, hospital, first 10 rowsA separate dataframe named hosp_info, contains details hospitalTwo separate small dataframes probabilistic matching section","code":""},{"path":"joining-data.html","id":"miniature-linelist","chapter":"13 Joining data","heading":"“Miniature” linelist","text":"miniature linelist, contains 10 rows columns case_id, date_onset, hospital.","code":"\nlinelist_mini <- linelist %>%                 # start with original linelist\n  select(case_id, date_onset, hospital) %>%   # select columns\n  head(10)                                    # only take the first 10 rows"},{"path":"joining-data.html","id":"hospital-information-dataframe","chapter":"13 Joining data","heading":"Hospital information dataframe","text":"separate dataframe additional information hospital.","code":"\n# Make the hospital information dataframe\nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, 12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\", \"Secondary\", \"Primary\", \"Primary\")\n)"},{"path":"joining-data.html","id":"pre-cleaning","chapter":"13 Joining data","heading":"Pre-cleaning","text":"traditional (non-probabilistic) joins case-sensitive require exact string matches, clean-hosp_info dataset prior joins.Identify differencesWe need values hosp_name column hosp_info dataframe match values hospital column linelist dataframe.values linelist_mini:values hosp_info:Align matching valuesWe begin cleaning values hosp_name. use logic code values new column using case_when() (read case_when() Cleaning data core functions page). correct hospital names exist dataframes, leave others (TRUE ~ hosp_name).CAUTION: Typically, one create new column (e.g. hosp_name_clean), ease demonstration show modification old columnWe now see hospital names appear dataframe aligned. hospitals hosp_info present linelist - deal later, join.need convert values UPPER lower case, use functions stringr, shown page Characters strings.str_to_upper()str_to_upper()str_to_title()","code":"\nunique(linelist_mini$hospital)## [1] \"Other\"                                \"Missing\"                              \"St. Mark's Maternity Hospital (SMMH)\"\r\n## [4] \"Port Hospital\"                        \"Military Hospital\"\nunique(hosp_info$hosp_name)## [1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"       \"ignace\"           \"sisters\"\nhosp_info <- hosp_info %>% \n  mutate(\n    hosp_name = case_when(\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\nunique(hosp_info$hosp_name)## [1] \"Central Hospital\"                     \"Military Hospital\"                    \"Port Hospital\"                       \r\n## [4] \"St. Mark's Maternity Hospital (SMMH)\" \"ignace\"                               \"sisters\""},{"path":"joining-data.html","id":"dplyr-joins","chapter":"13 Joining data","heading":"13.2 dplyr joins","text":"dplyr package offers several different joins. dplyr included tidyverse package. join functions described , simple use cases. Many thanks https://github.com/gadenbuie moving images!","code":""},{"path":"joining-data.html","id":"general-syntax","chapter":"13 Joining data","heading":"General syntax","text":"General function structureAny join commands can run independently, like .object created, re-defined: dataframe 2 (df2) joined dataframe 1 (df1), basis matches column “ID” df1 column “identifier” df2. example uses left_join(), rows df2 match row df1 dropped.join commands can also run within pipe chain. first dataframe df1 dataframe passed pipes. df2 joined left_join() command. example shown .Join columns (=)must specify columns dataset values must match, using arguemnt =. options:Specify one column name (= \"ID\") - works exact column name present dataframes!Specify different names (= c(\"ID\" = \"Identifier\") - use column names different 2 dataframesSpecify multiple columns match (= c(\"ID\" = \"Identifier\", \"date_onset\" = \"Date_of_Onset\")) - require exact matches multiple columns rows join.CAUTION: Joins case-specific! Therefore useful convert values lowercase uppercase prior joining. See page characters/strings.","code":"\nobject <- left_join(df1, df2, by = c(\"ID\" = \"identifier\"))\nobject <- df1 %>%\n  left_join(df2, by = c(\"ID\" = \"identifier\"))  # join df2 to df1"},{"path":"joining-data.html","id":"add-columns-left-right-joins","chapter":"13 Joining data","heading":"Add columns: left & right joins","text":"left right join commonly used add information dataframe - new information added rows already exist baseline (starting) dataframe.common joins epidemiological work - used add information one dataset another.order dataframes important.left join, first (left) dataframe listed baselineIn right join, second (right) dataframe listed baselineAll rows baseline dataframe kept. Information secondary dataframe joined baseline dataframe match via identifier column(s). addition:Rows secondary dataframe match dropped.many baseline rows match one row secondary dataframe (many--one), baseline information added matching baseline row.baseline row matches multiple rows secondary dataframe (one--many), combinations given, meaning new rows may added returned dataframe!ExampleBelow output left_join() hosp_info (secondary dataframe) linelist_mini (baseline dataframe). Note following:Two new columns, catchment_pop level added leftAll original rows baseline dataframe linelist_mini keptAny original rows linelist_mini “Military Hospital” duplicated matched two rows secondary dataframe, combinations returnedThe join identifier column secondary dataset (hosp_name) disappeared redundant identifier column primary dataset (hospital)baseline row match secondary row (e.g. hospital “” “Missing”), NA fills columns secondary dataframeRows secondary dataframe match baseline dataframe (“sisters” “ignace”) dropped“use right join, left join?”\r\nimportant ask “dataframe retain rows?” - use one baseline.two commands achieve output - 10 rows hosp_info joined linelist_mini baseline. However, column order differ based whether hosp_info arrives right (left join) arrives left (right join). order rows may also shift consequently.Also consider whether use-case within pipe chain (%>%). dataset pipes baseline, likely use left join add data .","code":"\nlinelist_mini %>% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\n# The two commands below achieve the same data, but with differently ordered rows and columns\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining-data.html","id":"full-join","chapter":"13 Joining data","heading":"Full join","text":"full join inclusive joins - returns rows dataframes.rows present one (match found), dataframe become wider NA values added fill-. Watch number columns rows carefully troubleshoot case-sensitivity exact string matches.Adjustment “baseline” (first) dataframe impact records returned, impact column order, row order, identifier column retained.ExampleBelow output full_join() hosp_info linelist_mini. Note following:baseline rows (linelist_mini) keptAny baseline rows “Military Hospital” duplicated match two secondary rows combinations returnedOnly identifier column baseline kept (hospital)NA fills baseline rows match secondary rows (hospital “” “Missing”), opposite (hosp_name “ignace” “sisters”)","code":"\nlinelist_mini %>% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-data.html","id":"inner-join","chapter":"13 Joining data","heading":"Inner join","text":"inner join restrictive joins - returns rows matches across dataframes.\r\nmeans original dataset may reduce number rows. Adjustment “baseline” (first) dataframe impact records returned, impact column order, row order, identifier column retained.ExampleBelow output inner_join() linelist_mini (baseline) hosp_info (secondary). Note following:baseline rows kept (rows hospital “Missing” “” removed match secondary dataframeLikewise, secondary rows hosp_name “sisters” “ignace” removed match baseline dataframeOnly identifier column baseline kept (hospital)","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nhosp_info %>% \n  inner_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining-data.html","id":"semi-join","chapter":"13 Joining data","heading":"Semi join","text":"semi join “filtering join” uses another dataset add rows columns, perform filtering.\r\nsemi-join keeps observations dataframe 1 match dataframe 2 (add new columns duplicate rows multiple matches). Read filtering joins .code return 0 rows, two dataframes completely different - rows .","code":"\nhosp_info %>% \n  semi_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining-data.html","id":"anti-join","chapter":"13 Joining data","heading":"Anti join","text":"anti join “filtering join” returns rows dataframe 1 match dataframe 2.Read filtering joins .Common scenarios anti-join include identifying records present another dataframe, troubleshooting spelling join (catching records matched), examining records excluded another join.right_join() left_join(), baseline dataframe (listed first) important. returned rows . Notice gif row non-baseline dataframe (purple 4) returned even though match.Simple anti_join() exampleFor example, let’s find hosp_info hospitals cases present linelist_mini. list hosp_info first, baseline dataframe. two hospitals present linelist_mini returned.anti_join() example 2For another example, let us say ran inner_join() linelist_mini hosp_info. returns 8 original 11 linelist_mini records.review 3 linelist_mini records excluded inner join, can run anti-join linelist_mini baseline dataframe.see hosp_info records excluded inner join, also run anti-join hosp_info baseline dataframe.","code":"\nhosp_info %>% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nlinelist_mini %>% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-data.html","id":"probabalistic-matching","chapter":"13 Joining data","heading":"13.3 Probabalistic matching","text":"unique identifier common across datasets join , consider using probabilistic matching algorithm. find matches records based similarity (e.g. Jaro–Winkler string distance, numeric distance). simple example using package fastLink .Load packagesHere two small example datasets use demonstrate probabilistic matching (cases test_results):code used make datasets:cases dataset 9 records patients awaiting test results.test_results dataset 14 records contains column result, want add records cases based probabilistic matching records.","code":"\npacman::p_load(\n  tidyverse,      # data manipulation and visualization\n  fastLink        # record matching\n  )\n# make datasets\n\ncases <- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults <- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )"},{"path":"joining-data.html","id":"probabilistic-matching","chapter":"13 Joining data","heading":"Probabilistic matching","text":"fastLink() function fastLink package can used apply matching algorithm. basic informaton. can read detail entering ?fastLink console.Define two dataframes comparison arguments dfA = dfB =varnames = give column names used matching. must exist dfA dfB.stringdist.match = give columns varnames evaluated string “distance”.numeric.match = give columns varnames evaluated numeric distance.Missing values ignoredBy default, row either dataframe matched one row dataframe. want see evaluated matches, set dedupe.matches = FALSE. deduplication done using Winkler’s linear assignment solution.Tip: split one date column three separate numeric columns using day(), month(), year() lubridate packageThe default threshold matches 0.94 (threshold.match =) can adjust higher lower. define threshold, consider higher thresholds yield false-negatives (rows match actually match) likewise lower threshold yield false-positive matches., data matched string distance across name district columns, numeric distance year, month, day birth. match threshold 95% probability set.Review matchesWe defined object returned fastLink() fl_output. class list, actually contains several dataframes within , detailing results matching. One dataframes matches, contains likely matches across cases results. can access “matches” dataframe fl_output$matches. , saved my_matches ease accessing later.my_matches printed, see two column vectors: pairs row numbers/indices (also called “rownames”) cases (“inds.”) results (“inds.b”) representing best matches. row number datafrane missing, match found specified match threshold.Things note:Matches occurred despite slight differences name spelling dates birth:\r\n“Tony” matched “Anthony”\r\n“Maria” matched “Marialisa”\r\n“Betty” matched “Elizabeth”\r\n“Olivier Laurent De Bordeaux” matched “Oliver Laurent De Bordow” (missing date birth ignored)\r\n“Tony” matched “Anthony”“Maria” matched “Marialisa”“Betty” matched “Elizabeth”“Olivier Laurent De Bordeaux” matched “Oliver Laurent De Bordow” (missing date birth ignored)One row cases (“Blessing Adebayo”, row 9) good match results, present my_matches.Join based probabilistic matchesTo use matches join results cases, one strategy :Use left_join() join my_matches cases (matching rownames cases “inds.” my_matches)use another left_join() join results cases (matching newly-acquired “inds.b” cases rownames results)joins, clean three datasets:dfA dfB row numbers (“rowname”) converted proper columnBoth columns my_matches converted class character, can joined character rownamesAs performed using code , resulting dataframe complete contain columns cases results. Many appended suffixes “.x” “.y”, column names otherwise duplicated.Alternatively, achieve “original” 9 records cases new column(s) results, use select() results joins, contains rownames columns want add cases (e.g. column result).want subset either dataset rows matched, can use codes :, see rows match:","code":"\nfl_output <- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)## \r\n## ==================== \r\n## fastLink(): Fast Probabilistic Record Linkage\r\n## ==================== \r\n## \r\n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\r\n## Calculating matches for each variable.\r\n## Getting counts for parameter estimation.\r\n##     Parallelizing calculation using OpenMP. 1 threads out of 4 are used.\r\n## Running the EM algorithm.\r\n## Getting the indices of estimated matches.\r\n##     Parallelizing calculation using OpenMP. 1 threads out of 4 are used.\r\n## Deduping the estimated matches.\r\n## Getting the match patterns for each estimated match.\n# print matches\nmy_matches <- fl_output$matches\nmy_matches##   inds.a inds.b\r\n## 1      1      1\r\n## 2      2      2\r\n## 3      3      3\r\n## 4      4      4\r\n## 5      8      8\r\n## 6      7      9\r\n## 7      6     10\r\n## 8      5     12\n# Clean data prior to joining\n#############################\n\n# convert cases rownames to a column \ncases_clean <- cases %>% rownames_to_column()\n\n# convert test_results rownames to a column\nresults_clean <- results %>% rownames_to_column()  \n\n# convert all columns in matches dataset to character, so they can be joined to the rownames\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n\n\n# Join matches to dfA, then add dfB\n###################################\n# column \"inds.b\" is added to dfA\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# column(s) from dfB are added \ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_clean <- cases %>% rownames_to_column()\n\nresults_clean <- results %>%\n  rownames_to_column() %>% \n  select(rowname, result)    # select only certain columns \n\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n# joins\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_matched <- cases[my_matches$inds.a,]  # Rows in cases that matched to a row in results\nresults_matched <- results[my_matches$inds.b,]  # Rows in results that matched to a row in cases\ncases_not_matched <- cases[!rownames(cases) %in% my_matches$inds.a,]  # Rows in cases that did NOT match to a row in results\nresults_not_matched <- results[!rownames(results) %in% my_matches$inds.b,]  # Rows in results that did NOT match to a row in cases"},{"path":"joining-data.html","id":"probabilistic-deduplication","chapter":"13 Joining data","heading":"Probabilistic deduplication","text":"Probabilistic matching can used deduplicate dataset well. See page deduplication methods deduplication.began cases dataset, now calling cases_dup, 2 additional rows duplicates previous rows:\r\nSee “Tony” “Anthony”, “Marialisa Rodrigues” “Maria Rodriguez”.Run fastLink() command , compare cases_dup dataframe . two dataframes provided identical, function assumes want de-duplicate.fl.must class fastLink.dedupe, words, result either fastLink().Now, can review potential duplicates getMatches(). Provide dataframe dfA = dfB =, provide output fastLink() function fl.=.See right-column, indicates duplicate IDs - final two rows identified likely duplicates rows 2 3.return row numbers rows likely duplicates, can count number rows per unique value dedupe.ids column, filter keep one row. case leaves rows 2 3.inspect whole rows likely duplicates, put row number command:","code":"\n## Run fastLink on the same dataset\ndedupe_output <- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\")\n)## \r\n## ==================== \r\n## fastLink(): Fast Probabilistic Record Linkage\r\n## ==================== \r\n## \r\n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\r\n## dfA and dfB are identical, assuming deduplication of a single data set.\r\n## Setting return.all to FALSE.\r\n## \r\n## Calculating matches for each variable.\r\n## Getting counts for parameter estimation.\r\n##     Parallelizing calculation using OpenMP. 1 threads out of 4 are used.\r\n## Running the EM algorithm.\r\n## Getting the indices of estimated matches.\r\n##     Parallelizing calculation using OpenMP. 1 threads out of 4 are used.\r\n## Calculating the posterior for each pair of matched observations.\r\n## Getting the match patterns for each estimated match.\n## Run getMatches()\ncases_dedupe <- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\ncases_dedupe %>% \n  count(dedupe.ids) %>% \n  filter(n > 1)##   dedupe.ids n\r\n## 1          2 2\r\n## 2          3 2\n# displays row 2 and all likely duplicates of it\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   ##    gender   first middle  last   yr mon day district dedupe.ids\r\n## 2       M Anthony     B. Smith 1970   9  19    River          2\r\n## 10      M    Tony     B. Smith 1970   9  19    River          2"},{"path":"joining-data.html","id":"resources-6","chapter":"13 Joining data","heading":"13.4 Resources","text":"dplyr page joinsSee vignette fastLink package’s Github pagePublication describing methodolgy fastLinkPublication describing RecordLinkage package","code":""},{"path":"characters-and-strings.html","id":"characters-and-strings","chapter":"14 Characters and strings","heading":"14 Characters and strings","text":"page demonstrates use stringr package evaluate manage character (strings).Evaluate extract position - str_length(), str_sub(), word()Combine, order, arrange - str_c(), str_glue(), str_order()Modify replace - str_sub(), str_replace_all()Adjust length - str_pad(), str_trunc(), str_wrap()Change case - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()Search patterns - str_detect(), str_subset(), str_match()Regular expressions (regex)ease display examples shown acting short defined character vector, however can easily applied/adapted column within dataset.Much page adapted online vignette","code":""},{"path":"characters-and-strings.html","id":"preparation-5","chapter":"14 Characters and strings","heading":"14.1 Preparation","text":"Install load stringr package.","code":"\n# install/load the stringr package\npacman::p_load(\n  stringr,    # many functions for handling strings\n  tidyverse,  # for optional data manipulation\n  tools)      # alternative for converting to title case"},{"path":"characters-and-strings.html","id":"handle-by-position","chapter":"14 Characters and strings","heading":"14.2 Handle by position","text":"","code":""},{"path":"characters-and-strings.html","id":"extract-by-character-position","chapter":"14 Characters and strings","heading":"Extract by character position","text":"Use str_sub() return part string. function takes three main arguments:character vector(s)start positionend positionA notes position numbers:position number positive, position counted starting left end string.position number negative, counted starting right end string.Position numbers inclusive.Positions extending beyond string truncated (removed).examples applied string “pneumonia”:","code":"\n# start and end third from left (3rd letter from left)\nstr_sub(\"pneumonia\", 3, 3)## [1] \"e\"\n# 0 is not present\nstr_sub(\"pneumonia\", 0, 0)## [1] \"\"\n# 6th from left, to the 1st from right\nstr_sub(\"pneumonia\", 6, -1)## [1] \"onia\"\n# 5th from right, to the 2nd from right\nstr_sub(\"pneumonia\", -5, -2)## [1] \"moni\"\n# 4th from left to a position outside the string\nstr_sub(\"pneumonia\", 4, 15)## [1] \"umonia\""},{"path":"characters-and-strings.html","id":"extract-by-word-position","chapter":"14 Characters and strings","heading":"Extract by word position","text":"extract nth ‘word’, use word(), also stringr. Provide string(s), first word position extract, last word position extract.default, separator ‘words’ assumed space, unless otherwise indicated sep = (e.g. sep = \"_\" words separated underscores.","code":"\n# strings to evaluate\nchief_complaints <- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# extract 1st to 3rd words of each string\nword(chief_complaints, start = 1, end = 3, sep = \" \")## [1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\""},{"path":"characters-and-strings.html","id":"replace-by-character-position","chapter":"14 Characters and strings","heading":"Replace by character position","text":"str_sub() paired assignment operator (<-) can used modify part string:example applied multiple strings (e.g. column). Note expansion length “HIV”.","code":"\nword <- \"pneumonia\"\n\n# convert the third and fourth characters to X \nstr_sub(word, 3, 4) <- \"XX\"\n\nword## [1] \"pnXXmonia\"\nwords <- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# convert the third and fourth characters to X \nstr_sub(words, 3, 4) <- \"XX\"\n\nwords## [1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\""},{"path":"characters-and-strings.html","id":"evaluate-length","chapter":"14 Characters and strings","heading":"Evaluate length","text":"Alternatively, use nchar() base R","code":"\nstr_length(\"abc\")## [1] 3"},{"path":"characters-and-strings.html","id":"unite-split-and-arrange","chapter":"14 Characters and strings","heading":"14.3 Unite, split, and arrange","text":"section covers:Using str_c(), str_glue(), unite() combine stringsUsing str_order() arrange stringsUsing str_split() separate() split strings","code":""},{"path":"characters-and-strings.html","id":"combine-strings","chapter":"14 Characters and strings","heading":"Combine strings","text":"combine concatenate multiple strings one string, suggest using str_c stringr.argument sep = inserts characters input (e.g. comma newline \"\\n\")argument collapse = relevant producing multiple combined elements output. example shows combination two vectors one (first names last names). Another similar example might jurisdictions case counts.sep displays respective string inputs, collapse displays elements produced.example:sep value goes first last nameThe collapse value goes personWhen printing combined string newlines, may need wrap whole phrase cat() newlines print properly:","code":"\nstr_c(\"String1\", \"String2\", \"String3\")## [1] \"String1String2String3\"\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")## [1] \"String1, String2, String3\"\nfirst_names <- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  <- c(\"hussein\", \"akinleye\", \"musa\")\n\n# sep displays between the respective input strings, while collapse displays between the elements produced\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")## [1] \"abdul hussein;  fahruk akinleye;  janice musa\"\n# For newlines to print correctly, the phrase may need to be wrapped in cat()\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))## abdul hussein;\r\n## fahruk akinleye;\r\n## janice musa"},{"path":"characters-and-strings.html","id":"dynamic-strings","chapter":"14 Characters and strings","heading":"Dynamic strings","text":"Use str_glue() insert dynamic R code string. useful function creating dynamic plot captions, demonstrated .content goes quotation marks str_glue(\"\")dynamic code calls defined values within curly brackets {} within parentheses. can many curly brackets.display quotes within outer quotation marks, use single quotes (e.g. providing date format)can use \\n within quotes force new lineYou use format() adjust date display, use Sys.Date() display current dateA simple example, dynamic plot caption:alternative format use placeholders within brackets define code separate arguments end str_glue() function, . can improve code readability codes long.Pulling dataframeSometimes, useful pull data dataframe pasted together sequence. example using dataset make summary output jurisdictions new total cases:Option 1:Use str_c() dataframe column names. Provide sep collapse arguments.Add text “New Cases:” beginning summary wrapping separate str_c() (“New Cases:” within original str_c() appear multiple times).Option 2:can achieve similar result str_glue(), newlines added automatically:use str_glue() control (e.g. use double newlines), wrap within str_c() adjust collapse value. may need print using cat() correctly print newlines.","code":"\nstr_glue(\"The linelist is current to {format(Sys.Date(), '%d %b %Y')} and includes {nrow(linelist)} cases.\")## The linelist is current to 30 Mar 2021 and includes 5888 cases.\nstr_glue(\"Data source is the confirmed case linelist as of {current_date}.\\nThe last case was reported hospitalized on {last_hospital}.\\n{n_missing_onset} cases are missing date of onset and not shown\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %>% filter(is.na(date_onset)))\n         )## Data source is the confirmed case linelist as of 30 Mar 2021.\r\n## The last case was reported hospitalized on 30 Apr 2015.\r\n## 256 cases are missing date of onset and not shown\n# make case table\ncase_table <- data.frame(\n  zone       = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103))\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")## [1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))## [1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\nstr_glue(\"{case_table$zone}: {case_table$new_cases} new cases ({case_table$total_cases} total cases)\")## Zone 1: 3 new cases (40 total cases)\r\n## Zone 2: 0 new cases (4 total cases)\r\n## Zone 3: 7 new cases (25 total cases)\r\n## Zone 4: 0 new cases (10 total cases)\r\n## Zone 5: 15 new cases (103 total cases)\ncase_summary <- str_c(str_glue(\"{case_table$zone}: {case_table$new_cases} new cases ({case_table$total_cases} total cases)\"), collapse = \"\\n\\n\")\n\ncat(case_summary) # print## Zone 1: 3 new cases (40 total cases)\r\n## \r\n## Zone 2: 0 new cases (4 total cases)\r\n## \r\n## Zone 3: 7 new cases (25 total cases)\r\n## \r\n## Zone 4: 0 new cases (10 total cases)\r\n## \r\n## Zone 5: 15 new cases (103 total cases)"},{"path":"characters-and-strings.html","id":"unite-columns","chapter":"14 Characters and strings","heading":"Unite columns","text":"Within dataframe, bringing together character values multiple columns can achieved unite() tidyr. opposite separate().Provide name new united column. provide names columns wish unite.default separator used united column underscore _, can changed sep argument.remove = removes input columns data frame (TRUE default)na.rm = removes missing values uniting (FALSE default), unite three symptom columns dataframe.","code":"\ndf_split %>% \n  unite(\n    col = \"all_symptoms\",         # name of the new united column\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # columns to unite\n    sep = \", \",                   # separator to use in united column\n    remove = TRUE,                # if TRUE, removes input cols from the data frame\n    na.rm = TRUE                  # if TRUE, missing values are removed before uniting\n  )##   case_ID                all_symptoms outcome\r\n## 1       1     jaundice, fever, chills Success\r\n## 2       2        chills, aches, pains Failure\r\n## 3       3                       fever Failure\r\n## 4       4         vomiting, diarrhoea Success\r\n## 5       5 bleeding, from, gums, fever Success\r\n## 6       6      rapid, pulse, headache Success"},{"path":"characters-and-strings.html","id":"split","chapter":"14 Characters and strings","heading":"14.3.1 Split","text":"split string based pattern, use str_split(). evaluates strings returns list character vectors consisting newly-split values.simple example evaluates one string splits three. default returns list one element (character vector) string provided. simplify = TRUE returns character matrix.One string provided, returned list one element, character vector three valuesYou can assign named object, access nth symptom. access specific symptom can use syntax like : the_split_return_object[[1]][2], access second symptom first evaluated string (“fever”). See R Basics page detail accessing elements.multiple strings evaluated, one element returned list.return “character matrix” instead, may useful creating dataframe columns, set argument simplify = TRUE shown :can also adjust number splits create n = argument. example, restricts number splits (left side) 2 splits. commas remain within second split.Note - outputs can achieved str_split_fixed(), give simplify argument, must instead designate number columns (n).","code":"\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")## [[1]]\r\n## [1] \"jaundice\" \" fever\"   \" chills\"\npt1_symptoms <- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # extracts 2nd value from 1st (and only) element of the list## [1] \" fever\"\nsymptoms <- c(\"jaundice, fever, chills\",     # patient 1\n              \"chills, aches, pains\",        # patient 2 \n              \"fever\",                       # patient 3\n              \"vomiting, diarrhoea\",         # patient 4\n              \"bleeding from gums, fever\",   # patient 5\n              \"rapid pulse, headache\")       # patient 6\n\nstr_split(symptoms, \",\")                     # split each patient's symptoms## [[1]]\r\n## [1] \"jaundice\" \" fever\"   \" chills\" \r\n## \r\n## [[2]]\r\n## [1] \"chills\" \" aches\" \" pains\"\r\n## \r\n## [[3]]\r\n## [1] \"fever\"\r\n## \r\n## [[4]]\r\n## [1] \"vomiting\"   \" diarrhoea\"\r\n## \r\n## [[5]]\r\n## [1] \"bleeding from gums\" \" fever\"            \r\n## \r\n## [[6]]\r\n## [1] \"rapid pulse\" \" headache\"\nstr_split(symptoms, \",\", simplify = TRUE)##      [,1]                 [,2]         [,3]     \r\n## [1,] \"jaundice\"           \" fever\"     \" chills\"\r\n## [2,] \"chills\"             \" aches\"     \" pains\" \r\n## [3,] \"fever\"              \"\"           \"\"       \r\n## [4,] \"vomiting\"           \" diarrhoea\" \"\"       \r\n## [5,] \"bleeding from gums\" \" fever\"     \"\"       \r\n## [6,] \"rapid pulse\"        \" headache\"  \"\"\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)##      [,1]                 [,2]            \r\n## [1,] \"jaundice\"           \" fever, chills\"\r\n## [2,] \"chills\"             \" aches, pains\" \r\n## [3,] \"fever\"              \"\"              \r\n## [4,] \"vomiting\"           \" diarrhoea\"    \r\n## [5,] \"bleeding from gums\" \" fever\"        \r\n## [6,] \"rapid pulse\"        \" headache\"\nstr_split_fixed(symptoms, \",\", n = 2)"},{"path":"characters-and-strings.html","id":"split-columns","chapter":"14 Characters and strings","heading":"Split columns","text":"Use separate() dplyr within dataframe, split one character column columns.simple dataframe df consisting case ID column, one character column symptoms, one outcome column:First, provide column separated. provide = vector c( ) containing new columns names, shown .sep = separator, can character, number (interpreted character position split ).remove = FALSE default, removes input columnconvert = FALSE default, cause string “NA”s become NAextra = controls happens values created separation new columns named.\r\nextra = \"warn\" means see warning drop excess values (default)\r\nextra = \"drop\" means excess values dropped warning\r\nextra = \"merge\" split number new columns listed - setting preserve data\r\nextra = \"warn\" means see warning drop excess values (default)extra = \"drop\" means excess values dropped warningextra = \"merge\" split number new columns listed - setting preserve dataAn example extra = \"merge\" - data lost third symptoms combined second new named column:default extra = \"drop\" used , warning given third symptoms lost:CAUTION: provide enough values new columns, data may truncated.","code":"\n# third symptoms combined into second new column\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1          sym_2 outcome\r\n## 1       1           jaundice  fever, chills Success\r\n## 2       2             chills   aches, pains Failure\r\n## 3       3              fever           <NA> Failure\r\n## 4       4           vomiting      diarrhoea Success\r\n## 5       5 bleeding from gums          fever Success\r\n## 6       6        rapid pulse       headache Success\n# third symptoms are lost\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")## Warning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1      sym_2 outcome\r\n## 1       1           jaundice      fever Success\r\n## 2       2             chills      aches Failure\r\n## 3       3              fever       <NA> Failure\r\n## 4       4           vomiting  diarrhoea Success\r\n## 5       5 bleeding from gums      fever Success\r\n## 6       6        rapid pulse   headache Success"},{"path":"characters-and-strings.html","id":"arrange","chapter":"14 Characters and strings","heading":"Arrange","text":"Several strings can sorted alphabetical order. str_order() returns order, str_sort() returns strings order.use different alphabet, add argument locale =. See full list locales entering stringi::stri_locale_list() R console.arrange strings order value another column, use arrange() like : ","code":"\n# strings\nhealth_zones <- c(\"Alba\", \"Takota\", \"Delta\")\n\n# return the alphabetical order\nstr_order(health_zones)## [1] 1 3 2\n# return the strings in alphabetical order\nstr_sort(health_zones)## [1] \"Alba\"   \"Delta\"  \"Takota\""},{"path":"characters-and-strings.html","id":"base-r-functions","chapter":"14 Characters and strings","heading":"14.3.2 base R functions","text":"common see base R functions paste() paste0(), concatenate vectors converting parts character. act similarly str_c() syntax differs - code part separated comma. parts either text (quotes) pre-defined code objects. example:sep collapse arguments can adjusted. default, sep space, unless using paste0() space parts.","code":"\nn_beds <- 10\nn_masks <- 20\n\npaste(\"Regional hospital needs\", n_beds, \"beds and\", n_masks, \"masks.\")## [1] \"Regional hospital needs 10 beds and 20 masks.\""},{"path":"characters-and-strings.html","id":"adjust-length","chapter":"14 Characters and strings","heading":"14.4 Adjust length","text":"","code":""},{"path":"characters-and-strings.html","id":"pad","chapter":"14 Characters and strings","heading":"Pad","text":"Use str_pad() add characters string, minimum length. default spaces added, can also pad characters using pad = argument.example, pad numbers leading zeros (hours minutes), can pad number minimum length 2 pad = \"0\".","code":"\n# ICD codes of differing length\nICD_codes <- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# ICD codes padded to 7 characters on the right side\nstr_pad(ICD_codes, 7, \"right\")## [1] \"R10.13 \" \"R10.819\" \"R17    \"\n# Pad with periods instead of spaces\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")## [1] \"R10.13.\" \"R10.819\" \"R17....\"\n# Add leading zeros to two digits (e.g. for times minutes/hours)\nstr_pad(\"4\", 2, pad = \"0\") ## [1] \"04\"\n# example using a numeric column named \"hours\"\n# hours <- str_pad(hours, 2, pad = \"0\")"},{"path":"characters-and-strings.html","id":"truncate","chapter":"14 Characters and strings","heading":"Truncate","text":"str_trunc() sets maximum length string. string exceeds length, truncated (shortened) ellipsis (…) included indicate string previously longer. Note ellipsis counted length. ellipsis characters can changed argument ellipsis =. optional side = argument specifies ellipsis appear within truncated string (“left”, “right”, “center”).","code":"\noriginal <- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")## [1] \"Symp...ing\""},{"path":"characters-and-strings.html","id":"standardize-length","chapter":"14 Characters and strings","heading":"Standardize length","text":"Use str_trunc() set maximum length, use str_pad() expand short strings truncated length. example , 6 set maximum length (one value truncated), short value padded achieve length 6.","code":"\n# ICD codes of differing length\nICD_codes   <- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# truncate to maximum length of 6\nICD_codes_2 <- str_trunc(ICD_codes, 6)\nICD_codes_2## [1] \"R10.13\" \"R10...\" \"R17\"\n# expand to minimum length of 6\nICD_codes_3 <- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3## [1] \"R10.13\" \"R10...\" \"R17   \""},{"path":"characters-and-strings.html","id":"remove-leadingtrailing-whitespace","chapter":"14 Characters and strings","heading":"Remove leading/trailing whitespace","text":"Use str_trim() remove spaces, newlines (\\n) tabs (\\t) sides string input. Add \"right\" \"left\", \"\" command specify side trim (e.g. str_trim(x, \"right\").","code":"\n# ID numbers with excess spaces on right\nIDs <- c(\"provA_1852  \", # two excess spaces\n         \"provA_2345\",   # zero excess spaces\n         \"provA_9460 \")  # one excess space\n\n# IDs trimmed to remove excess spaces on right side only\nstr_trim(IDs)## [1] \"provA_1852\" \"provA_2345\" \"provA_9460\""},{"path":"characters-and-strings.html","id":"remove-repeated-whitespace-within","chapter":"14 Characters and strings","heading":"Remove repeated whitespace within","text":"Use str_squish() remove repeated spaces appear inside string. example, convert double spaces single spaces. also removes spaces, newlines, tabs outside string like str_trim().Enter ?str_trim, ?str_pad R console see details.","code":"\n# original contains excess spaces within string\nstr_squish(\"  Pt requires   IV saline\\n\") ## [1] \"Pt requires IV saline\""},{"path":"characters-and-strings.html","id":"wrap-into-paragraphs","chapter":"14 Characters and strings","heading":"Wrap into paragraphs","text":"Use str_wrap() wrap long unstructured text structured paragraph fixed line length. Provide ideal character length line, applies algorithm insert newlines (\\n) within paragraph, seen example .base function cat() can wrapped around command order print output, displaying new lines added.","code":"\npt_course <- \"Symptom onset 1/4/2020 vomiting chills fever. Pt saw traditional healer in home village on 2/4/2020. On 5/4/2020 pt symptoms worsened and was admitted to Lumta clinic. Sample was taken and pt was transported to regional hospital on 6/4/2020. Pt died at regional hospital on 7/4/2020.\"\n\nstr_wrap(pt_course, 40)## [1] \"Symptom onset 1/4/2020 vomiting chills\\nfever. Pt saw traditional healer in\\nhome village on 2/4/2020. On 5/4/2020\\npt symptoms worsened and was admitted\\nto Lumta clinic. Sample was taken and pt\\nwas transported to regional hospital on\\n6/4/2020. Pt died at regional hospital\\non 7/4/2020.\"\ncat(str_wrap(pt_course, 40))## Symptom onset 1/4/2020 vomiting chills\r\n## fever. Pt saw traditional healer in\r\n## home village on 2/4/2020. On 5/4/2020\r\n## pt symptoms worsened and was admitted\r\n## to Lumta clinic. Sample was taken and pt\r\n## was transported to regional hospital on\r\n## 6/4/2020. Pt died at regional hospital\r\n## on 7/4/2020."},{"path":"characters-and-strings.html","id":"change-case","chapter":"14 Characters and strings","heading":"14.5 Change case","text":"Often one must alter case/capitalization string value, example names jursidictions. Use str_to_upper(), str_to_upper(), str_to_title(), shown :Using *base** R, can also achieved toupper(), tolower().Title caseTransforming string word capitalized can achieved str_to_title():Use toTitleCase() tools package achieve nuanced capitalization (words like “”, “”, “” capitalized).can also use str_to_sentence(), capitalizes first letter string.","code":"\nstr_to_upper(\"California\")## [1] \"CALIFORNIA\"\nstr_to_lower(\"California\")## [1] \"california\"\nstr_to_title(\"go to the US state of california \")## [1] \"Go To The Us State Of California \"\ntools::toTitleCase(\"This is the US state of california\")## [1] \"This is the US State of California\"\nstr_to_sentence(\"the patient must be transported\")## [1] \"The patient must be transported\""},{"path":"characters-and-strings.html","id":"patterns","chapter":"14 Characters and strings","heading":"14.6 Patterns","text":"Many stringr functions work detect, locate, extract, match, replace, split based specified pattern.","code":""},{"path":"characters-and-strings.html","id":"detect-a-pattern","chapter":"14 Characters and strings","heading":"Detect a pattern","text":"Use str_detect() detect presence/absence pattern within string. First list string vector search , pattern look . Note default search case sensitive!argument negate = can included set TRUE want know pattern present.ignore case/capitalization, wrap pattern within regex() within regex() add argument ignore_case = T.str_detect() applied character vector/column, return TRUE/FALSE values vector.need count , apply sum() output. counts number TRUE.search inclusive multiple terms, include separated bars (|) within pattern, shown :need make long list search terms, can combine using str_c() sep = |, define character object, reference later succinctly. example includes possible occupation search terms frontline medical providers.command returns number occupations contain one search terms front-line medical providers (occupation_med_frontline):Base R string search functionsThe base function grepl() works similarly str_detect(), searches matches pattern returns logical vector. basic syntax grepl(pattern, strings_to_search, ignore.case = FALSE, ...). One advantage ignore.case argument easier write (need involve regex() function).Likewise, base functions sub() gsub() act similarly str_replace(). basic syntax : gsub(pattern, replacement, strings_to_search, ignore.case = FALSE). sub() replace first instance pattern, whereas gsub() replace instances pattern.","code":"\nstr_detect(\"primary school teacher\", \"teach\")## [1] TRUE\nstr_detect(\"primary school teacher\", \"teach\", negate = TRUE)## [1] FALSE\nstr_detect(\"Teacher\", regex(\"teach\", ignore_case = T))## [1] TRUE\n# a vector/column of occupations \noccupations <- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# Detect presence of pattern \"teach\" in each string - output is vector of TRUE/FALSE\nstr_detect(occupations, \"teach\")##  [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\nsum(str_detect(occupations, \"teach\"))## [1] 1\nsum(str_detect(occupations, \"teach|professor|tutor\"))## [1] 3\n# search terms\noccupation_med_frontline <- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline## [1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\nsum(str_detect(occupations, occupation_med_frontline))## [1] 2"},{"path":"characters-and-strings.html","id":"convert-commas-to-periods","chapter":"14 Characters and strings","heading":"Convert commas to periods","text":"example using gsub() convert commas periods vector numbers. useful data come much world United States Great Britain.inner gsub() acts first lengths converting periods space \"“. period character”.\" “escaped” two slashes actually signify period, “.” regex means “character”. , result (commas) passed outer gsub() commas replaced periods.","code":"\nlengths <- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # find commas     \n                replacement = \".\",            # replace with periods\n                x = gsub(\"\\\\.\", \"\", lengths)  # vector with other periods removed (periods escaped)\n                )\n           )                                  # convert outcome to numeric"},{"path":"characters-and-strings.html","id":"replace-all","chapter":"14 Characters and strings","heading":"Replace all","text":"Use str_replace_all() “find replace” tool. First, provide strings evaluated, pattern replaced, replacement value. example replaces instances “dead” “deceased”. Note, case sensitive.replace pattern NA, use str_replace_na(). function str_replace() replaces first instance pattern within evaluated string.","code":"\noutcome <- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(outcome, \"dead\", \"deceased\")## [1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\""},{"path":"characters-and-strings.html","id":"detect-within-logic","chapter":"14 Characters and strings","heading":"Detect within logic","text":"Within case_when()str_detect() often used within case_when() (dplyr). Let’s say occupations column linelist called occupations. mutate() creates new column called is_educator using conditional logic via case_when(). See page data cleaning learn case_when().reminder, may important add exclusion criteria conditional logic (negate = F):","code":"\ndf <- df %>% \n  mutate(is_educator = case_when(\n    # term search within occupation, not case sensitive\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # all others\n    TRUE                                               ~ \"Not an educator\"))df <- df %>% \r\n  # value in new column is_educator is based on conditional logic\r\n  mutate(is_educator = case_when(\r\n    \r\n    # occupation column must meet 2 criteria to be assigned \"Educator\":\r\n    # it must have a search term AND NOT any exclusion term\r\n    \r\n    # Must have a search term AND\r\n    str_detect(occupations,\r\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &              \r\n    # Must NOT have an exclusion term\r\n    str_detect(occupations,\r\n               regex(\"admin\", ignore_case = T),\r\n               negate = T)                          ~ \"Educator\"\r\n    \r\n    # All rows not meeting above criteria\r\n    TRUE                                            ~ \"Not an educator\"))"},{"path":"characters-and-strings.html","id":"locate-pattern-position","chapter":"14 Characters and strings","heading":"Locate pattern position","text":"locate first position pattern, use str_locate(). outputs start end position.Like str functions, \"_all\" version (str_locate_all()) return positions instances pattern within string. outputs list.","code":"\nstr_locate(\"I wish\", \"sh\")##      start end\r\n## [1,]     5   6\nphrases <- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" )     # position of *first* instance of the pattern##      start end\r\n## [1,]     6   6\r\n## [2,]     3   3\r\n## [3,]     1   1\r\n## [4,]     4   4\nstr_locate_all(phrases, \"h\" ) # position of *every* instance of the pattern## [[1]]\r\n##      start end\r\n## [1,]     6   6\r\n## \r\n## [[2]]\r\n##      start end\r\n## [1,]     3   3\r\n## \r\n## [[3]]\r\n##      start end\r\n## [1,]     1   1\r\n## [2,]     4   4\r\n## \r\n## [[4]]\r\n##      start end\r\n## [1,]     4   4"},{"path":"characters-and-strings.html","id":"extract-a-match","chapter":"14 Characters and strings","heading":"Extract a match","text":"str_extract_all() returns matching patterns , useful offered several patterns via “” conditions. example, looking string vector occupations (see previous tab) either “teach”, “prof”, “tutor”.str_extract_all() returns list contains matches evaluated string. See occupation 3 two pattern matches within .str_extract() extracts first match evaluated string, producing character vector one element evaluated string. returns NA match. NAs can removed wrapping returned vector na.exclude(). Note second occupation 3’s matches shown.","code":"\nstr_extract_all(occupations, \"teach|prof|tutor\")## [[1]]\r\n## character(0)\r\n## \r\n## [[2]]\r\n## [1] \"prof\"\r\n## \r\n## [[3]]\r\n## [1] \"teach\" \"tutor\"\r\n## \r\n## [[4]]\r\n## [1] \"tutor\"\r\n## \r\n## [[5]]\r\n## character(0)\r\n## \r\n## [[6]]\r\n## character(0)\r\n## \r\n## [[7]]\r\n## character(0)\r\n## \r\n## [[8]]\r\n## character(0)\r\n## \r\n## [[9]]\r\n## character(0)\r\n## \r\n## [[10]]\r\n## character(0)\nstr_extract(occupations, \"teach|prof|tutor\")##  [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA      NA"},{"path":"characters-and-strings.html","id":"subset-and-count","chapter":"14 Characters and strings","heading":"Subset and count","text":"Subset, CountAligned functions include str_subset() str_count().str_subset() returns actual values contained pattern:`str_count() returns vector numbers: number times search term appears evaluated value.","code":"\nstr_subset(occupations, \"teach|prof|tutor\")## [1] \"university professor\"           \"primary school teacher & tutor\" \"tutor\"\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))##  [1] 0 1 2 1 0 0 0 0 0 0"},{"path":"characters-and-strings.html","id":"regex-groups","chapter":"14 Characters and strings","heading":"Regex groups","text":"Groups within stringsstr_match() TBD","code":""},{"path":"characters-and-strings.html","id":"regex-and-special-characters","chapter":"14 Characters and strings","heading":"14.7 Regex and special characters","text":"Regular expressions, “regex”, concise language describing patterns strings.Much section adapted tutorial cheatsheet","code":""},{"path":"characters-and-strings.html","id":"special-characters","chapter":"14 Characters and strings","heading":"Special characters","text":"Backslash \\ escapeThe backslash \\ used “escape” meaning next character. way, backslash can used quote mark display within quote marks (\\\") - middle quote mark “break” surrounding quote marks.Note - thus, want display backslash, must escape ’s meaning *another backslash. must write two backslashes \\\\ display one.Special charactersRun ?\"'\" R Console display complete list special characters (appear RStudio Help pane).","code":""},{"path":"characters-and-strings.html","id":"regular-expressions-regex","chapter":"14 Characters and strings","heading":"Regular expressions (regex)","text":"familiar , regular expression can look like alien language:regular expression applied extract specific patterns unstructured text - example medical notes, chief complaint, matient history, free text columns dataset.four basic tools one can use create basic regular expression:Character setsMeta charactersQuantifiersGroupsCharacter setsCharacter sets, way expressing listing options character match, within brackets. match triggered characters within brackets found string. example, look vowels one use character set: “[aeiou]”. common character sets :Character sets can combined within one bracket (spaces!), \"[-Za-z]\" (upper lowercase letter), another example \"[t-z0-5]\" (lowercase t z number 0 5).Meta charactersMeta characters shorthand character sets. important ones listed :QuantifiersTypically want search match one character. Quantifiers allow designate length letters/numbers allow match.Quantifiers numbers written within curly brackets { } character quantifying, example,\"{2}\" return instances two capital letters.\"{2,4}\" return instances two four capital letters (put spaces!).\"{2,}\" return instances two capital letters.\"+\" return instances one capital letters (group extended different character encountered).Precede * asterisk return zero matches (useful sure pattern present)Using + plus symbol quantifier, match occur different character encountered. example, expression return words (alpha characters: \"[-Za-z]+\"quantifier {2} used, pairs consecutive ’s returned. Two pairs identified within AAAA.quantifier {2,4} used, groups consecutive ’s two four length returned.quantifier +, groups one returned:Relative positionThese express requirements precedes follows pattern. example, extract sentences, “two numbers followed period” (\"\"). (?<=\\.)\\s(?=[-Z])GroupsCapturing groups regular expression way organized output upon extraction.Regex examplesBelow free text examples. try extract useful information using regular expression search term.expression matches words (character hitting non-character space):expression \"[0-9]{1,2}\" matches consecutive numbers 1 2 digits length. also written \"\\\\d{1,2}\", \"[:digit:]{1,2}\".expression extract sentences (assuming first letter capitalized, sentence ends period). pattern reads English : \"capital letter followed lowercase letters, space, letters, space,can view useful list regex expressions tips page 2 cheatsheetAlso see tutorial.","code":"\n# test string for quantifiers\ntest <- \"A-AA-AAA-AAAA\"\nstr_extract_all(test, \"A{2}\")## [[1]]\r\n## [1] \"AA\" \"AA\" \"AA\" \"AA\"\nstr_extract_all(test, \"A{2,4}\")## [[1]]\r\n## [1] \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"A+\")## [[1]]\r\n## [1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"\")## [[1]]\r\n##  [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\npt_note <- \"Patient arrived at Broward Hospital emergency ward at 18:00 on 6/12/2005. Patient presented with radiating abdominal pain from LR quadrant. Patient skin was pale, cool, and clammy. Patient temperature was 99.8 degrees farinheit. Patient pulse rate was 100 bpm and thready. Respiratory rate was 29 per minute.\"\nstr_extract_all(pt_note, \"[A-Za-z]+\")## [[1]]\r\n##  [1] \"Patient\"     \"arrived\"     \"at\"          \"Broward\"     \"Hospital\"    \"emergency\"   \"ward\"        \"at\"          \"on\"          \"Patient\"    \r\n## [11] \"presented\"   \"with\"        \"radiating\"   \"abdominal\"   \"pain\"        \"from\"        \"LR\"          \"quadrant\"    \"Patient\"     \"skin\"       \r\n## [21] \"was\"         \"pale\"        \"cool\"        \"and\"         \"clammy\"      \"Patient\"     \"temperature\" \"was\"         \"degrees\"     \"farinheit\"  \r\n## [31] \"Patient\"     \"pulse\"       \"rate\"        \"was\"         \"bpm\"         \"and\"         \"thready\"     \"Respiratory\" \"rate\"        \"was\"        \r\n## [41] \"per\"         \"minute\"\nstr_extract_all(pt_note, \"[0-9]{1,2}\")## [[1]]\r\n##  [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\"\nstr_split(pt_note, \".\")## [[1]]\r\n##   [1] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\r\n##  [48] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\r\n##  [95] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\r\n## [142] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\r\n## [189] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\r\n## [236] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\r\n## [283] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\nstr_extract_all(pt_note, \"[A-Z][a-z]+\\\\s\\\\w+\\\\s\\\\d{1,2}\\\\s\\\\w+\\\\s*\\\\w*\")## [[1]]\r\n## character(0)"},{"path":"characters-and-strings.html","id":"resources-7","chapter":"14 Characters and strings","heading":"14.8 Resources","text":"reference sheet stringr functions can found hereA vignette stringr can found ","code":""},{"path":"de-duplication.html","id":"de-duplication","chapter":"15 De-duplication","heading":"15 De-duplication","text":"","code":""},{"path":"de-duplication.html","id":"overview-4","chapter":"15 De-duplication","heading":"15.1 Overview","text":"page covers following subjects:Identifying removing duplicate rows“Slicing” keeping certain rows (min, max, random…), also group“Rolling-”, combining values multiple rows one","code":""},{"path":"de-duplication.html","id":"preparation-6","chapter":"15 De-duplication","heading":"15.2 Preparation","text":"","code":""},{"path":"de-duplication.html","id":"load-packages-6","chapter":"15 De-duplication","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,   # deduplication, grouping, and slicing functions\n  janitor,     # function for reviewing duplicates\n  stringr)      # for string searches, can be used in \"rolling-up\" values"},{"path":"de-duplication.html","id":"import-data-6","chapter":"15 De-duplication","heading":"Import data","text":"demonstration, use example dataset created R code . data records COVID-19 phone encounters, including contacts cases.first two records 100% complete duplicates including duplicate recordID (computer glitch)second two rows duplicates, columns except recordIDSeveral people multiple phone encounters, various dates/times contacts casesAt encounter, person asked ever symptoms, information missing.code create dataset:dataset:quick summary people dataset purposes encounters:","code":"\nobs <- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\"))\nobs %>% \n  tabyl(name, purpose)##     name case contact\r\n##     adam    1       2\r\n##   amrish    1       3\r\n##    brian    1       2\r\n##   mariah    1       2\r\n##  natalie    1       0\r\n##   nikhil    0       2\r\n##   raquel    0       2\r\n##    smita    0       1"},{"path":"de-duplication.html","id":"deduplication-1","chapter":"15 De-duplication","heading":"15.3 Deduplication","text":"section describes review remove duplicate rows dataframe. also show handle duplicate elements vector.","code":""},{"path":"de-duplication.html","id":"examine-duplicate-rows","chapter":"15 De-duplication","heading":"Examine duplicate rows","text":"quickly review rows duplicates, can use get_dupes() janitor package. default, columns considered duplicates evaluated - rows returned 100% duplicates considering values columns.obs dataframe, first two rows 100% duplicates - value every column (including recordID column, supposed unique - must computer glitch). returned dataframe automatically includes new column dupe_count, showing number rows combination duplicate values.However, choose ignore recordID, 3rd 4th rows rows also duplicates . , values columns except recordID. can specify specific columns ignored function using - minus symbol.can also positively specify columns consider. , rows values name purpose columns returned. Notice “amrish” now dupe_count equal 3 reflect three “contact” encounters.*Scroll left rows**See ?get_dupes details, see online reference","code":"\n# 100% duplicates across all columns\nobs %>% \n  janitor::get_dupes()\n# Duplicates when column recordID is not considered\nobs %>% \n  janitor::get_dupes(-recordID)         # if multiple columns, wrap them in c()\n# duplicates based on name and purpose columns ONLY\nobs %>% \n  janitor::get_dupes(name, purpose)"},{"path":"de-duplication.html","id":"keep-only-unique-rows","chapter":"15 De-duplication","heading":"Keep only unique rows","text":"keep unique rows dataframe, use distinct() dplyr. Rows duplicates removed first rows kept. default, “first” means highest rownumber (order rows top--bottom). unique rows kept.example , run distinct() column recordID excluded consideration - thus two duplicate rows removed. first row (“adam”) 100% duplicated removed. Also row 3 (“amrish”) duplicate every column except recordID (considered) also removed. obs dataset n now 17, 19 rows).Scroll left see entire dataframeCAUTION: using distinct() grouped data, function apply group.Deduplicate based specific columnsYou can also specify columns basis de-duplication. way, de-duplication applies rows duplicates within specified columns. Unless specified .keep_all = TRUE, columns mentioned dropped.example , de-duplication applies rows identical values name purpose columns. Thus, “brian” 2 rows instead 3 - first “contact” encounter “case” encounter. adjust brian’s latest encounter purpose kept, see tab Slicing within groups.Scroll left see entire dataframe","code":"\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(across(-recordID), # reduces dataframe to only unique rows (keeps first one of any duplicates)\n           .keep_all = TRUE) \n\n# if outside pipes, include the data as first argument \n# distinct(obs)\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(name, purpose, .keep_all = TRUE) %>%  # keep rows unique by name and purpose, retain all columns\n  arrange(name)                                  # arrange for easier viewing"},{"path":"de-duplication.html","id":"duplicate-elements-in-a-vector","chapter":"15 De-duplication","heading":"Duplicate elements in a vector","text":"function duplicated() base R evaluate vector (column) return logical vector length (TRUE/FALSE). first time value appears, return FALSE (duplicate), subsequent times value appears return TRUE. Note NA treated value.return duplicated elements, can use brackets subset original vector:return unique elements, use unique() base R. remove NAs output, nest na.omit() within unique().","code":"\nx <- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)##  [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\nx[duplicated(x)]## [1]  1 NA  4  4  1  2\nunique(x)           # alternatively, use x[!duplicated(x)]## [1]  1  2 NA  4  5\nunique(na.omit(x))  # remove NAs ## [1] 1 2 4 5"},{"path":"de-duplication.html","id":"with-base-r","chapter":"15 De-duplication","heading":"with base R","text":"return duplicate rowsIn base R, can also see rows 100% duplicates dataframe df command duplicated(df) (returns logical vector rows).Thus, can also use base subset [ ] dataframe see duplicated rows df[duplicated(df),] (don’t forget comma, meaning want see columns!).return unique rowsSee notes . see unique rows add logical negator ! front duplicated() function:df[!duplicated(df),]return rows duplicates certain columnsSubset df within duplicated() parentheses, function operate certain columns df.specify columns, provide column numbers names comma (remember, within duplicated() function).sure keep comma , outside duplicated() function well!example, evaluate columns 2 5 duplicates: df[!duplicated(df[, 2:5]),]\r\nevaluate columns name purpose duplicates: df[!duplicated(df[, c(\"name\", \"purpose)]),]","code":""},{"path":"de-duplication.html","id":"slicing","chapter":"15 De-duplication","heading":"15.4 Slicing","text":"“slice” dataframe useful de-duplication multiple rows per functional group (e.g. per “person”) want analyze one . Think slicing filter rows, row number/position.basic slice() function accepts number n. positive, nth row returned. negative, rows except nth returned.Variations include:slice_min() slice_max() - keep row minimium maximum value specified column. Also worked ordered factors.slice_head() slice_tail - keep first last rowslice_sample() - keep random sample rowsUse arguments n = prop = specify number proportion rows keep. using function pipe chain, provide data argument first (e.g. slice(df, n = 2)). See ?slice information.arguments:.order_by = used slice_min() slice_max() column order slicing.with_ties = TRUE default, meaning ties kept..preserve = FALSE default. TRUE grouping structure re-calculated slicing.weight_by = Optional, numeric column weight (bigger number likely get sampled). Also replace = whether sampling done /without replacement.TIP: using slice_max() slice_min(), sure specify/write n = (e.g. n = 2, just 2). Otherwise may get error Error:…empty. NOTE: may encounter function top_n(), superseded slice functions., basic slice() function used keep 4th row:","code":"\nobs %>% \n  slice(4)  # keeps the 4th row only"},{"path":"de-duplication.html","id":"slice-with-groups","chapter":"15 De-duplication","heading":"Slice with groups","text":"slice_*() functions can useful applied grouped dataframe, slice operation performed group separately. Use function group_by() conjunction slice() group data take slice group.helpful de-duplication multiple rows per person want keep one . first use group_by() key columns , use slice function column differ among grouped rows.example , keep latest encounter per person, group rows name use slice_max() n = 1 date column. aware! apply function like slice_max() dates, date column must class Date.default, “ties” (e.g. date scenario) kept, still get multiple rows people (e.g. adam). avoid set with_ties = FALSE. get back one row per person.CAUTION: using arrange(), specify .by_group = TRUE data arranged within group.DANGER: with_ties = FALSE, first row tie kept. may deceptive. See Mariah, two encounters latest date (6 Jan) first (earliest) one kept. Likely, want keep later encounter day. See “break” ties next example. Breaking “ties”Multiple slice statements can run “break ties”. case, person multiple encounters latest date, encounter latest time kept (lubridate::hm() used convert character times sortable time class).\r\nNote now, one row kept “Mariah” 6 Jan encounter 3 08:32, encounter 2 07:25.example , also possible slice encounter number, showed slice date time example purposes.TIP: use slice_max() slice_min() “character” column, mutate ordered factor class!","code":"\nobs %>% \n  group_by(name) %>%       # group the rows by 'name'\n  slice_max(date,          # keep row per group with maximum date value \n            n = 1,         # keep only the single highest row \n            with_ties = F) # if there's a tie (of date), take the first row\n# Example of multiple slice statements to \"break ties\"\nobs %>%\n  group_by(name) %>%\n  \n  # FIRST - slice by latest date\n  slice_max(date, n = 1, with_ties = TRUE) %>% \n  \n  # SECOND - if there is a tie, select row with latest time; ties prohibited\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)"},{"path":"de-duplication.html","id":"keep-all-but-mark-them","chapter":"15 De-duplication","heading":"Keep all but mark them","text":"want keep records mark analysis, consider two-step approach utilizing unique recordID/encounter number:Reduce/slice orginal dataframe rows analysis. Save/retain reduced dataframe.original dataframe, mark rows appropriate case_when(), based whether record unique identifier (recordID example) present reduced dataframe.","code":"\n# 1. Define dataframe of rows to keep for analysis\nobs_keep <- obs %>%\n  group_by(name) %>%\n  slice_max(encounter, n = 1, with_ties = FALSE) # keep only latest encounter per person\n\n\n# 2. Mark original dataframe\nobs_marked <- obs %>%\n\n  # make new dup_record column\n  mutate(dup_record = case_when(\n    \n    # if record is in obs_keep dataframe\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    # all else marked as \"Ignore\" for analysis purposes\n    TRUE                            ~ \"Ignore\"))\n\n# print\nobs_marked"},{"path":"de-duplication.html","id":"calculate-row-completeness","chapter":"15 De-duplication","heading":"Calculate row completeness","text":"Create column contains metric row’s completeness (non-missingness). helpful deciding rows prioritize others de-duplicating/slicing.example, “key” columns want measure completeness saved vector column names.new column key_completeness created mutate(). new value row defined calculated fraction: number non-missing values row among key columns, divided number key columns.involves function rowSums() base R. Also used ., within piping refers dataframe point pipe (case, subset brackets []).*Scroll right see rows**","code":"\n# create a \"key variable completeness\" column\n# this is a *proportion* of the columns designated as \"key_cols\" that have non-missing values\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %>% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) "},{"path":"de-duplication.html","id":"roll-up-values","chapter":"15 De-duplication","heading":"15.5 Roll-up values","text":"section describes:“roll-” values multiple rows just one row, variationsOnce “rolled-” values, overwrite/prioritize values cellThis tab uses example dataset Preparation tab.","code":""},{"path":"de-duplication.html","id":"roll-up-values-into-one-row","chapter":"15 De-duplication","heading":"Roll-up values into one row","text":"code example uses group_by() summarise() group rows person, paste together unique values within grouped rows. Thus, get one summary row per person. notes:suffix appended new columns (\"_roll\" example)want show unique values per cell, wrap na.omit() unique()na.omit() removes NA values, desired can removed paste0(.x)…Scroll left see rowsThe result one row per group (ID), entries arranged date pasted together.variation shows unique values :variation appends suffix column.\r\ncase \"_roll\" signify rolled:","code":"\n# \"Roll-up\" values into one row per group (per \"personID\") \ncases_rolled <- obs %>% \n  \n  # create groups by name\n  group_by(personID) %>% \n  \n  # order the rows within each group (e.g. by date)\n  arrange(date, .by_group = TRUE) %>% \n  \n  # For each column, paste together all values within the grouped rows, separated by \";\"\n  summarise(\n    across(everything(),                           # apply to all columns\n           ~paste0(na.omit(.x), collapse = \"; \"))) # function is defined which combines non-NA values\n# Variation - show unique values only \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                                   # apply to all columns\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # function is defined which combines unique non-NA values\n# Variation - suffix added to column names \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll is appended to column names"},{"path":"de-duplication.html","id":"overwrite-valueshierarchy","chapter":"15 De-duplication","heading":"Overwrite values/hierarchy","text":"want evaluate rolled values, keep specific value (e.g. “best” “maximum” value), can use mutate() across desired columns, implement case_when(), uses str_detect() stringr package sequentially look string patterns overwrite cell content.Now can see column symptoms_ever person EVER said “Yes” symptoms, “Yes” displayed.","code":"\n# CLEAN CASES\n#############\ncases_clean <- cases_rolled %>% \n    \n    # clean Yes-No-Unknown vars: replace text with \"highest\" value present in the string\n    mutate(across(c(contains(\"symptoms_ever\")),                     # operates on specified columns (Y/N/U)\n             list(mod = ~case_when(                                 # adds suffix \"_mod\" to new cols; implements case_when()\n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # if \"Yes\" is detected, then cell value converts to yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # then, if \"No\" is detected, then cell value converts to no\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # then, if \"Unknown\" is detected, then cell value converts to Unknown\n               TRUE                        ~ as.character(.x)))),   # then, if anything else if it kept as is\n      .keep = \"unused\")                                             # old columns removed, leaving only _mod columns"},{"path":"de-duplication.html","id":"probabilistic-de-duplication","chapter":"15 De-duplication","heading":"15.6 Probabilistic de-duplication","text":"Sometimes, may want identify “likely” duplicates based similarity (e.g. string “distance”) across several columns name, age, sex, date birth, etc. can apply probabilistic matching algorithm identify likely duplicates.See page Joining data explanation method. section Probabilistic Matching contains example applying algorithms compare dataframe , thus performing probabilistic de-duplication.","code":""},{"path":"de-duplication.html","id":"resources-8","chapter":"15 De-duplication","heading":"15.7 Resources","text":"Much information page adapted resources vignettes online:datanoviadplyr tidyverse referencecran janitor vignette","code":""},{"path":"iteration-and-loops.html","id":"iteration-and-loops","chapter":"16 Iteration and loops","heading":"16 Iteration and loops","text":"PAGE CURRENTLY CONSTRUCTIONThis page introduce two approaches iterative operations - using loops using package purrr. Iterative operations help perform repetitive tasks, reduce chances error, reduce code length, maximize efficiency.purrr facilitates “mapping” function across many inputs (columns, datasets, etc.)purrr facilitates “mapping” function across many inputs (columns, datasets, etc.)loops also iterate code across series inputs, less common R programming languages R can wrap processes functionsfor loops also iterate code across series inputs, less common R programming languages R can wrap processes functions","code":""},{"path":"iteration-and-loops.html","id":"preparation-7","chapter":"16 Iteration and loops","heading":"16.1 Preparation","text":"","code":""},{"path":"iteration-and-loops.html","id":"load-packages-7","chapter":"16 Iteration and loops","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n     rio,         # import/export\n     here,        # file locator\n     purrr,       # iteration\n     tidyverse    # data management and visualization\n)"},{"path":"iteration-and-loops.html","id":"import-data-7","chapter":"16 Iteration and loops","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"iteration-and-loops.html","id":"purrr","chapter":"16 Iteration and loops","heading":"16.2 purrr","text":"One approach iterative operations purrr package. faced performing task several times, probably worth creating generalised solution can use across many inputs. example, producing plots multiple jurisdictions, importing combining many files.using loop, can probably cleanly purrr!","code":""},{"path":"iteration-and-loops.html","id":"load-packages-8","chapter":"16 Iteration and loops","heading":"Load packages","text":"purrr part tidyverse, need install/load separate package.","code":"\npacman::p_load(\n  rio,            # import/export\n  here,           # relative filepaths\n  tidyverse,      # data mgmt and viz\n  writexl,        # write Excel file with multiple sheets\n  readxl          # import Excel with multiple sheets\n  )"},{"path":"iteration-and-loops.html","id":"map","chapter":"16 Iteration and loops","heading":"map()","text":"One core purrr function map(), “maps” (applies) function input element provide.\r\nbasic syntax map(.x = SEQUENCE, .f = FUNCTION, ARGUMENTS). bit detail:.x = inputs upon .f function iteratively applied - e.g. vector jurisdiction names, columns data frame, list data frames.f = function apply element .x input - function define. written tilde ~.notes syntax:.f needs arguments specified, can written parentheses (e.g. map(.x, ~mean))provide arguments value iteration, provide outside .f function map(.x ~mean, na.rm=T)value argument change iteration, value .x , provide within .f function parentheses\r\ncan use .x (simply .) within .f function placeholder .x value iteration\r\ncan use .x (simply .) within .f function placeholder .x value iterationLet’s demonstrate common epidemiologist task: want import Excel workbook case data, data split across different named sheets workbook. efficiently import combine sheets one data frame?Let’s say sent Excel workbook. sheet contains cases given hospital.one approach uses map():map() function import() Excel sheetCombine data frames one using bind_rows()Along way, preserve sheet name origin case, storing new column data frameFirst, need extract sheet names save . provide Excel workbook’s file path function excel_sheets() package readxl, extracts sheet names. store character vector called sheet_names.names:Now vector names, map() can provide one--one function import(). example, sheet_names .x import() function .f.Recall Import export page used Excel workbooks, import() can accept argument = specifying sheet import. Within .f function (import()), provide = .x, whose value change iteration vector sheet_names - first “Central Hospital”, “Military Hospital”, etc.note - used map(), data Excel sheet saved R separate data frame within List. want list elements (data frames) name, pass sheet_names map() pass set_names(), ensures list elements gets appropriate name.save output List combined.inspect combined List output, see data Excel sheet saved named data frames within List. good, quite finished.Lastly, use function bind_rows() (dplyr) accepts list data frames combines one data frame. create column list element names, use argument .id = provide desired name new column.whole sequence commands:variations map() aware . example - map_dfr() returns data frame, list. Thus, used task bind rows. able capture sheet (hospital) case came .variations include map_chr(), map_dbl(), map_if(). - EXPLANATION","code":"\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\nsheet_names## [1] \"Central Hospital\"              \"Military Hospital\"             \"Missing\"                       \"Other\"                        \r\n## [5] \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\ncombined <- sheet_names %>% \n  set_names() %>% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\ncombined <- sheet_names %>% \n  set_names() %>% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %>% \n  bind_rows(.id = \"origin_sheet\")"},{"path":"iteration-and-loops.html","id":"mapping-a-function-across-columns","chapter":"16 Iteration and loops","heading":"Mapping a function across columns","text":"Another common use-case map function across many columns. , map() function t.test() across numeric columns data frame linelist, comparing numeric values gender.Recall page Simple statistical tests t.test() can take inputs formula format, t.test(numeric column ~ binary column). example, following:numeric columns interest selected linelist - become .x inputs map()function t.test() supplied .f function, applied numeric columnWithin parentheses t.test():\r\nfirst ~ preceedes .f map iterate .x\r\n.x represents current column supplied function t.test()\r\nsecond ~ part t-test equation described \r\nt.test() function expects binary column right-hand side equation. supply vector linelist$gender independently statically (note included select()).\r\nfirst ~ preceedes .f map iterate .xthe .x represents current column supplied function t.test()second ~ part t-test equation described abovethe t.test() function expects binary column right-hand side equation. supply vector linelist$gender independently statically (note included select()).map() returns List, output list t-test results - one list element numeric column analysed. show first one six, demonstration purposes.wanted p-values , can modify .f function appending $p.value t.test() output. way, value map() returns ’s output list p-value entire t.test output.Note:\r\nRemember want apply function certain columns data frame, can also use mutate() across(), explained Cleaning data core functions page. example applying .character() “age” columns. Note placement parentheses commas.","code":"\n# Results are saved as a list\nt.test_results <- linelist %>% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %>%  # keep only the numeric columns to map across\n  map(.f = ~t.test(.x ~ linelist$gender))              # t.test function, with equation NUMERIC ~ CATEGORICAL\n\nt.test_results[[1]] # show first result ## \r\n##  Welch Two Sample t-test\r\n## \r\n## data:  .x by linelist$gender\r\n## t = -21, df = 4903, p-value <2e-16\r\n## alternative hypothesis: true difference in means is not equal to 0\r\n## 95 percent confidence interval:\r\n##  -7.54 -6.27\r\n## sample estimates:\r\n## mean in group f mean in group m \r\n##            12.7            19.6\nlinelist %>% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %>% \n  map(.f = ~t.test(. ~ linelist$gender)$p.value)## $age\r\n## [1] 2.35e-96\r\n## \r\n## $wt_kg\r\n## [1] 2.66e-182\r\n## \r\n## $ht_cm\r\n## [1] 3.52e-144\r\n## \r\n## $ct_blood\r\n## [1] 0.447\r\n## \r\n## $temp\r\n## [1] 0.574\n# convert columns with column name containing \"age\" to class Character\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  "},{"path":"iteration-and-loops.html","id":"custom-functions","chapter":"16 Iteration and loops","heading":"Custom functions","text":"often want create function provide map(). One example making purely custom plotting function provide map() shown .Let’s say want create epidemic curves hospital’s cases. using purrr, .f function can ggplot() extensions + usual. output map() always list, plots stored list. can extracted plotted ggarrange() function ggpubr package (documentation).code style looks messy, can achieve result saving specific ggplot() command custom user-defined function, example can name make_epicurve()). function used within map(). .x iteratively replaced hospital name, used hosp_name make_epicurve() function. See page Writing functions.","code":"\n# load package for plotting elements from list\npacman::p_load(ggpubr)\n\n# map across the vector of 6 hospital \"names\" (created earlier)\n# use the ggplot function specified\n# output is a list with 6 ggplots\n\nhospital_names <- unique(linelist$hospital)\n\nmy_plots <- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %>% filter(hospital == .x))+\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\nmake_epicurve <- function(hosp_name){\n  \n  ggplot(data = linelist %>% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n# mapping\nmy_plots <- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)"},{"path":"iteration-and-loops.html","id":"split-datasets","chapter":"16 Iteration and loops","heading":"Split datasets","text":"","code":""},{"path":"iteration-and-loops.html","id":"split-dataset-and-export-csv-files","chapter":"16 Iteration and loops","heading":"Split dataset and export CSV files","text":"complex purrr map() example involves splitting dataset mapping functions part.Let’s say complete case linelist data frame, now want create separate linelist hospital export separate CSV file. , following steps:Use group_split() (dplyr) split linelist data frame unique values column hospital. output List containing one data frame per hospital subset.can View(linelsit_split) see list contains 6 data frames, representing cases one hospital.However, note data frames list names default! want name, use name saving CSV file., use pull() (purrr) extract hospital column data frame list. , safe, convert values character use unique() get name particular dataset. steps applied data frame via map()can now see list elements name. names can accessed via names(linelist_split).Lastly, export data frame .csv file, name specific hospital. use map(): take vector list element names (shown ) use map() iterate , applying export() (rio package, see Import export page) data frame list linelist_split name. also use name create unique file name. works:begin vector character names, passed map() .xThe .f function export() , requires data frame file path write toThe input .x (hospital name) used within .f extract/index specific element linelist_split list. results one data frame time provided export().\r\nexample, map() iterates “Military Hospital”, linelist_split[[.x]] actually linelist_split[[\"Military Hospital\"]], thus returning second element linelist_split - cases Military Hospital.\r\nexample, map() iterates “Military Hospital”, linelist_split[[.x]] actually linelist_split[[\"Military Hospital\"]], thus returning second element linelist_split - cases Military Hospital.file path provided export() dynamic via use str_glue() (see Characters strings page):\r\n() used get base file path specify “data” folder (note single quotes interrupt str_glue() double quotes)\r\nslash /, .x prints current hospital name make file identifiable\r\nFinally extension “.csv” export() uses create CSV file\r\n() used get base file path specify “data” folder (note single quotes interrupt str_glue() double quotes)slash /, .x prints current hospital name make file identifiableFinally extension “.csv” export() uses create CSV fileNow can see file saved “data” folder R Project “Epi_R_handbook”!","code":"\nlinelist_split <- linelist %>% \n  group_split(hospital)\nnames(linelist_split) <- linelist_split %>%   # Assign the names of each data frame in the list linelist_split \n                                              # Extract the names by doing the following to each data frame: \n  map(.f = ~pull(.x, hospital)) %>%             # Pull out hospital column\n  map(.f = ~as.character(.x)) %>%               # Convert to character\n  map(.f = ~unique(.x))                         # Take the unique hospital name\nnames(linelist_split)## [1] \"Central Hospital\"                     \"Military Hospital\"                    \"Missing\"                             \r\n## [4] \"Other\"                                \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\nnames(linelist_split) %>%\n  map(.f = ~export(linelist_split[[.x]], file= str_glue(\"{here('data')}/{.x}.csv\")))"},{"path":"iteration-and-loops.html","id":"split-dataset-and-export-as-excel-sheets","chapter":"16 Iteration and loops","heading":"Split dataset and export as Excel sheets","text":"export hospital linelists Excel workbook one linelist per sheet, can just provide named list linelist_split write_xlsx() function writexl package. ability save one Excel workbook multiple sheets. list element names automatically applied sheet names.can now open Excel file see hospital sheet.","code":"\nlinelist_split %>% \n  writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))"},{"path":"iteration-and-loops.html","id":"more-than-one-group_split-column","chapter":"16 Iteration and loops","heading":"More than one group_split() column","text":"wanted split linelist one grouping column, produce subset linelist intersection hospital gender, need different approach naming list elements. involves collecting unique “group keys” using group_keys() dplyr - returned data frame. can combine group keys values unite() shown , assign conglomerate names linelist_split.Now combine groupings together, separated dashes, assign names list elements linelist_split. takes extra lines replace NA “Missing”, use unite() dplyr combine column values together (separated dashes), convert un-named vector can used names linelist_split.","code":"\n# split linelist by unique hospital-gender combinations\nlinelist_split <- linelist %>% \n  group_split(hospital, gender)\n\n# extract group_keys() as a dataframe\ngroupings <- linelist %>% \n  group_by(hospital, gender) %>%       \n  group_keys()\n\ngroupings      # show unique groupings ## # A tibble: 18 x 2\r\n##    hospital                             gender\r\n##    <chr>                                <chr> \r\n##  1 Central Hospital                     f     \r\n##  2 Central Hospital                     m     \r\n##  3 Central Hospital                     <NA>  \r\n##  4 Military Hospital                    f     \r\n##  5 Military Hospital                    m     \r\n##  6 Military Hospital                    <NA>  \r\n##  7 Missing                              f     \r\n##  8 Missing                              m     \r\n##  9 Missing                              <NA>  \r\n## 10 Other                                f     \r\n## 11 Other                                m     \r\n## 12 Other                                <NA>  \r\n## 13 Port Hospital                        f     \r\n## 14 Port Hospital                        m     \r\n## 15 Port Hospital                        <NA>  \r\n## 16 St. Mark's Maternity Hospital (SMMH) f     \r\n## 17 St. Mark's Maternity Hospital (SMMH) m     \r\n## 18 St. Mark's Maternity Hospital (SMMH) <NA>\n# Combine into one name value \nnames(linelist_split) <- groupings %>% \n  mutate(across(everything(), replace_na, \"Missing\")) %>%  # replace NA with \"Missing\" in all columns\n  unite(\"combined\", sep = \"-\") %>%                         # Unite all column values into one\n  setNames(NULL) %>% \n  as_vector() %>% \n  as.list()"},{"path":"iteration-and-loops.html","id":"pmap","chapter":"16 Iteration and loops","heading":"pmap()","text":"SECTION CONSTRUCTION","code":""},{"path":"iteration-and-loops.html","id":"for-loops","chapter":"16 Iteration and loops","heading":"16.3 for loops","text":"epidemiologist, common need repeat analyses sub-groups (e.g. jurisdictions sub-populations). Iterating loop one method automate process.loop three core parts:container results (optional)sequence items iterate throughThe operations conduct per item sequenceThe basic syntax : (item sequence) {operations using item}. Note parentheses curly brackets. results printed console, stored container R object.","code":""},{"path":"iteration-and-loops.html","id":"container","chapter":"16 Iteration and loops","heading":"Container","text":"Sometimes results loop printed console Plots pane. times, want store outputs container later use. container vector, data frame, even list.efficient create container results even beginning loop. practice, means creating empty vector, data frame, list. can created functions vector() vectors lists, matrix() data.frame() data frame.Empty vector\r\nSay want store median delay--admission hospital new vector. Use vector() specify class either “double” (hold numbers), “character”, “logical”. case use “double” set length number expected outputs (length sequence, case number unique hospitals data set).Empty data frameYou can make empty data frame specifying number rows columns like :Empty listSay want store plots created loop list. actually initialize container using vector() command , mode = \"list\". Specify length however wish.","code":"\ndelays <- vector(mode = \"double\",\n                 length = length(unique(linelist$hospital))) # this is the number of unique hospitals in the dataset\ndelays <- data.frame(matrix(ncol = 2, nrow = 3))\nplots <- vector(mode = \"list\", length = 16)"},{"path":"iteration-and-loops.html","id":"sequence","chapter":"16 Iteration and loops","heading":"Sequence","text":"“” part loop - operations run item sequence. sequence can series character values (e.g. jurisdictions, diseases, etc), R object names (e.g. column names list element names), sequence can series consecutive numbers (e.g. 1,2,3,4,5). approach utilities, described .Sequence character valuesIn case, loop applied value character vector.value “item”, whose value changes iteration loop, proceeds value character vector. example, term hosp represents value vector hospital_names. first iteration loop value “Port Hospital”. TFor second loop “St. Mark’s Maternity Hospital (SMMH)”. …Sequence namesThis variation character sequence , names existing R object extracted become character vector. example, column names data frame. useful know names exact matches column names thus can used index R object within loop., sequence names() (column names) linelist. Inside loop, column names used index (subset) linelist one---time. example, demonstrate conditional statement part operations code within loop. column interest class Numeric, mean column printed console. column class Numeric another statement printed console.note indexing column names - whenever referencing column (e.g. within mean()) just write “col”! col just character column name! refer entire column use column name index* linelist via linelist[[col]].Sequence numbersUse approach plan complicated operations store results loop. approach, sequence series consecutive numbers. Thus, value “item” character value (e.g. “Central Hospital” “date_onset”) number. useful looping data frames, can use numeric item inside loop index dataframe row number.example, let’s say want loop every row data frame extract certain information. “items” numeric row numbers. process explained “every item sequence numbers 1 total number rows data frame, X”. first iteration loop, 1. second iteration, 2, etc.Whew, mouthful words! looks like code: (seq_len(nrow(linelist)) {} represents item seq_len() produces sequence consecutive numbers 1 number rows linelist. using approach named vector (data frame), use seq_along(), like (seq_along(hospital_names) {}.code actually returns numbers, become value respective loop.","code":"\n# make vector of the hospital names\nhospital_names <- unique(linelist$hospital)\nhospital_names # print## [1] \"Other\"                                \"Missing\"                              \"St. Mark's Maternity Hospital (SMMH)\"\r\n## [4] \"Port Hospital\"                        \"Military Hospital\"                    \"Central Hospital\"\n# 'for loop'\nfor (hosp in hospital_names){       # sequence\n  \n  # OPERATIONS HERE\n  \n}\nfor (col in names(linelist)){ \n  \n  # if column is class Numeric, print the mean value\n  if(is.numeric(linelist[[col]])) {\n    print(mean(linelist[[col]], na.rm=T))     # don't forget to index with [[col]]\n    } else {        \n    print(\"Column not numeric\")            # if column is not numeric, print this\n  }\n  \n}## [1] \"Column not numeric\"\r\n## [1] 16.6\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] 16.1\r\n## [1] \"Column not numeric\"\r\n## [1] 16\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] -13.2\r\n## [1] 8.47\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] 52.6\r\n## [1] 125\r\n## [1] 21.2\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] \"Column not numeric\"\r\n## [1] 38.6\r\n## [1] \"Column not numeric\"\r\n## [1] 46.9\r\n## [1] 2.06for (i in seq_len(nrow(linelist)) {  # use on a data frame\r\n  # OPERATIONS HERE\r\n}  \nseq_along(hospital_names)  # use on a named vector## [1] 1 2 3 4 5 6"},{"path":"iteration-and-loops.html","id":"operations","chapter":"16 Iteration and loops","heading":"Operations","text":"code within loop. want run item sequence. Therefore, careful every part code changes item correctly coded changes! Remember use [[ ]] indexing. example,, use seq_len() linelist. gender age row pasted together stored container character vector cases_demographics.","code":"\n# create container to store results - a character vector\ncases_demographics <- vector(mode = \"character\", length = nrow(linelist))\n\n# the for loop\nfor (i in seq_len(nrow(linelist))){\n  \n  # OPERATIONS\n  # extract values from linelist for i using indexing\n  row_gender  <- linelist$gender[[i]]\n  row_age     <- linelist$age_years[[i]]    # don't forget to index!\n  \n  # store the gender-age in container at indexed location\n  cases_demographics[[i]] <- str_c(row_gender, row_age, sep = \", \") \n\n}  # end for loop\n\n# display first 10 rows of container\nhead(cases_demographics, 10)##  [1] \"m, 2\"  \"f, 3\"  \"m, 56\" \"f, 18\" \"m, 3\"  \"f, 16\" \"f, 16\" \"f, 0\"  \"m, 61\" \"f, 27\""},{"path":"iteration-and-loops.html","id":"printing","chapter":"16 Iteration and loops","heading":"Printing","text":"Note print within loop likely need explicitly wrap function print().example , sequence explicit character vector, used subset linelist hospital.results stored container, rather print console print() function.","code":"\nfor (hosp in hospital_names){ \n  hospital_cases <- linelist %>% filter(hospital == hosp)\n  print(nrow(hospital_cases))\n}## [1] 885\r\n## [1] 1469\r\n## [1] 422\r\n## [1] 1762\r\n## [1] 896\r\n## [1] 454"},{"path":"iteration-and-loops.html","id":"testing-your-for-loop","chapter":"16 Iteration and loops","heading":"Testing your for loop","text":"test loop, can make temporarily assignment item, <- 10 hosp <- \"Central Hospital\" run operations code see expected results produced.","code":""},{"path":"iteration-and-loops.html","id":"looping-plots","chapter":"16 Iteration and loops","heading":"Looping plots","text":"put three components together (container, sequence, operations) let’s try plot epicurve hospital (see page Epidemic curves.course, can make epicurve cases using incidence2 package :produce separate plot hospital’s cases, can put epicurve code within loop.First, save named vector unique hospital names, hospital_names. loop run names ((hosp hospital_names)). iteration loop, current hospital name vector represented “hosp” use within loop.Within loop, can write R code normal, use item (hosp case) knowing value changing. Within loop:filter() applied linelist, column hospital must equal current value hospThe incidence object created filtered linelistThe plot current hospital created, auto-adjusting titleThe plot current hospital temporarily saved printedThe loop moves onward repeat next hospital hospital_names","code":"\n# create 'incidence' object\noutbreak <- incidence2::incidence(   \n     x = linelist,                   # dataframe - complete linelist\n     date_index = date_onset,        # date column\n     interval = \"week\",              # aggregate counts weekly\n     groups = gender,                # group values by gender\n     na_as_group = TRUE)             # missing gender is own group\n\n# plot epi curve\nplot(outbreak,                       # name of incidence object\n     fill = \"gender\",                # color bars by gender\n     color = \"black\",                # outline color of bars\n     title = \"Outbreak of ALL cases\" # title\n     )\n# make vector of the hospital names\nhospital_names <- unique(linelist$hospital)\n\n# for each name (\"hosp\") in hospital_names, create and print the epi curve\nfor (hosp in hospital_names) {\n     \n     # create incidence object specific to the current hospital\n     outbreak_hosp <- incidence2::incidence(\n                    x = linelist %>% filter(hospital == hosp),   # linelist is filtered to the current hospital\n                    date_index = date_onset,\n                    interval = \"week\", \n                    groups = gender,\n                    na_as_group = TRUE\n     )\n     \n     # Create and save the plot. Title automatically adjusts to the current hospital\n     plot_hosp <- plot(outbreak_hosp,\n                       fill = \"gender\",\n                       color = \"black\",\n                       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n                       )\n     \n     # print the plot for the current hospital\n     print(plot_hosp)\n\n} # end the for loop when it has been run for every hospital in hospital_names "},{"path":"iteration-and-loops.html","id":"tracking-progress-of-a-loop","chapter":"16 Iteration and loops","heading":"Tracking progress of a loop","text":"loop many iterations can run many minutes even hours. Thus, can helpful print progress R console. code can placed within loop print every 100th number.","code":"# loop with code to print progress every 100 iterations\r\nfor (row in 1:nrow(linelist)){\r\n\r\n  # print progress\r\n  if(row %% 100==0){    # The %% operator is the remainder\r\n    print(row)\r\n\r\n}"},{"path":"iteration-and-loops.html","id":"resources-9","chapter":"16 Iteration and loops","heading":"16.4 Resources","text":"loops Data CarpentryThe R Data Science page iterationVignette write/read Excel filesA purrr tutorialpurrr cheatsheetTO \r\ngroup_split\r\ncollapse\r\npluckset_names()\r\nvars = linelist %>%\r\nselect_if(.numeric) %>%\r\nselect(-cyl, - year) %>%\r\nnames() %>%\r\nset_names()","code":""},{"path":"descriptive-tables.html","id":"descriptive-tables","chapter":"17 Descriptive tables","heading":"17 Descriptive tables","text":"page demonstrates use janitor, dplyr, gtsummary, base R produce tables descriptive statistics. tools advantages disadvantages areas code simplicity, accessibility outputs, quality printed outputs. Use page decide approach works scenario.","code":""},{"path":"descriptive-tables.html","id":"preparation-8","chapter":"17 Descriptive tables","heading":"17.1 Preparation","text":"","code":""},{"path":"descriptive-tables.html","id":"load-packages-9","chapter":"17 Descriptive tables","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics, \n  gtsummary,    # summary statistics and tests\n  janitor,      # adding totals and percents to tables\n  scales,       # easily convert proportions to percents  \n  flextable     # converting tables to HTML\n  )"},{"path":"descriptive-tables.html","id":"import-data-8","chapter":"17 Descriptive tables","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"descriptive-tables.html","id":"browse-data","chapter":"17 Descriptive tables","heading":"17.2 Browse data","text":"","code":""},{"path":"descriptive-tables.html","id":"skimr-package","chapter":"17 Descriptive tables","heading":"skimr package","text":"Using skimr package can get detailed aesthetically pleasing overview variables dataset. Read skimr github page., function skim() applied entire linelist data frame. overview data frame summary every column (class) produced.\r\nTable 17.1: Data summary\r\nVariable type: characterVariable type: DateVariable type: factorVariable type: numericYou can also use summary() function, base R, get information entire dataset, output can difficult read using skimr. Therefore output shown , conserve page space.","code":"\n## get information about each variable in a dataset \nskim(linelist)\n## get information about each column in a dataset \nsummary(linelist)"},{"path":"descriptive-tables.html","id":"summary-statistics","chapter":"17 Descriptive tables","heading":"Summary statistics","text":"can use base R functions return summary statistics numeric column. can return useful summary statistics numeric column using summary(), . Note data frame name must also specified shown .can access save one specific part index brackets [ ]:can return individual statistics base R functions like max(), min(), median(), mean(), quantile(), sd(), range(). See R Basics page complete list.CAUTION: data contain missing values, R wants know return NA unless specify mathematical functions want R ignore missing values, via argument na.rm = TRUE.","code":"\nsummary(linelist$age_years)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \r\n##       0       6      13      16      23      84      86\nsummary(linelist$age_years)[[2]]            # return only the 2nd element## [1] 6\n# summary(linelist$age_years)[[\"1st Qu.\"]]  # equivalent, alternative to above by element name"},{"path":"descriptive-tables.html","id":"descriptive-tables-1","chapter":"17 Descriptive tables","heading":"17.3 Descriptive tables","text":"several choices producing tabulation cross-tabulation summary tables. factors consider include code simplicity ease, desired output (printed R console, pretty HTML), can data afterward. Consider points choose tool situation.Use tabyl() janitor produce “adorn” tabulations cross-tabulationsUse summarise() count() dplyr calculating complex statistics preparing data ggplot()Use tbl_summary() gtsummary produce detailed publication-ready tablesUse table() base R access packages","code":""},{"path":"descriptive-tables.html","id":"janitor-package","chapter":"17 Descriptive tables","heading":"17.4 janitor package","text":"janitor packages offers tabyl() function produce tabulations cross-tabulations, can “adorned” modified helper functions display percents, proportions, counts, etc., pipe linelist data frame janitor functions print result. desired, can also save resulting tables assignment operator <-.","code":""},{"path":"descriptive-tables.html","id":"simple-tabyl","chapter":"17 Descriptive tables","heading":"Simple tabyl","text":"default use tabyl() specific column produces unique values, counts, column-wise “percents” (actually proportions). proportions may many digits. can adjust number decimals adorn_rounding() described .can see , missing values display row labeled <NA>. can suppress show_na = FALSE. missing values, row appear. missing values, proportions given raw (denominator inclusive NA counts) “valid” (denominator excludes NA counts).column class Factor certain levels present data, levels still appear table. can suppress feature specifying show_missing_levels = FALSE.","code":"\nlinelist %>% tabyl(age_cat)##  age_cat    n percent valid_percent\r\n##      0-4 1095 0.18597       0.18873\r\n##      5-9 1095 0.18597       0.18873\r\n##    10-14  941 0.15982       0.16219\r\n##    15-19  743 0.12619       0.12806\r\n##    20-29 1073 0.18224       0.18494\r\n##    30-49  754 0.12806       0.12996\r\n##    50-69   95 0.01613       0.01637\r\n##      70+    6 0.00102       0.00103\r\n##     <NA>   86 0.01461            NA"},{"path":"descriptive-tables.html","id":"cross-tabulation","chapter":"17 Descriptive tables","heading":"Cross-tabulation","text":"Cross-tabulation counts achieved adding one additional columns within tabyl(). Note counts returned - proportions percents can added additional steps shown .","code":"\nlinelist %>% tabyl(age_cat, gender)##  age_cat   f   m NA_\r\n##      0-4 640 416  39\r\n##      5-9 641 412  42\r\n##    10-14 518 383  40\r\n##    15-19 359 364  20\r\n##    20-29 468 575  30\r\n##    30-49 179 557  18\r\n##    50-69   2  91   2\r\n##      70+   0   5   1\r\n##     <NA>   0   0  86"},{"path":"descriptive-tables.html","id":"adorning-the-tabyl","chapter":"17 Descriptive tables","heading":"“Adorning” the tabyl","text":"Use janitor’s “adorn” functions add totals convert proportions, percents, otherwise adjust display. Often, pipe tabyl multiple functions.conscious order apply functions. examples.simple one-way table percents instead default proportions.cross-tabulation total row row percents.cross-tabulation adjusted counts percents displayed.","code":"\nlinelist %>%               # case linelist\n  tabyl(age_cat) %>%       # tabulate counts and proportions by age category\n  adorn_pct_formatting()   # convert proportions to percents##  age_cat    n percent valid_percent\r\n##      0-4 1095   18.6%         18.9%\r\n##      5-9 1095   18.6%         18.9%\r\n##    10-14  941   16.0%         16.2%\r\n##    15-19  743   12.6%         12.8%\r\n##    20-29 1073   18.2%         18.5%\r\n##    30-49  754   12.8%         13.0%\r\n##    50-69   95    1.6%          1.6%\r\n##      70+    6    0.1%          0.1%\r\n##     <NA>   86    1.5%             -\nlinelist %>%                                  \n  tabyl(age_cat, gender) %>%                  # counts by age and gender\n  adorn_totals(where = \"row\") %>%             # add total row\n  adorn_percentages(denominator = \"row\") %>%  # convert counts to proportions\n  adorn_pct_formatting(digits = 1)            # convert proportions to percents##  age_cat     f     m    NA_\r\n##      0-4 58.4% 38.0%   3.6%\r\n##      5-9 58.5% 37.6%   3.8%\r\n##    10-14 55.0% 40.7%   4.3%\r\n##    15-19 48.3% 49.0%   2.7%\r\n##    20-29 43.6% 53.6%   2.8%\r\n##    30-49 23.7% 73.9%   2.4%\r\n##    50-69  2.1% 95.8%   2.1%\r\n##      70+  0.0% 83.3%  16.7%\r\n##     <NA>  0.0%  0.0% 100.0%\r\n##    Total 47.7% 47.6%   4.7%\nlinelist %>%                                  # case linelist\n  tabyl(age_cat, gender) %>%                  # cross-tabulate counts\n  adorn_totals(where = \"row\") %>%             # add a total row\n  adorn_percentages(denominator = \"col\") %>%  # convert to proportions\n  adorn_pct_formatting() %>%                  # convert to percents\n  adorn_ns(position = \"front\") %>%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                      Gender                           \r\n##  Age Category             f             m          NA_\r\n##           0-4  640  (22.8%)  416  (14.8%)  39  (14.0%)\r\n##           5-9  641  (22.8%)  412  (14.7%)  42  (15.1%)\r\n##         10-14  518  (18.5%)  383  (13.7%)  40  (14.4%)\r\n##         15-19  359  (12.8%)  364  (13.0%)  20   (7.2%)\r\n##         20-29  468  (16.7%)  575  (20.5%)  30  (10.8%)\r\n##         30-49  179   (6.4%)  557  (19.9%)  18   (6.5%)\r\n##         50-69    2   (0.1%)   91   (3.2%)   2   (0.7%)\r\n##           70+    0   (0.0%)    5   (0.2%)   1   (0.4%)\r\n##          <NA>    0   (0.0%)    0   (0.0%)  86  (30.9%)\r\n##         Total 2807 (100.0%) 2803 (100.0%) 278 (100.0%)"},{"path":"descriptive-tables.html","id":"printing-the-tabyl","chapter":"17 Descriptive tables","heading":"Printing the tabyl","text":"default, tabyl print raw R console. Alternatively, can pass tabyl flextable package print HTML RStudio Viewer. Note using adorn_titles(), must specify placement = \"combined\" order print manner.Age Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%) 941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%) 743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%) 754 (12.8%)50-69  2  (0.1%) 91  (3.2%) 2  (0.7%)  95  (1.6%)70+  0  (0.0%)  5  (0.2%) 1  (0.4%)   6  (0.1%)  0  (0.0%)  0  (0.0%)86 (30.9%)  86  (1.5%)","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% # this is necessary to print to HTML \n  flextable::flextable() %>%    # convert to HTML\n  flextable::autofit()          # format to one line per row "},{"path":"descriptive-tables.html","id":"use-on-other-tables","chapter":"17 Descriptive tables","heading":"Use on other tables","text":"can use janitor’s adorn_*() functions tables, created summarise(), count(), table().","code":""},{"path":"descriptive-tables.html","id":"saving-the-tabyl","chapter":"17 Descriptive tables","heading":"Saving the tabyl","text":"convert table HTML package like flextable, can save functions save_as_html(), save_as_word(), save_as_ppt(), save_as_image(), discussed extensively HTML tables page. , table saved Word document, can hand-edited.","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% \n  flextable::flextable() %>%                     # convert to HTML flextable\n  flextable::autofit() %>%                       # ensure only one line per row\n  flextable::save_as_docx(path = \"tabyl.docx\")   # save as Word document"},{"path":"descriptive-tables.html","id":"statistics","chapter":"17 Descriptive tables","heading":"Statistics","text":"can apply statistical tests tabyls, like chisq.test() fisher.test() stats package, shown . Note missing values allowed excluded tabyl show_na = FALSE.","code":"\nage_by_outcome <- linelist %>% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)## \r\n##  Pearson's Chi-squared test\r\n## \r\n## data:  age_by_outcome\r\n## X-squared = 6, df = 7, p-value = 0.5"},{"path":"descriptive-tables.html","id":"other-tips","chapter":"17 Descriptive tables","heading":"Other tips","text":"Include argument na.rm = TRUE exclude missing values calculations.applying adorn_*() helper functions tables created tabyl(), can specify particular column(s) apply like adorn_percentage(,,,c(cases,deaths)) (specify 4th unnamed argument). syntax simple. Consider using summarise() instead.can read detail janitor page tabyl vignette.","code":""},{"path":"descriptive-tables.html","id":"dplyr-package","chapter":"17 Descriptive tables","heading":"17.5 dplyr package","text":"dplyr part tidyverse packages common data management tool. Creating tables dplyr functions summarise() count() useful approach calculating summary statistics, summarize group, pass tables ggplot().summarise() creates new, summary data frame. data ungrouped, return one-row dataframe specified summary statistics entire data frame. data grouped, new data frame one row per group (see Grouping data page).Within summarise() parentheses, provide names new summary column followed equals sign statistical function apply.TIP: summarise function works UK US spelling (summarise() summarize()).","code":""},{"path":"descriptive-tables.html","id":"get-counts","chapter":"17 Descriptive tables","heading":"Get counts","text":"simple function apply within summarise() n(). Leave parentheses empty count number rows.gets interesting grouped data beforehand.command can shortened using count() function instead. count() groups data columns provided , summarises n() (creating column n), finishes un-grouping data.Tabulations two columns manner still returned “long” format, counts n column.","code":"\nlinelist %>%                 # begin with linelist\n  summarise(n_rows = n())    # return new summary dataframe with column n_rows##   n_rows\r\n## 1   5888\nlinelist %>% \n  group_by(age_cat) %>%     # group data by unique values in column age_cat\n  summarise(n_rows = n())   # return number of rows *per group*## # A tibble: 9 x 2\r\n##   age_cat n_rows\r\n##   <fct>    <int>\r\n## 1 0-4       1095\r\n## 2 5-9       1095\r\n## 3 10-14      941\r\n## 4 15-19      743\r\n## 5 20-29     1073\r\n## 6 30-49      754\r\n## 7 50-69       95\r\n## 8 70+          6\r\n## 9 <NA>        86\nlinelist %>% \n  count(age_cat)##   age_cat    n\r\n## 1     0-4 1095\r\n## 2     5-9 1095\r\n## 3   10-14  941\r\n## 4   15-19  743\r\n## 5   20-29 1073\r\n## 6   30-49  754\r\n## 7   50-69   95\r\n## 8     70+    6\r\n## 9    <NA>   86\nlinelist %>% \n  count(age_cat, outcome)##    age_cat outcome   n\r\n## 1      0-4   Death 471\r\n## 2      0-4 Recover 364\r\n## 3      0-4    <NA> 260\r\n## 4      5-9   Death 476\r\n## 5      5-9 Recover 391\r\n## 6      5-9    <NA> 228\r\n## 7    10-14   Death 438\r\n## 8    10-14 Recover 303\r\n## 9    10-14    <NA> 200\r\n## 10   15-19   Death 323\r\n## 11   15-19 Recover 251\r\n## 12   15-19    <NA> 169\r\n## 13   20-29   Death 477\r\n## 14   20-29 Recover 367\r\n## 15   20-29    <NA> 229\r\n## 16   30-49   Death 329\r\n## 17   30-49 Recover 238\r\n## 18   30-49    <NA> 187\r\n## 19   50-69   Death  33\r\n## 20   50-69 Recover  38\r\n## 21   50-69    <NA>  24\r\n## 22     70+   Death   3\r\n## 23     70+ Recover   3\r\n## 24    <NA>   Death  32\r\n## 25    <NA> Recover  28\r\n## 26    <NA>    <NA>  26"},{"path":"descriptive-tables.html","id":"proportions","chapter":"17 Descriptive tables","heading":"Proportions","text":"Proportions can added piping table mutate() create new column. Define new column counts column (n default) divided sum() counts column (return proportion). easily get percents, can wrap result function percent() package scales.method calculate proportions within groups. relies different levels data grouping selectively applied removed. First, data grouped outcome via group_by(). , count() applied. function groups data age_cat returns counts outcome-age-cat combination. Importantly - finishes process, count() also ungroups age_cat grouping, remaining data grouping original grouping outcome. Thus, final step calculating percents (sum(n)) still grouped outcome.","code":"\nage_summary <- linelist %>% \n  count(age_cat) %>%                     # group and count by gender (produces \"n\" column)\n  mutate(                                # get percent of column - note the denominator\n    percent = scales::percent(n / sum(n))) \n\n# print\nage_summary##   age_cat    n percent\r\n## 1     0-4 1095  18.60%\r\n## 2     5-9 1095  18.60%\r\n## 3   10-14  941  15.98%\r\n## 4   15-19  743  12.62%\r\n## 5   20-29 1073  18.22%\r\n## 6   30-49  754  12.81%\r\n## 7   50-69   95   1.61%\r\n## 8     70+    6   0.10%\r\n## 9    <NA>   86   1.46%\nage_by_outcome <- linelist %>%                  # begin with linelist\n  group_by(outcome) %>%                         # group by outcome \n  count(age_cat) %>%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group"},{"path":"descriptive-tables.html","id":"plotting","chapter":"17 Descriptive tables","heading":"Plotting","text":"display “long” table output like ggplot() relatively straight-forward. data naturally “long” format, naturally accepted ggplot(). See examples pages Plot categorical data ggplot tips.","code":"\nlinelist %>%                      # begin with linelist\n  count(age_cat, outcome) %>%     # group and tabulate counts by two columns\n  ggplot()+                       # pass new data frame to ggplot\n    geom_bar(                     # create bar plot\n      mapping = aes(   \n        x = outcome,              # map outcome to x-axis\n        fill = age_cat,           # map age_cat to the fill\n        y = n),                   # map the counts column `n` to the height\n      stat = \"identity\")          # set height from the y value, not the number of rows"},{"path":"descriptive-tables.html","id":"summary-statistics-1","chapter":"17 Descriptive tables","heading":"Summary statistics","text":"One major advantage dplyr summarise() ability return advanced statistical summaries like median(), mean(), max(), min(), sd() (standard deviation), percentiles. can also use sum() return number rows meet certain logical criteria. , outputs can produced whole data frame set, group.noted , within summarise() parentheses provide names new summary column followed equals sign statistical function apply. Within statistical function, give column operated relevant arguments (e.g. na.rm = TRUE mathematical functions).can also use sum() return number rows meet logical criteria. expression within counted evaluates TRUE. example: sum(age_years < 18, na.rm=T) sum(gender == \"male\", na.rm=T)., linelist data summarised describe days delay symptom onset hospital admission (column days_onset_hosp), hospital.tips:Use sum() logic statement “count” rows meet certain criteria (==)Note use na.rm = TRUE within mathematical functions like sum(), otherwise NA returned missing valuesUse function percent() scales package easily convert percentsUse round() base R specify decimalsTo calculate statistics entire dataset, use summarise() without group_by()","code":"\nsummary_table <- linelist %>%                                        # begin with linelist, save out as new object\n  group_by(hospital) %>%                                             # group all calculations by hospital\n  summarise(                                                         # only the below summary columns will be returned\n    cases       = n(),                                                # number of rows per group\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # max delay\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # mean delay, rounded\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # standard deviation of delays, rounded\n    delay_3     = sum(days_onset_hosp >= 3, na.rm = T),               # number of rows with delay of 3 or more days\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # convert previously-defined delay column to percent \n  )\n\nsummary_table  # print## # A tibble: 6 x 7\r\n##   hospital                             cases delay_max delay_mean delay_sd delay_3 pct_delay_3\r\n##   <chr>                                <int>     <dbl>      <dbl>    <dbl>   <int> <chr>      \r\n## 1 Central Hospital                       454        12        1.9      1.9     108 24%        \r\n## 2 Military Hospital                      896        15        2.1      2.4     253 28%        \r\n## 3 Missing                               1469        22        2.1      2.3     399 27%        \r\n## 4 Other                                  885        18        2        2.2     234 26%        \r\n## 5 Port Hospital                         1762        16        2.1      2.2     470 27%        \r\n## 6 St. Mark's Maternity Hospital (SMMH)   422        18        2.1      2.3     116 27%"},{"path":"descriptive-tables.html","id":"glueing-together","chapter":"17 Descriptive tables","heading":"Glueing together","text":"can also use str_glue() stringr combine columns one new column - typically used summarise() command., summary_table data frame created mutated columns delay_mean delay_sd combined, parentheses formating added new column, respective old columns removed., make table presentable, total row added adorn_totals() janitor (ignores non-numeric columns). Lastly, use rename() dplyr make column names nicer.Now pass flextable print table Word, HTML, Powerpoint, RMarkdown, etc.! (see janitor section HTML tables page).","code":"\nsummary_table %>% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %>%  # combine and format other values\n  select(-c(delay_mean, delay_sd)) %>%                       # remove two old columns   \n  adorn_totals(where = \"row\") %>%                            # add total row\n  rename(                                                    # rename cols\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )##                         Hospital Name Cases Max delay Delay 3+ days % delay 3+ days Mean (sd)\r\n##                      Central Hospital   454        12           108             24% 1.9 (1.9)\r\n##                     Military Hospital   896        15           253             28% 2.1 (2.4)\r\n##                               Missing  1469        22           399             27% 2.1 (2.3)\r\n##                                 Other   885        18           234             26%   2 (2.2)\r\n##                         Port Hospital  1762        16           470             27% 2.1 (2.2)\r\n##  St. Mark's Maternity Hospital (SMMH)   422        18           116             27% 2.1 (2.3)\r\n##                                 Total  5888       101          1580               -         -"},{"path":"descriptive-tables.html","id":"percentiles","chapter":"17 Descriptive tables","heading":"Percentiles","text":"Percentiles deserve special mention. return percentiles, use quantile() defaults specify value(s) like probs =.","code":"\n# get default percentile values of age (0%, 25%, 50%, 75%, 100%)\nlinelist %>% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))##   age_percentiles\r\n## 1               0\r\n## 2               6\r\n## 3              13\r\n## 4              23\r\n## 5              84\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %>% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )##   age_percentiles\r\n## 1               1\r\n## 2              13\r\n## 3              23\r\n## 4              48"},{"path":"descriptive-tables.html","id":"on-aggregated-data","chapter":"17 Descriptive tables","heading":"On aggregated data","text":"begin aggregated data, use sum() data’s counts column. example, let’s say beginning data frame counts , called linelist_agg - shows “long” format case counts outcome gender.create example data frame linelist case counts outcome gender (missing values removed clarity).sum counts (e.g. column n) group can use summarise() set new column equal sum(n, na.rm=T). add subset criteria sum operation, can use subset bracket [ ] syntax counts column shown create male female columns.","code":"\nlinelist_agg <- linelist %>% \n  filter(!is.na(gender),\n         !is.na(outcome)) %>% \n  count(outcome, gender)\n\nlinelist_agg##   outcome gender    n\r\n## 1   Death      f 1227\r\n## 2   Death      m 1228\r\n## 3 Recover      f  953\r\n## 4 Recover      m  950\nlinelist_agg %>% \n  group_by(outcome) %>% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))## # A tibble: 2 x 4\r\n##   outcome total_cases male_cases female_cases\r\n##   <chr>         <int>      <int>        <int>\r\n## 1 Death          2455       1228         1227\r\n## 2 Recover        1903        950          953"},{"path":"descriptive-tables.html","id":"across-multiple-columns","chapter":"17 Descriptive tables","heading":"across() multiple columns","text":"can use summarise across multiple columns using across(). makes life easier want calculate statistics many columns. specify columns operate across, either:provide .cols = either vector column names c() select() semantic helper functions (explained )provide .fns = function perform (parenthese) - can provide multiple within list(), mean() applied several numeric columns. vector columns named explicitly single function mean specified (parentheses). additional arguments function (e.g. na.rm=TRUE) provided afterwards.can difficult get order parentheses commas correct using across(). Remember within across() must include columns, functions, extra arguments needed functions.Multiple functions can run . functions mean sd provided .fns = within list(). opportunity provide character names (e.g. “mean” “sd”) appended new column names.select() helper functions can place within across():helper functions available assist specifying columns:everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEstarts_with() - matches specified prefix. Example: starts_with(\"date\")ends_with() - matches specified suffix. Example: ends_with(\"_end\")contains() - columns containing character string. Example: contains(\"time\")matches() - apply regular expression (regex). Example: contains(\"[pt]al\")num_range() -any_of() - matches column named. Useful name might exist. Example: any_of(date_onset, date_death, cardiac_arrest)example, return mean every numeric column. () command takes place vector column names c(). Everything still within across() command.","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # columns\n                   .fns = mean,                               # function\n                   na.rm=T))                                  # extra arguments## # A tibble: 3 x 5\r\n##   outcome age_years  temp wt_kg ht_cm\r\n##   <chr>       <dbl> <dbl> <dbl> <dbl>\r\n## 1 Death        15.9  38.6  52.6  125.\r\n## 2 Recover      16.1  38.6  52.5  125.\r\n## 3 <NA>         16.2  38.6  53.0  125.\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # columns\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # multiple functions \n                   na.rm=T))                                 # extra arguments## # A tibble: 3 x 9\r\n##   outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd ht_cm_mean ht_cm_sd\r\n##   <chr>            <dbl>        <dbl>     <dbl>   <dbl>      <dbl>    <dbl>      <dbl>    <dbl>\r\n## 1 Death             15.9         12.3      38.6   0.962       52.6     18.4       125.     48.7\r\n## 2 Recover           16.1         13.0      38.6   0.997       52.5     18.6       125.     50.1\r\n## 3 <NA>              16.2         12.8      38.6   0.976       53.0     18.9       125.     50.4\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(\n    .cols = where(is.numeric),  # all numeric columns in the data frame\n    .fns = mean,\n    na.rm=T))## # A tibble: 3 x 12\r\n##   outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp   bmi days_onset_hosp\r\n##   <chr>        <dbl> <dbl>     <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl> <dbl> <dbl>           <dbl>\r\n## 1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6  45.6            1.84\r\n## 2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6  47.7            2.34\r\n## 3 <NA>          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6  48.3            2.07"},{"path":"descriptive-tables.html","id":"pivot-wider-1","chapter":"17 Descriptive tables","heading":"Pivot wider","text":"prefer table “wide” format can transform using tidyr pivot_wider() function. likely need re-name columns rename(). information see page Pivoting data.example begins “long” table age_by_outcome . new column names specified names_from = values specified come column n. column mentioned outcome, remains far left.","code":"\nage_by_outcome %>% \n  select(-percent) %>%   # keep only counts for simplicity\n  pivot_wider(names_from = age_cat, values_from = n)  ## # A tibble: 3 x 10\r\n## # Groups:   outcome [3]\r\n##   outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\r\n##   <chr>   <int> <int>   <int>   <int>   <int>   <int>   <int> <int> <int>\r\n## 1 Death     471   476     438     323     477     329      33     3    32\r\n## 2 Recover   364   391     303     251     367     238      38     3    28\r\n## 3 <NA>      260   228     200     169     229     187      24    NA    26"},{"path":"descriptive-tables.html","id":"total-rows","chapter":"17 Descriptive tables","heading":"Total rows","text":"summarise() operates grouped data automatically produce “total” statistics. , two approaches adding total row presented:","code":""},{"path":"descriptive-tables.html","id":"janitors-adorn_totals","chapter":"17 Descriptive tables","heading":"janitor’s adorn_totals()","text":"table consists counts proportions/percents can summed total, can add sum totals using janitor’s adorn_totals() described section . Note function can sum numeric columns - want calculate total summary statistics see next section., linelist grouped gender summarised table described numer cases known outcome, deaths, recovered. Piping table adorn_totals() adds total row bottom reflecting sum column. adorn_*() functions adjust display noted code.","code":"\nlinelist %>% \n  group_by(gender) %>%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # Number of rows in group where outcome is not missing\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # Number of rows in group where outcome is Death\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # Number of rows in group where outcome is Recovered\n  ) %>% \n  adorn_totals() %>%                                # Adorn total row (sums of each numeric column)\n  adorn_percentages(\"col\") %>%                      # Get column proportions\n  adorn_pct_formatting() %>%                        # Convert proportions to percents\n  adorn_ns(position = \"front\")                      # display % and counts (with counts in front)##  gender known_outcome       n_death     n_recover\r\n##       f 2180  (47.8%) 1227  (47.5%)  953  (48.1%)\r\n##       m 2178  (47.7%) 1228  (47.6%)  950  (47.9%)\r\n##    <NA>  207   (4.5%)  127   (4.9%)   80   (4.0%)\r\n##   Total 4565 (100.0%) 2582 (100.0%) 1983 (100.0%)"},{"path":"descriptive-tables.html","id":"summarise-on-total-data-and-then-bind_rows","chapter":"17 Descriptive tables","heading":"summarise() on “total” data and then bind_rows()","text":"table consists summary statistics median(), mean(), etc, adorn_totals() approach shown sufficient. Instead, get summary statistics entire dataset must calculate separate summarise() command bind results original grouped summary table. binding can use bind_rows() dplyr. example:can make summary table outcome hospital group_by() summarise() like :get totals, run summarise() command group data outcome (hospital), like :can bind two data frames together. Note by_hospital 4 columns whereas totals 3 columns. using bind_rows(), columns combined name, extra space filled NA (e.g column hospital values two new totals rows). binding rows, convert empty spaces “Total” using replace_na() (see Cleaning data core functions page).new table “Total” rows bottom.table “long” format, may want. Optionally, can pivot table wider make readable. See section pivoting wider , Pivoting data page. can also add columns, arrange nicely.can print nicely HTML - output printed flextable. can read depth example achieve nice table HTML tables page.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0","code":"\nby_hospital <- linelist %>% \n  filter(!is.na(outcome) & hospital != \"Missing\") %>%  # Remove cases with missing outcome or hospital\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T))               # median CT value per group\n  \nby_hospital # print table## # A tibble: 10 x 4\r\n## # Groups:   hospital [5]\r\n##    hospital                             outcome     N ct_value\r\n##    <chr>                                <chr>   <int>    <dbl>\r\n##  1 Central Hospital                     Death     193       22\r\n##  2 Central Hospital                     Recover   165       22\r\n##  3 Military Hospital                    Death     399       21\r\n##  4 Military Hospital                    Recover   309       22\r\n##  5 Other                                Death     395       22\r\n##  6 Other                                Recover   290       21\r\n##  7 Port Hospital                        Death     785       22\r\n##  8 Port Hospital                        Recover   579       21\r\n##  9 St. Mark's Maternity Hospital (SMMH) Death     199       22\r\n## 10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\ntotals <- linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # These statistics are now by outcome only     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # print table## # A tibble: 2 x 3\r\n##   outcome     N ct_value\r\n##   <chr>   <int>    <dbl>\r\n## 1 Death    1971       22\r\n## 2 Recover  1469       22\ntable_long <- bind_rows(by_hospital, totals) %>% \n  mutate(hospital = replace_na(hospital, \"Total\"))\ntable_long %>% \n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                      # number with known outcome\n    Pct_Death = N_Death / N_Known * 100,               # percent cases who died\n    Pct_Recover = N_Recover/N_Known * 100) %>%         # percent who recovered\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known)                                  # Arrange rows from lowest to highest (Total row at bottom)## # A tibble: 6 x 8\r\n## # Groups:   hospital [6]\r\n##   hospital                             N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death ct_value_Death\r\n##   <chr>                                  <int>     <int>       <dbl>            <dbl>   <int>     <dbl>          <dbl>\r\n## 1 St. Mark's Maternity Hospital (SMMH)     325       126        38.8               22     199      61.2             22\r\n## 2 Central Hospital                         358       165        46.1               22     193      53.9             22\r\n## 3 Other                                    685       290        42.3               21     395      57.7             22\r\n## 4 Military Hospital                        708       309        43.6               22     399      56.4             21\r\n## 5 Port Hospital                           1364       579        42.4               21     785      57.6             22\r\n## 6 Total                                   3440      1469        42.7               22    1971      57.3             22"},{"path":"descriptive-tables.html","id":"gtsummary-package","chapter":"17 Descriptive tables","heading":"17.6 gtsummary package","text":"want print summary statistics pretty, publication-ready graphic, can use gtsummary package function tbl_summary(). code can seem complex first, outputs look nice print RStudio Viewer panel HTML. Read vignette .introduce tbl_summary() show basic behavior first, actually produces large beautiful table. , examine detail make adjustments tailored tables.","code":""},{"path":"descriptive-tables.html","id":"summary-table","chapter":"17 Descriptive tables","heading":"Summary table","text":"default behavior tbl_summary() quite incredible - takes columns provide creates summary table one command. function prints statistics appropriate column class: median inter-quartile range (IQR) numeric columns, counts (%) categorical columns. Missing values converted “Unknown”. Footnotes added bottom explain statistics, total N shown top.\r\n          1\r\n          \r\n           \r\n          Median (IQR); n (%)\r\n          ","code":"\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>%  # keep only the columns of interest\n  tbl_summary()                                                  # default"},{"path":"descriptive-tables.html","id":"adjustments","chapter":"17 Descriptive tables","heading":"Adjustments","text":"Now explain function works make adjustments. key arguments detailed :=\r\ncan stratify table column (e.g. outcome), creating 2-way table.statistic =\r\nIndicate statistics show display equation. two sides equation, separated tilde ~. right quotes statistical display desired, left columns display apply.right side equation uses syntax str_glue() stringr (see Characters Strings), desired display string quotes statistics within curly brackets. can include statistics like “n” (counts), “N” (denominator), “mean”, “median”, “sd”, “max”, “min”, percentiles “p##” like “p25”, percent total “p”. See ?tbl_summary details.left side equation, can specify columns name (e.g. age c(age, gender)) using helpers all_continuous(), all_categorical(), contains(), starts_with(), etc.simple example statistic = equation might look like , print mean column age_years:\r\n          1\r\n          \r\n           \r\n          Mean\r\n          slightly complex equation might look like \"({min}, {max})\", incorporating max min values within parentheses separated comma:can also differentiate syntax separate columns types columns. complex example , value provided statistc = list indicating continuous columns table print mean standard deviation parentheses, categorical columns print n, denominator, percent.digits =\r\nAdjust digits rounding. Optionally, can specified continuous columns ().label =\r\nAdjust column name displayed. Provide column name desired label separated tilde. default column name.missing_text =\r\nAdjust missing values displayed. default “Unknown”.type =\r\nused adjust many levels statistics shown. syntax similar statistic = provide equation columns left value right. Two common scenarios include:type = all_categorical() ~ \"categorical\" Forces dichotomous columns (e.g. fever) show levels instead “yes” rowtype = all_continuous() ~ \"continuous2\" Allows multi-line statistics per variable, shown later sectionIn example , arguments used modify original summary table:\r\n          1\r\n          \r\n           \r\n          Mean (SD); n / N (%)\r\n          ","code":"\nlinelist %>% \n  select(age_years) %>%         # keep only columns of interest \n  tbl_summary(                  # create summary table\n    statistic = age_years ~ \"{mean}\") # print mean of age\nlinelist %>% \n  select(age_years) %>%                       # keep only columns of interest \n  tbl_summary(                                # create summary table\n    statistic = age_years ~ \"({min}, {max})\") # print min and max of age\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>% # keep only columns of interest\n  tbl_summary(     \n    by = outcome,                                               # stratify entire table by outcome\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats and format for continuous columns\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats and format for categorical columns\n    digits = all_continuous() ~ 1,                              # rounding for continuous columns\n    type   = all_categorical() ~ \"categorical\",                 # force all categorical levels to display\n    label  = list(                                              # display labels for column names\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # how missing values should display\n  )## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"descriptive-tables.html","id":"multi-line-stats-for-continuous-variables","chapter":"17 Descriptive tables","heading":"Multi-line stats for continuous variables","text":"want print multiple lines statistics continuous variables, can indicate setting type = “continuous2”. can combine previously shown elements one table choosing statistics want show. need tell function want get table back entering type “continuous2”. number missing values shown “Unknown”.many ways modify tables, including adding p-values, adjusting color headings, etc. Many described documentation (enter ?tbl_summary Console), given section statistical tests.","code":"\nlinelist %>% \n  select(age_years, temp) %>%                      # keep only columns of interest\n  tbl_summary(                                     # create summary table\n    type = all_continuous() ~ \"continuous2\",       # indicate that you want to print multiple statistics \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # line 1: mean and SD\n      \"{median} ({p25}, {p75})\",                   # line 2: median and IQR\n      \"{min}, {max}\")                              # line 3: min and max\n    )"},{"path":"descriptive-tables.html","id":"base-r-1","chapter":"17 Descriptive tables","heading":"17.7 base R","text":"can use function table() tabulate cross-tabulate columns. Unlike options , must specify dataframe, shown .CAUTION: NA (missing) values tabulated unless include argument useNA = \"always\" (also set “” “ifany”).Multiple columns can cross-tabulated listing one , separated commas. Optionally, can assign column “name” like Outcome = linelist$outcome.","code":"\ntable(linelist$outcome, useNA = \"always\")## \r\n##   Death Recover    <NA> \r\n##    2582    1983    1323\nage_by_outcome <- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # save table as object\nage_by_outcome   # print table##        \r\n##         Death Recover <NA>\r\n##   0-4     471     364  260\r\n##   5-9     476     391  228\r\n##   10-14   438     303  200\r\n##   15-19   323     251  169\r\n##   20-29   477     367  229\r\n##   30-49   329     238  187\r\n##   50-69    33      38   24\r\n##   70+       3       3    0\r\n##   <NA>     32      28   26"},{"path":"descriptive-tables.html","id":"proportions-1","chapter":"17 Descriptive tables","heading":"Proportions","text":"return proportions, passing table function prop.table(). Use margins = argument specify whether want proportions rows (1), columns (2), whole table (3). clarity, pipe table round() function base R, specifying 2 digits.","code":"\n# get proportions of table defined above, by rows, rounded\nprop.table(age_by_outcome, 1) %>% round(2)##        \r\n##         Death Recover <NA>\r\n##   0-4    0.43    0.33 0.24\r\n##   5-9    0.43    0.36 0.21\r\n##   10-14  0.47    0.32 0.21\r\n##   15-19  0.43    0.34 0.23\r\n##   20-29  0.44    0.34 0.21\r\n##   30-49  0.44    0.32 0.25\r\n##   50-69  0.35    0.40 0.25\r\n##   70+    0.50    0.50 0.00\r\n##   <NA>   0.37    0.33 0.30"},{"path":"descriptive-tables.html","id":"totals","chapter":"17 Descriptive tables","heading":"Totals","text":"add row column totals, pass table addmargins(). works counts proportions.","code":"\naddmargins(age_by_outcome)##        \r\n##         Death Recover <NA>  Sum\r\n##   0-4     471     364  260 1095\r\n##   5-9     476     391  228 1095\r\n##   10-14   438     303  200  941\r\n##   15-19   323     251  169  743\r\n##   20-29   477     367  229 1073\r\n##   30-49   329     238  187  754\r\n##   50-69    33      38   24   95\r\n##   70+       3       3    0    6\r\n##   <NA>     32      28   26   86\r\n##   Sum    2582    1983 1323 5888"},{"path":"descriptive-tables.html","id":"convert-to-data-frame","chapter":"17 Descriptive tables","heading":"Convert to data frame","text":"Converting table() object directly data frame straight-forward. One approach demonstrated :Create table, without using useNA = \"always\". Instead convert NA values “(Missing)” fct_explicit_na() forcats.Add totals (optional) piping addmargins()Pipe base R function .data.frame.matrix()Pipe table tibble function rownames_to_column(), specifying name first columnPrint, View, export desired. example use flextable() package flextable described HTML tables page. print RStudio viewer pane pretty HTML.Age CategoryDeathRecover(Missing)Sum0-4471.0364.0260.01,095.05-9476.0391.0228.01,095.010-14438.0303.0200.0941.015-19323.0251.0169.0743.020-29477.0367.0229.01,073.030-49329.0238.0187.0754.050-6933.038.024.095.070+3.03.00.06.0(Missing)32.028.026.086.0Sum2,582.01,983.01,323.05,888.0","code":"\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %>% \n  addmargins() %>% \n  as.data.frame.matrix() %>% \n  tibble::rownames_to_column(var = \"Age Category\") %>% \n  flextable::flextable()"},{"path":"descriptive-tables.html","id":"resources-10","chapter":"17 Descriptive tables","heading":"17.8 Resources","text":"Much information page adapted resources vignettes online:gtsummarydplyr","code":""},{"path":"simple-statistical-tests.html","id":"simple-statistical-tests","chapter":"18 Simple statistical tests","heading":"18 Simple statistical tests","text":"page demonstrates use base R, gtsummary, dplyr conduct simple statistical tests.","code":""},{"path":"simple-statistical-tests.html","id":"preparation-9","chapter":"18 Simple statistical tests","heading":"18.1 Preparation","text":"","code":""},{"path":"simple-statistical-tests.html","id":"load-packages-10","chapter":"18 Simple statistical tests","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics, \n  gtsummary,    # summary statistics and tests\n  janitor,      # adding totals and percents to tables\n  flextable,    # converting tables to HTML\n  corrr         # correlation analayis for numeric variables\n  )"},{"path":"simple-statistical-tests.html","id":"import-data-9","chapter":"18 Simple statistical tests","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"simple-statistical-tests.html","id":"base-r-2","chapter":"18 Simple statistical tests","heading":"base R","text":"can use base R functions produce results statistical tests. commands relatively simple results print R Console simple viewing. However, outputs usually lists harder manipulate want use results subsequent code operations.","code":""},{"path":"simple-statistical-tests.html","id":"t-tests","chapter":"18 Simple statistical tests","heading":"T-tests","text":"Syntax 1: Best numeric categorical columns data frame. Provide numeric column left side equation categorical column right side. Specify dataset data =. Optionally, set paired = TRUE, conf.level = (0.95 default), alternative = (either “two.sided”, “less”, “greater”). Enter ?t.test details.Syntax 2: can compare two separate numeric vectors using alternative syntax. example, two columns different data sets.Conduct one-sample t-test known/hypothesized populaton mean right side equation:","code":"\n## compare mean age by outcome group with a t-test\nt.test(age_years ~ outcome, data = linelist)## \r\n##  Welch Two Sample t-test\r\n## \r\n## data:  age_years by outcome\r\n## t = -0.5, df = 4092, p-value = 0.6\r\n## alternative hypothesis: true difference in means is not equal to 0\r\n## 95 percent confidence interval:\r\n##  -0.925  0.570\r\n## sample estimates:\r\n##   mean in group Death mean in group Recover \r\n##                  15.9                  16.1\nt.test(df1$age_years, df2$age_years)\nt.test(linelist$age_years, mu = 45)"},{"path":"simple-statistical-tests.html","id":"shapiro-wilks-test","chapter":"18 Simple statistical tests","heading":"Shapiro-Wilk’s test","text":"","code":"\nshapiro.test(linelist$age_years)"},{"path":"simple-statistical-tests.html","id":"wilcoxon-rank-sum-test","chapter":"18 Simple statistical tests","heading":"Wilcoxon rank sum test","text":"","code":"\n## compare age distribution by outcome group with a wilcox test\nwilcox.test(age_years ~ outcome, data = linelist)## \r\n##  Wilcoxon rank sum test with continuity correction\r\n## \r\n## data:  age_years by outcome\r\n## W = 3e+06, p-value = 0.8\r\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"simple-statistical-tests.html","id":"kruskal-wallis-test","chapter":"18 Simple statistical tests","heading":"Kruskal-wallis test","text":"","code":"\n## compare age distribution by outcome group with a kruskal-wallis test\nkruskal.test(age_years ~ outcome, linelist)## \r\n##  Kruskal-Wallis rank sum test\r\n## \r\n## data:  age_years by outcome\r\n## Kruskal-Wallis chi-squared = 0.05, df = 1, p-value = 0.8"},{"path":"simple-statistical-tests.html","id":"chi-squared-test","chapter":"18 Simple statistical tests","heading":"Chi-squared test","text":"","code":"\n## compare the proportions in each group with a chi-squared test\nchisq.test(linelist$gender, linelist$outcome)## \r\n##  Pearson's Chi-squared test with Yates' continuity correction\r\n## \r\n## data:  linelist$gender and linelist$outcome\r\n## X-squared = 0.001, df = 1, p-value = 1"},{"path":"simple-statistical-tests.html","id":"gtsummary-package-1","chapter":"18 Simple statistical tests","heading":"gtsummary package","text":"Use gtsummary looking add results statistical test pretty table (described section ).\r\nPerforming statistical tests comparison tbl_summary done adding \r\nadd_p function table specifying test use. possible get p-values corrected multiple testing using \r\nadd_q function. Run ?tbl_summary details.","code":""},{"path":"simple-statistical-tests.html","id":"chi-squared-test-1","chapter":"18 Simple statistical tests","heading":"18.1.1 Chi-squared test","text":"Compare proportions categorical variable two groups. default statistical test \r\nadd_p() perform chi-squared test independence continuity correction, \r\nexpected call count 5 Fisher’s exact test used.\r\n          1\r\n          \r\n           \r\n          n (%)\r\n          \r\n          2\r\n          \r\n           \r\n          Pearson's Chi-squared test\r\n          ","code":"\nlinelist %>% \n  select(gender, outcome) %>%    # keep variables of interest\n  tbl_summary(by = outcome) %>%  # produce summary table and specify grouping variable\n  add_p()                        # specify what test to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"t-tests-1","chapter":"18 Simple statistical tests","heading":"T-tests","text":"Compare difference means continuous variable two groups.\r\nexample, compare mean age patient outcome.\r\n          1\r\n          \r\n           \r\n          Mean (SD)\r\n          \r\n          2\r\n          \r\n           \r\n          Welch Two Sample t-test\r\n          ","code":"\nlinelist %>% \n  select(age_years, outcome) %>%             # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age_years ~ \"{mean} ({sd})\", # specify what statistics to show\n    by = outcome) %>%                        # specify the grouping variable\n  add_p(age_years ~ \"t.test\")                # specify what tests to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"wilcoxon-rank-sum-test-1","chapter":"18 Simple statistical tests","heading":"Wilcoxon rank sum test","text":"Compare distribution continuous variable two groups. default\r\nuse Wilcoxon rank sum test median (IQR) comparing two\r\ngroups. However non-normally distributed data comparing multiple groups,\r\nKruskal-wallis test appropriate.\r\n          1\r\n          \r\n           \r\n          Median (IQR)\r\n          \r\n          2\r\n          \r\n           \r\n          Wilcoxon rank sum test\r\n          ","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (this is default so could remove)\n    by = outcome) %>%                                  # specify the grouping variable\n  add_p(age_years ~ \"wilcox.test\")                     # specify what test to perform (default so could leave brackets empty)## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"kruskal-wallis-test-1","chapter":"18 Simple statistical tests","heading":"Kruskal-wallis test","text":"Compare distribution continuous variable two groups,\r\nregardless whether data normally distributed.\r\n          1\r\n          \r\n           \r\n          Median (IQR)\r\n          \r\n          2\r\n          \r\n           \r\n          Kruskal-Wallis rank sum test\r\n          ","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (default, so could remove)\n    by = outcome) %>%                                  # specify the grouping variable\n  add_p(age_years ~ \"kruskal.test\")                    # specify what test to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"dplyr-package-1","chapter":"18 Simple statistical tests","heading":"dplyr package","text":"Performing statistical tests dplyr alone dense, \r\nfit within tidy-data framework. requires using purrr create\r\nlist dataframes subgroups want compare. See page Iteration loops learn purrr.easier alternative may rstatix package.","code":""},{"path":"simple-statistical-tests.html","id":"t-tests-2","chapter":"18 Simple statistical tests","heading":"T-tests","text":"","code":"\nlinelist %>% \n  ## only keep variables of interest\n  select(age, outcome) %>% \n  ## drop those missing outcome \n  filter(!is.na(outcome)) %>% \n  ## specify the grouping variable\n  group_by(outcome) %>% \n  ## create a subset of data for each group (as a list)\n  nest() %>% \n  ## spread in to wide format\n  pivot_wider(names_from = outcome, values_from = data) %>% \n  mutate(\n    ## calculate the mean age for the death group\n    Death_mean = map(Death, ~mean(.x$age, na.rm = TRUE)),\n    ## calculate the sd among dead \n    Death_sd = map(Death, ~sd(.x$age, na.rm = TRUE)),\n    ## calculate the mean age for the recover group\n    Recover_mean = map(Recover, ~mean(.x$age, na.rm = TRUE)), \n    ## calculate the sd among recovered \n    Recover_sd = map(Recover, ~sd(.x$age, na.rm = TRUE)),\n    ## using both grouped data sets compare mean age with a t-test\n    ## keep only the p.value\n    t_test = map2(Death, Recover, ~t.test(.x$age, .y$age)$p.value)\n  ) %>% \n  ## drop datasets \n  select(-Death, -Recover) %>% \n  ## return a dataset with the medians and p.value (drop missing)\n  unnest(cols = everything())## # A tibble: 1 x 5\r\n##   Death_mean Death_sd Recover_mean Recover_sd t_test\r\n##        <dbl>    <dbl>        <dbl>      <dbl>  <dbl>\r\n## 1       15.9     12.3         16.2       12.9  0.494"},{"path":"simple-statistical-tests.html","id":"wilcoxon-rank-sum-test-2","chapter":"18 Simple statistical tests","heading":"Wilcoxon rank sum test","text":"","code":"\nlinelist %>% \n  ## only keep variables of interest\n  select(age, outcome) %>% \n  ## drop those missing outcome \n  filter(!is.na(outcome)) %>% \n  ## specify the grouping variable\n  group_by(outcome) %>% \n  ## create a subset of data for each group (as a list)\n  nest() %>% \n  ## spread in to wide format\n  pivot_wider(names_from = outcome, values_from = data) %>% \n  mutate(\n    ## calculate the median age for the death group\n    Death_median = map(Death, ~median(.x$age, na.rm = TRUE)),\n    ## calculate the sd among dead \n    Death_iqr = map(Death, ~str_c(\n      quantile(.x$age, probs = c(0.25, 0.75), na.rm = TRUE), \n      collapse = \", \"\n      )),\n    ## calculate the median age for the recover group\n    Recover_median = map(Recover, ~median(.x$age, na.rm = TRUE)), \n    ## calculate the sd among recovered \n    Recover_iqr = map(Recover, ~str_c(\n      quantile(.x$age, probs = c(0.25, 0.75), na.rm = TRUE), \n      collapse = \", \"\n      )),\n    ## using both grouped data sets compare age distribution with a wilcox test\n    ## keep only the p.value\n    wilcox = map2(Death, Recover, ~wilcox.test(.x$age, .y$age)$p.value)\n  ) %>% \n  ## drop datasets \n  select(-Death, -Recover) %>% \n  ## return a dataset with the medians and p.value (drop missing)\n  unnest(cols = everything())## # A tibble: 1 x 5\r\n##   Death_median Death_iqr Recover_median Recover_iqr wilcox\r\n##          <dbl> <chr>              <dbl> <chr>        <dbl>\r\n## 1           13 6, 23                 13 6, 23        0.942"},{"path":"simple-statistical-tests.html","id":"kruskal-wallis-test-2","chapter":"18 Simple statistical tests","heading":"Kruskal-wallis test","text":"","code":"\nlinelist %>% \n  ## only keep variables of interest\n  select(age, outcome) %>% \n  ## drop those missing outcome \n  filter(!is.na(outcome)) %>% \n  ## specify the grouping variable\n  group_by(outcome) %>% \n  ## create a subset of data for each group (as a list)\n  nest() %>% \n  ## spread in to wide format\n  pivot_wider(names_from = outcome, values_from = data) %>% \n  mutate(\n    ## calculate the median age for the death group\n    Death_median = map(Death, ~median(.x$age, na.rm = TRUE)),\n    ## calculate the sd among dead \n    Death_iqr = map(Death, ~str_c(\n      quantile(.x$age, probs = c(0.25, 0.75), na.rm = TRUE), \n      collapse = \", \"\n      )),\n    ## calculate the median age for the recover group\n    Recover_median = map(Recover, ~median(.x$age, na.rm = TRUE)), \n    ## calculate the sd among recovered \n    Recover_iqr = map(Recover, ~str_c(\n      quantile(.x$age, probs = c(0.25, 0.75), na.rm = TRUE), \n      collapse = \", \"\n      )),\n    ## using the original data set compare age distribution with a kruskal test\n    ## keep only the p.value\n    kruskal = kruskal.test(linelist$age, linelist$outcome)$p.value\n  ) %>% \n  ## drop datasets \n  select(-Death, -Recover) %>% \n  ## return a dataset with the medians and p.value (drop missing)\n  unnest(cols = everything())## # A tibble: 1 x 5\r\n##   Death_median Death_iqr Recover_median Recover_iqr kruskal\r\n##          <dbl> <chr>              <dbl> <chr>         <dbl>\r\n## 1           13 6, 23                 13 6, 23         0.942"},{"path":"simple-statistical-tests.html","id":"chi-squared-test-2","chapter":"18 Simple statistical tests","heading":"Chi-squared test","text":"","code":"\nlinelist %>% \n  ## do everything by gender \n  group_by(outcome) %>% \n  ## count the variable of interest\n  count(gender) %>% \n  ## calculate proportion \n  ## note that the denominator here is the sum of each gender\n  mutate(percentage = n / sum(n) * 100) %>% \n  pivot_wider(names_from = outcome, values_from = c(n, percentage)) %>% \n  filter(!is.na(gender)) %>% \n  mutate(pval = chisq.test(linelist$gender, linelist$outcome)$p.value)## # A tibble: 2 x 8\r\n##   gender n_Death n_Recover  n_NA percentage_Death percentage_Recover percentage_NA  pval\r\n##   <chr>    <int>     <int> <int>            <dbl>              <dbl>         <dbl> <dbl>\r\n## 1 f         1227       953   627             47.5               48.1          47.4 0.973\r\n## 2 m         1228       950   625             47.6               47.9          47.2 0.973"},{"path":"simple-statistical-tests.html","id":"correlations","chapter":"18 Simple statistical tests","heading":"18.2 Correlations","text":"Correlation numeric variables can investigated using tidyversecorrr package. allows compute correlations using Pearson, Kendall\r\ntau Spearman rho. package creates table also function \r\nautomatically plot values.","code":"\ncorrelation_tab <- linelist %>% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %>%   # keep numeric variables of interest\n  correlate()      # create correlation table (using default pearson)\n\ncorrelation_tab    # print## # A tibble: 6 x 7\r\n##   term            generation       age ct_blood days_onset_hosp    wt_kg    ht_cm\r\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>    <dbl>    <dbl>\r\n## 1 generation        NA       -0.0222    0.179         -0.288    -0.0302  -0.00942\r\n## 2 age               -0.0222  NA         0.00849       -0.000635  0.833    0.877  \r\n## 3 ct_blood           0.179    0.00849  NA             -0.600    -0.00636  0.0181 \r\n## 4 days_onset_hosp   -0.288   -0.000635 -0.600         NA         0.0153  -0.00953\r\n## 5 wt_kg             -0.0302   0.833    -0.00636        0.0153   NA        0.884  \r\n## 6 ht_cm             -0.00942  0.877     0.0181        -0.00953   0.884   NA\n## remove duplicate entries (the table above is mirrored) \ncorrelation_tab <- correlation_tab %>% \n  shave()\n\n## view correlation table \ncorrelation_tab## # A tibble: 6 x 7\r\n##   term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\r\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>  <dbl> <dbl>\r\n## 1 generation        NA       NA        NA              NA       NA        NA\r\n## 2 age               -0.0222  NA        NA              NA       NA        NA\r\n## 3 ct_blood           0.179    0.00849  NA              NA       NA        NA\r\n## 4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\r\n## 5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\r\n## 6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n## plot correlations \nrplot(correlation_tab)"},{"path":"simple-statistical-tests.html","id":"resources-11","chapter":"18 Simple statistical tests","heading":"18.3 Resources","text":"Much information page adapted resources vignettes online:gtsummary\r\ndplyr\r\ncorrr\r\nsthda correlation","code":""},{"path":"univariate-and-multivariate-regression.html","id":"univariate-and-multivariate-regression","chapter":"19 Univariate and multivariate regression","heading":"19 Univariate and multivariate regression","text":"","code":""},{"path":"univariate-and-multivariate-regression.html","id":"overview-5","chapter":"19 Univariate and multivariate regression","heading":"19.1 Overview","text":"page demonstrates use base R regression function glm() gtsummary package \r\nlook associations variables (e.g. odds ratios, risk ratios hazard\r\nratios). also uses functions like tidy() broom package clean-regression outputs.Univariate: two--two tablesStratified: mantel-haenszel estimatesMultivariable: variable selection, model selection, final tableForest plots","code":""},{"path":"univariate-and-multivariate-regression.html","id":"preparation-10","chapter":"19 Univariate and multivariate regression","heading":"19.2 Preparation","text":"","code":""},{"path":"univariate-and-multivariate-regression.html","id":"load-packages-11","chapter":"19 Univariate and multivariate regression","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  tidyverse,    # data management + ggplot2 graphics, \n  stringr,      # manipulate text strings \n  purrr,        # loop over objects in a tidy way\n  gtsummary,    # summary statistics and tests \n  broom,        # tidy up results from regressions\n  lmtest,       # likelihood-ratio tests\n  parameters,   # alternative to tidy up results from regressions\n  see          # alternative to visualise forest plots\n  )"},{"path":"univariate-and-multivariate-regression.html","id":"import-data-10","chapter":"19 Univariate and multivariate regression","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"univariate-and-multivariate-regression.html","id":"clean-data","chapter":"19 Univariate and multivariate regression","heading":"Clean data","text":"Store explanatory variablesConvert 1’s 0’sBelow convert explanatory columns “yes”/“” “m”/“f”, “dead”/“alive” 1 / 0, cooperate expectations logistic regression models. efficiently, define vector column names explanatory variables.apply function case_when() convert specified values 1’s 0’s. function applied explanatory_vars columns using across() (see page Grouping data).Drop rows missing valuesTo drop rows missing values, add column age explanatory_vars (age produced error previous case_when() operation). pipe linelist drop_na() remove rows missing values outcome column explanatory_vars columns.number rows remaining linelist 4167.","code":"\n## define variables of interest \nexplanatory_vars <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n## convert dichotomous variables to 0/1 \nlinelist <- linelist %>% \n  mutate(\n    ## for each of the variables listed and \"outcome\"\n    across(\n      all_of(c(explanatory_vars, \"outcome\")), \n      ## recode male, yes and death to 1; female, no and recover to 0\n      ## otherwise set to missing\n           ~case_when(\n             . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,\n             . %in% c(\"f\", \"no\",  \"Recover\") ~ 0, \n             TRUE                            ~ NA_real_\n           ))\n  )\n## add in age_category to the explanatory vars \nexplanatory_vars <- c(explanatory_vars, \"age_cat\")\n\n## drop rows with missing information for variables of interest \nlinelist <- linelist %>% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))"},{"path":"univariate-and-multivariate-regression.html","id":"univariate","chapter":"19 Univariate and multivariate regression","heading":"19.3 Univariate","text":"Just like page Descriptive tables, use case determine R package use. present two options univariate analysis:Use functions available base quickly print results console. Use broom package tidy outputs.Use gtsummary package model get publication-ready outputs","code":""},{"path":"univariate-and-multivariate-regression.html","id":"base-r-3","chapter":"19 Univariate and multivariate regression","heading":"base R","text":"function glm() stats package (part base R) used fit Generalized Linear Models (GLM).glm() can used univariate multivariate logistic regression (e.g. get Odds Ratios). core parts:formula = model provided glm() equation, outcome left explanatory variables right tilde ~. example assessing association different age categories outcome death (now coded 1, see Preparation section).family = determines type model run. logistic regression, use family = \"binomial\", poisson use family = \"poisson\". examples table .data = Specify data frameIf necessary, can also specify link function via syntax family = familytype(link = \"linkfunction\")). can read documentation families optional arguments weights = subset = (?glm).running glm() common save results named R object. can print results console using summary() shown , perform operations results (e.g. exponentiate).","code":"\n# arguments for glm()\nglm(formula, family, data, weights, subset, ...)"},{"path":"univariate-and-multivariate-regression.html","id":"univariate-glm","chapter":"19 Univariate and multivariate regression","heading":"Univariate glm()","text":"univariate model outcome age category. save model output model print within summary() console. Note Estimates provided log odds. baseline level first factor level age_cat (0-4).alter baseline level given variable, ensure column class Factor set first level (see page Factors. example take linelist column age_cat set “20-29” baseline piping modified dataset glm().","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)## \r\n## Call:\r\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\r\n## \r\n## Deviance Residuals: \r\n##    Min      1Q  Median      3Q     Max  \r\n##  -1.34   -1.28    1.02    1.08    1.35  \r\n## \r\n## Coefficients:\r\n##              Estimate Std. Error z value Pr(>|z|)   \r\n## (Intercept)   0.23374    0.07280    3.21   0.0013 **\r\n## age_cat5-9   -0.06290    0.10173   -0.62   0.5364   \r\n## age_cat10-14  0.13820    0.10719    1.29   0.1973   \r\n## age_cat15-19 -0.00557    0.11334   -0.05   0.9608   \r\n## age_cat20-29  0.02751    0.10213    0.27   0.7877   \r\n## age_cat30-49  0.06376    0.11377    0.56   0.5752   \r\n## age_cat50-69 -0.38789    0.25924   -1.50   0.1346   \r\n## age_cat70+   -0.63920    0.91577   -0.70   0.4852   \r\n## ---\r\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n## \r\n## (Dispersion parameter for binomial family taken to be 1)\r\n## \r\n##     Null deviance: 5712.4  on 4166  degrees of freedom\r\n## Residual deviance: 5705.1  on 4159  degrees of freedom\r\n## AIC: 5721\r\n## \r\n## Number of Fisher Scoring iterations: 4\nlinelist %>% \n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %>% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %>% \n  summary()## \r\n## Call:\r\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\r\n## \r\n## Deviance Residuals: \r\n##    Min      1Q  Median      3Q     Max  \r\n##  -1.34   -1.28    1.02    1.08    1.35  \r\n## \r\n## Coefficients:\r\n##              Estimate Std. Error z value Pr(>|z|)    \r\n## (Intercept)    0.2612     0.0716    3.65  0.00027 ***\r\n## age_cat0-4    -0.0275     0.1021   -0.27  0.78765    \r\n## age_cat5-9    -0.0904     0.1009   -0.90  0.37022    \r\n## age_cat10-14   0.1107     0.1064    1.04  0.29813    \r\n## age_cat15-19  -0.0331     0.1126   -0.29  0.76893    \r\n## age_cat30-49   0.0363     0.1130    0.32  0.74839    \r\n## age_cat50-69  -0.4154     0.2589   -1.60  0.10863    \r\n## age_cat70+    -0.6667     0.9157   -0.73  0.46655    \r\n## ---\r\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n## \r\n## (Dispersion parameter for binomial family taken to be 1)\r\n## \r\n##     Null deviance: 5712.4  on 4166  degrees of freedom\r\n## Residual deviance: 5705.1  on 4159  degrees of freedom\r\n## AIC: 5721\r\n## \r\n## Number of Fisher Scoring iterations: 4"},{"path":"univariate-and-multivariate-regression.html","id":"printing-results","chapter":"19 Univariate and multivariate regression","heading":"Printing results","text":"uses, several modifications must made outputs. function tidy() package broom convenient making model results presentable. demonstrate combine model outputs table counts.Get exponentiated log odds ratio estimates confidence intervals passing model tidy() setting exponentiate = TRUE conf.int = TRUE.outputted tibble model:Combine model results table counts. , create counts table applying dplyr functions linelist (see page Grouping data).Group rows outcome, get counts age categoryPivot wider column age_cat, 0, 1Remove row NA age_cat, applicable, align model resultsHere counts_table data frame looks like:Now can bind counts_table model results together horizontally bind_cols() (dplyr). code, . represents piped object counts_table bind model. finish process, use select() pick desired columns order, apply base R round() function numeric columns specifying 2 decimal places.combined data frame looks like:","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %>% \n  # clean up the outputs of the regression (exponentiate and produce CIs)\n  tidy(exponentiate = TRUE, conf.int = TRUE) %>% \n  # round all numeric columns\n  mutate(across(is.numeric, round, digits = 2))## Warning: Predicate functions must be wrapped in `where()`.\r\n## \r\n##   # Bad\r\n##   data %>% select(is.numeric)\r\n## \r\n##   # Good\r\n##   data %>% select(where(is.numeric))\r\n## \r\n## i Please update your code.\r\n## This message is displayed once per session.\ncounts_table <- linelist %>% \n  ## remove cases with missing outcome or age category\n  filter(!is.na(outcome) & !is.na(age_cat)) %>% \n  ## get counts of variable of interest grouped by outcome\n  group_by(outcome) %>% \n  ## gets number or rows by unique outcome-age category combinations  \n  count(age_cat) %>% \n  ## spread data to wide format (as in cross-tabulation)\n  pivot_wider(names_from = outcome, values_from = n) \ncombined <- counts_table %>% \n  ## merge with the outputs of the regression \n  bind_cols(., model) %>% \n  ## only keep columns interested in \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %>% \n  ## round values to 2 decimal places\n  mutate(across(is.numeric, round, digits = 2))"},{"path":"univariate-and-multivariate-regression.html","id":"looping-multiple-univariate-models","chapter":"19 Univariate and multivariate regression","heading":"Looping multiple univariate models","text":"present method using glm() tidy() simple approach, see section gtsummary.run models several exposure variables produce univariate odds ratios (.e. \r\ncontrolling ), can use approach . uses str_c() stringr create univariate formulas,, runs glm() regression formula, passes glm() output tidy() finally collapses model outputs together bind_rows() tidyr*. approach uses map() package purrr iterate - see page Iteration loops information tool.Create vector column names explanatory variables. already explanatory_vars data Preparation section page.Create vector column names explanatory variables. already explanatory_vars data Preparation section page.Use str_c() create multiple string formulas, outcome left, column name explanatory_vars right. period . substitutes column name explanatory_vars.Use str_c() create multiple string formulas, outcome left, column name explanatory_vars right. period . substitutes column name explanatory_vars.Pass string formulas map() set ~glm() function apply input. Within glm(), set regression formula .formula(.x) .x replaced string formula defined step . map() loop string formulas, running regressions one.Pass string formulas map() set ~glm() function apply input. Within glm(), set regression formula .formula(.x) .x replaced string formula defined step . map() loop string formulas, running regressions one.outputs first map() passed second map() command, applied tidy() regression outputs.outputs first map() passed second map() command, applied tidy() regression outputs.Finally output second map() (list tidied data frames) condensed bind_rows(), resulting one data frame univariate results.Finally output second map() (list tidied data frames) condensed bind_rows(), resulting one data frame univariate results.time, end object models longer now represents combined results several univariate regressions. Click see rows model., can create counts table linelist explanatory variable, bind models, make nice table. begin variables, iterate map(). iterate user-defined function involves creating counts table dplyr functions. results combined bound models model results.data frame looks like. See page HTML tables ideas convert table pretty HTML output (e.g. flextable).","code":"\nexplanatory_vars %>% str_c(\"outcome ~ \", .)## [1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\"  \"outcome ~ cough\"   \"outcome ~ aches\"   \"outcome ~ vomit\"   \"outcome ~ age_cat\"\nmodels <- explanatory_vars %>%       # begin with variables of interest\n  str_c(\"outcome ~ \", .) %>%         # combine each variable into formula (\"outcome ~ variable of interest\")\n  \n  # iterate through each univariate formula\n  map(                               \n    .f = ~glm(                       # pass the formulas one-by-one to glm()\n      formula = as.formula(.x),      # within glm(), the string formula is .x\n      family = \"binomial\",           # specify type of glm (logistic)\n      data = linelist)) %>%          # dataset\n  \n  # tidy up each of the glm regression outputs from above\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # exponentiate \n      conf.int = TRUE)) %>%          # return confidence intervals\n  \n  # collapse the list of regression outputs in to one data frame\n  bind_rows() %>% \n  \n  # round all numeric columns\n  mutate(across(is.numeric, round, digits = 2))\n## for each explanatory variable\nuniv_tab_base <- explanatory_vars %>% \n  map(.f = \n    ~{linelist %>%                ## begin with linelist\n        group_by(outcome) %>%     ## group data set by outcome\n        count(.data[[.x]]) %>%    ## produce counts for variable of interest\n        pivot_wider(              ## spread to wide format (as in cross-tabulation)\n          names_from = outcome,\n          values_from = n) %>% \n        filter(!is.na(.data[[.x]])) %>%  ## drop rows with missings\n        rename(\"variable\" = .x) %>%      ## change variable of interest column to \"variable\"\n        mutate(variable = as.character(variable))} ## convert to character, else non-dichotomous (categorical) variables come out as factor and cant be merged\n      ) %>% \n  \n  ## collapse the list of count outputs in to one data frame\n  bind_rows() %>% \n  \n  ## merge with the outputs of the regression \n  bind_cols(., models) %>% \n  \n  ## only keep columns interested in \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %>% \n  \n  ## round decimal places\n  mutate(across(is.numeric, round, digits = 2))"},{"path":"univariate-and-multivariate-regression.html","id":"gtsummary-package-2","chapter":"19 Univariate and multivariate regression","heading":"gtsummary package","text":"present use tbl_uvregression() gtsummary package. Just like page Descriptive tables, gtsummary functions good job running statistics producing professional-looking outputs. function produces table univariate regression results.select necessary columns linelist (explanatory variables outcome variable) pipe tbl_uvregression(). going run univariate regression columns defined explanatory_vars data Preparation section (gender, fever, chills, cough, aches, vomit, age_cat).Within function , provide method = glm (quotes), y = outcome column (outcome), specify method.args = want run logistic regression via family = binomial, tell exponentiate results.output HTML contains counts\r\n          1\r\n          \r\n           \r\n          = Odds Ratio, CI = Confidence Interval\r\n          many modifications can make table output, adjusting text labels, bolding rows p-value, etc. See tutorials elsewhere online.","code":"\nuniv_tab <- linelist %>% \n  dplyr::select(explanatory_vars, outcome) %>% ## select variables of interest\n\n  tbl_uvregression(                         ## produce univariate table\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = outcome,                            ## define outcome variable\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n## view univariate results table \nuniv_tab"},{"path":"univariate-and-multivariate-regression.html","id":"stratified","chapter":"19 Univariate and multivariate regression","heading":"19.4 Stratified","text":"Stratified analysis currently still worked gtsummary,\r\npage updated due course.","code":""},{"path":"univariate-and-multivariate-regression.html","id":"gtsummary-package-3","chapter":"19 Univariate and multivariate regression","heading":"gtsummary package","text":"TODO","code":""},{"path":"univariate-and-multivariate-regression.html","id":"base-r-4","chapter":"19 Univariate and multivariate regression","heading":"base R","text":"TODO","code":""},{"path":"univariate-and-multivariate-regression.html","id":"multivariate","chapter":"19 Univariate and multivariate regression","heading":"19.5 Multivariate","text":"multivariate analysis, present two approaches:glm() tidy()gtsummary packageThe workflow similar , shown , last step pulling final table together different.","code":""},{"path":"univariate-and-multivariate-regression.html","id":"conduct-multivariate","chapter":"19 Univariate and multivariate regression","heading":"Conduct multivariate","text":"Use glm() add variables right side equation, separated plus symbols (+).run model explanatory variables run:want include two variables interaction can separate asterisk * instead +. Separate colon : specifying interaction. example:Optionally, can leverage pre-defined vector column names re-create command using str_c() shown . might useful explanatory variable names changing, don’t want type .","code":"\nmv_reg <- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)## \r\n## Call:\r\n## glm(formula = outcome ~ gender + fever + chills + cough + aches + \r\n##     vomit + age_cat, family = \"binomial\", data = linelist)\r\n## \r\n## Deviance Residuals: \r\n##    Min      1Q  Median      3Q     Max  \r\n##  -1.38   -1.28    1.03    1.08    1.35  \r\n## \r\n## Coefficients:\r\n##              Estimate Std. Error z value Pr(>|z|)\r\n## (Intercept)   0.06905    0.13173    0.52     0.60\r\n## gender        0.00245    0.06513    0.04     0.97\r\n## fever         0.00431    0.08052    0.05     0.96\r\n## chills        0.03411    0.07892    0.43     0.67\r\n## cough         0.13858    0.08991    1.54     0.12\r\n## aches        -0.07071    0.10408   -0.68     0.50\r\n## vomit         0.08610    0.06262    1.37     0.17\r\n## age_cat5-9   -0.06356    0.10185   -0.62     0.53\r\n## age_cat10-14  0.13637    0.10727    1.27     0.20\r\n## age_cat15-19 -0.01107    0.11364   -0.10     0.92\r\n## age_cat20-29  0.02655    0.10278    0.26     0.80\r\n## age_cat30-49  0.05957    0.11640    0.51     0.61\r\n## age_cat50-69 -0.38896    0.26238   -1.48     0.14\r\n## age_cat70+   -0.64744    0.91737   -0.71     0.48\r\n## \r\n## (Dispersion parameter for binomial family taken to be 1)\r\n## \r\n##     Null deviance: 5712.4  on 4166  degrees of freedom\r\n## Residual deviance: 5700.2  on 4153  degrees of freedom\r\n## AIC: 5728\r\n## \r\n## Number of Fisher Scoring iterations: 4\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n## run a regression with all variables of interest \nmv_reg <- explanatory_vars %>%  ## begin with vector of explanatory column names\n  str_c(collapse = \"+\") %>%     ## combine all names of the variables of interest separated by a plus\n  str_c(\"outcome ~ \", .) %>%    ## combine the names of variables of interest with outcome in formula style\n  glm(family = \"binomial\",      ## define type of glm as logistic,\n      data = linelist)          ## define your dataset"},{"path":"univariate-and-multivariate-regression.html","id":"building-the-model","chapter":"19 Univariate and multivariate regression","heading":"Building the model","text":"can build model step--step, saving various models include certain explanatory variables. can compare models likelihood-ratio tests using lrtest() package lmtest, :Another option take model object apply step() function stats package. Specify variable selection direction want use building model.can also turn scientific notation R session, clarity:described section univariate analysis, pass model output tidy() exponentiate log odds CIs. Finally round numeric columns two decimal places. Scroll see rows.resulting data frame looks like:","code":"\nmodel1 <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 <- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)## Likelihood ratio test\r\n## \r\n## Model 1: outcome ~ age_cat\r\n## Model 2: outcome ~ age_cat + gender\r\n##   #Df LogLik Df Chisq Pr(>Chisq)\r\n## 1   8  -2853                    \r\n## 2   9  -2853  1     0       0.99\n## choose a model using forward selection based on AIC\n## you can also do \"backward\" or \"both\" by adjusting the direction\nfinal_mv_reg <- mv_reg %>%\n  step(direction = \"forward\", trace = FALSE)\noptions(scipen=999)\nmv_tab_base <- final_mv_reg %>% \n  ## get a tidy dataframe of estimates \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %>% \n  ## round \n  mutate(across(is.numeric, round, digits = 2))"},{"path":"univariate-and-multivariate-regression.html","id":"combine-univariate-and-multivariate","chapter":"19 Univariate and multivariate regression","heading":"Combine univariate and multivariate","text":"","code":""},{"path":"univariate-and-multivariate-regression.html","id":"combine-with-gtsummary","chapter":"19 Univariate and multivariate regression","heading":"Combine with gtsummary","text":"gtsummary package provides tbl_regression function, \r\ntake outputs regression (glm() case) produce easy\r\nsummary table. can also combine several different output tables produced gtsummary \r\ntbl_merge function.now combine univariate multivariate results:\r\n          1\r\n          \r\n           \r\n          = Odds Ratio, CI = Confidence Interval\r\n          ","code":"\n## show results table of final regression \nmv_tab <- tbl_regression(final_mv_reg, exponentiate = TRUE)\n## combine with univariate results \ntbl_merge(\n  tbls = list(univ_tab, mv_tab), \n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # set header names"},{"path":"univariate-and-multivariate-regression.html","id":"combine-with-dplyr","chapter":"19 Univariate and multivariate regression","heading":"Combine with dplyr","text":"alternative way combining glm()/tidy() univariate multivariate outputs dplyr join functions.Join univariate results earlier (contains counts) tidied multivariate resultsUse select() keep columns want, specify order, re-name themUse round() two decimal places column class Double","code":"\n## combine univariate and multivariable tables \nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %>% \n  ## choose columns and rename them\n  select( # new name =  old name\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %>% \n  mutate(across(is.double, round, 2))## # A tibble: 20 x 11\r\n##    characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_pval mv_or mvv_ci_low mv_ci_high mv_pval\r\n##    <chr>              <dbl> <dbl>   <dbl>       <dbl>        <dbl>     <dbl> <dbl>      <dbl>      <dbl>   <dbl>\r\n##  1 (Intercept)          909  1168    1.28        1.18         1.4      0      1.07       0.83       1.39    0.6 \r\n##  2 gender               916  1174    1           0.88         1.13     0.97   1          0.88       1.14    0.97\r\n##  3 (Intercept)          340   436    1.28        1.11         1.48     0      1.07       0.83       1.39    0.6 \r\n##  4 fever               1485  1906    1           0.85         1.17     0.99   1          0.86       1.18    0.96\r\n##  5 (Intercept)         1472  1877    1.28        1.19         1.37     0      1.07       0.83       1.39    0.6 \r\n##  6 chills               353   465    1.03        0.89         1.21     0.68   1.03       0.89       1.21    0.67\r\n##  7 (Intercept)          272   309    1.14        0.97         1.34     0.13   1.07       0.83       1.39    0.6 \r\n##  8 cough               1553  2033    1.15        0.97         1.37     0.11   1.15       0.96       1.37    0.12\r\n##  9 (Intercept)         1636  2114    1.29        1.21         1.38     0      1.07       0.83       1.39    0.6 \r\n## 10 aches                189   228    0.93        0.76         1.14     0.51   0.93       0.76       1.14    0.5 \r\n## 11 (Intercept)          931  1144    1.23        1.13         1.34     0      1.07       0.83       1.39    0.6 \r\n## 12 vomit                894  1198    1.09        0.96         1.23     0.17   1.09       0.96       1.23    0.17\r\n## 13 (Intercept)          338   427    1.26        1.1          1.46     0      1.07       0.83       1.39    0.6 \r\n## 14 age_cat5-9           365   433    0.94        0.77         1.15     0.54   0.94       0.77       1.15    0.53\r\n## 15 age_cat10-14         273   396    1.15        0.93         1.42     0.2    1.15       0.93       1.41    0.2 \r\n## 16 age_cat15-19         238   299    0.99        0.8          1.24     0.96   0.99       0.79       1.24    0.92\r\n## 17 age_cat20-29         345   448    1.03        0.84         1.26     0.79   1.03       0.84       1.26    0.8 \r\n## 18 age_cat30-49         228   307    1.07        0.85         1.33     0.580  1.06       0.85       1.33    0.61\r\n## 19 age_cat50-69          35    30    0.68        0.41         1.13     0.13   0.68       0.4        1.13    0.14\r\n## 20 age_cat70+             3     2    0.53        0.07         3.2      0.49   0.52       0.07       3.19    0.48"},{"path":"univariate-and-multivariate-regression.html","id":"forest-plot","chapter":"19 Univariate and multivariate regression","heading":"19.6 Forest plot","text":"section shows produce plot outputs regression.\r\ntwo options, can build plot using ggplot2 use \r\nmeta-package called easystats (package includes many packages).","code":""},{"path":"univariate-and-multivariate-regression.html","id":"ggplot2-package","chapter":"19 Univariate and multivariate regression","heading":"ggplot2 package","text":"can build forest plot ggplot() plotting elements multivariate regression results. Add layers:estimates geom_point()confidence intervals geom_errorbar()vertical line = 1 geom_vline()may want re-arrange order variables/levels y-axis (see order age_cat levels alphabetical sensical). , use fct_relevel() forcats package classify column term factor specify order manually. See page Factors details.","code":"\n## remove the intercept term from your multivariable results\nmv_tab_base %>% \n  filter(term != \"(Intercept)\") %>% \n  ## plot with variable on the y axis and estimate (OR) on the x axis\n  ggplot(aes(x = estimate, y = term)) +\n  ## show the estimate as a point\n  geom_point() + \n  ## add in an error bar for the confidence intervals\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  ## show where OR = 1 is for reference as a dashed line\n  geom_vline(xintercept = 1, linetype = \"dashed\")"},{"path":"univariate-and-multivariate-regression.html","id":"easystats-packages","chapter":"19 Univariate and multivariate regression","heading":"easystats packages","text":"alternative want decide different things required\r\nggplot, use combination easystats packages.\r\ncase parameters package function model_parameters() equivalent\r\nbroom package function tidy(). see package accepts outputs\r\ncreates default forest plot ggplot() object.","code":"\n## remove the intercept term from your multivariable results\nfinal_mv_reg %>% \n  model_parameters(exponentiate = TRUE) %>% \n  plot()"},{"path":"univariate-and-multivariate-regression.html","id":"resources-12","chapter":"19 Univariate and multivariate regression","heading":"19.7 Resources","text":"Much information page adapted resources vignettes online:gtsummarysthda stepwise regression","code":""},{"path":"missing-data.html","id":"missing-data","chapter":"20 Missing data","heading":"20 Missing data","text":"page cover:Useful functions assessing missingnessAssess missingness dataframeHow filter rows missingnessPlotting missingness timeHandling NA displayed plotsMissing value imputation, MCAR, MAR, MNAR","code":""},{"path":"missing-data.html","id":"preparation-11","chapter":"20 Missing data","heading":"20.1 Preparation","text":"","code":""},{"path":"missing-data.html","id":"load-packages-12","chapter":"20 Missing data","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,           # import/export\n  tidyverse,     # data mgmt and viz\n  naniar         # assess and visualize missingness\n)"},{"path":"missing-data.html","id":"import-data-11","chapter":"20 Missing data","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .importing data, aware values classified missing. example, 99, 999, “Missing”, blank cells (\"“), cells empty space (” \"). can convert NA (R’s version missing data) data import. See page Import export details.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"missing-data.html","id":"na","chapter":"20 Missing data","heading":"20.2 NA","text":"NAIn R, missing values represented reserved (special) value - NA. Note typed without quotes. “NA” different just normal character value (also Beatles lyric song Hey Jude).data may ways representing missingness, “99”, “Missing”, “Unknown” - may even empty character value \"\" looks “blank”, single space \" “. aware consider whether convert NA importation data cleaning (e.g. na_if()). may also want convert way - changing NA ”Missing\" similar (e.g. replace_na() fct_explicit_na())Versions NAMost time, need know/use NA .na(). However sometimes may encounter need variations NA listed . One example creating new column case_when() deciding assign NA outcome logical criteria (see Cleaning data core functions page tips case_when()).may circumstances NA right-hand side (RHS) case_when() rejected RHS values class Character. RHS values case_when() command must class. Thus, character outcomes RHS like “Confirmed”, “Suspect”, “Probable” NA - get error. Instead NA, put “Missing”, else must put NA_character_. Likewise integers, use NA_integer_ instead NA. NA work dates logical. See R documentation NA information.NANA_character_NA_integer_NA_real_NA_complex_na.rm = TRUEWhen apply mathematical functions max(), min(), sum() mean(), NA value present -rides calculation NA returned. must specify arguemnt na.rm = TRUE within function remove NA values calculation. default behavior intentional, alerted data missing.NULLNULL another reserved value R. logical representation statement neither true false. returned expressions functions whose values undefined. Generally assign NULL value, unless writing functions perhaps writing Shiny return NULL specific scenarios. Null-ness can assessed using .null() conversion can made .null().See blog post difference NULL NA.NaNImpossible values represented special value - NaN. example force R divide 0 0. infinite value. can assess .nan(). may also encounter complementary functions include .infinite() .finite()InfSay column z contains values: z <- c(1, 22, NA, Inf, NaN, 5)want use max() column, can use na.rm = TRUE described remove NA calculation, Inf NaN remain Inf returned. can use brackets [ ] subset vector finite values used calculation: max(z[.finite(z)]).Examples“NAs introduced coercion” common warning message. can happen attempt make illegal conversion like inserting character value vector otherwise numeric.NULL ignored vector.Variance one number results NA.","code":"\nz <- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # returns NA\nmax(z, na.rm=T)                  # returns Inf\nmax(z[is.finite(z)])             # returns 22\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))## Warning: NAs introduced by coercion## [1] 10 20 NA 40\nmy_vector <- c(25, NA, 10, NULL)  # define\nmy_vector                         # print## [1] 25 NA 10\nvar(22)## [1] NA"},{"path":"missing-data.html","id":"useful-functions","chapter":"20 Missing data","heading":"20.3 Useful functions","text":"following useful base R functions assessing handling missing values:.na() !.na()Use .na()identify missing values, use opposite (! front) identify non-missing values. return logical value (TRUE FALSE). Remember can sum() resulting vector count number TRUE, e.g. sum(.na(linelist$date_outcome)).na.omit()function, applied dataframe, remove rows missing values. also base R.\r\napplied vector, remove NA values vector applied . example:na.rm = TRUEIn R, mathematical functions default include NA calculations, results function returning NA. designed intentionally, order make aware missing data.can avoid removing missing values calculation, including argument na.rm = TRUE (na.rm stands “remove NA”).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)## [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n!is.na(my_vector)## [1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\nsum(is.na(my_vector))## [1] 2\nsum(na.omit(my_vector))## [1] 88\nmean(my_vector)## [1] NA\nmean(my_vector, na.rm = TRUE)## [1] 17.6"},{"path":"missing-data.html","id":"assess-missingness-in-a-dataframe","chapter":"20 Missing data","heading":"20.4 Assess missingness in a dataframe","text":"can use package naniar assess visualize missingness dataframe linelist.","code":"\n# install and/or load package\npacman::p_load(naniar)"},{"path":"missing-data.html","id":"quantifying-missingness","chapter":"20 Missing data","heading":"Quantifying missingness","text":"find percent values missing use pct_miss(). Use n_miss() get number missing values.two functions return percent rows missing value, entirely complete, respectively. Remember NA means missing, `\"\" \" \" register non-missing.","code":"\npct_miss(linelist)## [1] 6.69\npct_miss_case(linelist)   # also see n_complete() for counts## [1] 69.1\npct_complete_case(linelist) # see n_complete## [1] 30.9"},{"path":"missing-data.html","id":"visualizing-missingness","chapter":"20 Missing data","heading":"Visualizing missingness","text":"gg_miss_var() function show number missing values column. can add bare column name argument facet = desired see plot groups. default, counts shown instead percents (show_pct = FALSE). can also add labs normal ggplot +labs().can use vis_miss() visualize dataframe heatmap, showing whether value missing . usual, can also select() certain columns dataframe provide function.","code":"\ngg_miss_var(linelist, show_pct = TRUE)\nvis_miss(linelist)"},{"path":"missing-data.html","id":"explore-and-visualize-missingness-relationships","chapter":"20 Missing data","heading":"Explore and visualize missingness relationships","text":"visualize something ??? default, ggplot removes points missing values plots.naniar offers solution via geom_miss_point(). creating scatterplot two columns, records one values missing present shown setting missing values 10% lower lowest value column, coloring distinctly.scatterplot , red dots records value one column present value column missing.assess missingness dataframe stratified another column, consider gg_miss_fct(), returns heatmap percent missingness dataframe factor/categorical (date) column:function can also used date column see missingness time:","code":"\nggplot(\n  linelist, \n  aes(x = age_years,             \n      y = temp)) +     # column to show missingness\n  geom_miss_point()\ngg_miss_fct(linelist, age_cat5)\ngg_miss_fct(linelist, date_onset)## Warning: Removed 29 rows containing missing values (geom_tile)."},{"path":"missing-data.html","id":"shadow-columns","chapter":"20 Missing data","heading":"“Shadow” columns","text":"Another way visualize missingness one column values second column using “shadow” naniar can create. bind_shadow() creates binary NA/NA column every existing column, binds new columns original dataset appendix \"_NA\". doubles number columns - see :“shadow” columns can used plot density proportion values missing, another column X. example, plot shows proportion records missing days_onset_hosp (number days symptom onset hospitalisation), record’s value date_hospitalisation. Essentially, plotting density x-axis column, stratifying results (color =) shadow column interest. analysis works best x-axis numeric date column.can also use “shadow” columns stratify statistical summary, shown :alternative way plot proportion values one column, including missingness, given . involve naniar. example shows percent weekly observations missing column):Aggregate data useful time unit (days, weeks, etc.), summarizing proportion observations NA (values interest)Plot proportion missing line using ggplot(), take linelist, add new column week, group data week, calculate percent week’s records value missing. (note: want % 7 days calculation slightly different).plot proportion missing line, week","code":"\nshadowed_linelist <- linelist %>% \n  bind_shadow()\n\nnames(shadowed_linelist)##  [1] \"case_id\"                 \"generation\"              \"date_infection\"          \"date_onset\"              \"date_hospitalisation\"   \r\n##  [6] \"date_outcome\"            \"outcome\"                 \"gender\"                  \"age\"                     \"age_unit\"               \r\n## [11] \"age_years\"               \"age_cat\"                 \"age_cat5\"                \"hospital\"                \"lon\"                    \r\n## [16] \"lat\"                     \"infector\"                \"source\"                  \"wt_kg\"                   \"ht_cm\"                  \r\n## [21] \"ct_blood\"                \"fever\"                   \"chills\"                  \"cough\"                   \"aches\"                  \r\n## [26] \"vomit\"                   \"temp\"                    \"time_admission\"          \"bmi\"                     \"days_onset_hosp\"        \r\n## [31] \"case_id_NA\"              \"generation_NA\"           \"date_infection_NA\"       \"date_onset_NA\"           \"date_hospitalisation_NA\"\r\n## [36] \"date_outcome_NA\"         \"outcome_NA\"              \"gender_NA\"               \"age_NA\"                  \"age_unit_NA\"            \r\n## [41] \"age_years_NA\"            \"age_cat_NA\"              \"age_cat5_NA\"             \"hospital_NA\"             \"lon_NA\"                 \r\n## [46] \"lat_NA\"                  \"infector_NA\"             \"source_NA\"               \"wt_kg_NA\"                \"ht_cm_NA\"               \r\n## [51] \"ct_blood_NA\"             \"fever_NA\"                \"chills_NA\"               \"cough_NA\"                \"aches_NA\"               \r\n## [56] \"vomit_NA\"                \"temp_NA\"                 \"time_admission_NA\"       \"bmi_NA\"                  \"days_onset_hosp_NA\"\nggplot(\n  shadowed_linelist,                   # dataframe with shadow columns\n  aes(x = date_hospitalisation,        # numeric or date column\n      colour = age_years_NA)) +        # shadow column of interest\n  geom_density()                       # plots the density curves\nlinelist %>%\n  bind_shadow() %>%                # create the shows cols\n  group_by(date_outcome_NA) %>%    # shadow col for stratifying\n  summarise_at(.vars = c(\"age_years\"),                        # variable of interest for calculations\n               .funs = c(\"mean\", \"sd\", \"var\", \"min\", \"max\"),  # stats to calculate\n               na.rm = TRUE)       # other arguments for the stat calculations## # A tibble: 2 x 6\r\n##   date_outcome_NA  mean    sd   var   min   max\r\n##   <fct>           <dbl> <dbl> <dbl> <dbl> <dbl>\r\n## 1 !NA              16.0  12.6  158.     0    84\r\n## 2 NA               16.2  12.9  167.     0    69\noutcome_missing <- linelist %>%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %>%   # create new week column\n  group_by(week) %>%                                             # group the rows by week\n  summarize(                                                     # summarize each week\n    n_obs = n(),                                                     # number of records\n    \n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),       # number of records missing the value\n    outcome_p_miss  = outcome_missing / n_obs,                   # proportion of records missing the value\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),          # number of records as dead\n    outcome_p_dead  = outcome_dead / n_obs) %>%                  # proportion of records as dead\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %>%         # pivot all columns except week, to long format for ggplot\n  filter(stringr::str_detect(statistic, \"_p_\"))                  # keep only the proportion values\nggplot(data = outcome_missing)+\n    geom_line(\n      aes(x = week, y = value, group = statistic, color = statistic),\n      size = 2,\n      stat = \"identity\")+\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\"))+\n    scale_y_continuous(breaks = c(seq(0,1,0.1)))+\n  theme_minimal()+\n  theme(\n    legend.position = \"bottom\"\n  )"},{"path":"missing-data.html","id":"using-data-with-missing-values","chapter":"20 Missing data","heading":"20.5 Using data with missing values","text":"","code":""},{"path":"missing-data.html","id":"filter-out-rows-with-missing-values","chapter":"20 Missing data","heading":"Filter out rows with missing values","text":"quickly remove rows missing values, use dplyr function drop_na().original linelist rnrow(linelist)` rows. adjusted number rows shown :can specify drop rows missingness certain columns:Multiple columns can specified one , using standard syntax:","code":"\nlinelist %>% \n  drop_na() %>%     # remove rows with ANY missing values\n  nrow()## [1] 1818\nlinelist %>% \n  drop_na(date_onset) %>% # remove rows missing date_onset \n  nrow()## [1] 5632\nlinelist %>% \n  drop_na(contains(\"date\")) %>% # remove rows missing values in any \"date\" column \n  nrow()## [1] 3029"},{"path":"missing-data.html","id":"handling-na-in-ggplot","chapter":"20 Missing data","heading":"Handling NA in ggplot()","text":"often wise report number values excluded plot caption. example:ggplot(), can add labs() within caption =. caption, can use str_glue() stringr package paste values together sentence dynamically adjust data. example :Note use \\n new line.Note multiple column contribute values plotted (e.g. age sex reflected plot), must filter columns well correctly calculate number shown.Sometimes, can easier save string object commands prior ggplot() command, simply reference named string object within str_glue().","code":"\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} from Central Hospital;\n  {nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown.\"))  "},{"path":"missing-data.html","id":"na-in-factors","chapter":"20 Missing data","heading":"NA in factors","text":"column interest factor, use fct_explicit_na() forcats package convert NA values character value. default character value “(Missing)” can adjusted via na_level = arguement.","code":"\npacman::p_load(forcats)   # load package\n\nlinelist <- linelist %>% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)## [1] \"f\"       \"m\"       \"Missing\""},{"path":"missing-data.html","id":"imputation","chapter":"20 Missing data","heading":"20.6 Imputation","text":"Sometimes, analyzing data, important “fill gaps” impute missing data can always simply analyze dataset removing missing values, can cause problems many ways. two examples:removing observations missing values variables large amount missing data, might reduce power ability types analysis. example, discovered earlier, small fraction observations linelist dataset missing data across variables. removed majority dataset ’d losing lot information! , variables amount missing data–analysis ’s probably reasonable drop every variable lot missing data either.removing observations missing values variables large amount missing data, might reduce power ability types analysis. example, discovered earlier, small fraction observations linelist dataset missing data across variables. removed majority dataset ’d losing lot information! , variables amount missing data–analysis ’s probably reasonable drop every variable lot missing data either.Depending data missing, analysis non-missing data might lead biased misleading results. example, learned earlier missing data patients whether ’ve important symptoms like fever cough. , one possibility, maybe information wasn’t recorded people just obviously weren’t sick. case, just removed observations ’d excluding healthiest people dataset might really bias results.Depending data missing, analysis non-missing data might lead biased misleading results. example, learned earlier missing data patients whether ’ve important symptoms like fever cough. , one possibility, maybe information wasn’t recorded people just obviously weren’t sick. case, just removed observations ’d excluding healthiest people dataset might really bias results.’s important think data might missing addition seeing much missing. can help decide important might impute missing data, also method imputing missing data might best situation.","code":""},{"path":"missing-data.html","id":"types-of-missing-data","chapter":"20 Missing data","heading":"Types of missing data","text":"three general types missing data:Missing Completely Random (MCAR). means relationship probability data missing variables data. probability missing cases rare situation. , strong reason believe data MCAR analyzing non-missing data without imputing won’t bias results (although may lose power). [TODO: consider discussing statistical tests MCAR]Missing Completely Random (MCAR). means relationship probability data missing variables data. probability missing cases rare situation. , strong reason believe data MCAR analyzing non-missing data without imputing won’t bias results (although may lose power). [TODO: consider discussing statistical tests MCAR]Missing Random (MAR). name actually bit misleading MAR means data missing systematic, predictable way based information . example, maybe every observation dataset missing value fever actually recorded every patient chills aches just assumed fever temperature never taken. true, easily predict every missing observation chills aches fever well use information impute missing data. practice, spectrum. Maybe patient chills aches likely fever well didn’t temperature taken, always. still predictable even isn’t perfectly predictable. common type missing dataMissing Random (MAR). name actually bit misleading MAR means data missing systematic, predictable way based information . example, maybe every observation dataset missing value fever actually recorded every patient chills aches just assumed fever temperature never taken. true, easily predict every missing observation chills aches fever well use information impute missing data. practice, spectrum. Maybe patient chills aches likely fever well didn’t temperature taken, always. still predictable even isn’t perfectly predictable. common type missing dataMissing Random (MNAR). Sometimes, also called Missing Random (NMAR). assumes probability value missing systematic predictable using information also isn’t missing randomly. situation data missing unknown reasons reasons don’t information . example, dataset maybe information age missing elderly patients either don’t know refuse say old . situation, missing data age related value (thus isn’t random) isn’t predictable based information . MNAR complex often best way dealing try collect data information data missing rather attempt impute .Missing Random (MNAR). Sometimes, also called Missing Random (NMAR). assumes probability value missing systematic predictable using information also isn’t missing randomly. situation data missing unknown reasons reasons don’t information . example, dataset maybe information age missing elderly patients either don’t know refuse say old . situation, missing data age related value (thus isn’t random) isn’t predictable based information . MNAR complex often best way dealing try collect data information data missing rather attempt impute .general, imputing MCAR data often fairly simple, MNAR challenging impossible. Many common data imputation methods assume MAR.","code":""},{"path":"missing-data.html","id":"useful-packages","chapter":"20 Missing data","heading":"Useful packages","text":"useful packages imputing missing data Mmisc, missForest (uses random forests impute missing data), mice (Multivariate Imputation Chained Equations). section ’ll just use mice package, implements variety techniques. maintainer mice package published online book imputing missing data goes detail (https://stefvanbuuren.name/fimd/).code load mice package:","code":"\npacman::p_load(mice)"},{"path":"missing-data.html","id":"mean-imputation","chapter":"20 Missing data","heading":"Mean Imputation","text":"Sometimes simple analysis strong reason think can assume MCAR, can simply set missing numerical values mean variable. Perhaps can assume missing temperature measurements dataset either MCAR just normal values. code create new variable replaces missing temperature values mean temperature value dataset. However, many situations replacing data mean can lead bias, careful.also similar process replacing categorical data specific value. dataset, imagine knew observations missing value outcome (can “Death” “Recover”) actually people died (note: actually true dataset):","code":"\nlinelist <- linelist %>%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\nlinelist <- linelist %>%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))"},{"path":"missing-data.html","id":"regression-imputation","chapter":"20 Missing data","heading":"Regression imputation","text":"somewhat advanced method use sort statistical model predict missing value likely replace predicted value. example creating predicted values observations temperature missing, age fever , using simple linear regression using fever status age years predictors. practice ’d want use better model sort simple approach., using modeling approach mice package create imputed values missing temperature observations:type approach advanced methods like using missForest package replace missing data predicted values. case, prediction model random forest instead linear regression. can use types models well. However, approach works well MCAR bit careful believe MAR MNAR accurately describes situation. quality imputation depend good prediction model even good model variability imputed data may underestimated.","code":"\nsimple_temperature_model_fit <- lm(temp ~ fever + age_years, data = linelist)\n\n#using our simple temperature model to predict values just for the observations where temp is missing\npredictions_for_missing_temps <- predict(simple_temperature_model_fit,\n                                        newdata = linelist %>% filter(is.na(temp))) \nmodel_dataset <- linelist %>%\n  select(temp, fever, age_years)  \n\ntemp_imputed <- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = F)## Warning: Number of logged events: 1\ntemp_imputed_values <- temp_imputed$imp$temp"},{"path":"missing-data.html","id":"locf-and-bocf","chapter":"20 Missing data","heading":"LOCF and BOCF","text":"Last observation carried forward (LOCF) baseline observation carried forward (BOCF) imputation methods time series/longitudinal data. idea take previous observed value replacement missing data. multiple values missing succession, method searches last observed value.[COMPLETED]","code":""},{"path":"missing-data.html","id":"multiple-imputation","chapter":"20 Missing data","heading":"Multiple Imputation","text":"online book mentioned earlier author mice package (https://stefvanbuuren.name/fimd/) contains detailed explanation multiple imputation ’d want use . , basic explanation method:multiple imputation, create multiple datasets missing values imputed plausible data values (depending research data might want create less imputed datasets, mice package sets default number 5). difference rather single, specific value imputed value drawn estimated distribution (includes randomness). result, datasets slightly different different imputed values (however, non-missing data imputed datasets). still use sort predictive model imputation new datasets (mice many options prediction methods including Predictive Mean Matching, logistic regression, random forest) mice package can take care many modeling details., created new imputed datasets, can apply apply whatever statistical model analysis planning new imputed datasets pool results models together. works well reduce bias MCAR many MAR settings often results accurate standard error estimates.example applying Multiple Imputation process predict temperature linelist dataset using age fever status (simplified model_dataset ):\r\n[Note Daniel: good model example ’ll change later]used mice default method imputation, Predictive Mean Matching. used imputed datasets separately estimate pool results simple linear regressions datasets. many details ’ve glossed many settings can adjust Multiple Imputation process using mice package. example, won’t always numerical data might need use imputation methods (can still use mice package many types data methods). , robust analysis missing data significant concern, Multiple Imputation good solution isn’t always much work complete case analysis.","code":"\n# imputing missing values for all variables in our model_dataset, and creating 10 new imputed datasets\nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) ## Warning: Number of logged events: 1\nmodel_fit <- with(multiple_imputation, lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))##          term estimate std.error statistic    df p.value\r\n## 1 (Intercept) 3.70e+01  0.027086 1367.1624  26.8   0.000\r\n## 2   age_years 3.87e-05  0.000609    0.0635 171.4   0.949\r\n## 3    feveryes 1.98e+00  0.019359  102.1785 176.5   0.000"},{"path":"missing-data.html","id":"resources-13","chapter":"20 Missing data","heading":"20.7 Resources","text":"Vignette naniar packageGallery missing value visualizations","code":""},{"path":"standardization.html","id":"standardization","chapter":"21 Standardization","heading":"21 Standardization","text":"page show two ways standardize outcome, hospitalizations mortality, characteristics age sex.Using dsr packageUsing PHEindicatormethods packageWe begin extensively demonstrating processes data preparation/cleaning/joining, common combining population data multiple countries, standard population data, deaths, etc.","code":""},{"path":"standardization.html","id":"overview-6","chapter":"21 Standardization","heading":"21.1 Overview","text":"two main ways standardize: direct indirect standardization.\r\nLet’s say like standardize mortality age sex country country B, compare standardized rates countries.direct standardization, know number -risk population number deaths stratum age sex, country country B. One stratum example females ages 15-44.indirect standardization, need know total number deaths age- sex structure country. option therefore feasible age- sex-specific mortality rates population numbers available. Indirect standardization furthermore preferable case small numbers per stratum, estimates direct standardization influenced substantial sampling variation.","code":""},{"path":"standardization.html","id":"preparation-12","chapter":"21 Standardization","heading":"21.2 Preparation","text":"show standardization done, use fictitious population counts death counts country country B, age (5 year categories) sex (female, male). make datasets ready use, perform following preparation steps:Load packagesLoad datasetsJoin populaton death data two countriesPivot longer one row per age-sex stratumClean reference population (world standard population) join country dataIn scenario, data may come different format. Perhaps data province, city, catchment area. may one row death information age sex (significant proportion) deaths. case, see pages Grouping data Pivoting data create dataset event population counts per age-sex stratum.also need reference population, standard population. several standard populations available, purpose exercise use world_standard_population_by_sex. World standard population based populations 46 countries developed 1960. many “standard” populations - one example, website NHS Scotland quite informative European Standard Population, World Standard Population Scotland Standard Population.","code":""},{"path":"standardization.html","id":"load-packages-13","chapter":"21 Standardization","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.CAUTION: newer version R, dsr package directly downloaded CRAN. However, still available CRAN archive. can install use one. non-Mac users:Mac users:","code":"\npacman::p_load(\n     rio,         # to import data\n     here,        # to locate files\n     tidyverse,   # to clean, handle, and plot the data (includes ggplot2 package)\n     stringr,     # cleaning characters and strings\n     frailtypack, # needed for dsr, for frailty models\n     dsr,  \n     PHEindicatormethods)\nrequire(Rtools)\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n# Other solution that may work\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"http:/cran.us.r.project.org\")\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"https://mac.R-project.org\")"},{"path":"standardization.html","id":"load-population-data","chapter":"21 Standardization","heading":"Load population data","text":"First load demographic data (counts males females 5-year age category) two countries comparing, “Country ” “Country B”.","code":"\n# Country A\ncountryA_demo <- import(\"country_demographics.csv\")\n# Country B\ncountryB_demo <- import(\"country_demographics_2.csv\")"},{"path":"standardization.html","id":"load-death-counts","chapter":"21 Standardization","heading":"Load death counts","text":"Conveniently, also counts deaths time period interest, age sex. country’s counts separate file, shown .Deaths Country ADeaths Country B","code":""},{"path":"standardization.html","id":"clean-populations-and-deaths","chapter":"21 Standardization","heading":"Clean populations and deaths","text":"need join transform data following ways:Combine country populations one dataset pivot “long” age-sex stratum one rowCombine country death counts one dataset pivot “long” age-sex stratum one rowJoin deaths populationsFirst, combine country populations datasets, pivot longer, minor cleaning. See page Pivoting data detail.population data now look like :now perform similar operations two deaths datasets.deaths data now look like , contains data countries:now join deaths population data based common columns Country, age_cat5, Sex.can now classify Sex, age_cat5, Country factors ordering specified correctly. use as_factor() function forcats package, described page Factors. Note, classifying factor levels doesn’t visibly change data, arrange() command sort Country, age category, sex.CAUTION: NB. deaths per stratum, use 10-, 15-year categories, instead 5-year categories age, combine categories","code":"\npop_countries <- countryA_demo %>%  # begin with country A dataset\n     bind_rows(countryB_demo) %>%        # bind rows, because cols are identically named\n     pivot_longer(                       # pivot longer\n          cols = c(m, f),                   # columns to combine into one\n          names_to = \"Sex\",                 # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Population\") %>%     # name for new column containing the numeric values pivoted\n     mutate(Sex = recode(Sex,            # re-code values for clarity\n          \"m\" = \"Male\",\n          \"f\" = \"Female\"))\ndeaths_countries <- A_deaths %>%    # begin with country A deaths dataset\n     bind_rows(B_deaths) %>%        # bind rows with B dataset, because cols are identically named\n     pivot_longer(                  # pivot longer\n          cols = c(Male, Female),        # column to transform into one\n          names_to = \"Sex\",              # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Deaths\") %>%      # name for new column containing the numeric values pivoted\n     rename(age_cat5 = AgeCat)    # rename for clarity\ncountry_data <- pop_countries %>% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\ncountry_data <- country_data %>% \n     mutate(\n          Country = as_factor(Country),\n          Country = fct_relevel(Country, \"A\", \"B\"),\n          \n          Sex = as_factor(Sex),\n          Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n          \n          age_cat5 = as_factor(age_cat5),\n          age_cat5 = fct_relevel(age_cat5,\n                                 \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n                                 \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n                                 \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n                                 \"60-64\", \"65-69\", \"70-74\",\n                                 \"75-79\", \"80-84\", \"85\")) %>% \n          arrange(Country, age_cat5, Sex)"},{"path":"standardization.html","id":"load-reference-population","chapter":"21 Standardization","heading":"Load reference population","text":"Lastly, import reference population (world “standard population” sex)","code":"\n# Reference population\nstandard_pop_data <- import(\"world_standard_population_by_sex.csv\")"},{"path":"standardization.html","id":"clean-reference-population","chapter":"21 Standardization","heading":"Clean reference population","text":"values column age_cat5 standard_pop_data contain word “years” “plus”, country_data . remove string make age category values match. use str_replace_all() stringr package, described page Characters strings.Furthermore, package dsr expects standard population, column containing counts called \"pop\". rename column accordingly.CAUTION: try use str_replace_all() remove plus symbol, won’t work special symbol. “Escape” specialnes putting two back slashes front, str_replace_call(column, \"\\\\+\", \"\"). Finally, package PHEindicatormethods, detailed , expects standard populations joined country event population counts. , create dataset all_data purpose.complete dataset looks like :","code":"\n# Remove specific string from column values\nstandard_pop_clean <- standard_pop_data %>%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"),   # remove \"year\"\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"),    # remove \"plus\"\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %>%   # remove \" \" space\n     \n     rename(pop = WorldStandardPopulation)   # change col name to \"pop\", as this is expected by dsr package\nall_data <- left_join(country_data, standard_pop_clean, by=c(\"age_cat5\", \"Sex\"))"},{"path":"standardization.html","id":"dsr-package","chapter":"21 Standardization","heading":"21.3 dsr package","text":"demonstrate calculating comparing directly standardized rates using dsr package. dsr package allows calculate compare directly standardized rates (indirectly standardized rates!).data Preparation section, made separate datasets country counts standard population:country_data object, population table number population number deaths per stratum per countrythe standard_pop_clean object, containing number population per stratum reference population, World Standard PopulationWe use separate datasets dsr approach.","code":""},{"path":"standardization.html","id":"standardized-rates","chapter":"21 Standardization","heading":"Standardized rates","text":", calculate rates per country directly standardized age sex. use dsr() function.note - dsr() expects one data frame country populations event counts (deaths), separate data frame reference population. also expects reference population dataset unit-time column name “pop” (assured data Preparation section).many arguments, annotated code . Notably, event = set column Deaths, fu = (“follow-”) set Population column. set subgroups comparison column Country standardize based age_cat5 Sex. last two columns assigned particular named argument. See ?dsr details., see country lower crude mortality rate country B, higher standardized rate direct age sex standardization.","code":"\n# Calculate rates per country directly standardized for age and sex\nmortality_rate <- dsr::dsr(\n     data = country_data,  # specify object containing number of deaths per stratum\n     event = Deaths,       # column containing number of deaths per stratum \n     fu = Population,      # column containing number of population per stratum\n     subgroup = Country,   # units we would like to compare\n     age_cat5,             # other columns - rates will be standardized by these\n     Sex,\n     refdata = standard_pop_clean, # reference population data frame, with column called pop\n     method = \"gamma\",      # method to calculate 95% CI\n     sig = 0.95,            # significance level\n     mp = 100000,           # we want rates per 100.000 population\n     decimals = 2)          # number of decimals)\n\n\n# Print output as nice-looking HTML table\nknitr::kable(mortality_rate) # show mortality rate before and after direct standardization"},{"path":"standardization.html","id":"standardized-rate-ratios","chapter":"21 Standardization","heading":"Standardized rate ratios","text":"standardized mortality rate 1.22 times higher country compared country B (95% CI 1.17-1.27).","code":"\n# Calculate RR\nmortality_rr <- dsr::dsrr(\n     data = country_data, # specify object containing number of deaths per stratum\n     event = Deaths,      # column containing number of deaths per stratum \n     fu = Population,     # column containing number of population per stratum\n     subgroup = Country,  # units we would like to compare\n     age_cat5,\n     Sex,                 # characteristics to which we would like to standardize \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",      # reference for comparison\n     estimate = \"ratio\",  # type of estimate\n     sig = 0.95,          # significance level\n     mp = 100000,         # we want rates per 100.000 population\n     decimals = 2)        # number of decimals\n\n# Print table\nknitr::kable(mortality_rr) "},{"path":"standardization.html","id":"standardized-rate-difference","chapter":"21 Standardization","heading":"Standardized rate difference","text":"Country 4.24 additional deaths per 100.000 population (95% CI 3.24-5.24) compared country .","code":"\n# Calculate RD\nmortality_rd <- dsr::dsrr(\n     data = country_data,       # specify object containing number of deaths per stratum\n     event = Deaths,            # column containing number of deaths per stratum \n     fu = Population,           # column containing number of population per stratum\n     subgroup = Country,        # units we would like to compare\n     age_cat5,                  # characteristics to which we would like to standardize\n     Sex,                        \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",            # reference for comparison\n     estimate = \"difference\",   # type of estimate\n     sig = 0.95,                # significance level\n     mp = 100000,               # we want rates per 100.000 population\n     decimals = 2)              # number of decimals\n\n# Print table\nknitr::kable(mortality_rd) "},{"path":"standardization.html","id":"pheindicatormethods-package","chapter":"21 Standardization","heading":"21.4 PHEindicatormethods package","text":"Another way calculating standardized rates PHEindicatormethods package. package allows calculate directly well indirectly standardized rates. show .","code":""},{"path":"standardization.html","id":"directly-standardized-rates","chapter":"21 Standardization","heading":"Directly standardized rates","text":", first group data Country pass function phe_dsr() get directly standardized rates per country.note - reference (standard) population can provided column within country-specific data frame separate vector. provided within country-specific data frame, set stdpoptype = \"field\". provided vector, set stdpoptype = \"vector\". latter case, make sure ordering rows strata similar country-specific data frame reference population, records matched position. example , provided reference population column within country-specific data frame.See help ?phr_dsr links References section information.","code":"\n# Calculate rates per country directly standardized for age and sex\nmortality_ds_rate_phe <- all_data %>%\n     group_by(Country) %>%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          stdpop = pop,               # standard populations for each stratum\n          stdpoptype = \"field\")       # either \"vector\" for a standalone vector or \"field\" meaning std populations are in the data  \n\n# Print table\nknitr::kable(mortality_ds_rate_phe)"},{"path":"standardization.html","id":"indirectly-standardized-rates","chapter":"21 Standardization","heading":"Indirectly standardized rates","text":"indirect standardization, need reference population number deaths number population per stratum. example, calculating rates country using country B reference population, previous standard_pop_clean reference population include number deaths per stratum., first create reference population country B. , pass mortality population data country , combine reference population, pass function phe_isr(), get indirectly standardized rates. course, can also vice versa.note - example , reference population provided separate data frame. case, make sure x =, n =, x_ref = n_ref = vectors ordered standardization category (stratum) values country-specific data frame, records matched position.See help ?phr_isr links References section information.","code":"\n# Create reference population\nrefpopCountryB <- country_data %>% \n  filter(Country==\"B\") \n\n# Calculate rates for country A indirectly standardized by age and sex\nmortality_is_rate_phe_A <- country_data %>%\n     filter(Country==\"A\") %>%\n     PHEindicatormethods::phe_isr(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          x_ref = refpopCountryB$Deaths,  # reference number of deaths for each stratum\n          n_ref = refpopCountryB$Population)  # reference population for each stratum\n\n# Print table\nknitr::kable(mortality_is_rate_phe_A)"},{"path":"standardization.html","id":"resources-14","chapter":"21 Standardization","heading":"21.5 Resources","text":"TIP: like see another reproducible example using dsr listed Handbook, please go https://mran.microsoft.com/snapshot/2020-02-12/web/packages/dsr/vignettes/dsr.html.TIP: another example using PHEindicatormethods, please go https://mran.microsoft.com/snapshot/2018-10-22/web/packages/PHEindicatormethods/vignettes/IntroductiontoPHEindicatormethods.htmlPHEindicatormethods reference file: https://cran.r-project.org/web/packages/PHEindicatormethods/PHEindicatormethods.pdf","code":""},{"path":"moving-averages.html","id":"moving-averages","chapter":"22 Moving averages","heading":"22 Moving averages","text":"page cover two methods calculate visualize moving averages:Calculate slider packageCalculate within ggplot() command tidyquant package","code":""},{"path":"moving-averages.html","id":"preparation-13","chapter":"22 Moving averages","heading":"22.1 Preparation","text":"","code":""},{"path":"moving-averages.html","id":"load-packages-14","chapter":"22 Moving averages","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,      # for data management and viz\n  slider,         # for calculating moving averages\n  tidyquant       # for calculating moving averages within ggplot\n)"},{"path":"moving-averages.html","id":"import-data-12","chapter":"22 Moving averages","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"moving-averages.html","id":"calculate-with-slider","chapter":"22 Moving averages","heading":"22.2 Calculate with slider","text":"Use approach calculate moving average data frame prior plotting.slider package provides several “sliding window” functions compute rolling averages, cumulative sums, rolling regressions, etc. treats dataframe vector rows, allowing iteration row-wise dataframe.common functions:slide_dbl() - iterates numeric column performing operation using sliding window\r\nslide_sum() - rolling sum shortcut\r\nslide_mean() - rolling average shortcut\r\nslide_sum() - rolling sum shortcutslide_mean() - rolling average shortcutslide_index_dbl() - applies rolling window using separate index column (useful using dates missing rows)Core arguments.x, first argument default, vector iterate apply function .f, second argument default, either:\r\nfunction, written without parentheses, like mean, \r\nformula, converted function. example ~ .x - mean(.x) return result current value minus mean window’s value\r\nfunction, written without parentheses, like mean, orA formula, converted function. example ~ .x - mean(.x) return result current value minus mean window’s valueFor details see reference materialWindow sizeSpecify size window using either ., ., arguments:.= - Provide integer.= - Provide integer.complete = - Set TRUE want calculation performed complete windowsFor example, achieve 7-day window including current value six previous, use .= 6. achieve “centered” window provide number .= .=.default, .complete = FALSE full window rows exist, functions use available rows perform calculation. Setting TRUE restricts calculations performed complete windows.Expanding windowTo achieve cumulative operations, set .= argument Inf. conduct operation current value coming .","code":""},{"path":"moving-averages.html","id":"rolling-operations","chapter":"22 Moving averages","heading":"Rolling operations","text":"Use slide_dbl(), made specifically slide across numeric vector. operates across data frame row 1 onwards, careful ordering rows. example, arrange dataset date onset, calculate rolling mean days delay symptom onset hospital admission (days_onset_hosp column). set window value two values .Grouped dataYou can group data moving average calculated within groups.set .complete = TRUE careful rows arranged. Every change grouping variable start minimum window allow calculation.See handbook page Grouping data details grouping data.can now plot moving averages group. See page ggplot tips information facetting using gghighlight.DANGER: get error saying “slide() deprecated tsibble 0.9.0 now defunct. Please use slider::slide() instead.”, means slide() function tsibble package masking slide() function slider package. Fix specifying package command, slider::slide_dbl().","code":"\nrolled <- linelist %>%  \n  \n  arrange(date_onset) %>%             # arrange rows by ascending date of onset\n  \n  select(                             # select only some columns, for visibility\n    case_id,                     \n    date_onset,\n    days_onset_hosp) %>% \n  \n  mutate(\n    delay_roll = slider::slide_dbl(   # define column delay_roll \n      .x        = days_onset_hosp,    # apply function to delays column\n      .f        = mean,               # use mean()\n      .before   = 2,                  # use value and 2 previous values\n      .complete = FALSE)) %>%         # calculate even if three values not present\n\n  mutate(delay_roll = round(delay_roll, 2)) # round values to 2 decimal places\ngrouped_roll <- linelist %>%\n  \n  select(                             # select only some columns, for example clarity\n    case_id,                     \n    hospital,\n    date_onset,\n    days_onset_hosp) %>%  \n  \n  arrange(hospital, date_onset) %>%   # arrange rows by hospital and then by date of onset\n\n  group_by(hospital) %>%              # group by month of onset \n    \n  \n  mutate(                             # rolling mean, as before  \n    delay_roll_hosp = slider::slide_dbl(\n      .x = days_onset_hosp,\n      .f = mean,\n      .before = 30,                   # 30-day sliding window\n      .complete = TRUE)\n    )\ngrouped_roll %>% \n  ggplot()+\n  geom_line(aes(x = date_onset, y = delay_roll_hosp, color = hospital))+\n  theme_classic()+\n  gghighlight::gghighlight()+\n  facet_wrap(~hospital, ncol = 2)+\n  labs(\n    title = \"Monthly rolling average of delay to care\",\n    x = \"Date of symptom onset\",\n    y = \"Days onset to admission\")"},{"path":"moving-averages.html","id":"indexed-rolling","chapter":"22 Moving averages","heading":"Indexed rolling","text":"Often conducting rolling operations date (common epidemiological linelists), can encounter problems like:Dates missing dataframe, included windowTo solve , use slide_index() slider. uses separate column index rolling window. column date, know dates present data include window NA. example return 7-day rolling average new cases reported per day:First count number cases reported day count() dplyr (see page Grouping data).new dataset now looks like . Note days present (cases days). simple slide_dbl() incorrectly include first seven rows first window.use function slide_index() specifically recognize missing days dataframe, must accounted creating windows time. set “index” column (.argument) column date_onset. date_onset column class Date, function accounts days appear dataframe. arguments ..can use integers, use lubridate functions like days() months().can see time windows account days appear data.can now plot linelist, 7-day moving average overlaid. needed, see page ggplot tips.rolling average months, can use lubridate group data month, apply slide_index_dbl() shown three-month rolling average:","code":"\n# make dataset of daily counts and 7-day moving average\ncounts_7day <- linelist %>% \n  \n  # get counts\n  count(\n    date_onset,        # count rows per unique onset_date\n    name = \"new_cases\" # name of new column\n    ) %>%\n  \n  # remove counts with missing onset_date\n  filter(!is.na(date_onset))\n## calculate 7-day rolling average, accounting for missing days\nrolling <- counts_7day %>% \n  mutate(\n    avg_7day = slider::slide_index_dbl(  # create new column\n        new_cases,                       # calculate avg based on value in new_cases column\n        .i = date_onset,                 # index column is date_onset, so non-present dates are included in 7day window \n        .f = ~mean(.x, na.rm = TRUE),    # function is mean() with missing values removed\n        .before = days(6),               # window is the day and 6-days before\n        .complete = TRUE))               # fills in first days with NA\nggplot(data = rolling, aes(x = date_onset))+\n  geom_histogram(         # plot histogram of daily cases\n    aes(y = new_cases),\n    fill   =\"#92a8d1\",    # bar color\n    stat   = \"identity\",  # height = value\n    colour = \"#92a8d1\")+  # color around bars\n  geom_line(              # overlay line\n    aes(y = avg_7day),    # use 7-day average column\n    color=\"red\",         \n    size = 1) +           # line thickness  \n  scale_x_date(           # x-axis by months\n    date_breaks = \"1 month\",\n    date_labels = '%d/%m',\n    expand = c(0,0)) +\n  scale_y_continuous(\n    expand = c(0,0),\n    limits = c(0, NA)) + \n  labs(\n    x=\"\",\n    y =\"Number of confirmed cases\")+ \n  theme_minimal() \nll_months <- linelist %>%\n  mutate(\n    month_onset = floor_date(date_onset, \"month\")) %>% \n  count(month_onset) %>% \n  filter(!is.na(month_onset)) %>% \n  mutate(\n    monthly_roll = slider::slide_index_dbl(\n      n,                                # calculate avg based on value in new_cases column\n      .i = month_onset,                 # index column is date_onset, so non-present dates are included in 7day window \n      .f = ~mean(.x, na.rm = TRUE),     # function is mean() with missing values removed\n      .before = months(2),              # window is the day and 6-days before\n      .complete = TRUE))                # fills in first days with NA"},{"path":"moving-averages.html","id":"calculate-with-tidyquant-within-ggplot","chapter":"22 Moving averages","heading":"22.3 Calculate with tidyquant within ggplot()","text":"package tidyquant offers another approach calculating moving averages - time within ggplot() command .linelist data counted date onset, plotted faded line (alpha < 1). Overlaid top line created geom_ma(), window 7 days (n = 7) specified color thickness.default geom_ma() uses simple moving average (ma_fun = \"SMA\"), types can specified, :“EMA” - exponential moving average (weight recent observations)“WMA” - weighted moving average (wts used weight observations moving average)Others can found function documentationSee vignette details options available within tidyquant.","code":"\nlinelist %>% \n  count(date_onset) %>%                 # count cases per day\n  filter(!is.na(date_onset)) %>%        # remove cases missing onset date\n  ggplot(aes(x = date_onset, y = n))+   # start ggplot\n    geom_line(                          # plot raw values\n      size = 1,\n      alpha = 0.2                       # semi-transparent line\n      )+             \n    tidyquant::geom_ma(                 # plot moving average\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal()                       # simple background"},{"path":"moving-averages.html","id":"resources-15","chapter":"22 Moving averages","heading":"22.4 Resources","text":"See helpful online vignette slider packageThe slider github pageA slider vignettetidyquant vignetteIf use case requires “skip ” weekends even holidays, might like almanac package.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"time-series-and-outbreak-detection","chapter":"23 Time series and outbreak detection","heading":"23 Time series and outbreak detection","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"overview-7","chapter":"23 Time series and outbreak detection","heading":"23.1 Overview","text":"tab demonstrates use several packages time series analysis.\r\nprimarily relies packages tidyverts\r\nfamily, also use RECON trending\r\npackage fit models appropriate infectious disease epidemiology.Time series dataDescriptive analysisFitting regressionsRelation two time seriesOutbreak detectionInterrupted time series","code":""},{"path":"time-series-and-outbreak-detection.html","id":"preparation-14","chapter":"23 Time series and outbreak detection","heading":"23.2 Preparation","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"packages-1","chapter":"23 Time series and outbreak detection","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               slider,       # for calculating moving averages\n               imputeTS,     # for filling in missing values\n               feasts,       # for time series decomposition and autocorrelation\n               forecast,     # fit sin and cosin terms to data (note: must load after feasts)\n               trending,     # fit and assess models \n               tmaptools,    # for getting geocoordinates (lon/lat) based on place names\n               ecmwfr,       # for interacting with copernicus sateliate CDS API\n               stars,        # for reading in .nc (climate data) files\n               units,        # for defining units of measurement (climate data)\n               yardstick,    # for looking at model accuracy\n               surveillance  # for aberration detection\n               )"},{"path":"time-series-and-outbreak-detection.html","id":"load-data","chapter":"23 Time series and outbreak detection","heading":"Load data","text":"example dataset used section:Weekly counts campylobacter cases reported Germany 2001 2011.dataset reduced version dataset available surveillance package.\r\n(details load surveillance package see ?campyDE)dataset imported using import() function rio package. See page Import export various ways import data.first 10 rows counts displayed .","code":"\n# import the linelist\ncounts <- rio::import(\"campylobacter_germany.xlsx\")"},{"path":"time-series-and-outbreak-detection.html","id":"clean-data-1","chapter":"23 Time series and outbreak detection","heading":"Clean data","text":"makes sure date column appropriate format.\r\ntab using tsibble package yearweek\r\nfunction used create calendar week variable. several \r\nways (see Working dates page details), however \r\ntime series best keep within one framework.","code":"\n## ensure the date column is in the appropriate format\ncounts$date <- as.Date(counts$date)\n\n## create a calendar week variable \n## fitting ISO definitons of weeks starting on a monday\ncounts <- counts %>% \n     mutate(epiweek = yearweek(date, week_start = 1))"},{"path":"time-series-and-outbreak-detection.html","id":"download-climate-data","chapter":"23 Time series and outbreak detection","heading":"Download climate data","text":"relation two time series section tab, comparing\r\ncampylobacter case counts climate data.Climate data anywhere world can downloaded EU’s Copernicus\r\nSatellite. exact measurements, based model (similar \r\ninterpolation), however benefit global hourly coverage well forecasts.using ecmwfr package pull data Copernicus\r\nclimate data store. need create free account order \r\nwork. package website useful walkthrough\r\n. example code go , \r\nappropriate API keys. replace X’s account\r\nIDs.\r\nneed download one year data time otherwise server times-.sure coordinates location want download data\r\n, can use tmaptools package pull coordinates open street\r\nmaps. alternative option photon\r\npackage, however released CRAN yet; nice thing \r\nphoton provides contextual data several\r\nmatches search.","code":"\n## retrieve location coordinates\ncoords <- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## pull together long/lats in format for ERA-5 querying (bounding box) \n## (as just want a single point can repeat coords)\nrequest_coords <- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## Pulling data modelled from copernicus satellite (ERA-5 reanalysis)\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## set up key for weather data \nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX\",\n           service = \"cds\") \n\n## run for each year of interest (otherwise server times out)\nfor (i in 2002:2011) {\n  \n  ## pull together a query \n  ## see here for how to do: https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## change request to a list using addin button above (python to list)\n  ## Target is the name of the output file!!\n  request <- request <- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ## download the file and store it in the current working directory\n  file <- wf_request(user     = \"XXXXX\",  # user ID (for authentication)\n                     request  = request,  # the request\n                     transfer = TRUE,     # download the file\n                     path     = here::here(\"data\", \"Weather\")) ## path to save the data\n  }"},{"path":"time-series-and-outbreak-detection.html","id":"load-climate-data","chapter":"23 Time series and outbreak detection","heading":"Load climate data","text":"","code":"\n## define path to weather folder \nfile_paths <- list.files(\n  here::here(\"data\", \"weather\"), \n  full.names = TRUE)\n\n## only keep those with the current name of interest \nfile_paths <- file_paths[str_detect(file_paths, \"germany\")]\n\n\n## read in as a stars object \ndata <- stars::read_stars(file_paths)## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp,\n## change to a data frame \ntemp_data <- as_tibble(data) %>% \n  ## add in variables and correct units\n  mutate(\n    ## create an calendar week variable \n    epiweek = tsibble::yearweek(time), \n    ## create a date variable (start of calendar week)\n    date = as.Date(epiweek),\n    ## change temperature from kelvin to celsius\n    t2m = set_units(t2m, celsius), \n    ## change precipitation from metres to millimetres \n    tp  = set_units(tp, mm)) %>% \n  ## group by week (keep the date too though)\n  group_by(epiweek, date) %>% \n  ## get the average per week\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))"},{"path":"time-series-and-outbreak-detection.html","id":"time-series-data","chapter":"23 Time series and outbreak detection","heading":"23.3 Time series data","text":"number different packages structuring handling time series\r\ndata. said, focus tidyverts family packages \r\nuse tsibble package define time series object. data set\r\ndefined time series object means much easier structure analysis.use tsibble() function specify “index”, .e. variable\r\nspecifying time unit interest. case epiweek variable.data set weekly counts province, example, also\r\nable specify grouping variable using key = argument.\r\nallow us analysis group.Looking class(counts) tells top tidy data frame\r\n(“tbl_df”, “tbl”, “data.frame”), additional properties time series\r\ndata frame (“tbl_ts”).can take quick look data using ggplot2. see plot \r\nclear seasonal pattern, missings. However, \r\nseems issue reporting beginning year; cases drop\r\nlast week year increase first week next year.DANGER: datasets aren’t clean example.\r\nneed check duplicates missings . ","code":"\n## define time series object \ncounts <- tsibble(counts, index = epiweek)\n## plot a line graph of cases by week\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()"},{"path":"time-series-and-outbreak-detection.html","id":"duplicates","chapter":"23 Time series and outbreak detection","heading":"Duplicates","text":"tsibble allow duplicate observations. row need \r\nunique, unique within group (key variable).\r\npackage functions help identify duplicates. include\r\nare_duplicated() gives TRUE/FALSE vector whether row \r\nduplicate, duplicates() gives data frame duplicated rows.See page De-duplication details select rows want.","code":"\n## get a vector of TRUE/FALSE whether rows are duplicates\nare_duplicated(counts, index = epiweek) \n\n## get a data frame of any duplicated rows \nduplicates(counts, index = epiweek) "},{"path":"time-series-and-outbreak-detection.html","id":"missings","chapter":"23 Time series and outbreak detection","heading":"Missings","text":"saw brief inspection missings, also\r\nsaw seems problem reporting delay around new year.\r\nOne way address problem set values missing \r\nimpute values. simplest form time series imputation draw\r\nstraight line last non-missing next non-missing value.\r\nuse imputeTS package function na_interpolation().See Missing data page options imputation.Another alternative calculating moving average, try smooth\r\napparent reporting issues (see next section, page Moving averages).","code":"\n## create a variable with missings instead of weeks with reporting issues\ncounts <- counts %>% \n     mutate(case_miss = if_else(\n          ## if epiweek contains 52, 53, 1 or 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## then set to missing \n          NA_real_, \n          ## otherwise keep the value in case\n          case\n     ))\n\n## alternatively interpolate missings by linear trend \n## between two nearest adjacent points\ncounts <- counts %>% \n  mutate(case_int = na_interpolation(case_miss)\n         )\n\n## to check what values have been imputed compared to the original\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"descriptive-analysis","chapter":"23 Time series and outbreak detection","heading":"23.4 Descriptive analysis","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"moving-averages-1","chapter":"23 Time series and outbreak detection","heading":"Moving averages","text":"data noisy (counts jumping ) can helpful \r\ncalculate moving average. example , week calculate \r\naverage number cases four previous weeks. smooths data, \r\nmake interpretable. case really add much, \r\nstick interpolated data analysis.\r\nSee Moving averages page detail.","code":"\n## create a moving average variable (deals with missings)\ncounts <- counts %>% \n     ## create the ma_4w variable \n     ## slide over each row of the case variable\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## for each row calculate the name\n                               ~ mean(.x, na.rm = TRUE),\n                               ## use the four previous weeks\n                               .before = 4))\n\n## make a quick visualisation of the difference \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")"},{"path":"time-series-and-outbreak-detection.html","id":"periodicity","chapter":"23 Time series and outbreak detection","heading":"Periodicity","text":"NOTE: possible use weeks add sin cosine terms, however use function generate terms (see regression section ) ","code":"\n## x is a dataset\n## counts is variable with count data or rates within x \n## start_week is the first week in your dataset\n## period is how many units in a year \n## output is whether you want return spectral periodogram or the peak weeks\n  ## \"periodogram\" or \"weeks\"\nperiodogram <- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## make sure is not a tsibble, filter to project and only keep columns of interest\n    prepare_data <- dplyr::as_tibble(x)\n    # prepare_data <- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data <- dplyr::select(prepare_data, {{counts}})\n    \n    ## create an intermediate \"zoo\" time series to be able to use with spec.pgram\n    zoo_cases <- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## get a spectral periodogram not using fast fourier transform \n    periodo <- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## return the peak weeks \n    periodo_weeks <- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## get spectral periodogram for extracting weeks with the highest frequencies \n## (checking of seasonality) \nperiodo <- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## pull spectrum and frequence in to a dataframe for plotting\nperiodo <- data.frame(periodo$freq, periodo$spec)\n\n## plot a periodogram showing the most frequently occuring periodicity \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52),  y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (Weeks)\", y = \"Log(density)\")\n## get a vector weeks in ascending order \npeak_weeks <- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")"},{"path":"time-series-and-outbreak-detection.html","id":"decomposition","chapter":"23 Time series and outbreak detection","heading":"Decomposition","text":"Classical decomposition used break time series several parts, \r\ntaken together make pattern see.\r\ndifferent parts :trend-cycle (long-term direction data)seasonality (repeating patterns)random (left removing trend season)","code":"\n## decompose the counts dataset \ncounts %>% \n  # using an additive classical decomposition model\n  model(classical_decomposition(case_int, type = \"additive\")) %>% \n  ## extract the important information from the model\n  components() %>% \n  ## generate a plot \n  autoplot()"},{"path":"time-series-and-outbreak-detection.html","id":"autocorrelation","chapter":"23 Time series and outbreak detection","heading":"Autocorrelation","text":"Autocorrelation tells relation counts week\r\nweeks (called lags).Using ACF() function, can produce plot shows us number lines\r\nrelation different lags. lag 0 (x = 0), line \r\nalways 1 shows relation observation (shown ).\r\nfirst line shown (x = 1) shows relation observation\r\nobservation (lag 1), second shows relation \r\nobservation observation last (lag 2) lag \r\n52 shows relation observation observation 1\r\nyear (52 weeks ).Using PACF() function (partial autocorrelation) shows type relation\r\nadjusted weeks . less informative determining\r\nperiodicity.can formally test null hypothesis independence time series (.e. \r\nautocorrelated) using Ljung-Box test (stats package).\r\nsignificant p-value suggests autocorrelation data.","code":"\n## using the counts dataset\ncounts %>% \n  ## calculate autocorrelation using a full years worth of lags\n  ACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## using the counts data set \ncounts %>% \n  ## calculate the partial autocorrelation using a full years worth of lags\n  PACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## test for independance \nBox.test(counts$case_int, type = \"Ljung-Box\")## \r\n##  Box-Ljung test\r\n## \r\n## data:  counts$case_int\r\n## X-squared = 473, df = 1, p-value <2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"fitting-regressions","chapter":"23 Time series and outbreak detection","heading":"23.5 Fitting regressions","text":"possible fit large number different regressions time series,\r\nhowever, demonstrate fit negative binomial regression - \r\noften appropriate counts data infectious diseases.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"fourier-terms","chapter":"23 Time series and outbreak detection","heading":"Fourier terms","text":"Fourier terms equivalent sin cosin curves. difference \r\nfit based finding appropriate combination curves explain\r\ndata.fitting one fourier term, equivalent fitting sin\r\ncosin frequently occurring lag seen periodogram (\r\ncase 52 weeks). use fourier() function forecast package.code assign using $, fourier() returns two columns (one\r\nsin one cosin) added dataset list, called\r\n“fourier” - list can used normal variable regression.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  fourier(K = 1)"},{"path":"time-series-and-outbreak-detection.html","id":"negative-binomial","chapter":"23 Time series and outbreak detection","heading":"Negative binomial","text":"possible fit regressions using base stats MASS\r\nfunctions (e.g. lm(), glm() glm.nb()). However using \r\ntrending package, allows calculating appropriate confidence\r\nprediction intervals (otherwise available).\r\nsyntax , specify outcome variable tilde (~)\r\nadd various exposure variables interest separated plus (+).difference first define model fit() \r\ndata. useful allows comparing multiple different models\r\nsyntax.TIP: wanted use rates, rather \r\ncounts include population variable logarithmic offset term, adding\r\noffset(log(population). need set population 1, \r\nusing predict() order produce rate. TIP: fitting complex models \r\nARIMA prophet, see fable package.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier)\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model)\n\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"residuals","chapter":"23 Time series and outbreak detection","heading":"Residuals","text":"see well model fits observed data need look residuals.\r\nresiduals difference observed counts counts\r\nestimated model. calculate simply using case_int - estimate,\r\nresiduals() function extracts directly regression us.see , explaining variation\r\nmodel. might fit fourier terms,\r\naddress amplitude. However example leave .\r\nplots show model worse peaks troughs (counts \r\nhighest lowest) might likely underestimate\r\nobserved counts.","code":"\n## calculate the residuals \nobserved <- observed %>% \n  mutate(resid = residuals(fitted_model$fitted_model, type = \"response\"))\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nobserved %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nobserved %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nobserved %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n## compare observed counts to their residuals \n  ## should also be no pattern \nobserved %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(observed$resid, type = \"Ljung-Box\")## \r\n##  Box-Ljung test\r\n## \r\n## data:  observed$resid\r\n## X-squared = 357, df = 1, p-value <2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"relation-of-two-time-series","chapter":"23 Time series and outbreak detection","heading":"23.6 Relation of two time series","text":"look using weather data (specifically temperature) explain\r\ncampylobacter case counts.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"merging-datasets","chapter":"23 Time series and outbreak detection","heading":"Merging datasets","text":"can join datasets using week variable. merging see \r\nhandbook section [joining].","code":"\n## left join so that we only have the rows already existing in counts\n## drop the date variable from temp_data (otherwise is duplicated)\ncounts <- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")"},{"path":"time-series-and-outbreak-detection.html","id":"descriptive-analysis-1","chapter":"23 Time series and outbreak detection","heading":"Descriptive analysis","text":"First plot data see obvious relation.\r\nplot shows clear relation seasonality two\r\nvariables, temperature might peak weeks case number.\r\npivoting data, see handbook section [cleaning data].","code":"\ncounts %>% \n  ## keep the variables we are interested \n  select(epiweek, case_int, t2m) %>% \n  ## change your data in to long format\n  pivot_longer(\n    ## use epiweek as your key\n    !epiweek,\n    ## move column names to the new \"measure\" column\n    names_to = \"measure\", \n    ## move cell values to the new \"values\" column\n    values_to = \"value\") %>% \n  ## create a plot with the dataset above\n  ## plot epiweek on the x axis and values (counts/celsius) on the y \n  ggplot(aes(x = epiweek, y = value)) + \n    ## create a separate plot for temperate and case counts \n    ## let them set their own y-axes\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## plot both as a line\n    geom_line()"},{"path":"time-series-and-outbreak-detection.html","id":"lags-and-cross-correlation","chapter":"23 Time series and outbreak detection","heading":"Lags and cross-correlation","text":"formally test weeks highly related cases temperature.\r\ncan use cross-correlation function (CCF()) feasts package.\r\nalso visualise (rather using arrange) using autoplot() function.see lag 4 weeks highly correlated,\r\nmake lagged temperature variable include regression.","code":"\ncounts %>% \n  ## calculate cross-correlation between interpolated counts and temperature\n  CCF(case_int, t2m,\n      ## set the maximum lag to be 52 weeks\n      lag_max = 52, \n      ## return the correlation coefficient \n      type = \"correlation\") %>% \n  ## arange in decending order of the correlation coefficient \n  ## show the most associated lags\n  arrange(-ccf) %>% \n  ## only show the top ten \n  slice_head(n = 10)## Warning: Current temporal ordering may yield unexpected results.\r\n## i Suggest to sort by ``, `lag` first.## # A tsibble: 10 x 2 [1W]\r\n##      lag   ccf\r\n##    <lag> <dbl>\r\n##  1    4W 0.750\r\n##  2    5W 0.746\r\n##  3    3W 0.736\r\n##  4    6W 0.731\r\n##  5    2W 0.727\r\n##  6    7W 0.705\r\n##  7    1W 0.694\r\n##  8    8W 0.671\r\n##  9    0W 0.647\r\n## 10  -47W 0.640\ncounts <- counts %>% \n  ## create a new variable for temperature lagged by four weeks\n  mutate(t2m_lag4 = lag(t2m, n = 4))"},{"path":"time-series-and-outbreak-detection.html","id":"negative-binomial-with-two-variables","chapter":"23 Time series and outbreak detection","heading":"Negative binomial with two variables","text":"fit negative binomial regression done previously. time add \r\ntemperature variable lagged four weeks.investigate individual terms, can pull original negative binomial\r\nregression trending format using get_model() pass \r\nbroom package tidy() function retrieve exponentiated estimates associated\r\nconfidence intervals.shows us lagged temperature, controlling trend seasonality,\r\nsimilar case counts (estimate ~ 1) significantly associated.\r\nsuggests might good variable use predicting future case\r\nnumbers (climate forecasts readily available).quick visual inspection model shows might better job \r\nestimating observed case counts.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier + \n    ## use the temperature lagged by four weeks \n    t2m_lag4\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model)\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)## Warning: Tidiers for objects of class negbin are not maintained by the broom team, and are only supported through the glmlm tidier method. Please be\r\n## cautious in interpreting and reporting broom output.## # A tibble: 5 x 7\r\n##   term         estimate  std.error statistic  p.value conf.low conf.high\r\n##   <chr>           <dbl>      <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\r\n## 1 (Intercept)   369.    0.105          56.4  0.        300.      453.   \r\n## 2 epiweek         1.00  0.00000747     10.5  9.57e-26    1.00      1.00 \r\n## 3 fourierS1-52    0.753 0.0213        -13.3  1.98e-40    0.723     0.785\r\n## 4 fourierC1-52    0.816 0.0198        -10.3  9.30e-25    0.786     0.848\r\n## 5 t2m_lag4        1.01  0.00267         2.36 1.81e- 2    1.00      1.01\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"residuals-1","chapter":"23 Time series and outbreak detection","heading":"Residuals","text":"investigate residuals see well model fits observed data.\r\nresults interpretation similar previous regression,\r\nmay feasible stick simpler model without temperature.","code":"\n## calculate the residuals \nobserved <- observed %>% \n  mutate(resid = case_int - estimate)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nobserved %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")## Warning: Removed 4 row(s) containing missing values (geom_path).## Warning: Removed 4 rows containing missing values (geom_point).\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nobserved %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nobserved %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") ## Warning: Removed 4 rows containing non-finite values (stat_bin).\n## compare observed counts to their residuals \n  ## should also be no pattern \nobserved %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")## Warning: Removed 4 rows containing missing values (geom_point).\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(observed$resid, type = \"Ljung-Box\")## \r\n##  Box-Ljung test\r\n## \r\n## data:  observed$resid\r\n## X-squared = 350, df = 1, p-value <2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"outbreak-detection","chapter":"23 Time series and outbreak detection","heading":"23.7 Outbreak detection","text":"demonstrate two (similar) methods detecting outbreaks .\r\nfirst builds sections .\r\nuse trending package fit regressions previous years, \r\npredict expect see following year. observed counts \r\nexpect, suggest outbreak.\r\nsecond method based similar principles uses surveillance package,\r\nnumber different algorithms aberration detection.CAUTION: Normally, interested current year (know counts present week). example pretending week 52 2011.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"trending-package","chapter":"23 Time series and outbreak detection","heading":"trending package","text":"method define baseline (usually 5 years data).\r\nfit regression baseline data, use predict estimates\r\nnext year.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"cut-off-date","chapter":"23 Time series and outbreak detection","heading":"Cut-off date","text":"easier define dates one place use throughout \r\nrest code.define start date (observations started) cut-date\r\n(end baseline period - period want predict starts).\r\nalso define many weeks year interest (one going \r\npredicting).","code":"\n## define start date (when observations began)\nstart_date <- min(counts$epiweek)\n\n## define a cut-off week (end of baseline, start of prediction period)\ncut_off <- yearweek(\"2010-12-31\")\n\n## get the year which want to predict for \n## add one week to cut_off (to push in to next year) and change to only have Year\npred_year <- format(cut_off + 1, format = \"%Y\") %>% \n  ## change to numeric\n  as.numeric()\n\n## find how many weeks in year of interest\nnum_weeks <- ifelse(\n  ## true/false of whether pred_year is a 53 week year\n  is_53weeks(pred_year),\n  ## if true then return 53 \n  53, \n  ## otherwise return 52\n  52)"},{"path":"time-series-and-outbreak-detection.html","id":"fourier-terms-1","chapter":"23 Time series and outbreak detection","heading":"23.7.0.1 Fourier terms","text":"need redefine fourier terms - want fit baseline\r\ndate predict (extrapolate) terms next year.\r\nneed combine two output lists fourier() function together;\r\nfirst one baseline data, second one predicts \r\nyear interest (defining h argument).N.b. bind rows use rbind() (rather tidyverse bind_rows) \r\nfourier columns list (named individually).","code":"\n## define fourier terms (sincos) \ncounts <- counts %>% \n  mutate(\n    ## combine fourier terms for weeks prior to  and after 2010 cut-off date\n    ## (nb. 2011 fourier terms are predicted)\n    fourier = rbind(\n      ## get fourier terms for previous years\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for 2011 (using baseline data)\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = num_weeks\n        )\n      )\n    )"},{"path":"time-series-and-outbreak-detection.html","id":"split-data-and-fit-regression","chapter":"23 Time series and outbreak detection","heading":"Split data and fit regression","text":"now split dataset baseline period prediction\r\nperiod. done using dplyr group_split() function group_by(),\r\ncreate list two data frames, one cut-one\r\n.use purrr package pluck() function pull datasets \r\nlist (equivalent using square brackets, e.g. dat[[1]]), can fit\r\nmodel baseline data, use predict() function data\r\ninterest cut-.See page [Iteration] learn purrr.previously, can visualise model ggplot. highlight alerts \r\nred dots observed counts 95% prediction interval.\r\ntime also add vertical line label forecast starts.","code":"\n# split data for fitting and prediction\ndat <- counts %>% \n  group_by(epiweek <= cut_off) %>%\n  group_split()\n\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier\n)\n\n# define which data to use for fitting and which for predicting\nfitting_data <- pluck(dat, 2)\npred_data <- pluck(dat, 1) %>% \n  select(case_int, epiweek, fourier)\n\n# fit model \nfitted_model <- trending::fit(model, fitting_data)\n\n# get confint and estimates for fitted data\nobserved <- fitted_model %>% \n  predict()\n\n# forecast with data want to predict with \nforecasts <- fitted_model %>% \n  predict(pred_data)\n\n## combine baseline and predicted datasets\nobserved <- bind_rows(observed, forecasts)\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## plot in points for the observed counts above expected\n  geom_point(\n    data = filter(observed, case_int > upper_pi), \n    aes(y = case_int), \n    colour = \"red\", \n    size = 2) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"prediction-validation","chapter":"23 Time series and outbreak detection","heading":"Prediction validation","text":"Beyond inspecting residuals, important investigate good model \r\npredicting cases future. gives idea reliable \r\nthreshold alerts .traditional way validating see well can predict latest\r\nyear present one (don’t yet know counts “current year”).\r\nexample data set use data 2002 2009 predict 2010,\r\nsee accurate predictions . refit model include\r\n2010 data use predict 2011 counts.can seen figure Hyndman et al “Forecasting principles\r\npractice”.downside using data available , \r\nfinal model using prediction.alternative use method called cross-validation. scenario \r\nroll data available fit multiple models predict one year ahead.\r\nuse data model, seen figure \r\nHyndman et al text.\r\nexample, first model uses 2002 predict 2003, second uses 2002 \r\n2003 predict 2004, .\r\nuse purrr package map() function loop dataset.\r\nput estimates one data set merge original case counts,\r\nuse yardstick package compute measures accuracy.\r\ncompute four measures including: Root mean squared error (RMSE), Mean absolute error\r\n(MAE), Mean absolute scaled error (MASE), Mean absolute percent error (MAPE).","code":"\n## Cross validation: predicting week(s) ahead based on sliding window\n\n## expand your data by rolling over in 52 week windows (before + after) \n## to predict 52 week ahead\n## (creates longer and longer chains of observations - keeps older data)\n\n## define window want to roll over\nroll_window <- 52\n\n## define weeks ahead want to predict \nweeks_ahead <- 52\n\n## create a data set of repeating, increasingly long data\n## label each data set with a unique id\n## only use cases before year of interest (i.e. 2011)\ncase_roll <- counts %>% \n  filter(epiweek < cut_off) %>% \n  ## only keep the week and case counts variables\n  select(epiweek, case_int) %>% \n    ## drop the last x observations \n    ## depending on how many weeks ahead forecasting \n    ## (otherwise will be an actual forecast to \"unknown\")\n    slice(1:(n() - weeks_ahead)) %>%\n    as_tsibble(index = epiweek) %>% \n    ## roll over each week in x after windows to create grouping ID \n    ## depending on what rolling window specify\n    stretch_tsibble(.init = roll_window, .step = 1) %>% \n  ## drop the first couple - as have no \"before\" cases\n  filter(.id > roll_window)\n\n\n## for each of the unique data sets run the code below\nforecasts <- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## only keep the current fold being fit \n  mini_data <- filter(case_roll, .id == i) %>% \n    as_tibble()\n  \n  ## create an empty data set for forecasting on \n  forecast_data <- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## add the forecast data to the original \n  mini_data <- bind_rows(mini_data, forecast_data)\n  \n  ## define the cut off based on latest non missing count data \n  cv_cut_off <- mini_data %>% \n    ## only keep non-missing rows\n    filter(!is.na(case_int)) %>% \n    ## get the latest week\n    summarise(max(epiweek)) %>% \n    ## extract so is not in a dataframe\n    pull()\n  \n  ## make mini_data back in to a tsibble\n  mini_data <- tsibble(mini_data, index = epiweek)\n  \n  ## define fourier terms (sincos) \n  mini_data <- mini_data %>% \n    mutate(\n    ## combine fourier terms for weeks prior to  and after cut-off date\n    fourier = rbind(\n      ## get fourier terms for previous years\n      forecast::fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for following year (using baseline data)\n      fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # split data for fitting and prediction\n  dat <- mini_data %>% \n    group_by(epiweek <= cv_cut_off) %>%\n    group_split()\n\n  ## define the model you want to fit (negative binomial) \n  model <- glm_nb_model(\n    ## set number of cases as outcome of interest\n    case_int ~\n      ## use epiweek to account for the trend\n      epiweek +\n      ## use the furier terms to account for seasonality\n      fourier\n  )\n\n  # define which data to use for fitting and which for predicting\n  fitting_data <- pluck(dat, 2)\n  pred_data <- pluck(dat, 1)\n  \n  # fit model \n  fitted_model <- trending::fit(model, fitting_data)\n  \n  # forecast with data want to predict with \n  forecasts <- fitted_model %>% \n    predict(pred_data) %>% \n    ## only keep the week and the forecast estimate\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## make the list in to a data frame with all the forecasts\nforecasts <- bind_rows(forecasts)\n\n## join the forecasts with the observed\nforecasts <- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## using {yardstick} compute metrics\n  ## RMSE: Root mean squared error\n  ## MAE:  Mean absolute error  \n  ## MASE: Mean absolute scaled error\n  ## MAPE: Mean absolute percent error\nmodel_metrics <- bind_rows(\n  ## in your forcasted dataset compare the observed to the predicted\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %>% \n  ## only keep the metric type and its output\n  select(Metric  = .metric, \n         Measure = .estimate) %>% \n  ## make in to wide format so can bind rows after\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## return model metrics \nmodel_metrics## # A tibble: 1 x 4\r\n##    rmse   mae  mase  mape\r\n##   <dbl> <dbl> <dbl> <dbl>\r\n## 1  252.  199.  1.96  17.3"},{"path":"time-series-and-outbreak-detection.html","id":"surveillance-package","chapter":"23 Time series and outbreak detection","heading":"surveillance package","text":"section use surveillance package create alert thresholds\r\nbased outbreak detection algorithms. several different methods\r\navailable package, however focus two options .\r\ndetails, see papers application\r\ntheory\r\nalogirthms used.first option uses improved Farrington method. fits negative\r\nbinomial glm (including trend) -weights past outbreaks (outliers) \r\ncreate threshold level.second option use glrnb method. also fits negative binomial glm\r\nincludes trend fourier terms (favoured ). regression used\r\ncalculate “control mean” (~fitted values) - uses computed\r\ngeneralized likelihood ratio statistic assess shift mean\r\nweek. Note threshold week takes account previous\r\nweeks sustained shift alarm triggered.\r\n(Also note alarm algorithm reset)order work surveillance package, first need define \r\n“surveillance time series” object (using sts() function) fit within \r\nframework.","code":"\n## define surveillance time series object\n## nb. you can include a denominator with the population object (see ?sts)\ncounts_sts <- sts(observed = counts$case_int,\n                  start = c(\n                    ## subset to only keep the year from start_date \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## subset to only keep the week from start_date\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## define the type of data (in this case weekly)\n                  freq = 52)\n\n## define the week range that you want to include (ie. prediction period)\n## nb. the sts object only counts observations without assigning a week or \n## year identifier to them - so we use our data to define the appropriate observations\nweekrange <- cut_off - start_date"},{"path":"time-series-and-outbreak-detection.html","id":"farrington-method","chapter":"23 Time series and outbreak detection","heading":"Farrington method","text":"define parameters Farrington method list.\r\nrun algorithm using farringtonFlexible() can extract \r\nthreshold alert using farringtonmethod@upperboundto include \r\ndataset. also possible extract TRUE/FALSE week triggered\r\nalert (threshold) using farringtonmethod@alarm.can visualise results ggplot done previously.","code":"\n## define control\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  b = 9, ## how many years backwards for baseline\n  w = 2, ## rolling window size in weeks\n  weightsThreshold = 2.58, ## reweighting past outbreaks (improved noufaily method - original suggests 1)\n  ## pastWeeksNotIncluded = 3, ## use all weeks available (noufaily suggests drop 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normally, however 1 is advised in the improved method (i.e. always keep)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## apply farrington flexible method\nfarringtonmethod <- farringtonFlexible(counts_sts, ctrl)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from farrington \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off),\n              \"threshold\"] <- farringtonmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series-and-outbreak-detection.html","id":"glrnb-method","chapter":"23 Time series and outbreak detection","heading":"GLRNB method","text":"Similarly GLRNB method define parameters list,\r\nfit algorithm extract upper bounds.CAUTION: method uses “brute force” (similar bootstrapping) calculating thresholds, can take long time!See GLRNB vignette\r\ndetails.Visualise outputs previously.","code":"\n## define control options\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2020)\n  range = which(counts_sts@epoch > weekrange),\n  mu0 = list(S = 1,    ## number of fourier terms (harmonics) to include\n  trend = TRUE,   ## whether to include trend or not\n  refit = FALSE), ## whether to refit model after each alarm\n  ## cARL = threshold for GLR statistic (arbitrary)\n     ## 3 ~ middle ground for minimising false positives\n     ## 1 fits to the 99%PI of glm.nb - with changes after peaks (threshold lowered for alert)\n   c.ARL = 2,\n   # theta = log(1.5), ## equates to a 50% increase in cases in an outbreak\n   ret = \"cases\"     ## return threshold upperbound as case counts\n  )\n\n## apply the glrnb method\nglrnbmethod <- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from glrnb \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off),\n              \"threshold_glrnb\"] <- glrnbmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold_glrnb, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series-and-outbreak-detection.html","id":"interrupted-timeseries","chapter":"23 Time series and outbreak detection","heading":"23.8 Interrupted timeseries","text":"Interrupted timeseries (also called segmented regression intervention analysis),\r\noften used assessing impact vaccines incidence disease.\r\ncan used assessing impact wide range interventions introductions.\r\nexample changes hospital procedures introduction new disease\r\nstrain population.\r\nexample pretend new strain Campylobacter introduced\r\nGermany end 2008, see affects number cases.\r\nuse negative binomial regression . regression time \r\nsplit two parts, one intervention (introduction new strain )\r\none (pre post-periods). allows us calculate incidence rate ratio comparing \r\ntwo time periods. Explaining equation might make clearer (just\r\nignore!).negative binomial regression can defined follows:\\[\\log(Y_t)= β_0 + β_1 \\times t+ β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]:\r\n\\(Y_t\\)number cases observed time \\(t\\)\\(pop_t\\) population size 100,000s time \\(t\\) (used )\\(t_0\\) last year pre-period (including transition time )\\(δ(x\\) indicator function (0 x≤0 1 x>0)\\((x)^+\\) cut operator (x x>0 0 otherwise)\\(e_t\\) denotes residual\r\nAdditional terms trend season can added needed.\\(β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+\\) generalised linear\r\npart post-period zero pre-period.\r\nmeans \\(β_2\\) \\(β_3\\) estimates effects intervention.need re-calculate fourier terms without forecasting , use\r\ndata available us (.e. retrospectively). Additionally need calculate\r\nextra terms needed regression.use terms fit negative binomial regression, produce \r\ntable percentage change. example shows \r\nsignificant change.previously can visualise outputs regression.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  as_tsibble(index = epiweek) %>% \n  fourier(K = 1)\n\n## define intervention week \nintervention_week <- yearweek(\"2008-12-31\")\n\n## define variables for regression \ncounts <- counts %>% \n  mutate(\n    ## corresponds to t in the formula\n      ## count of weeks (could probably also just use straight epiweeks var)\n    # linear = row_number(epiweek), \n    ## corresponds to delta(t-t0) in the formula\n      ## pre or post intervention period\n    intervention = as.numeric(epiweek >= intervention_week), \n    ## corresponds to (t-t0)^+ in the formula\n      ## count of weeks post intervention\n      ## (choose the larger number between 0 and whatever comes from calculation)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier + \n    ## add in whether in the pre- or post-period \n    intervention + \n    ## add in the time post intervention \n    time_post\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model)\n\n\n\n## show estimates and percentage change in a table\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %>% \n  ## only keep the intervention value \n  filter(term == \"intervention\") %>% \n  ## change the IRR to percentage change for estimate and CIs \n  mutate(\n    ## for each of the columns of interest - create a new column\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## apply the formula to calculate percentage change\n            .f = function(i) 100 * (i - 1), \n      ## add a suffix to new column names with \"_perc\"\n      .names = \"{.col}_perc\")\n    ) %>% \n  ## only keep (and rename) certain columns \n  select(\"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Percentage change\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)## # A tibble: 1 x 7\r\n##     IRR `95%CI low` `95%CI high` `Percentage change` `95%CI low (perc)` `95%CI high (perc)` `p-value`\r\n##   <dbl>       <dbl>        <dbl>               <dbl>              <dbl>               <dbl>     <dbl>\r\n## 1 0.958       0.896         1.03               -4.17              -10.4                2.53     0.220\nggplot(observed, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"resources-16","chapter":"23 Time series and outbreak detection","heading":"23.9 Resources","text":"forecasting: principles practice textbookEPIET timeseries analysis case studiesPenn State course\r\nSurveillance package manuscript","code":""},{"path":"epidemic-modeling.html","id":"epidemic-modeling","chapter":"24 Epidemic modeling","heading":"24 Epidemic modeling","text":"","code":""},{"path":"epidemic-modeling.html","id":"overview-8","chapter":"24 Epidemic modeling","heading":"24.1 Overview","text":"exists growing body tools epidemic modelling lets us conduct\r\nfairly complex analyses minimal effort. section provide \r\noverview use tools :estimate effective reproduction number Rt related statistics\r\ndoubling timeproduce short-term projections future incidenceIt intended overview methodologies statistical methods\r\nunderlying tools, please refer Resources tab links \r\npapers covering . Make sure understanding \r\nmethods using tools; ensure can accurately\r\ninterpret results.example one outputs ’ll producing section.","code":""},{"path":"epidemic-modeling.html","id":"preparation-15","chapter":"24 Epidemic modeling","heading":"24.2 Preparation","text":"use two different methods packages Rt estimation,\r\nnamely EpiNow EpiEstim, well projections package \r\nforecasting case incidence.code chunk shows loading packages required analyses.\r\nhandbook emphasize p_load() pacman, installs package necessary loads use.\r\ncan also load packages library() base R. See page R basics information R packages.use standard, cleaned linelist analyses section. want download data follow step--step, see instructions Download book data page.","code":"\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   epicontacts,  # Analysing transmission networks\n   EpiNow2,      # Rt estimation\n   EpiEstim,     # Rt estimation\n   projections,  # Incidence projections\n   incidence2,   # Handling incidence data\n   epitrix,      # Useful epi functions\n   distcrete     # Discrete delay distributions\n)\n# import the cleaned linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"epidemic-modeling.html","id":"estimating-rt","chapter":"24 Epidemic modeling","heading":"24.3 Estimating Rt","text":"","code":""},{"path":"epidemic-modeling.html","id":"epinow2-vs.-epiestim","chapter":"24 Epidemic modeling","heading":"EpiNow2 vs. EpiEstim","text":"reproduction number R measure transmissibility disease \r\ndefined expected number secondary cases per infected case. \r\nfully susceptible population, value represents basic reproduction\r\nnumber R0. However, number susceptible individuals \r\npopulation changes course outbreak pandemic, various\r\nresponse measures implemented, commonly used measure \r\ntransmissibility effective reproduction number Rt; \r\ndefined expected number secondary cases per infected case given\r\ntime t.EpiNow2 package provides sophisticated framework estimating\r\nRt. two key advantages commonly used package,\r\nEpiEstim:accounts delays reporting can therefore estimate Rt\r\neven recent data incomplete.estimates Rt dates infection rather dates \r\nonset reporting, means effect intervention \r\nimmediately reflected change Rt, rather \r\ndelay.However, also two key disadvantages:requires knowledge generation time distribution (.e. distribution\r\ndelays infection primary secondary cases), incubation\r\nperiod distribution (.e. distribution delays infection symptom\r\nonset) delay distribution relevant data (e.g. \r\ndates reporting, require distribution delays symptom\r\nonset reporting). allow accurate estimation \r\nRt, EpiEstim requires serial interval distribution\r\n(.e. distribution delays symptom onset primary \r\nsecondary case), may distribution available .EpiNow2 significantly slower EpiEstim, anecdotally factor\r\n100-1000! example, estimating Rt sample outbreak\r\nconsidered section takes four hours (run large\r\nnumber iterations ensure high accuracy probably reduced \r\nnecessary, however points stands algorithm slow \r\ngeneral). may unfeasible regularly updating \r\nRt estimates.package choose use therefore depend data, time \r\ncomputational resources available .","code":""},{"path":"epidemic-modeling.html","id":"epinow2","chapter":"24 Epidemic modeling","heading":"EpiNow2","text":"","code":""},{"path":"epidemic-modeling.html","id":"estimating-delay-distributions","chapter":"24 Epidemic modeling","heading":"Estimating delay distributions","text":"delay distributions required run EpiNow2 depend data \r\n. Essentially, need able describe delay date \r\ninfection date event want use estimate Rt. \r\nusing dates onset, simply incubation period\r\ndistribution. using dates reporting, require \r\ndelay infection reporting. distribution unlikely known\r\ndirectly, EpiNow2 lets chain multiple delay distributions together; \r\ncase, delay infection symptom onset (e.g. incubation\r\nperiod, likely known) symptom onset reporting (\r\ncan often estimate data).dates onset cases example linelist, \r\nrequire incubation period distribution link data (e.g. dates \r\nsymptom onset) date infection. can either estimate distribution\r\ndata use values literature.literature estimate incubation period Ebola (taken\r\npaper) \r\nmean 9.1, standard deviation 7.3 maximum value 30 \r\nspecified follows:Note EpiNow2 requires delay distributions provided log\r\nscale, hence log call around value (except max parameter ,\r\nconfusingly, provided natural scale). mean_sd sd_sd\r\ndefine standard deviation mean standard deviation estimates. \r\nknown case, choose fairly arbitrary value 0.1.analysis, instead estimate incubation period distribution\r\nlinelist using function bootstrapped_dist_fit, \r\nfit lognormal distribution observed delays infection onset\r\nlinelist.distribution require generation time. data \r\ninfection times transmission links, can estimate \r\ndistribution linelist calculating delay infection times\r\ninfector-infectee pairs. , use handy get_pairwise function\r\npackage epicontacts, allows us calculate pairwise\r\ndifferences linelist properties transmission pairs. first create \r\nepicontacts object (see Transmission chains page \r\ndetails):fit difference infection times transmission pairs,\r\ncalculated using get_pairwise, gamma distribution:","code":"\nincubation_period_lit <- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n## estimate incubation period\nincubation_period <- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma generation time\ngeneration_time <- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)"},{"path":"epidemic-modeling.html","id":"running-epinow2","chapter":"24 Epidemic modeling","heading":"Running EpiNow2","text":"Now just need calculate daily incidence linelist, can \r\neasily dplyr functions group_by() n(). Note\r\nEpiNow2 requires column names date confirm.can estimate Rt using epinow function. notes \r\ninputs:can provide number ‘chained’ delay distributions delays\r\nargument; simply insert alongside incubation_period object\r\nwithin delay_opts function.return_output ensures output returned within R just saved \r\nfile.verbose specifies want readout progress.horizon indicates many days want project future incidence .pass additional options stan argument specify long\r\nwant run inference . Increasing samples chains give\r\naccurate estimate better characterises uncertainty, however\r\ntake longer run.","code":"\n## get incidence from onset dates\ncases <- linelist %>%\n  group_by(date = date_onset) %>%\n  summarise(confirm = n())\n## run epinow\nepinow_res <- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)"},{"path":"epidemic-modeling.html","id":"analysing-outputs","chapter":"24 Epidemic modeling","heading":"Analysing outputs","text":"code finished running, can plot summary easily follows:can also look various summary statistics:analyses custom plotting, can access summarised daily\r\nestimates via $estimates$summarised. convert default\r\ndata.table tibble ease use dplyr.example, let’s make plot doubling time Rt. \r\nlook first months outbreak Rt well\r\none, avoid plotting extremely high doublings times.use formula log(2)/growth_rate calculate doubling time \r\nestimated growth rate.","code":"\n## plot summary figure\nplot(epinow_res)\n## summary table\nepinow_res$summary##                                  measure                  estimate  numeric_estimate\r\n## 1: New confirmed cases by infection date                4 (2 -- 6) <data.table[1x9]>\r\n## 2:        Expected change in daily cases                    Unsure              0.56\r\n## 3:            Effective reproduction no.        0.88 (0.73 -- 1.1) <data.table[1x9]>\r\n## 4:                        Rate of growth -0.012 (-0.028 -- 0.0052) <data.table[1x9]>\r\n## 5:          Doubling/halving time (days)          -60 (130 -- -25) <data.table[1x9]>\n## extract summary and convert to tibble\nestimates <- as_tibble(epinow_res$estimates$summarised)\nestimates\n## make wide df for median plotting\ndf_wide <- estimates %>%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date < as.Date(\"2014-09-01\")\n  ) %>%\n  ## convert growth rates to doubling times\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## rename variable to reflect transformation\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## make long df for quantile plotting\ndf_long <- df_wide %>%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credibel\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic-modeling.html","id":"epiestim","chapter":"24 Epidemic modeling","heading":"EpiEstim","text":"run EpiEstim, need provide data daily incidence specify \r\nserial interval (.e. distribution delays symptom onset \r\nprimary secondary cases).Incidence data can provided vector, dataframe incidence\r\nobject incidence2 package, can even distinguish imports\r\nlocally acquired infections; see documentation ?estimate_R \r\ndetails.create incidence object. See page Epidemic curves examples incidence package. incidence object consists tibble dates respective case counts. use complete() ensure dates included (even cases), rename() columns expected estimate_R() later step.package provides several options specifying serial interval, \r\ndetails provided documentation ?estimate_R. \r\ncover two .","code":"\n## get incidence from onset date\ncases <- incidence2::incidence(linelist, date_index = date_onset) %>% \n  rename(I = count,\n         dates = date)## 256 missing observations were removed."},{"path":"epidemic-modeling.html","id":"using-serial-interval-estimates-from-the-literature","chapter":"24 Epidemic modeling","heading":"Using serial interval estimates from the literature","text":"Using option method = \"parametric_si\", can manually specify mean \r\nstandard deviation serial interval config object created using \r\nfunction make_config. use mean standard deviation 12.0 5.2, respectively, defined \r\npaper:can estimate Rt estimate_R function:plot summary outputs:","code":"\n## make config\nconfig_lit <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\nepiestim_res_lit <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_lit\n)## Default config will estimate R on weekly sliding windows.\r\n##     To change this change the t_start and t_end arguments.\nplot(epiestim_res_lit)"},{"path":"epidemic-modeling.html","id":"using-serial-interval-estimates-from-the-data","chapter":"24 Epidemic modeling","heading":"Using serial interval estimates from the data","text":"data dates symptom onset transmission links, can\r\nalso estimate serial interval linelist calculating delay\r\nonset dates infector-infectee pairs. EpiNow2\r\nsection, use get_pairwise function epicontacts\r\npackage, allows us calculate pairwise differences linelist\r\nproperties transmission pairs. first create epicontacts object\r\n(see Transmission chains page details):fit difference onset dates transmission pairs, calculated\r\nusing get_pairwise, gamma distribution. use handy fit_disc_gamma\r\nepitrix package fitting procedure, require \r\ndiscretised distribution.pass information config object, run EpiEstim\r\nplot results:","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma serial interval\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n## make config\nconfig_emp <- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## run epiestim\nepiestim_res_emp <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_emp\n)## Default config will estimate R on weekly sliding windows.\r\n##     To change this change the t_start and t_end arguments.\n## plot outputs\nplot(epiestim_res_emp)"},{"path":"epidemic-modeling.html","id":"specifying-estimation-time-windows","chapter":"24 Epidemic modeling","heading":"Specifying estimation time windows","text":"default options provide weekly sliding estimate might act \r\nwarning estimating Rt early outbreak \r\nprecise estimate. can change setting later start date \r\nestimation shown . Unfortunately, EpiEstim provides \r\nclunky way specifying estimations times, provide \r\nvector integers referring start end dates time\r\nwindow.Now re-run EpiEstim can see estimates start June:","code":"\n## define a vector of dates starting on June 1st\nstart_dates <- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %>%\n  ## subtract the starting date to convert to numeric\n  `-`(min(cases$dates)) %>%\n  ## convert to integer\n  as.integer()\n\n## add six days for a one week sliding window\nend_dates <- start_dates + 6\n  \n## make config\nconfig_partial <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n## run epiestim\nepiestim_res_partial <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## plot outputs\nplot(epiestim_res_partial)"},{"path":"epidemic-modeling.html","id":"analysing-outputs-1","chapter":"24 Epidemic modeling","heading":"Analysing outputs","text":"main outputs can accessed via $R. example, create plot \r\nRt measure “transmission potential” given product \r\nRt number cases reported day; represents \r\nexpected number cases next generation infection.","code":"\n## make wide dataframe for median\ndf_wide <- epiestim_res_lit$R %>%\n  rename_all(clean_labels) %>%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %>%\n  mutate(\n    ## extract the median date from t_start and t_end\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %>%\n  ## merge in daily incidence data\n  left_join(cases, \"dates\") %>%\n  ## calculate risk across all r estimates\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %>%\n  ## seperate r estimates and risk estimates\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %>%\n  ## assign factor levels\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make long dataframe from quantiles\ndf_long <- df_wide %>%\n  select(-variable, -median) %>%\n  ## seperate r/risk estimates and quantile levels\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %>%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic-modeling.html","id":"projecting-incidence","chapter":"24 Epidemic modeling","heading":"24.4 Projecting incidence","text":"","code":""},{"path":"epidemic-modeling.html","id":"epinow2-1","chapter":"24 Epidemic modeling","heading":"EpiNow2","text":"Besides estimating Rt, EpiNow2 also supports forecasting \r\nRt projections case numbers integration \r\nEpiSoon package hood. need specify horizon\r\nargument epinow function call, indicating many days want \r\nproject future; see EpiNow2 section “Estimating\r\nRt” details get EpiNow2 running. \r\nsection, just plot outputs analysis, stored \r\nepinow_res object.","code":"\n## define minimum date for plot\nmin_date <- as.Date(\"2015-03-01\")\n\n## extract summarised estimates\nestimates <-  as_tibble(epinow_res$estimates$summarised)\n\n## extract raw data on case incidence\nobservations <- as_tibble(epinow_res$estimates$observations) %>%\n  filter(date > min_date)\n\n## extract forecasted estimates of case numbers\ndf_wide <- estimates %>%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date > min_date\n  )\n\n## convert to even longer format for quantile plotting\ndf_long <- df_wide %>%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14)"},{"path":"epidemic-modeling.html","id":"projections","chapter":"24 Epidemic modeling","heading":"projections","text":"projections package developed RECON makes easy make short\r\nterm incidence forecasts, requiring knowledge effective reproduction\r\nnumber Rt serial interval. cover use\r\nserial interval estimates literature use estimates\r\nlinelist.","code":""},{"path":"epidemic-modeling.html","id":"using-serial-interval-estimates-from-the-literature-1","chapter":"24 Epidemic modeling","heading":"Using serial interval estimates from the literature","text":"projections requires discretised serial interval distribution class\r\ndistcrete package distcrete. use gamma distribution\r\nmean 12.0 standard deviation 5.2 defined \r\npaper. \r\nconvert values shape scale parameters required gamma\r\ndistribution, use function gamma_mucv2shapescale \r\nepitrix package.quick check make sure serial interval looks correct. \r\naccess density gamma distribution just defined $d, \r\nequivalent calling dgamma:","code":"\n## get shape and scale parameters from the mean mu and the coefficient of\n## variation (e.g. the ratio of the standard deviation to the mean)\nshapescale <- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## make distcrete object\nserial_interval_lit <- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n## check to make sure the serial interval looks correct\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)"},{"path":"epidemic-modeling.html","id":"using-serial-interval-estimates-from-the-data-1","chapter":"24 Epidemic modeling","heading":"Using serial interval estimates from the data","text":"data dates symptom onset transmission links, can\r\nalso estimate serial interval linelist calculating delay\r\nonset dates infector-infectee pairs. EpiNow2\r\nsection, use get_pairwise function epicontacts\r\npackage, allows us calculate pairwise differences linelist\r\nproperties transmission pairs. first create epicontacts object\r\n(see Transmission chains page details):fit difference onset dates transmission pairs, calculated\r\nusing get_pairwise, gamma distribution. use handy fit_disc_gamma\r\nepitrix package fitting procedure, require \r\ndiscretised distribution.","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma serial interval\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## inspect estimate\nserial_interval[c(\"mu\", \"sd\")]## $mu\r\n## [1] 11.5\r\n## \r\n## $sd\r\n## [1] 7.7"},{"path":"epidemic-modeling.html","id":"projecting-incidence-1","chapter":"24 Epidemic modeling","heading":"Projecting incidence","text":"project future incidence, still need provide historical incidence \r\nform incidence object, well sample plausible\r\nRt values. generate values using Rt\r\nestimates generated EpiEstim previous section (“Estimating\r\nRt”) stored epiestim_res_emp object. code ,\r\nextract mean standard deviation estimates Rt \r\nlast time window outbreak (using tail function access last\r\nelement vector), simulate 1000 values gamma distribution using\r\nrgamma. can also provide vector Rt values \r\nwant use forward projections.use project() function make actual forecast. specify \r\nmany days want project via n_days arguments, specify \r\nnumber simulations using n_sim argument.can handily plot incidence projections using plot() \r\nadd_projections() functions. can easily subset incidence object \r\nshow recent cases using square bracket operator.can also easily extract raw estimates daily case numbers \r\nconverting output dataframe.","code":"\n## create incidence object from dates of onset\ninc <- incidence::incidence(linelist$date_onset)## 256 missing observations were removed.\n## extract plausible r values from most recent estimate\nmean_r <- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r <- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale <- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r <- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## check distribution\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n## make projection\nproj <- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n## plot incidence and projections\nplot(inc[inc$dates > as.Date(\"2015-03-01\")]) %>%\n  add_projections(proj)## Scale for 'x' is already present. Adding another scale for 'x', which will replace the existing scale.\n## convert to data frame for raw data\nproj_df <- as.data.frame(proj)\nproj_df"},{"path":"epidemic-modeling.html","id":"resources-17","chapter":"24 Epidemic modeling","heading":"24.5 Resources","text":"paper describing\r\nmethodology implemented EpiEstim.paper describing\r\nmethodology implemented EpiNow2.paper describing\r\nvarious methodological practical considerations estimating Rt.","code":""},{"path":"survey-analysis.html","id":"survey-analysis","chapter":"25 Survey analysis","heading":"25 Survey analysis","text":"PAGE CONSTRUCTION","code":""},{"path":"survey-analysis.html","id":"overview-9","chapter":"25 Survey analysis","heading":"25.1 Overview","text":"","code":""},{"path":"survey-analysis.html","id":"preparation-16","chapter":"25 Survey analysis","heading":"25.2 Preparation","text":"","code":""},{"path":"survey-analysis.html","id":"weighting","chapter":"25 Survey analysis","heading":"25.3 Weighting","text":"","code":""},{"path":"survey-analysis.html","id":"random-selection","chapter":"25 Survey analysis","heading":"25.4 Random selection","text":"","code":""},{"path":"survey-analysis.html","id":"resources-18","chapter":"25 Survey analysis","heading":"25.5 Resources","text":"","code":""},{"path":"survival-analysis.html","id":"survival-analysis","chapter":"26 Survival analysis","heading":"26 Survival analysis","text":"","code":""},{"path":"survival-analysis.html","id":"overview-10","chapter":"26 Survival analysis","heading":"26.1 Overview","text":"Survival analysis focuses describing given individual group individuals, defined point event called failure (occurrence disease, cure disease, death, relapse response treatment…) occurs period time called failure time (follow-time cohort/population-based studies) individuals observed. determine failure time, necessary define time origin (can inclusion date, date diagnosis…).target inference survival analysis time origin event.\r\ncurrent medical research, widely used clinical studies assess effect treatment instance, cancer epidemiology assess large variety cancer survival measures.usually expressed survival probability probability event interest occurred duration t.Censoring: Censoring occurs end follow-, individuals event interest, thus true time event unknown. mostly focus right censoring details censoring survival analysis general, can see references.","code":""},{"path":"survival-analysis.html","id":"preparation-17","chapter":"26 Survival analysis","heading":"26.2 Preparation","text":"","code":""},{"path":"survival-analysis.html","id":"load-packages-15","chapter":"26 Survival analysis","heading":"Load packages","text":"run survival analyses R, one widely used package survival package. first install load well packages used section:handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.page explores survival analyses using linelist used previous pages apply changes proper survival data.","code":""},{"path":"survival-analysis.html","id":"import-dataset","chapter":"26 Survival analysis","heading":"Import dataset","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.","code":"\n# import linelist\nlinelist_case_data <- rio::import(\"linelist_cleaned.xlsx\")"},{"path":"survival-analysis.html","id":"data-management-and-transformation","chapter":"26 Survival analysis","heading":"Data management and transformation","text":"short, survival data can described following three characteristics:dependent variable response waiting time occurrence well-defined event,observations censored, sense units event interest occurred time data analyzed, andthere predictors explanatory variables whose effect waiting time wish assess control.Thus, create different variables needed respect structure run survival analysis.define:event interest “death” (hence survival probability probability alive certain time time origin),follow-time (futime) time time onset time outcome days,censored patients recovered final outcome known ie event “death” observed (event=0).CAUTION: Since real cohort study, information time origin end follow-known given individuals observed, remove observations date onset date outcome unknown. Also cases date onset later date outcome removed since considered wrong.TIP: Given filtering greater (>) less (<) date can remove rows missing values, applying filter wrong dates also remove rows missing dates.create var age_cat another variable age_cat_small indicates reduces categories age groups 3.TIP: can verify new variables created summary futime cross-tabulation event outcome created. Besides verification good habit communicating median follow-time interpreting survival analysis results.can also cross-tabule variable age_cat_small gender details distribution new variable among gender groups. use stat.table() function Epi package.","code":"\n#create a new data called linelist_surv from the linelist_case_data\n\nlinelist_surv <-  linelist_case_data %>% \n     \n  dplyr::filter(\n       # remove observations with wrong or missing dates of onset or date of outcome\n       date_outcome > date_onset) %>% \n  \n  dplyr::mutate(\n       # create the event var which is 1 if the patient died and 0 if he was right censored\n       event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n    \n       # create the var on the follow-up time in days\n       futime = as.double(date_outcome - date_onset), \n    \n       # create a new age category variable with only 3 strata levels\n       age_cat_small = dplyr::case_when( \n            age_years < 5  ~ \"0-4\",\n            age_years >= 5 & age_years < 20 ~ \"5-19\",\n            age_years >= 20   ~ \"20+\"),\n       \n       # previous step created age_cat_small var as character.\n       # now convert it to factor and specify the levels.\n       # Note that the NA values remain NA's and are not put in a level \"unknown\" for example,\n       # since in the next analyses they have to be removed.\n       age_cat_small = factor(age_cat_small,\n                              levels = c(\"0-4\", \"5-19\", \"20+\")))\nsummary(linelist_surv$futime)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n##       1       6      10      12      16      64\n# cross tabulate the new event var and the outcome var from which it was created\n# to make sure the code did what it was intended to\nwith(linelist_surv, \n     table(outcome, event, useNA = \"ifany\")\n     )##          event\r\n## outcome      0    1\r\n##   Death      0 1952\r\n##   Recover 1547    0\r\n##   <NA>    1040    0\n# cross tabulate the new age_cat_small var and the age_cat var from which it was created,\n# to make sure the code did what it was intended to\n\nwith(linelist_surv, \n     table(age_cat_small, age_cat, useNA = \"ifany\")\n     ) ##              age_cat\r\n## age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ <NA>\r\n##          0-4  834   0     0     0     0     0     0   0    0\r\n##          5-19   0 852   717   575     0     0     0   0    0\r\n##          20+    0   0     0     0   862   554    69   5    0\r\n##          <NA>   0   0     0     0     0     0     0   0   71\n# print the 10 first observations of the linelist_surv data looking at specific variables (including those newly created)\n\nhead(linelist_surv[,c(\"case_id\", \"age_cat_small\", \"date_onset\",\"date_outcome\",\"outcome\",\"event\",\"futime\")], 10)##    case_id age_cat_small date_onset date_outcome outcome event futime\r\n## 1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\r\n## 2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\r\n## 3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\r\n## 4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\r\n## 5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\r\n## 6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\r\n## 7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\r\n## 8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\r\n## 9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\r\n## 10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\nEpi::stat.table( \n  #give variables for the cross tabulation\n  list(\n    gender, \n    age_cat_small\n    ),\n  \n  #precise the function you want to call (mean,count..)\n  list( \n    count(),\n    percent(age_cat_small)\n    ), \n  \n  #add margins\n  margins=T, \n  \n  #data used\n  data = linelist_surv \n  )##  ----------------------------------------- \r\n##          ----------age_cat_small---------- \r\n##  gender       0-4    5-19     20+   Total  \r\n##  ----------------------------------------- \r\n##  f            482    1184     490    2156  \r\n##              22.4    54.9    22.7   100.0  \r\n##                                            \r\n##  m            325     880     960    2165  \r\n##              15.0    40.6    44.3   100.0  \r\n##                                            \r\n##                                            \r\n##  Total        834    2144    1490    4539  \r\n##              18.7    48.0    33.3   100.0  \r\n##  -----------------------------------------"},{"path":"survival-analysis.html","id":"basics-of-survival-analysis","chapter":"26 Survival analysis","heading":"26.3 Basics of survival analysis","text":"","code":""},{"path":"survival-analysis.html","id":"building-a-surv-type-object","chapter":"26 Survival analysis","heading":"Building a surv-type object","text":"first use Surv() build standard survival object form follow-time event variables.result step produce object type survival focuses time information precising whether event interest (death) observed. done using “+” time print survobj indicates right-censoring.","code":"\nsurvobj <- with(linelist_surv, \n                \n                survival::Surv(futime, event)\n                \n                )\n\n#print the 50 first elements of the vector to see how it presents\nhead(survobj,50)##  [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+ 12+ 22+  9+  2+ 11   6  11+  5+ 12+ 13   6+  2   8   3+  6  13+  4   9  28+ 14+  4  37+  6+  9+  7  43+\r\n## [37]  2   4   5+ 13   6+ 19+ 20+  9   7  32+  6   4  19+ 15+"},{"path":"survival-analysis.html","id":"running-initial-analyses","chapter":"26 Survival analysis","heading":"Running initial analyses","text":"start analysis using survfit() function produce survfit object, fits default calculations Kaplan Meier (KM) estimates overall (marginal) survival curve, fact step function jumps observed event times. final survfit object contains one survival curvesis created using Surv object response variable model formul.NOTE: Kaplan-Meier estimate nonparametric maximum likelihood estimate (MLE) survival function. . (see resources information).summary survfit object give called life table contains:time follow-(time) event happened ascending ordered,number people risk developing event (people event yet censored: n.risk),develop (n.event),, probability developing event (probability dying surviving past specific time ).Finally standard error confidence interval probability derived.using summary() can add option times precise specific times want see survival informationWe can also use print() function. print.rmean=TRUE argument used obtain mean survival time standard error (se).NOTE: restricted mean survival time (RMST) specific survival measure used cancer survival analysis often defined area survival curve given observe patients restricted time T: details resourcesTIP: can create surv object directly survfit() function save line code. give linelistsurv_quick <-  survfit(Surv(futime, event) ~ 1, data=linelist_surv). seen, case precise data variables time event taken .Besides summary() function, can also use str() function gives details structure survfit() object. Among details important one: cumhaz allows instance plot cumulative hazard, hazard instantaneous rate event occurrence (see references).","code":"\n#fit the KM estimates using the formula where the previously Surv object \"survobj\" is the response variable. \"~ 1\" precises we run the model for the overall survival.\n\nlinelistsurv_fit <-  survival::survfit(\n  survobj ~ 1\n  )\n\n#print its summary for more details\nsummary(linelistsurv_fit)## Call: survfit(formula = survobj ~ 1)\r\n## \r\n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\r\n##     1   4539      30    0.993 0.00120        0.991        0.996\r\n##     2   4500      69    0.978 0.00217        0.974        0.982\r\n##     3   4394     149    0.945 0.00340        0.938        0.952\r\n##     4   4176     194    0.901 0.00447        0.892        0.910\r\n##     5   3899     214    0.852 0.00535        0.841        0.862\r\n##     6   3592     210    0.802 0.00604        0.790        0.814\r\n##     7   3223     179    0.757 0.00656        0.745        0.770\r\n##     8   2899     167    0.714 0.00700        0.700        0.728\r\n##     9   2593     145    0.674 0.00735        0.660        0.688\r\n##    10   2311     109    0.642 0.00761        0.627        0.657\r\n##    11   2081     119    0.605 0.00788        0.590        0.621\r\n##    12   1843      89    0.576 0.00809        0.560        0.592\r\n##    13   1608      55    0.556 0.00823        0.540        0.573\r\n##    14   1448      43    0.540 0.00837        0.524        0.556\r\n##    15   1296      31    0.527 0.00848        0.511        0.544\r\n##    16   1152      48    0.505 0.00870        0.488        0.522\r\n##    17   1002      29    0.490 0.00886        0.473        0.508\r\n##    18    898      21    0.479 0.00900        0.462        0.497\r\n##    19    798       7    0.475 0.00906        0.457        0.493\r\n##    20    705       4    0.472 0.00911        0.454        0.490\r\n##    21    626      13    0.462 0.00932        0.444        0.481\r\n##    22    546       8    0.455 0.00948        0.437        0.474\r\n##    23    481       5    0.451 0.00962        0.432        0.470\r\n##    24    436       4    0.447 0.00975        0.428        0.466\r\n##    25    378       4    0.442 0.00993        0.423        0.462\r\n##    26    336       3    0.438 0.01010        0.419        0.458\r\n##    27    297       1    0.436 0.01017        0.417        0.457\r\n##    29    235       1    0.435 0.01030        0.415        0.455\r\n##    38     73       1    0.429 0.01175        0.406        0.452\n#print its summary at specific times\nsummary(\n  linelistsurv_fit,\n        times=c(5,10,20,30,60)\n        )## Call: survfit(formula = survobj ~ 1)\r\n## \r\n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\r\n##     5   3899     656    0.852 0.00535        0.841        0.862\r\n##    10   2311     810    0.642 0.00761        0.627        0.657\r\n##    20    705     446    0.472 0.00911        0.454        0.490\r\n##    30    210      39    0.435 0.01030        0.415        0.455\r\n##    60      2       1    0.429 0.01175        0.406        0.452\n#print the linelistsurv_fit object and ask for information on the mean survival time and its se. \nprint(\n  linelistsurv_fit, \n      print.rmean = TRUE\n      )## Call: survfit(formula = survobj ~ 1)\r\n## \r\n##          n     events     *rmean *se(rmean)     median    0.95LCL    0.95UCL \r\n##   4539.000   1952.000     33.105      0.539     17.000     16.000     18.000 \r\n##     * restricted mean with upper limit =  64\nprint(\n  str(linelistsurv_fit)\n      )## List of 16\r\n##  $ n        : int 4539\r\n##  $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\r\n##  $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\r\n##  $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\r\n##  $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\r\n##  $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\r\n##  $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\r\n##  $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\r\n##  $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\r\n##  $ type     : chr \"right\"\r\n##  $ logse    : logi TRUE\r\n##  $ conf.int : num 0.95\r\n##  $ conf.type: chr \"log\"\r\n##  $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\r\n##  $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\r\n##  $ call     : language survfit(formula = survobj ~ 1)\r\n##  - attr(*, \"class\")= chr \"survfit\"\r\n## NULL"},{"path":"survival-analysis.html","id":"plotting-kaplan-meir-curves","chapter":"26 Survival analysis","heading":"Plotting Kaplan-Meir curves","text":"KM estimates fitted, can visualize probability alive time using basic plot() function draws -known “Kaplan-Meier curve”. words curve conventional illustration survival experience whole patient group.can easily verify follow-time min max curve.easy way interpret say time zero, participants still alive: survival probability 100%. decreases time patients die. proportion participants surviving past 60 days f-u around 40%.confidence interval KM estimates survival also plotted default can dismissed adding option conf.int=FALSE plot() command.Since event interest “death”, drawing curve describing complements survival proportions lead drawing cumulative mortality proportions.","code":"\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\",    #xaxis label\n     ylab=\"Survival Probability\",   #yaxis label\n     main= \"Overall survival curve\" #figure title\n     )\nplot(\n     linelistsurv_fit,\n     xlab = \"Days of follow-up\",       \n     ylab=\"Survival Probability\",       \n     mark.time=TRUE,              #mark times of events to facilitate reading of the curve: a \"+\" sign is printed on the curve at every event\n     conf.int=FALSE,             #do not plot the confidence interval\n     main= \"Overall survival curve and cumulative mortality\"\n     )\n\n\n\n#draw an additional curve to the previous plot\nlines( \n      linelistsurv_fit, \n      lty=3,          #use a different line type to differenciate between the two curves and for legend clarity purposes\n      fun = \"event\", #draw the cumulative events instead of the survival \n      mark.time=FALSE, \n      conf.int=FALSE \n      )\n\n#add a legend to the plot\nlegend(\"topright\", #position of the legend in the plot\n       legend=c(\"Survival\",\"Cum. Mortality\"), #legend text \n       lty = c(1,3), #line types to use in the legend, should follow linetype used to draw the two curves\n       cex=.85, #factor that defines size of the legend text\n       bty = \"n\" #no box type to be drawn for the legend\n       )"},{"path":"survival-analysis.html","id":"comparison-of-survival-curves","chapter":"26 Survival analysis","heading":"26.4 Comparison of survival curves","text":"compare survival within different groups observed participants patients, might need first look respective survival curves run tests evaluate difference independent groups. comparison can concern groups based gender, age, treatment, comorbidity…","code":""},{"path":"survival-analysis.html","id":"log-rank-test","chapter":"26 Survival analysis","heading":"Log rank test","text":"log rank test popular test compares entire survival experience two independent groups can thought test whether survival curves identical (overlapping) (null hypothesis difference survival groups). survdiff() function survival package allows running log-rank test specify rho=0 (default). test results gives chi-square statistic along p-value since log rank statistic approximately distributed chi-square test statistic.first try compare survival curves gender group. , first try visualize (check whether two survival curves overlapping). new survfit object created slightly different formula. survdiff object created.see survival curve women one men overlap 15 days follow-women seem slightly better survival. Yet log-rank test gives enough evidence statistical difference survival women survival Men \\alpha= 0.05.packages allow illustrating survival curves different groups testing difference . Using ggsurvplot() function survminer package, can add curve print risk tables group well p-value log-rank test.find back p-value found previous step.CAUTION: survminer functions require since latest versions, specifying data used fit survival object. Remember avoid non-specific error messages. can look difference source contamination. case, Log rank test gives enough evidence difference survival probabilities \\alpha= 0.005.\r\nsurvival probabilities patients got infected funerals higher survival probabilities patients got infected places, suggesting survival benefit.","code":"\n#create the new survfit object based on gender\nlinelistsurv_fit_sex <-  survfit(\n  \n              Surv(futime, event) ~ gender, #formula to create the survival curve: ~ gender indicates we no longer plot the overall survival but based on gender\n              data = linelist_surv #data to use \n              )\n\n\n#plot the survival curves by gender: have a look at the order of the strata level in the gender var before defining your colors\ncol_sex <- c(\"lightgreen\", \"darkgreen\")\n\nplot(linelistsurv_fit_sex,\n     col=col_sex,\n     xlab = \"Days of follow-up\", \n     ylab=\"Survival Probability\"\n     )\n\nlegend(\"topright\", \n       legend=c(\"Female\",\"Male\"), \n       col =col_sex,\n       lty = 1, cex=.9, bty = \"n\" \n       )\n#compute the test of the difference between the survival curves\nsurvival::survdiff(\n          Surv(futime, event) ~ gender, \n          data = linelist_surv\n         )## Call:\r\n## survival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\r\n## \r\n## n=4321, 218 observations deleted due to missingness.\r\n## \r\n##             N Observed Expected (O-E)^2/E (O-E)^2/V\r\n## gender=f 2156      924      909     0.255     0.524\r\n## gender=m 2165      929      944     0.245     0.524\r\n## \r\n##  Chisq= 0.5  on 1 degrees of freedom, p= 0.5\nsurvminer::ggsurvplot(\n  \n    linelistsurv_fit_sex, \n    data= linelist_surv, #precise again the data used to fit the linelistsurv_fit_sex even though it is already precised in that object\n    conf.int = F, #do not show confidence interval of KM estimates\n    surv.scale = \"percent\",  #present probabilities in the y axis in %\n    break.time.by=10, #present the time axis with an increment of 10 days\n    xlab = \"Follow-up days\", ylab= \"Survival Probability\",\n    pval=T, pval.coord= c(40,.91),  #print p-value of Log-rank test and at the position with these coordinates\n    risk.table=T,  #print the risk table \n    legend.title = \"Gender\",\n    legend.labs = c(\"Female\",\"Male\"), font.legend = 10, #legend characteristics\n    palette = \"Dark2\", #existing palette name precised,\n    surv.median.line = \"hv\", #draw a line to the median survival\n    ggtheme = theme_light()\n)\nlinelistsurv_fit_source <-  survfit(\n              Surv(futime, event) ~ source,\n              data = linelist_surv\n              )\n\nggsurvplot( \n      linelistsurv_fit_source, data= linelist_surv,\n      size=1, linetype = \"strata\",\n      conf.int = T, \n      surv.scale = \"percent\",  \n      break.time.by=10, \n      xlab = \"Follow-up days\", ylab= \"Survival Probability\",\n      pval=T, pval.coord= c(40,.91),  \n      risk.table=T,\n      legend.title = \"Source of \\ninfection\", legend.labs = c(\"Funeral\",\"Other\"), \n      font.legend = 10,\n      palette = c(\"#E7B800\",\"#3E606F\"),\n      surv.median.line = \"hv\", \n      ggtheme = theme_light()\n)## Warning: Vectorized input to `element_text()` is not officially supported.\r\n## Results may be unexpected or may change in future versions of ggplot2."},{"path":"survival-analysis.html","id":"cox-regression-analysis","chapter":"26 Survival analysis","heading":"26.5 Cox regression analysis","text":"Cox proportional hazards regression one popular regression techniques survival analysis. models can also used since Cox model requires important assumptions need verified appropriate use proportional hazards assumption: see references.Cox proportional hazards regression model, measure effect hazard rate (HR), risk failure (risk death example), given participant survived specific time. Usually, interested comparing independent groups respect hazards, use hazard ratio, analogous odds ratio setting multiple logistic regression analysis. cox.ph() survival package used fit model.\r\nfunction cox.zph() survival package may used test proportional hazards assumption Cox regression model fit.NOTE: probability must lie range 0 1. However, hazard represents expected number events per one unit time.hazard ratio predictor close 1 predictor affect survival,HR less 1, predictor protective (.e., associated improved survival),HR greater 1, predictor associated increased risk (decreased survival).","code":""},{"path":"survival-analysis.html","id":"fitting-a-cox-model","chapter":"26 Survival analysis","heading":"Fitting a Cox model","text":"can first fit model assess effect age gender survival. just printing model, information :estimated regression coefficients (coef) quantifies association predictors outcome,exponential (interpretability, exp(coef)) produces hazard ratio,standard error (se(coef)),z-score: many standard errors estimated coefficient away 0,p-value: propability estimated coefficient 0.summary() function applied cox model object gives info confidence interval estimated HR different test scores.effect first covariate gender presented first row. genderm printed stating first strata level (“f”) .e female group reference group gender. Thus interpretation test parameter men compared women. p-value indicates enough evidence effect gender expected hazard association gender -cause mortality.lack evidence noted regarding age-group.interesting run model look results first look verify whether proportional hazards assumptions respected help saving time.NOTE: second argument called method can specified computing cox model. determines ties handled. default “efron”, options “breslow” “exact”.another model add risk factors source infection number days date onset admission. time, first verify proportional hazards assumption going forward.model, included continuous predictor (days_onset_hosp). case interpret parameter estimates increase expected log relative hazard one unit increase predictor, holding predictors constant. first verify proportional hazards assumption. graphical verification assumption may performed function ggcoxzph() survminer package.model results indicates negative association onset admission duration -cause mortality. expected hazard 0.9 times lower person one day later admitted another, holding gender constant. straightforward explanation, one unit increase duration onset admission associated 10.7% (coef *100) decrease risk death.Results show also positive association source infection -cause mortality. say increased risk death (1.21x) patients got source infection funerals.","code":"\n#fitting the cox model\nlinelistsurv_cox_sexage <-  survival::coxph(\n              Surv(futime, event) ~ gender + age_cat_small, \n              data = linelist_surv\n              )\n\n\n#printing the model fitted\nlinelistsurv_cox_sexage## Call:\r\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \r\n##     data = linelist_surv)\r\n## \r\n##                    coef exp(coef) se(coef)    z   p\r\n## genderm           -0.03      0.97     0.05 -0.7 0.5\r\n## age_cat_small5-19  0.09      1.10     0.06  1.5 0.1\r\n## age_cat_small20+   0.05      1.05     0.07  0.7 0.5\r\n## \r\n## Likelihood ratio test=3  on 3 df, p=0.4\r\n## n= 4321, number of events= 1853 \r\n##    (218 observations deleted due to missingness)\n#summary of the model\nsummary(linelistsurv_cox_sexage)## Call:\r\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \r\n##     data = linelist_surv)\r\n## \r\n##   n= 4321, number of events= 1853 \r\n##    (218 observations deleted due to missingness)\r\n## \r\n##                      coef exp(coef) se(coef)     z Pr(>|z|)\r\n## genderm           -0.0315    0.9690   0.0477 -0.66     0.51\r\n## age_cat_small5-19  0.0940    1.0986   0.0645  1.46     0.15\r\n## age_cat_small20+   0.0503    1.0516   0.0695  0.72     0.47\r\n## \r\n##                   exp(coef) exp(-coef) lower .95 upper .95\r\n## genderm               0.969      1.032     0.883      1.06\r\n## age_cat_small5-19     1.099      0.910     0.968      1.25\r\n## age_cat_small20+      1.052      0.951     0.918      1.21\r\n## \r\n## Concordance= 0.514  (se = 0.007 )\r\n## Likelihood ratio test= 2.8  on 3 df,   p=0.4\r\n## Wald test            = 2.78  on 3 df,   p=0.4\r\n## Score (logrank) test = 2.78  on 3 df,   p=0.4\ntest_ph_sexage <- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage##               chisq df    p\r\n## gender        0.454  1 0.50\r\n## age_cat_small 0.838  2 0.66\r\n## GLOBAL        1.399  3 0.71\n#fit the model\nlinelistsurv_cox <-  coxph(\n                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,\n                        data = linelist_surv\n                        )\n\n\n#test the proportional hazard model\nlinelistsurv_ph_test <- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test##                    chisq df       p\r\n## gender           0.45062  1    0.50\r\n## age_years        0.00199  1    0.96\r\n## source           1.79622  1    0.18\r\n## days_onset_hosp 31.66167  1 1.8e-08\r\n## GLOBAL          34.08502  4 7.2e-07\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n#print the summary of the model\nsummary(linelistsurv_cox)## Call:\r\n## coxph(formula = Surv(futime, event) ~ gender + age_years + source + \r\n##     days_onset_hosp, data = linelist_surv)\r\n## \r\n##   n= 2772, number of events= 1180 \r\n##    (1767 observations deleted due to missingness)\r\n## \r\n##                     coef exp(coef) se(coef)     z Pr(>|z|)    \r\n## genderm          0.00471   1.00472  0.06083  0.08    0.938    \r\n## age_years       -0.00225   0.99775  0.00242 -0.93    0.353    \r\n## sourceother      0.17839   1.19529  0.08429  2.12    0.034 *  \r\n## days_onset_hosp -0.10406   0.90117  0.01425 -7.31  2.8e-13 ***\r\n## ---\r\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n## \r\n##                 exp(coef) exp(-coef) lower .95 upper .95\r\n## genderm             1.005      0.995     0.892     1.132\r\n## age_years           0.998      1.002     0.993     1.002\r\n## sourceother         1.195      0.837     1.013     1.410\r\n## days_onset_hosp     0.901      1.110     0.876     0.927\r\n## \r\n## Concordance= 0.566  (se = 0.009 )\r\n## Likelihood ratio test= 71.3  on 4 df,   p=1e-14\r\n## Wald test            = 59.2  on 4 df,   p=4e-12\r\n## Score (logrank) test = 59.5  on 4 df,   p=4e-12"},{"path":"survival-analysis.html","id":"forest-plots","chapter":"26 Survival analysis","heading":"Forest plots","text":"can visualize results cox model using practical forest plots ggforest() function survminer package.","code":"\nggforest(linelistsurv_cox, data = linelist_surv)"},{"path":"survival-analysis.html","id":"time-dependent-covariates-in-survival-models","chapter":"26 Survival analysis","heading":"26.6 Time-dependent covariates in survival models","text":"following sections adapted permission excellent introduction survival analysis R Dr. Emily ZaborIn last section covered using Cox regression examine associations covariates interest survival outcomes.analyses rely covariate measured baseline, , follow-time event begins.happens interested covariate measured follow-time begins? , covariate can change time?example, maybe working clinical data repeated measures hospital laboratory values can change time. example Time Dependent Covariate. order address need special setup, fortunately cox model flexible type data can also modeled tools survival package.","code":""},{"path":"survival-analysis.html","id":"time-dependent-covariate-setup","chapter":"26 Survival analysis","heading":"Time-dependent covariate setup","text":"Analysis time-dependent covariates R requires setup special dataset. interested, see detailed paper author survival package Using Time Dependent Covariates Time Dependent Coefficients Cox Model., ’ll use new dataset SemiCompRisks package named BMT, includes data 137 bone marrow transplant patients. variables ’ll focus :T1 - time (days) death last follow-updelta1 - death indicator; 1-Dead, 0-AliveTA - time (days) acute graft-versus-host diseasedeltaA - acute graft-versus-host disease indicator;\r\n1 - Developed acute graft-versus-host disease\r\n0 - Never developed acute graft-versus-host disease\r\n1 - Developed acute graft-versus-host disease0 - Never developed acute graft-versus-host diseaseWe’ll load dataset survival package using base R command data(), can used loading data already included R package loaded. data frame BMT appear R environment.","code":"\ndata(BMT, package = \"SemiCompRisks\")"},{"path":"survival-analysis.html","id":"add-unique-patient-identifier","chapter":"26 Survival analysis","heading":"Add unique patient identifier","text":"unique ID column BMT data, needed create type dataset want. use function rowid_to_column() tidyverse package tibble create new id column called my_id (adds column start data frame sequential row ids, starting 1). name data frame bmt.dataset now looks like :","code":"\nbmt <- rowid_to_column(BMT, \"my_id\")"},{"path":"survival-analysis.html","id":"expand-patient-rows","chapter":"26 Survival analysis","heading":"Expand patient rows","text":"Next, ’ll use tmerge() function event() tdc() helper functions create restructured dataset. goal restructure dataset create separate row patient time interval different value deltaA. case, patient can two rows depending whether developed acute graft-versus-host disease data collection period. ’ll call new indicator development acute graft-versus-host disease agvhd.tmerge() creates long dataset multiple time intervals different covariate values patientevent() creates new event indicator go newly-created time intervalstdc() creates time-dependent covariate column, agvhd, go newly created time intervalsTo see , let’s look data first 5 individual patients.variables interest original data looked like :new dataset patients looks like :Now patients two rows dataset corresponding intervals different value new variable, agvhd. example, Patient 1 now two rows agvhd value zero time 0 time 67, value 1 time 67 time 2081.","code":"\ntd_dat <- \n  tmerge(\n    data1 = bmt %>% select(my_id, T1, delta1), \n    data2 = bmt %>% select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\nbmt %>% \n  select(my_id, T1, delta1, TA, deltaA) %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1   TA deltaA\r\n## 1     1 2081      0   67      1\r\n## 2     2 1602      0 1602      0\r\n## 3     3 1496      0 1496      0\r\n## 4     4 1462      0   70      1\r\n## 5     5 1433      0 1433      0\ntd_dat %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1 id tstart tstop death agvhd\r\n## 1     1 2081      0  1      0    67     0     0\r\n## 2     1 2081      0  1     67  2081     0     1\r\n## 3     2 1602      0  2      0  1602     0     0\r\n## 4     3 1496      0  3      0  1496     0     0\r\n## 5     4 1462      0  4      0    70     0     0\r\n## 6     4 1462      0  4     70  1462     0     1\r\n## 7     5 1433      0  5      0  1433     0     0"},{"path":"survival-analysis.html","id":"cox-regression-with-time-dependent-covariates","chapter":"26 Survival analysis","heading":"Cox regression with time-dependent covariates","text":"Now ’ve reshaped data added new time-dependent aghvd variable, let’s fit simple single variable cox regression model. can use coxph() function , just need change Surv() function specify start stop time interval using time1 = time2 = arguments., ’ll visualize cox model results using ggforest() function survminer package.:can see forest plot, confidence interval, p-value, appear strong association death acute graft-versus-host disease context simple model.","code":"\nbmt_td_model = coxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  )\n\nsummary(bmt_td_model)## Call:\r\n## coxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \r\n##     agvhd, data = td_dat)\r\n## \r\n##   n= 163, number of events= 80 \r\n## \r\n##        coef exp(coef) se(coef)    z Pr(>|z|)\r\n## agvhd 0.335     1.398    0.281 1.19     0.23\r\n## \r\n##       exp(coef) exp(-coef) lower .95 upper .95\r\n## agvhd       1.4      0.715     0.805      2.43\r\n## \r\n## Concordance= 0.535  (se = 0.024 )\r\n## Likelihood ratio test= 1.33  on 1 df,   p=0.2\r\n## Wald test            = 1.42  on 1 df,   p=0.2\r\n## Score (logrank) test = 1.43  on 1 df,   p=0.2\nggforest(bmt_td_model, data = td_dat)"},{"path":"survival-analysis.html","id":"resources-19","chapter":"26 Survival analysis","heading":"26.7 Resources","text":"Survival Analysis Part : Basic concepts first analysesSurvival Analysis RSurvival analysis infectious disease research: Describing events timeChapter advanced survival models PrincetonUsing Time Dependent Covariates Time Dependent Coefficients Cox ModelSurvival analysis cheatsheet RSurvminer cheastsheetPaper different survival measures cancer registry data Rcode provided supplementary materials","code":""},{"path":"gis-basics.html","id":"gis-basics","chapter":"27 GIS basics","heading":"27 GIS basics","text":"","code":""},{"path":"gis-basics.html","id":"overview-11","chapter":"27 GIS basics","heading":"27.1 Overview","text":"Spatial aspects data can provide lot insights situation outbreak, answer questions :current disease hotspots?hotspots changed time?access health facilities? improvements needed?section, explore basic spatial data visualization methods using tmap ggplot2 packages.\r\nalso walk basic spatial data management querying methods sf package.example outputs:Choropleth mapCase density heatmapHealth facility catchment areas","code":""},{"path":"gis-basics.html","id":"preparation-18","chapter":"27 GIS basics","heading":"27.2 Preparation","text":"","code":""},{"path":"gis-basics.html","id":"load-packages-16","chapter":"27 GIS basics","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # to import data\n  here,         # to locate files\n  tidyverse,    # to clean, handle, and plot the data (includes ggplot2 package)\n  sf,           # to manage spatial data using a Simple Feature format\n  tmap,         # to produce simple maps, works for both interactive and static maps\n  janitor,      # to clean column names\n  OpenStreetMap # to add OSM basemap in ggplot map\n  ) "},{"path":"gis-basics.html","id":"sample-case-data","chapter":"27 GIS basics","heading":"Sample case data","text":"demonstration purposes, work random sample 1000 cases simulated Ebola epidemic linelist dataframe (computationally, working fewer cases easier display handbook). want download data follow step--step, see instructions Download book data page.dataset imported using import() function rio package. See page Import export various ways import data.Next select random sample 1000 rows using sample() base R.Now want convert linelist class dataframe, object class “sf” (spatial features). Given linelist two columns “lon” “lat” representing longitude latitude case’s residence, easy.use package sf (spatial features) function st_as_sf() create new object call linelist_sf. new object look essentially linelist, columns lon lat designated coordinate columns, coordinate reference system (CRS) assigned points displayed.","code":"\n# import clean case linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")  \n# generate 1000 random row numbers, from the number of rows in linelist\nsample_rows <- sample(nrow(linelist), 1000)\n\n# subset linelist to keep only the sample rows, and all columns\nlinelist <- linelist[sample_rows,]\n# Create sf object\nlinelist_sf <- linelist %>%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)"},{"path":"gis-basics.html","id":"admin-boundary-shapefiles","chapter":"27 GIS basics","heading":"Admin boundary shapefiles","text":"Sierra Leone: Admin boundary shapefilesIn advance, downloaded administrative boundaries Sierra Leone Humanitarian Data Exchange (HDX) website .Now going following save Admin Level 3 shapefile R:Import shapefileClean column namesFilter rows keep areas interestTo import shapefile use read_sf() function sf. provided filepath via (). - case file within R project “Data” “shp” subfolders, filename “sle_adm3.shp” (see pages Import export R projects information).Next use clean_names() janitor package standardize column names shapefile. also use filter() keep rows admin2name “Western Area Urban” “Western Area Rural”.can see shapefile looks import cleaning. Scroll right see columns admin level 0 (country), admin level 1, admin level 2, finally admin level 3. level character name pcode unique identifier code. pcode expands increasing admin level e.g. SL (Sierra Leone) -> SL04 (Western) -> SL0410 (Western Area Rural) -> SL040101 (Koya Rural).","code":"\nsle_adm3_raw <- sf::read_sf(here::here(\"data\", \"shp\", \"sle_adm3.shp\"))\n# ADM3 level clean\nsle_adm3 <- sle_adm3_raw %>%\n  janitor::clean_names() %>% # standardize column names\n  filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # filter to keep certain areas"},{"path":"gis-basics.html","id":"population-data","chapter":"27 GIS basics","heading":"Population data","text":"Sierra Leone: Population ADM3Again, import data downloaded HDX (link ). time use import() load .csv file. also pass imported file clean_names() standardize column names.populaton file looks like. Scroll right see jurisdiction columns male population, female populaton, total population, population break-columns age group.","code":"\n# Population by ADM3\nsle_adm3_pop <- rio::import(here::here(\"data/population\", \"sle_admpop_adm3_2020.csv\")) %>%\n  janitor::clean_names()"},{"path":"gis-basics.html","id":"health-facilities","chapter":"27 GIS basics","heading":"Health Facilities","text":"Sierra Leone: Health facility data OpenStreetMapAgain downloaded locations health facilities HDX .import shapefile read_sf(), clean column names, filter keep points tagged either “hospital”, “clinic”, “doctors”.resulting dataframe - scroll right see facility name coordinates.","code":"\n# OSM health facility shapefile\nsle_hf <- sf::read_sf(here::here(\"data/shp\", \"sle_hf.shp\")) %>% \n  janitor::clean_names() %>%\n  filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))"},{"path":"gis-basics.html","id":"plotting-coordinates","chapter":"27 GIS basics","heading":"27.3 Plotting coordinates","text":"easiest way plot X-Y coordinates (longitude/latitude, points) draw points directly linelist_sf object created preparation section.package tmap offers simple mapping capabilities static (“plot” mode) interactive (“view” mode) just lines code. tmap syntax similar *ggplot2**, commands added +. Read detail vignette.set tmap mode. case use “plot” mode, produces static outputs., points plotted alone.tm_shape() provided linelist_sf objects. add points via tm_dots(), specifying size color. linelist_sf sf object, already designated two columns contain lat/long coordinates coordinate reference system (CRS):Alone, points tell us much. also map administrative boundaries:use tm_shape() (see documentation) instead providing case points shapefile, provide administrative boundary shapefile (polygons).bbox = argument (bbox stands “bounding box”) can specify coordinate boundaries. First show map display without bbox, .now points polygons together:read good comparison mapping options R, see blog post.","code":"\ntmap_mode(\"plot\") # choose either \"view\" or \"plot\"\n# Just the cases (points)\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n# Just the administrative boundaries (polygons)\ntm_shape(sle_adm3) +               # admin boundaries shapefile\n  tm_polygons(col = \"#F7F7F7\")+    # show polygons in light grey\n  tm_borders(col = \"#000000\",      # show borders with color and line weight\n             lwd = 2) +\n  tm_text(\"admin3name\")            # column text to display for each polygon\n\n\n# Same as above, but with zoom from bounding box\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # corner\n                  -13.2, 8.5)) +  # corner\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n# All together\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue') "},{"path":"gis-basics.html","id":"spatial-joins","chapter":"27 GIS basics","heading":"27.4 Spatial joins","text":"","code":""},{"path":"gis-basics.html","id":"points-in-polygon","chapter":"27 GIS basics","heading":"Points in polygon","text":"Spatial assign administrative units casesThe case linelist contain information administrative units cases. Although ideal collect information initial data collection phase, can also assign administrative units individual cases based spatial relationships (.e. point intersects polygon).sf package offers various methods spatial joins. See documentation st_join method spatial join types reference., spatially intersect case locations (points) ADM3 boundaries (polygons):Begin linelist (points)Spatial join boundaries, setting type join “st_intersects”Use select() keep certain new administrative boundary columnsAll columns sle_adms added linelist! case now columns detailing ’s administrative units. example, want keep two new columns, select() old column names just two additional interest:, just display purposes can see first ten cases admin level 3 (ADM3) jurisdictions attached, based point spatially intersected polygon shapes.Now can describe cases administrative unit - something able spatial join!can also create bar plot case counts administrative unit.example, begin ggplot() linelist_adm, can apply factor functions like fct_infreq() orders bars frequency (see page Factors tips).","code":"\nlinelist_adm <- linelist_sf %>%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3,   join = st_intersects)\nlinelist_adm <- linelist_sf %>%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects) %>% \n  \n  # Keep the old column names and two new admin ones of interest\n  select(names(linelist_sf), admin3name, admin3pcod)\n# Now you will see the ADM3 names attached to each case\nlinelist_adm %>% select(case_id, admin3name, admin3pcod)## Simple feature collection with 1000 features and 3 fields\r\n## geometry type:  POINT\r\n## dimension:      XY\r\n## bbox:           xmin: -13.3 ymin: 8.45 xmax: -13.2 ymax: 8.49\r\n## geographic CRS: WGS 84\r\n## First 10 features:\r\n##      case_id     admin3name admin3pcod           geometry\r\n## 4514  8c6a51 Mountain Rural   SL040102 POINT (-13.2 8.46)\r\n## 62    f97626        East II   SL040204 POINT (-13.2 8.48)\r\n## 5181  5f6943         East I   SL040203 POINT (-13.2 8.48)\r\n## 1312  05467b        West II   SL040207 POINT (-13.2 8.47)\r\n## 2677  3dc582        East II   SL040204 POINT (-13.2 8.48)\r\n## 4114  65fb4c        West II   SL040207 POINT (-13.2 8.46)\r\n## 5227  5c033b        East II   SL040204 POINT (-13.2 8.48)\r\n## 4915  2abc5b Mountain Rural   SL040102 POINT (-13.2 8.47)\r\n## 4188  f0ff1f         East I   SL040203 POINT (-13.2 8.49)\r\n## 3839  713b6f Mountain Rural   SL040102 POINT (-13.2 8.46)\n# Make new dataframe containing counts of cases by administrative unit\ncase_adm3 <- linelist_adm %>%          # begin with linelist with new admin cols\n  as_tibble() %>%                      # convert to tibble for better display\n  group_by(admin3pcod, admin3name) %>% # group by admin unit, both by name and pcode \n  summarise(cases = n()) %>%           # summarize and count rows\n  arrange(desc(cases))                     # arrange in descending order\n\ncase_adm3## # A tibble: 10 x 3\r\n## # Groups:   admin3pcod [10]\r\n##    admin3pcod admin3name     cases\r\n##    <chr>      <chr>          <int>\r\n##  1 SL040102   Mountain Rural   288\r\n##  2 SL040208   West III         224\r\n##  3 SL040207   West II          184\r\n##  4 SL040204   East II          117\r\n##  5 SL040201   Central I         56\r\n##  6 SL040203   East I            49\r\n##  7 SL040206   West I            38\r\n##  8 SL040202   Central II        24\r\n##  9 SL040205   East III          18\r\n## 10 <NA>       <NA>               2\nggplot(\n  data = linelist_adm,                       # begin with linelist containing admin unit info\n  aes(x = fct_rev(fct_infreq(admin3name))))+ # x-axis is admin units, ordered by frequency (reversed)\n  geom_bar()+                                # create bars, height is number of rows\n  coord_flip()+                              # flip X and Y axes for easier reading of adm units\n  theme_classic()+                           # simplify background\n  labs(                                      # titles and labels\n    x = \"Admin level 3\",\n    y = \"Number of cases\",\n    title = \"Number of cases, by adminstative unit\",\n    caption = \"As determined by a spatial join, from 1000 randomly sampled cases from linelist\"\n  )"},{"path":"gis-basics.html","id":"nearest-neighbor","chapter":"27 GIS basics","heading":"Nearest neighbor","text":"Finding nearest health facility / catchment areaIt might useful know health facilities located relation disease hot spots.can use st_nearest_feature join method st_join() function (sf package) visualize closest health facility individual cases.begin shapefile linelist linelist_sfWe spatially join sle_hf, locations health facilities clinics (points)can see (first 50 rows) case now data nearest clinic/hospitalWe can see “Den Clinic” closest health facility ~30% cases.visualize results, can use tmap - time interactive mode easier viewing","code":"\n# Closest health facility to each case\nlinelist_sf_hf <- linelist_sf %>%                  # begin with linelist shapefile  \n  st_join(sle_hf, join = st_nearest_feature) %>%   # data from nearest clinic joined to case data \n  select(case_id, osm_id, name, amenity)           # keep columns of interest, including id, name, type, and geometry of healthcare facility\n# Count cases by health facility\nhf_catchment <- linelist_sf_hf %>%    # begin with linelist including nearest clinic data\n  as.data.frame() %>%                 # convert from shapefile to dataframe\n  group_by(name) %>%                  # group by name of clinic\n  summarise(case_n = n()) %>%         # count number of rows per clinic \n  arrange(desc(case_n))               # arrange in descending order\n\nhf_catchment                          # print to console## # A tibble: 8 x 2\r\n##   name                                  case_n\r\n##   <chr>                                  <int>\r\n## 1 Shriners Hospitals for Children          350\r\n## 2 Den Clinic                               344\r\n## 3 GINER HALL COMMUNITY HOSPITAL            189\r\n## 4 panasonic                                 53\r\n## 5 Princess Christian Maternity Hospital     28\r\n## 6 ARAB EGYPT CLINIC                         14\r\n## 7 MABELL HEALTH CENTER                      11\r\n## 8 <NA>                                      11\ntmap_mode(\"view\")   # set tmap mode to interactive  \n\n# plot the cases and clinic points \ntm_shape(linelist_sf_hf) +            # plot cases\n  tm_dots(size=0.08, col='name') +    # cases colored by closest clinic\ntm_shape(sle_hf) +                    # plot clinic facilities  \n  tm_dots(size=0.3, col='red') +      # red large dots\n  tm_text(\"name\") +                   # overlay with name of facility\ntm_view(set.view = c(-13.2284, 8.4699, 13), # adjust zoom (center coords, zoom)\n        set.zoom.limits = c(13,14))"},{"path":"gis-basics.html","id":"buffers","chapter":"27 GIS basics","heading":"Buffers","text":"can also explore many cases located within 2.5km (~30 mins) walking distance closest health facility.Note: accurate distance calculations, better re-project sf object respective local map projection system UTM (Earth projected onto planar surface). example, simplicity stick World Geodetic System (WGS84) Geograhpic coordinate system (Earth represented spherical / round surface, therefore units decimal degrees). use general conversion : 1 decimal degree = ~111km.See information map projections coordinate systems esri article.First, create circular buffer radius ~2.5km around health facility. done function st_buffer() tmap. units map lat/long decimal degrees, “0.02” interpreted. map coordinate system meters, number must provided meters.plot buffer zones :**Second, intersect buffers cases (points) using st_join() join type st_intersects*. , data buffers joined points intersect .Now can count results: 210 1000 cases intersect buffer (value missing), live 30 mins walk nearest health facility.can visualize results cases intersect buffer appear red.","code":"\nsle_hf_2k <- sle_hf %>%\n  st_buffer(dist=0.02)       # decimal degrees translating to approximately 2.5km \ntmap_mode(\"plot\")\n# buffers\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"red\", lwd = 2)\n# Intersect the cases with the buffers\nlinelist_sf_hf_2k <- linelist_sf_hf %>%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %>%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %>%\n  select(case_id, osm_id.x, name.x, amenity.x, osm_id.y)\nlinelist_sf_hf_2k %>% \n  filter(is.na(osm_id.y)) %>% # empty column - did not join to any buffer\n  nrow()## [1] 210\ntmap_mode(\"view\")\n\n# cases\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='name') +\n# buffers\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"red\", lwd = 2) +\n\n# cases outside buffers\ntm_shape(linelist_sf_hf_2k %>%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))"},{"path":"gis-basics.html","id":"other-spatial-joins","chapter":"27 GIS basics","heading":"Other spatial joins","text":"Alternative values argument join include (documentation)st_contains_properlyst_containsst_covered_byst_coversst_crossesst_disjointst_equals_exactst_equalsst_is_within_distancest_nearest_featurest_overlapsst_touchesst_within","code":""},{"path":"gis-basics.html","id":"choropleth-maps","chapter":"27 GIS basics","heading":"27.5 Choropleth maps","text":"Choropleth maps can useful visualize data pre-defined area, usually administrative unit health area. outbreak response can help target resource allocation specific areas high incidence rates, example.Now administrative unit names assigned cases (see section spatial joins, ), can start mapping case counts area (choropleth maps).Since also population data ADM3, can add information case_adm3 table created previously.begin dataframe created previous step case_adm3, summary table administrative unit number cases.populaton data sle_adm3_pop joined using left_join() dplyr basis common values across column admin3pcod case_adm3 dataframe, column adm_pcode sle_adm3_pop dataframe. See page Joining data).select() applied new dataframe, keep useful columns - total total populationCases per 10,000 populaton calculated new column mutate()Join table ADM3 polygons shapefile mappingMapping resultsWe can also map incidence rates","code":"\n# Add population data and calculate cases per 10K population\ncase_adm3 <- case_adm3 %>% \n     left_join(sle_adm3_pop,                             # add columns from pop dataset\n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %>%  # join based on common values across these two columns\n     select(names(case_adm3), total) %>%                 # keep only important columns, including total population\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # make new column with case rate per 10000, rounded to 3 decimals\n\ncase_adm3                                                # print to console for viewing## # A tibble: 10 x 5\r\n## # Groups:   admin3pcod [10]\r\n##    admin3pcod admin3name     cases  total case_10kpop\r\n##    <chr>      <chr>          <int>  <int>       <dbl>\r\n##  1 SL040102   Mountain Rural   288  33993       84.7 \r\n##  2 SL040208   West III         224 210252       10.7 \r\n##  3 SL040207   West II          184 145109       12.7 \r\n##  4 SL040204   East II          117  99821       11.7 \r\n##  5 SL040201   Central I         56  69683        8.04\r\n##  6 SL040203   East I            49  68284        7.18\r\n##  7 SL040206   West I            38  60186        6.31\r\n##  8 SL040202   Central II        24  23874       10.1 \r\n##  9 SL040205   East III          18 500134        0.36\r\n## 10 <NA>       <NA>               2     NA       NA\ncase_adm3_sf <- case_adm3 %>%                 # begin with cases & rate by admin unit\n  left_join(sle_adm3, by=\"admin3pcod\") %>%    # join to shapefile data by common column\n  select(objectid, admin3pcod,                # keep only certain columns of interest\n         admin3name = admin3name.x,           # clean name of one column\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %>%                        # keep geometry so polygons can be plotted\n  st_as_sf()                                  # convert to shapefile\n# tmap mode\ntmap_mode(\"plot\")               # view static map\n\n# plot polygons\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # color by number of cases column\n        tm_text(\"admin3name\")   # name display\n# Cases per 10K population\ntmap_mode(\"plot\")             # static viewing mode\n\n# plot\ntm_shape(case_adm3_sf) +                # plot polygons\n  tm_polygons(\"case_10kpop\",            # color by column containing case rate\n              breaks=c(0, 10, 50, 100), # define break points for colors\n              palette = \"Purples\"       # use a purple color palette\n              ) +\n  tm_text(\"admin3name\")                 # display text"},{"path":"gis-basics.html","id":"basemaps","chapter":"27 GIS basics","heading":"27.6 Basemaps","text":"","code":""},{"path":"gis-basics.html","id":"openstreetmap","chapter":"27 GIS basics","heading":"OpenStreetMap","text":"describe achieve basemap using OpenStreetMap features. Alternative methods include using ggmap requires free registration Google (details).First load OpenStreetMap package, get basemap., create object map, define using function openmap() OpenStreetMap package (documentation). provide following:upperLeft lowerRight Two coordinate pairs specifying limits basemap tile\r\ncase ’ve put max min linelist rows, map respond dynamically data\r\ncase ’ve put max min linelist rows, map respond dynamically datazoom = (null determined automatically)type = type basemap - listed several possibilities code currently using first one ([1]) “osm”mergeTiles = chose TRUE basetiles merged oneIf plot basemap right now, using autoplot.OpenStreetMap() OpenStreetMap package, see units axes latitude/longitude coordinates. using different coordinate system. correctly display case residences (stored lat/long), must changed.\r\nThus, want convert map latitude/longitude openproj() function OpenStreetMap package. provide basemap map also provide Coordinate Reference System (CRS) want. providing “proj.4” character string WGS 1984 projection, can provide CRS ways well. (see page better understand proj.4 string )Now create plot see along axes latitude longitude coordinate. coordinate system converted. Now cases plot correctly overlaid!See tutorials info.","code":"\n# load package\npacman::p_load(OpenStreetMap)\n\n# Fit basemap by range of lat/long coordinates. Choose tile type\nmap <- openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # limits of basemap tile\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\",\"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\nautoplot.OpenStreetMap(map)\n# Projection WGS84\nmap_latlon <- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n# Plot map. Must use \"autoplot\" in order to work with ggplot\nautoplot.OpenStreetMap(map_latlon)"},{"path":"gis-basics.html","id":"contoured-density-heatmaps","chapter":"27 GIS basics","heading":"27.7 Contoured density heatmaps","text":"describe achieve contoured density heatmap cases, basemap, beginning linelist (one row per case).Create basemap tile OpenStreetMap, described abovePlot cases linelist using latitude longitude columnsConvert points density heatmap stat_density_2d() ggplot2,basemap lat/long coordinates, can plot cases top using lat/long coordinates residence.Building function autoplot.OpenStreetMap() create basemap, ggplot2 functions easily add top, shown geom_point() :\r\nmap might difficult interpret, especially points overlapping. can instead plot 2d density map using ggplot2 function stat_density_2d(). still using linelist lat/lon coordinates, 2D kernel density estimation performed results displayed contour lines - like topographical map. Read full documentation .","code":"\n# Plot map. Must be autoplotted to work with ggplot\nautoplot.OpenStreetMap(map_latlon)+                 # begin with the basemap\n  geom_point(                                       # add xy points from linelist lon and lat columns \n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # drop legend entirely\n  labs(x = \"Longitude\",                             # titles & labels\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")"},{"path":"gis-basics.html","id":"time-series-heatmap","chapter":"27 GIS basics","heading":"27.7.1 Time series heatmap","text":"density heatmap shows cumulative cases. can examine outbreak time space faceting heatmap based month symptom onset, derived linelist.begin linelist, creating new column Year Month onset. format() function base R changes date displayed. case want “YYYY-MM”.Now, simply introduce facetting via ggplot2 density heatmap. facet_wrap() applied, using new column rows. set number facet columns 3 clarity.","code":"\n# Extract month of onset\nlinelist <- linelist %>% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# Examine the values \ntable(linelist$date_onset_ym, useNA = \"always\")## \r\n## 2014-04 2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 2015-02 2015-03 2015-04    <NA> \r\n##       2      11       9      40      79     187     186     126      93      80      72      48      28      39\n# packages\npacman::p_load(OpenStreetMap, tidyverse)\n\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")+\n  \n  # facet the plot by month-year of onset\n  facet_wrap(~ date_onset_ym, ncol = 4)               "},{"path":"gis-basics.html","id":"resources-20","chapter":"27 GIS basics","heading":"27.8 Resources","text":"R Simple Features sf package\r\nhttps://cran.r-project.org/web/packages/sf/vignettes/sf1.htmlR Simple Features sf package\r\nhttps://cran.r-project.org/web/packages/sf/vignettes/sf1.htmlR tmap package\r\nhttps://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.htmlR tmap package\r\nhttps://cran.r-project.org/web/packages/tmap/vignettes/tmap-getstarted.htmlggmap: Spatial Visualization ggplot2\r\nhttps://journal.r-project.org/archive/2013-1/kahle-wickham.pdfggmap: Spatial Visualization ggplot2\r\nhttps://journal.r-project.org/archive/2013-1/kahle-wickham.pdfIntro making maps R, overview different packagesIntro making maps R, overview different packages","code":""},{"path":"ggplot-tips.html","id":"ggplot-tips","chapter":"28 ggplot tips","heading":"28 ggplot tips","text":"","code":""},{"path":"ggplot-tips.html","id":"overview-12","chapter":"28 ggplot tips","heading":"28.1 Overview","text":"ggplot2 popular data visualisation package R, generally used instead base R creating figures. ggplot2 benefits wide variety supplementary packages enhance functionality. Despite , ggplot syntax significantly different base R plotting, learning curve associated . Using ggplot2 generally requires user format data way highly tidyverse compatible, ultimately makes using packages together effective.can also download data visualization ggplot cheatsheet RStudio website.want inspiration ways creatively visualise data, suggest reviewing websites like R graph gallery Data--viz.","code":""},{"path":"ggplot-tips.html","id":"preparation-19","chapter":"28 ggplot tips","heading":"28.2 Preparation","text":"","code":""},{"path":"ggplot-tips.html","id":"load-packages-17","chapter":"28 ggplot tips","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,      # includes ggplot2 and other\n  rio,            # import/export\n  here,           # file locator\n  stringr,        # working with characters   \n  scales,         # transform numbers\n  ggrepel,        # smartly-placed labels\n  gghighlight,    # highlight one part of plot\n  RColorBrewer    # color scales\n)"},{"path":"ggplot-tips.html","id":"import-data-13","chapter":"28 ggplot tips","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.","code":"\nlinelist_cleaned <- rio::import(\"linelist_cleaned.xlsx\")"},{"path":"ggplot-tips.html","id":"general-cleaning","chapter":"28 ggplot tips","heading":"General cleaning","text":"preparing data plot, best make data adhere “tidy” data standards much possible. achieve expanded data management pages handbook, Cleaning data core functions.simple ways can prepare data make better plotting can include making contents data better display - necessarily mean better data manipulation! example:Replace NA values character column string “Unknown”Clean columns “data friendly” values underscores etc changed normal text title case (see Characters strings)examples action:","code":"\nlinelist_cleaned <- linelist_cleaned %>%\n  # make display version of columns with more friendly names\n  mutate(\n    # f to Male, f to Female, NA to Unknown\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",\n                            gender == \"f\" ~ \"Female\",\n                            is.na(gender) ~ \"Unknown\"),\n    # replace NA with unknown for outcome\n    outcome_disp = replace_na(outcome, \"Unknown\")\n  )"},{"path":"ggplot-tips.html","id":"pivoting-longer","chapter":"28 ggplot tips","heading":"Pivoting longer","text":"matter data structure, ggplot2 often also want pivot data longer formats, allow us use set variables single variable. Read page Pivoting data.example, wanted show number cases specific symptoms, limited fact symptom specific column. can pivot longer format like :Note format useful operations, just used plot made . However, users endeavor use practices much possible base dataset, tidyverse compliant, make working data easier.","code":"\nlinelist_sym <- linelist_cleaned %>%\n  pivot_longer(cols = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n               names_to = \"symptom_name\",\n               values_to = \"symptom_is_present\") %>%\n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\"))"},{"path":"ggplot-tips.html","id":"basics-of-ggplot","chapter":"28 ggplot tips","heading":"28.3 Basics of ggplot","text":"“Grammar graphics” - ggplot2Plotting ggplot2 based defining base attributes plot, “adding” layers top. addition, user can change various plot attributes like axis settings, colour schemes, labels additional objects “added” plot. ggplot objects can highly complex, basic order creating ggplot looks something like :Define base/default plot attributes aesthetics ggplot() functionAdd geometric objects plot - .e. plot bar graph, line plot, scatter plot, histogram? combination ? functions start geom_ prefix.Change plot aesthetics e.g. changing axes, labels, colour scheme, background etc.code, might look like :code, important things note :making ggplot, objects combined + sign.Understand principles behind aesthetic mapping mappping = aes() argument essential using ggplot. can done ggplot() function well every geometric object. Mapping aes() used define variables assigned axis (can continuous categorical variables). also used define whether variable can used create different plot aesthetics. can apply :line colour (col =)filled colour (fill =)linetype (e.g. dotted, dashed) (linetype =)size object (size =)list exhaustive, enough give rough overview.Aesthetics geometric objects can defined explicitly code - different assigning variable. cases done, must outside mapping argument.example defining aesthetics variable can seen :huge number different geoms can used, used similar attribute names. exhaustive, shapes can used :Histograms - geom_histogram()Barcharts - geom_bar()Boxplots - geom_boxplot()Dot plots (scatterplots discrete variables) - geom_point()Line graphs - geom_line() geom_path()Trend lines - geom_smooth()can also add straight lines plot geom_hline() (horizontal), geom_vline() (vertical) geom_abline() (specified y intercept slope)much detail show , ’ll finish example ties concepts together plotting correlation height weight patients. can also colour points age years","code":"\n# define base plot attributes and dataset\nggplot(data = linelist_cleaned, mapping = aes(x = age)) +\n  # add a geometric object with some parameters\n  geom_histogram(binwidth = 10, fill = \"red\", col = \"black\") +\n  # add labels to the axes\n  labs(x = \"Age in years\", y = \"Number of cases\")\n# correct\nggplot(data = linelist_cleaned, mapping = aes(x = age)) +\n  geom_histogram(col = \"black\")\n\n# incorrect\n# correct\nggplot(data = linelist_cleaned, mapping = aes(x = age)) +\n  geom_histogram(mapping = aes(col = \"black\"))\n# define base plot attributes and dataset\nggplot(data = linelist_cleaned, mapping = aes(x = age, fill = outcome)) +\n  # add a geometric object with some parameters (NO FILL GIVEN)\n  geom_histogram(binwidth = 10, col = \"black\") +\n  # add labels to the axes\n  labs(x = \"Age in years\", y = \"Number of cases\")\n# set up the plot and define key variables\n# colour is the outcome\nwt_ht_plot <- ggplot(data = linelist_cleaned,\n                     aes(y = wt_kg, x = ht_cm, col = age_years)) +\n  # define aspects of the geom that are NOT included specific to variables\n  # other attributes are inherited\n  geom_point(size = 1, alpha = 0.5) +\n  # add a trend line\n  # use a linear method\n  geom_smooth(method = \"lm\")\nwt_ht_plot## `geom_smooth()` using formula 'y ~ x'"},{"path":"ggplot-tips.html","id":"themes-and-labels","chapter":"28 ggplot tips","heading":"28.4 Themes and Labels","text":"One important aspects data visualisation presenting data clear way nice aesthetics. plot made previously looks ok, make theme little nicer. ggplot2 comes preset themes can used change theme plot. can also edit themes plot extreme detail theme() function. can also add nicer labels plot labs() function. 5 standard labeling locations:x - x-axisy - y-axistitle - main plot titlesubtitle - directly underneath plot title smaller text (default)caption - bottom plot, right defaultFor example, can update plot previously plotted nice labels like :theme() function can also used edit defaults elements. function can take extremely large number arguments, can used edit specific aspects plot. won’t go examples, look editing aspects text elements done. basic way done :Calling specific argument theme() element want edit (e.g. plot.title plot title)Supplying element_text() function argument (versions e.g. element_rect() editing plot background aesthetics)Changing arguments element_text()example, increase size plot title size, make subtitle italicised face, right\r\njustify caption hjust. ’ll also change legend location good measure!ever want remove element plot, can also theme()! Just pass element_blank() argument theme disappear completely!","code":"\nwt_ht_plot <- wt_ht_plot + \n  # set the theme to classic\n  theme_classic() +\n  # further edit the theme to move the legend position\n  # add nicer labels\n  labs(y = \"Weight (kg)\", \n       x = \"height (cm)\",\n       title = \"Patient height and weight\",\n       subtitle = glue::glue(\"total patients {nrow(linelist_cleaned)}\"),\n       caption = \"produced by me!\")\nwt_ht_plot## `geom_smooth()` using formula 'y ~ x'\nwt_ht_plot + \n    theme(legend.position = \"bottom\",\n          # size of title is 30\n          plot.title = element_text(size = 30),\n          # right justify caption\n          plot.caption = element_text(hjust = 0),\n          # subtitle is italicised\n          plot.subtitle = element_text(face = \"italic\"))## `geom_smooth()` using formula 'y ~ x'"},{"path":"ggplot-tips.html","id":"colour-schemes","chapter":"28 ggplot tips","heading":"28.5 Colour schemes","text":"One thing can initially difficult understand ggplot2 control colour schemes passing colour fill variable rather defining explicitly within geom. simple tricks can used achieve however. Remember setting colours, can use colour names (long recognised) like \"red\", specific hex colour \"#ff0505\".One useful tricks using manual scaling functions explicity define colours. functions syntax scale_xxx_manual() (e.g. scale_colour_manual()). function can explicitly define colours map factor using values argument. can control legend title name argument, order factors breaks.want predefined palettes, can use scale_xxx_brewer scale_xxx_viridis_y functions. brewer functions can draw colorbrewer.org palettes, viridis functions can draw viridis (colourblind friendly!) palettes. Remember define palette discrete, continuous, binned specifying end function (e.g. discrete scale_xxx_viridis_d)can see using symptom-specific dataframe made previous section:","code":"\nsymp_plot <- ggplot(linelist_sym, aes(x = symptom_name, fill = symptom_is_present)) +\n  # show as a portion of all\n  geom_bar(position = \"fill\", col = \"black\") +\n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot\nsymp_plot +\n  scale_fill_manual(\n    # explicitly define colours\n    values = c(\"yes\" = \"black\",\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    # order the factors correctly\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    # legend has no title\n    name = \"\"\n  ) \nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )"},{"path":"ggplot-tips.html","id":"change-order-of-discrete-variables","chapter":"28 ggplot tips","heading":"28.6 Change order of discrete variables","text":"Changing order discrete variables appear often difficult understand people new ggplot2 graphs. ’s easy understand however understand ggplot2 handles discrete variables hood. Generally speaking, discrete varaible used, automatically converted factor type - orders factors alphabetical order default. handle , simply reorder factor levels reflect order like appear chart. detailed information reorder factor objects, see factor section guide.can look common example using age groups - default 5-9 age group placed middle age groups (given alphabetical order), can move behind 0-4 age group chart releveling factors.","code":"\n# remove the instances of age_cat5 where data is missing\nggplot(linelist_cleaned %>%\n         filter(!is.na(age_cat5)),\n       # relevel the factor within the ggplot call (can do externally as well)\n       aes(x = forcats::fct_relevel(age_cat5, \"5-9\", after = 1))) +\n  geom_histogram(stat = \"count\") +\n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  theme_minimal()"},{"path":"ggplot-tips.html","id":"multiple-plots","chapter":"28 ggplot tips","heading":"28.7 Multiple plots","text":"Often useful show multiple graphs one page, one super-figure. ways achieve lot packages can help facilitate . However, external packages nice, often easier use faceting alternative prebuilt ggplot2. Faceting plots extremely easy terms code, produces plots predictable aesthetics - wont wrangle legends ensure axes aligned etc.Faceting specific way obtain multiple plots - definition, facet show type plot facet, every plot specific level variable. done one two functions:facet_wrap() used want show different graph level single variable. One example showing different epidemic curve hospital region.facet_wrap() used want show different graph level single variable. One example showing different epidemic curve hospital region.facet_grid() used want bring second variable faceting arrangement. element grid shows intersection x y element grid. example, involve showing different epidemic curve hospital region, shown horizontally, age group, shown vertically.facet_grid() used want bring second variable faceting arrangement. element grid shows intersection x y element grid. example, involve showing different epidemic curve hospital region, shown horizontally, age group, shown vertically.can quickly become overwhelming amount information - good ensure don’t many levels variable choose facet ! quick examples malaria dataset:can also use facet_grid() approach different age groups - need data transformations first however, age groups columns - want single column. pass two variables facet_grid(), can use formula notation (e.g. x ~ y) wrap variables vars(). reference, : facet_grid(x ~ y) equivalent facet_grid(rows = vars(x), cols = vars(y)) ’s can :faceting convenient approach plotting, sometimes possible get results want relatively restrictive approach. , may choose combine plots sticking together larger plot. three well known packages great - cowplot, gridExtra, patchwork. However, packages largely things, ’ll focus cowplot section.cowplot package fairly wide range functions, easiest use can achieved use plot_grid(). effectively way arrange predefined plots grid formation. can work another example malaria dataset - can plot total cases district, also show epidemic curve time.","code":"\nmalaria_data <- rio::import(here::here(\"data\", \"facility_count_data.rds\")) \n\n# show a wrapped plot with facets by district\n\nggplot(malaria_data, aes(x = data_date, y = malaria_tot, fill = District)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"date of data collection\",\n    y = \"malaria cases\",\n    title = \"Malaria cases by district\"\n  ) +\n  facet_wrap(~District) +\n  theme_minimal()\nmalaria_age <- malaria_data %>%\n  pivot_longer(\n    # choose all the columns that start with malaria rdt (age group specific)\n    cols = starts_with(\"malaria_rdt_\"),\n    # column names become age group\n    names_to = \"age_group\",\n    # values to a single column (num_cases)\n    values_to = \"num_cases\"\n  ) %>%\n  # clean up age group column - replace \"malaria_rdt_\" to leave only age group\n  # then replace 15 with 15+\n  # then refactor the age groups so they are in order\n  mutate(age_group = str_replace(age_group, \"malaria_rdt_\", \"\") %>%\n           ifelse(. == \"15\", \"15+\", .) %>%\n           forcats::fct_relevel(., \"5-14\", after = 1))\n\n\n# make the same plot as before, but show in a grid\nggplot(malaria_age, aes(x = data_date, y = num_cases, fill = age_group)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"date of data collection\",\n    y = \"malaria cases\",\n    title = \"Malaria cases by district and age group\"\n  ) +\n  facet_grid(rows = vars(District), cols = vars(age_group)) +\n  theme_minimal()\n# bar chart of total cases by district\np1 <- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# epidemic curve over time\np2 <- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 1 column and two rows - stacked on top of each other\n                   ncol = 1,\n                   nrow = 2,\n                   # top plot is 2/3 as tall as second\n                   rel_heights = c(2, 3))"},{"path":"ggplot-tips.html","id":"marginal-distributions","chapter":"28 ggplot tips","heading":"28.8 Marginal distributions","text":"show distributions edges geom_point() scatterplot, can use ggExtra package function ggMarginal(). Save original ggplot object, pass ggMarginal() shown . key arguments:must specify type = either “histogram”, “density” “boxplot”, “violin”, “densigram”.default, marginal plots appear axes. can set margins = “x” “y” want one.optional arguments include fill = (bar color), color = (line color), size = (plot size relative margin size, larger number makes marginal plot smaller).can provide axis-specific arguments xparams = yparams =. example, different histogram bin sizes, shown .can marginal plots reflect groups (columns assigned color = ggplot() mapped aesthetics). case, set ggMarginal() argument groupColour = groupFill = TRUE, shown .Read vignette, R Graph Gallery function R documentation ?ggMarginal.add marginal histograms:Marginal histograms grouped/colored values:Marginal density curve, demonstration size color arguments:Marginal boxplots, demonstration margins argument:","code":"\n# Install/load ggExtra\npacman::p_load(ggExtra)\n\n# Basic scatter plot of weight and age\nscatter_plot <- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n# with histograms\nggMarginal(\n  scatter_plot,                     # add marginal histograms\n  type = \"histogram\",               # specify histograms\n  fill = \"lightblue\",               # bar fill\n  xparams = list(binwidth = 10),    # other parameters for x-axis marginal\n  yparams = list(binwidth = 5))     # other parameters for y-axis marginal\n# Scatter plot, colored by outcome\n# Outcome column is assigned as color in ggplot. groupFill in ggMarginal set to TRUE\nscatter_plot_color <- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = outcome)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"histogram\", groupFill = TRUE)\n# with density curves\nggMarginal(\n  scatter_plot,\n  type = \"density\",\n  color = \"red\",                    # line color\n  size = 4)                         # smaller number makes larger marginal plots\n# with boxplot \nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # only show x-axis marginal plot\n  type = \"boxplot\")   "},{"path":"ggplot-tips.html","id":"smart-labeling","chapter":"28 ggplot tips","heading":"28.9 Smart Labeling","text":"ggplot2, also possible add text plots. However, comes notable limitation text labels often clash data points plot, making look messy hard read. ideal way deal base package, ggplot2 add-, known ggrepel makes dealing simple!ggrepel package provides two new functions, geom_label_repel() geom_text_repel(), replace geom_label() geom_text(). Simply use functions instead base functions produce neat labels. Within function, map aesthetics aes() always, include argument label = provide column name containing values want display (e.g. patient id, name, etc.). can make complex labels combining columns newlines (\\n) within str_glue() shown .tips:Use min.segment.length = 0 always draw line segments, min.segment.length = Inf never draw themUse size = outside aes() set text sizeUse force = change degree repulsion labels respective points (default 1)Include fill = within aes() label colored value\r\nletter “” may appear legend - add guides(fill = guide_legend(override.aes = aes(color = NA)))+ remove \r\nletter “” may appear legend - add guides(fill = guide_legend(override.aes = aes(color = NA)))+ remove itSee -depth tutorial .can label subset data points - using standard ggplot() syntax provide different data = geom layer plot. , cases plotted, labeled.","code":"\npacman::p_load(ggrepel)\n\nlinelist %>%                                               # start with linelist\n  group_by(hospital) %>%                                   # group by hospital\n  summarise(                                               # create new dataset with summary values per hospital\n    n_cases = n(),                                           # number of cases per hospital\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # mean delay per hospital\n  ) %>% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # send data frame to ggplot\n  geom_point(size = 2)+                                    # add points\n  geom_label_repel(                                        # add point labels\n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # how label displays\n      ), \n    size = 3,                                              # text size in labels\n    min.segment.length = 0)+                               # show all line segments                \n  labs(                                                    # add axes labels\n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\nggplot()+\n  # All points in grey\n  geom_point(\n    data = linelist_cleaned,                                   # all data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # grey and semi-transparent\n  \n  # Few points in black\n  geom_point(\n    data = linelist_cleaned %>% filter(days_onset_hosp > 15),  # filtered data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # default black and not transparent\n  \n  # point labels for few points\n  geom_label_repel(\n    data = linelist_cleaned %>% filter(days_onset_hosp > 15),  # filter the data for the labels\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # label color by outcome\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # label created with str_glue()\n    min.segment.length = 0) +                                  # show line segments for all\n  \n  # remove letter \"a\" from inside legend boxes\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # axis labels\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")"},{"path":"ggplot-tips.html","id":"time-axes","chapter":"28 ggplot tips","heading":"28.10 Time axes","text":"Working time axes ggplot can seem daunting, made easy key functions. Remember working time date ensure correct variables formatted date datetime class - see Working dates page information , Epidemic curves page (ggplot section) examples.single useful set functions working dates ggplot2 scale functions (scale_x_date(), scale_x_datetime(), cognate y-axis functions). functions let define often axis labels, format axis labels. find format dates, see working dates section ! can use date_breaks date_labels arguments specify dates look:date_breaks allows specify often axis breaks occur - can pass string (e.g. \"3 months\", \"2 days\")date_breaks allows specify often axis breaks occur - can pass string (e.g. \"3 months\", \"2 days\")date_labels allows define format dates shown . can pass date format string arguments (e.g. \"%b-%d-%Y\"):date_labels allows define format dates shown . can pass date format string arguments (e.g. \"%b-%d-%Y\"):","code":"\n# make epi curve by date of onset when available\nggplot(linelist_cleaned, aes(x = date_onset)) +\n  geom_bar(stat = \"count\") +\n  scale_x_date(\n    # 1 break every 1 month\n    date_breaks = \"1 months\",\n    # labels should show month then date\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()"},{"path":"ggplot-tips.html","id":"highlighting","chapter":"28 ggplot tips","heading":"28.11 Highlighting","text":"Highlighting specific elements chart useful way draw attention specific instance variable also providing information dispersion full dataset. easily done base ggplot2, external package can help known gghighlight. easy use within ggplot syntax.gghighlight package uses gghighlight() function achieve effect. use function, supply logical statement function - can quite flexible outcomes, ’ll show example age distribution cases linelist, highlighting outcome.also works well faceting functions - allows user produce facet plots background data highlighted doesn’t apply facet!","code":"\n# load gghighlight\nlibrary(gghighlight)\n\n\n# replace NA values with unknown in the outcome variable\nlinelist_cleaned <- linelist_cleaned %>%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# produce a histogram of all cases by age\nggplot(linelist_cleaned, \n       aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  # highlight instances where the patient has died.\n  gghighlight::gghighlight(outcome == \"Death\")\n# produce a histogram of all cases by age\nggplot(linelist_cleaned, \n       aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  # highlight instances where the patient has died.\n  gghighlight::gghighlight() +\n  facet_wrap(~outcome)"},{"path":"ggplot-tips.html","id":"dual-axes","chapter":"28 ggplot tips","heading":"28.12 Dual axes","text":"secondary y-axis often requested addition ggplot2 graph. robust debate validity graphs data visualization community, often recommended, manager may still want . , present two methods achieve .Using cowplot package combine two separate plotsUsing statistical transformation data primary axis","code":""},{"path":"ggplot-tips.html","id":"using-cowplot","chapter":"28 ggplot tips","heading":"Using cowplot","text":"approach involves creating two separate plots - one y-axis left, y-axis right. use specific theme_cowplot() must x-axis. third command two plots aligned overlaid top . functionalities cowplot, one, described depth site.demonstrate technique overlay epidemic curve line weekly percent patients died. use example alignment dates x-axis complex say, aligning bar chart another plot. things note:epicurve line aggregated weeks prior plotting date_breaks date_labels identical - x-axes two plots overlaid.y-axis moved right-side plot 2 position = argument scale_y_continuous().plots make use theme_cowplot()Note another example technique [Epicurves] page - overlaying cumulative incidence top epicurve.Make plot 1\r\nessentially epicurve. use geom_area() just demonstrate use (area line, default)Make plot 2\r\nCreate second plot showing line weekly percent cases died.Now align plot using function align_plots(), specifying horizontal vertical alignment (“hv”, also “h”, “v”, “none”). specify alignment axes well (top, bottom, left, right) “tblr”. output class list (2 elements).draw two plots together using ggdraw() (cowplot) referencing two parts aligned_plots object.","code":"\npacman::p_load(cowplot)            # load/install cowplot\n\np1 <- linelist %>%                 # save plot as object\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # view plot \np2 <- linelist %>%         # save plot as object\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %>% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # view plot\naligned_plots <- align_plots(p1, p2, align=\"hv\", axis=\"tblr\")                  # align the two plots and save them as list\naligned_plotted <- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # overlay them and save the visual plot\naligned_plotted                                                                # print the overlayed plots"},{"path":"ggplot-tips.html","id":"statistical-transformation","chapter":"28 ggplot tips","heading":"Statistical transformation","text":"Unfortunately, secondary axes well supported ggplot syntax. reason, ’re fairly limited terms can shown secondary axis - second axis direct transformation secondary axis.Differences axis values purely cosmetic - want show two different variables one graph, different y-axis scales variable, work without work behind scenes. obtain effect, transform one variables data, apply transformation reverse specifying axis labels. Based , can either specify transformation explicitly (e.g. variable around 10x large variable b) calculate code (e.g. ratio maximum values dataset).syntax adding secondary axis straightforward! calling scale_xxx_xxx() function (e.g. scale_y_continuous()), use sec.axis argument call sec_axis() function. trans argument function allows specify label transformation axis - provide standard tidyverse syntax.example, want show number positive RDTs malaria dataset facility 1, showing 0-4 year olds cases chart:","code":"\n# take malaria data from facility 1\nmalaria_facility_1 <- malaria_data %>%\n  filter(location_name == \"Facility 1\")\n\n# calculate the ratio between malaria_rdt_0-4 and malaria_tot \n\ntf_ratio <- max(malaria_facility_1$malaria_tot, na.rm = T) / max(malaria_facility_1$`malaria_rdt_0-4`, na.rm = T)\n\n# transform the values in the dataset\n\nmalaria_facility_1 <- malaria_facility_1 %>%\n  mutate(malaria_rdt_0_4_tf = `malaria_rdt_0-4` * tf_ratio)\n  \n\n# plot the graph with dual axes\n\nggplot(malaria_facility_1, aes(x = data_date)) +\n  geom_line(aes(y = malaria_tot, col = \"Total cases\")) +\n  geom_line(aes(y = malaria_rdt_0_4_tf, col = \"Cases: 0-4 years old\")) +\n  scale_y_continuous(\n    name = \"Total cases\",\n    sec.axis = sec_axis(trans = ~ . / tf_ratio, name = \"Cases: 0-4 years old\")\n  ) +\n  labs(x = \"date of data collection\") +\n  theme_minimal() +\n  theme(legend.title = element_blank())"},{"path":"ggplot-tips.html","id":"miscellaneous","chapter":"28 ggplot tips","heading":"28.13 Miscellaneous","text":"","code":""},{"path":"ggplot-tips.html","id":"numeric-display","chapter":"28 ggplot tips","heading":"Numeric display","text":"can disable scientific notation running command prior plotting.apply number_format() scales package specific value column, shown .Use functions package scales easily adjust numbers displayed. can applied columns data frame, shown individual numbers purpose example.","code":"\noptions(scipen=999)\nscales::number(6.2e5)## [1] \"620 000\"\nscales::number(1506800.62,  accuracy = 0.1,)## [1] \"1 506 800.6\"\nscales::comma(1506800.62, accuracy = 0.01)## [1] \"1,506,800.62\"\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")## [1] \"1.506.800,62\"\nscales::percent(0.1)## [1] \"10%\"\nscales::dollar(56)## [1] \"$56\"\nscales::scientific(100000)## [1] \"1e+05\""},{"path":"ggplot-tips.html","id":"resources-21","chapter":"28 ggplot tips","heading":"28.14 Resources","text":"Inspiration\r\nggplot graph galleryPresentation data\r\nEuropean Centre Disease Prevention Control Guidelines presentation surveillance dataFacets labellers\r\nUsing labellers facet strips\r\nLabellersAdjusting order factors\r\nfct_reorderfct_inorderHow reorder boxplotReorder variable ggplot2R Data Science - FactorsLegendsAdjust legend orderCaptions\r\nCaption alignmentLabelsggrepelCheatsheetsBeautiful plotting ggplot2TO - constructionUsing option label_wrap_gen facet_wrap multiple strip lines\r\nlabels colors stripsAxis text vertical adjustment\r\nrotation\r\nLabellerslimit range limit() coord_cartesian(), ylim(), scale_x_continuous()\r\ntheme_classic()expand = c(0,0)\r\ncoord_flip()\r\ntick marksggrepel\r\nanimationsremove\r\nremove title\r\nusing fill = color = labs()\r\nflip order / don’t flip order\r\nmove location\r\ncolor? theme(legend.title = element_text(colour=“chocolate”, size=16, face=“bold”))+ scale_color_discrete(name=“color ischocolate!?”)\r\nColor boxes behind points legend\r\ntheme(legend.key=element_rect(fill=‘pink’)) use fill = NA remove . http://zevross.com/blog/2014/08/04/beautiful-plotting--r--ggplot2-cheatsheet-3/\r\nChange size symbols legend guides(colour = guide_legend(override.aes = list(size=4)))Turn layer legend\r\ngeom_text(data=nmmaps, aes(date, temp, label=round(temp)), size=4)\r\ngeom_text(data=nmmaps, aes(date, temp, label=round(temp), size=4), show_guide=FALSE)Force legend even aes().\r\nggplot(nmmaps, aes(x=date, y=o3))+\r\ngeom_line(aes(color=“Important line”))+\r\ngeom_point(aes(color=“points”))\r\nControl shape legend guides - list linetype shape\r\nggplot(nmmaps, aes(x=date, y=o3))+geom_line(aes(color=“Important line”))+\r\ngeom_point(aes(color=“Point values”))+\r\nscale_colour_manual(name=’‘, values=c(’Important line’=‘grey’, ‘Point values’=‘red’), guide=‘legend’) +\r\nguides(colour = guide_legend(override.aes = list(linetype=c(1,0)\r\n, shape=c(NA, 16))))","code":""},{"path":"epidemic-curves.html","id":"epidemic-curves","chapter":"29 Epidemic curves","heading":"29 Epidemic curves","text":"epidemic curve (also known “epi curve”) core epidemiological chart typically used visualize temporal pattern illness onset among cluster epidemic cases.Analysis epicurve can reveal temporal trends, outliers, magnitude outbreak, likely time period exposure, time intervals case generations, can even help identify mode transmission unidentified disease (e.g. point source, continuous common source, person--person propagation). One online lesson interpretation epi curves can found website US CDC.page demonstrate two approaches producing epicurves R:incidence2 package, can produce epi curve simple commandsThe ggplot2 package, allows advanced customizability via complex commandsAlso addressed specific use-cases :Plotting aggregated count dataFaceting producing small-multiplesApplying moving averagesShowing data “tentative” subject reporting delaysOverlaying cumulative case incidence using second axis","code":""},{"path":"epidemic-curves.html","id":"preparation-20","chapter":"29 Epidemic curves","heading":"29.1 Preparation","text":"","code":""},{"path":"epidemic-curves.html","id":"packages-2","chapter":"29 Epidemic curves","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # file import/export\n  here,         # relative filepaths \n  lubridate,    # working with dates/epiweeks\n  aweek,        # alternative package for working with dates/epiweeks\n  incidence2,   # epicurves of linelist data\n  i2extras,     # supplement to incidence2\n  stringr,      # search and manipulate character strings\n  forcats,      # working with factors\n  RColorBrewer, # Color palettes from colorbrewer2.org\n  tidyverse     # data management + ggplot2 graphics\n) "},{"path":"epidemic-curves.html","id":"import-data-14","chapter":"29 Epidemic curves","heading":"Import data","text":"Two example datasets used section:Linelist individual cases simulated epidemicAggregated counts hospital simulated epidemicThe datasets imported using import() function rio package. See page Import export various ways import data.Case linelistWe import dataset cases simulated Ebola epidemic. want download data follow step--step, see instruction Download book data page.first 50 rows displayed .Case counts aggregated hospitalFor purposes handbook, dataset weekly aggregated counts hospital created linelist following code.first 50 rows displayed :","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")\n# import the counts data into R\ncount_data <- linelist %>% \n  group_by(hospital, date_hospitalisation) %>% \n  summarize(n_cases = dplyr::n()) %>% \n  filter(date_hospitalisation > as.Date(\"2013-06-01\")) %>% \n  ungroup()"},{"path":"epidemic-curves.html","id":"set-parameters","chapter":"29 Epidemic curves","heading":"Set parameters","text":"production report, may want set editable parameters date data current (“data date”).\r\ncan reference object data_date code applying filters dynamic captions.","code":"\n## set the report date for the report\n## note: can be set to Sys.Date() for the current date\ndata_date <- as.Date(\"2015-05-15\")"},{"path":"epidemic-curves.html","id":"verify-dates","chapter":"29 Epidemic curves","heading":"Verify dates","text":"Verify relevant date column class Date appropriate range values. can simply using hist() histograms, range() na.rm=TRUE, ggplot() .","code":"\n# check range of onset dates\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))"},{"path":"epidemic-curves.html","id":"epicurves-with-incidence2-package","chapter":"29 Epidemic curves","heading":"29.2 Epicurves with incidence2 package","text":"demonstrate make epicurves using incidence2 package. authors package tried allow user create modify epicurves without needing know ggplot2 syntax. Much page adapted package vignettes, can found incidence2 github page.","code":""},{"path":"epidemic-curves.html","id":"simple-example","chapter":"29 Epidemic curves","heading":"Simple example","text":"2 steps required plot epidemic curve incidence2 package:Create incidence object (using function incidence())\r\nProvide data\r\nSpecify date column date_index =\r\nSpecify interval = cases aggregated (daily, weekly, monthly..)\r\nSpecify grouping columns (e.g. gender, hospital, outcome)\r\nProvide dataSpecify date column date_index =Specify interval = cases aggregated (daily, weekly, monthly..)Specify grouping columns (e.g. gender, hospital, outcome)Plot incidence object\r\nSpecify labels, colors, titles, etc.\r\nSpecify labels, colors, titles, etc., load incidence2 package, create incidence object linelist column date_onset aggregated cases day. print summary incidence object.plot incidence object, use plot() name incidence object. background, function plot.incidence2() called, read incidence2-specific documentation run ?plot.incidence2.","code":"\n# load incidence2 package\npacman::p_load(incidence2)\n\n# create the incidence object, aggregating cases by day\nepi_day <- incidence(       # create incidence object\n  x = linelist,             # dataset\n  date_index = date_onset,  # date column\n  interval = \"day\"          # date grouping interval\n  )\n\n# print summary of the incidence object\nsummary(epi_day)## An incidence2 object: 389 x 2\r\n## 5632 cases from days 2014-04-07 to 2015-04-30\r\n## interval: 1 day\r\n## cumulative: FALSE\r\n## timespan: 389 days\n# plot the incidence object\nplot(epi_day)"},{"path":"epidemic-curves.html","id":"change-time-interval-of-case-aggregation","chapter":"29 Epidemic curves","heading":"Change time interval of case aggregation","text":"interval argument incidence() defines observations grouped vertical bars.Specify intervalincidence2 provides flexibility understandable syntax specifying want aggregate cases epicurve bars. Provide value like ones interval = argument:examples different intervals look applied linelist. Note default format frequency date labels x-axis change date interval changes.Begin first caseIf want intervals begin first case, can add argument standard = TRUE incidence() command. works interval either “week”, “month”, “quarter” “year”.First late dateYou can optionally specify first_date = last_date = incidence() command. given, data trimmed range.","code":"\n# Create the incidence objects (with different intervals)\n##############################\n# Weekly (Monday week by default)\nepi_wk      <- incidence(linelist, date_onset, interval = \"Monday week\")\n\n# Sunday week\nepi_Sun_wk  <- incidence(linelist, date_onset, interval = \"Sunday week\")\n\n# Three weeks (Monday weeks by default)\nepi_2wk     <- incidence(linelist, date_onset, interval = \"2 weeks\")\n\n# Monthly\nepi_month   <- incidence(linelist, date_onset, interval = \"month\")\n\n# Quarterly\nepi_quarter   <- incidence(linelist, date_onset, interval = \"quarter\")\n\n# Years\nepi_year   <- incidence(linelist, date_onset, interval = \"year\")\n\n\n# Plot the incidence objects (+ titles for clarity)\n############################\nplot(epi_wk)+      labs(title = \"Monday weeks\")\nplot(epi_Sun_wk)+  labs(title = \"Sunday weeks\")\nplot(epi_2wk)+     labs(title = \"2 (Monday) weeks\")\nplot(epi_month)+   labs(title = \"Months\")\nplot(epi_quarter)+ labs(title = \"Quarters\")\nplot(epi_year)+    labs(title = \"Years\")"},{"path":"epidemic-curves.html","id":"groups","chapter":"29 Epidemic curves","heading":"Groups","text":"Groups specified incidence() command, can used color bars facet data. specify groups data provide column name(s) groups = argument incidence() command (quotes). specifying multiple columns, put names within c().can specify cases missing values grouping columns listed distinct NA group setting na_as_group = TRUE. Otherwise, excluded plot.color bars grouping column*, must provide column name fill = plot() command.color bars grouping column*, must provide column name fill = plot() command.facet based grouping column*, see section facets incidence2.facet based grouping column*, see section facets incidence2.example , cases whole outbreak grouped age category. Missing values included group. epicurve interval weeks.TIP: Change title legend adding + ggplot2 command labs(fill = \"title\") incidence2 plot.can also grouped bars display side--side setting stack = FALSE plot(), shown :","code":"\n# Create incidence object, with data grouped by age category\nage_outbreak <- incidence(\n  linelist,                # dataset\n  date_index = date_onset, # date column\n  interval = \"week\",       # Monday weekly aggregation of cases\n  groups = age_cat,        # age_cat is set as a group\n  na_as_group = TRUE)      # missing values assigned their own group\n\n# plot the grouped incidence object\nplot(\n  age_outbreak,             # incidence object with age_cat as group\n  fill = age_cat)+          # age_cat is used for bar fill color (must have been set as a groups column above)\nlabs(fill = \"Age Category\") # change legend title from default \"age_cat\" (this is a ggplot2 modification)\n# Make incidence object of monthly counts. \nmonthly_gender <- incidence(\n linelist,\n date_index = date_onset,\n interval = \"month\",\n groups = gender            # set gender as grouping column\n)\n\nplot(\n  monthly_gender,   # incidence object\n  fill = gender,    # display bars colored by gender\n  stack = FALSE)    # side-by-side (not stacked)"},{"path":"epidemic-curves.html","id":"filtered-data","chapter":"29 Epidemic curves","heading":"Filtered data","text":"plot epicurve subset data:Filter linelist dataProvide filtered data incidence() commandPlot incidence objectThe example uses data filtered show cases Central Hospital.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(central_data, date_index = date_onset, interval = \"week\")\n\n# plot the incidence object\nplot(central_outbreak) + labs(title = \"Weekly case incidence at Central Hospital\")"},{"path":"epidemic-curves.html","id":"aggregated-counts","chapter":"29 Epidemic curves","heading":"Aggregated counts","text":"original data aggregated (counts), provide name column contains case counts count = argument creating incidence object.example, data frame count_data linelist aggregated daily counts hospital. first 50 rows look like :beginning analysis daily count data like dataset , incidence() command convert weekly epicurve hospital look like :","code":"\nepi_counts <- incidence(\n  count_data,                         # dataset with counts aggregated by day\n  date_index = date_hospitalisation,  # column with dates\n  count = n_cases,                    # column with counts\n  interval = \"week\",                  # aggregate daily counts up to weeks\n  groups = hospital                   # group by hospital\n  )\n\n# plot the weekly incidence epi curve, with stacked bars by hospital\nplot(epi_counts,                      # incidence object\n     fill = hospital)                 # color the bars by hospital"},{"path":"epidemic-curves.html","id":"facetssmall-multiples","chapter":"29 Epidemic curves","heading":"Facets/small multiples","text":"facet data group (.e. produce “small multiples”):Specify faceting column groups = create incidence objectUse facet_plot() command instead plot()Specify grouping columns use fill = use facets =, set columns hospital outcome grouping columns incidence() command. , facet_plot() plot epicurve, specifying want different epicurve hospital within epicurve bars stacked colored outcome.","code":"\nepi_wks_hosp_out <- incidence(\n  linelist,                      # dataset\n  date_index = date_onset,       # date column\n  interval = \"month\",            # monthly bars  \n  groups = c(outcome, hospital)  # both outcome and hospital are given as grouping columns\n  )\n\n# plot\nfacet_plot(\n  epi_wks_hosp_out,    # incidence object\n  facets = hospital,   # facet column\n  fill = outcome)      # fill column"},{"path":"epidemic-curves.html","id":"modifications-with-plot","chapter":"29 Epidemic curves","heading":"Modifications with plot()","text":"epicurve produced incidence2 can modified via arguments within incidence2 plot() function.plot() arguments relating bars:plot() arguments relating date axis:TIP: breaks every “nth” interval (e.g. every 4th), use n_breaks = nrow()/n (“” incidence object name “n” number). data grouped, need multiply “n” number unique groups.plot() arguments relating labels:example using many arguments:adjust plot appearance, see section applying ggplot() incidence plot.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = c(outcome))\n\n# plot incidence object\nplot(\n  central_outbreak,\n  fill = outcome,                       # box/bar color\n  legend = \"top\",                       # legend on top\n  title = \"Cases at Central Hospital\",  # title\n  xlab = \"Week of onset\",               # x-axis label\n  ylab = \"Week of onset\",               # y-axis label\n  show_cases = TRUE,                    # show each case as an individual box\n  centre_ticks = TRUE,                  # ticks appear in center of interval\n  alpha = 0.7,                          # transparency \n  border = \"grey\",                      # box border\n  format = \"%a %d %B\\n%Y (Week %W)\",    # adjust date label format - see dates Handbook page\n  n_breaks = nrow(central_outbreak)/15, # date labels every X weeks\n  angle = 45                            # angle of date labels\n  )"},{"path":"epidemic-curves.html","id":"modifications-with-ggplot2","chapter":"29 Epidemic curves","heading":"Modifications with ggplot2","text":"can modify incidence2 plot adding ggplot2 modifications + close incidence plot() function, demonstrated ., incidence2 plot finishes ggplot2 commands used modify axes, add caption, adjust bold font text size.Note add scale_x_date(), date formatting plot() overwritten. See ggplot() epicurves section Handbook page ggplot tips options.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = c(outcome))\n\n# plot incidence object\nplot(\n  central_outbreak,\n  fill = outcome,                       # box/bar color\n  legend = \"top\",                       # legend on top\n  title = \"Cases at Central Hospital\",  # title\n  xlab = \"Week of onset\",               # x-axis label\n  ylab = \"Week of onset\",               # y-axis label\n  show_cases = TRUE,                    # show each case as an individual box\n  centre_ticks = TRUE,                  # ticks appear in center of interval\n  alpha = 0.7,                          # transparency \n  border = \"grey\",                      # box border\n  #format = \"%a %d %B\\n%Y (Week %W)\",    # overwritten below\n  #n_breaks = nrow(central_outbreak)/15, # overwritten below\n  angle = 45                           # angle of date labels\n  )+\n  \n  # Add modifications using ggplot() functions\n  ############################################\n  scale_x_date(                              # converts to ggplot date scale (changes default label format)\n    expand = c(0,0),                         # remove excess space on left and right\n    date_labels = \"%a %d %B\\n%Y (Week %W)\",  # set how dates appear\n    date_breaks = \"6 weeks\"                  # set how often dates appear\n    )+      \n  \n  scale_y_continuous(\n    breaks = seq(from = 0, to = 30, by = 5),  # specify y-axis increments by 5\n    expand = c(0,0))+                         # remove excess space below 0 on y-axis\n  \n  # add dynamic caption\n  labs(\n    fill = \"Patient outcome\",                               # Legend title\n    caption = stringr::str_glue(                            # dynamic caption - see page on characters and strings for details\n      \"n = {central_cases} from Central Hospital\n      Case onsets range from {earliest_date} to {latest_date}. {missing_onset} cases are missing date of onset and not shown\",\n      central_cases = nrow(central_data),\n      earliest_date = format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y'),\n      latest_date = format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y'),      \n      missing_onset = nrow(central_data %>% filter(is.na(date_onset)))))+\n  \n  # adjust bold face, and caption position\n  theme(\n    axis.title = element_text(size = 12, face = \"bold\"),    # axis titles larger and bold\n    axis.text = element_text(size = 10, face = \"bold\"),     # axis text size and bold\n    plot.caption = element_text(hjust = 0, face = \"italic\") # move caption to left\n  )"},{"path":"epidemic-curves.html","id":"change-colors","chapter":"29 Epidemic curves","heading":"Change colors","text":"","code":""},{"path":"epidemic-curves.html","id":"specify-a-palette","chapter":"29 Epidemic curves","heading":"Specify a palette","text":"Provide name pre-defined palette col_pal = argument plot(). incidence2 package comes 2 pre-defined paletted: “vibrant” “muted”. “vibrant” first 6 colors distinct “muted” first 9 colors distinct. numbers, colors interpolations/intermediaries colors. pre-defined palettes can found website. palettes exclude grey, reserved missing data (use na_color = change default).can also use one base R palettes (put name palette without quotes).can also add color palette viridis package RColorBrewer package. First packages must loaded, add respective scale_fill_*() functions +, shown .","code":"\n# Create incidence object, with data grouped by age category  \nage_outbreak <- incidence(\n  linelist,\n  date_index = date_onset,   # date of onset for x-axis\n  interval = \"week\",         # weekly aggregation of cases\n  groups = age_cat)\n\n# plot the epicurve with default palette\nplot(age_outbreak, fill = age_cat, title = \"'vibrant' default incidence2 palette\")\n\n# plot with different color palette\n#plot(age_outbreak, fill = age_cat, col_pal = muted, title = \"'muted' incidence2 palette\")\n# plot with base R palette\nplot(age_outbreak, fill = age_cat, col_pal = heat.colors, title = \"base R heat.colors palette\")\n\n# plot with base R palette\nplot(age_outbreak, fill = age_cat, col_pal = rainbow, title = \"base R rainbow palette\")\npacman::p_load(RColorBrewer, viridis)\n\n# plot with color palette\nplot(age_outbreak, fill = age_cat, title = \"Viridis palette\")+\n  scale_fill_viridis_d(\n    option = \"inferno\",     # color scheme, try also \"plasma\" or the default\n    name = \"Age Category\",  # legend name\n    na.value = \"grey\")      # for missing values\n\n# plot with color palette\nplot(age_outbreak, fill = age_cat, title = \"RColorBrewer palette\")+\n  scale_fill_brewer(\n    palette = \"Dark2\",      # color palette, try also Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3\n    name = \"Age Category\",  # legend name\n    na.value = \"grey\")      # for missing values"},{"path":"epidemic-curves.html","id":"specify-manually","chapter":"29 Epidemic curves","heading":"Specify manually","text":"specify colors manually, add ggplot2 function scale_fill_manual() plot() + provide vector colors names HEX codes argument values =. number colors listed must equal number groups. aware whether missing values group - can converted character value like “Missing” data preparation function fct_explicit_na() explained page Factors.mentioned ggplot tips page, can create palettes using colorRampPalette() vector colors specifying number colors want return. good way get many colors ramp specifying .","code":"\n# manual colors\nplot(age_outbreak, fill = age_cat, title = \"Manually-specified colors\")+\n  scale_fill_manual(\n    values = c(\"darkgreen\", \"darkblue\", \"purple\", \"grey\", \"yellow\", \"orange\", \"red\", \"lightblue\"),  # colors\n    name = \"Age Category\")      # Name for legend\nmy_cols <- c(\"darkgreen\", \"darkblue\", \"purple\", \"grey\", \"yellow\", \"orange\")\nmy_palette <- colorRampPalette(my_cols)(12)  # expand the 6 colors above to 12 colors\nmy_palette##  [1] \"#006400\" \"#00363F\" \"#00097E\" \"#3A0BAF\" \"#821ADD\" \"#A84BE2\" \"#B592CB\" \"#C9C99B\" \"#E7E745\" \"#FFF600\" \"#FFCD00\" \"#FFA500\""},{"path":"epidemic-curves.html","id":"adjust-level-order-1","chapter":"29 Epidemic curves","heading":"Adjust level order","text":"adjust order group appearance (plot legend), grouping column must class Factor. See page Factors information.First, let’s see weekly epicurve hospital default ordering:Now, adjust order “Missing” “” top epicurve can following:Load package forcats, work factorsAdjust dataset - case ’ll define new dataset (plot_data) :\r\ngender column defined factor as_factor()\r\norder levels defined fct_relevel() “” “Missing” first appear top bars\r\ngender column defined factor as_factor()order levels defined fct_relevel() “” “Missing” first appear top barsThe incidence object created plotted beforeWe add ggplot2 modifications\r\nscale_fill_manual() manually assign colors “Missing” grey “” beige\r\nscale_fill_manual() manually assign colors “Missing” grey “” beigeTIP: want reverse order legend , add ggplot2 command guides(fill = guide_legend(reverse = TRUE)).","code":"\n# ORIGINAL - hospital NOT as factor\n###################################\n\n# create weekly incidence object, rows grouped by hospital and week\nhospital_outbreak <- incidence(\n  linelist,\n  date_index = date_onset, \n  interval = \"week\", \n  groups = hospital)\n\n# plot incidence object\nplot(hospital_outbreak, fill = hospital, title = \"ORIGINAL - hospital not a factor\")\n# MODIFIED - hospital as factor\n###############################\n\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Convert hospital column to factor and adjust levels\nplot_data <- linelist %>% \n  mutate(hospital = as_factor(hospital)) %>%                      # define as factor\n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Set \"Missing\" and \"Other\" as top levels\n\n\n# Create weekly incidence object, grouped by hospital and week\nhospital_outbreak_mod <- incidence(\n  plot_data,\n  date_index = date_onset, \n  interval = \"week\", \n  groups = hospital)\n\n# plot incidence object\nplot(hospital_outbreak_mod, fill = hospital)+\n  \n  # manual specify colors\n  scale_fill_manual(values = c(\"grey\", \"beige\", \"darkgreen\", \"green2\", \"orange\", \"red\", \"pink\"))+                      \n\n  # labels added via ggplot\n  labs(\n      title = \"MODIFIED - hospital as factor\",   # plot title\n      subtitle = \"Other & Missing at top of epicurve\",\n      y = \"Weekly case incidence\",               # y axis title  \n      x = \"Week of symptom onset\",               # x axis title\n      fill = \"Hospital\")                         # title of legend     "},{"path":"epidemic-curves.html","id":"vertical-gridlines","chapter":"29 Epidemic curves","heading":"Vertical gridlines","text":"plot default incidence2 settings, may notice vertical gridlines appear date label date label. can result gridlines intersecting top bars.can specify interval gridlines adding ggplot2’s scale_x_date() command incidence2 plot. Within , specify intervals date_breaks = date_minor_breaks = (e.g. “weeks” “3 weeks” “months”). Note use scale_x_date() -ride formatting date labels plot(), need specify string format date_labels = .can also remove gridlines adding ggplot2 command theme_classic().Note however, using weeks, date_breaks date_minor_breaks arguments work Monday weeks. weeks another day week need manually provide vector dates breaks = minor_breaks = arguments instead. See ggplot2 section examples using seq.Date().","code":"\n# make incidence object\na <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"Monday weeks\"\n)\n\n# Default gridlines\nplot(a, title = \"Default lines\")\n\n# Specified gridline intervals\nplot(a, title = \"Weekly lines\")+\n  scale_x_date(\n    date_breaks = \"4 weeks\",      # major vertical lines align on weeks\n    date_minor_breaks = \"weeks\",  # minor vertical lines every week\n    date_labels = \"%a\\n%d\\n%b\")   # format of date labels\n\n# No gridlines\nplot(a, title = \"No lines\")+\n  theme_classic()                 # remove all gridlines"},{"path":"epidemic-curves.html","id":"cumulative-incidence","chapter":"29 Epidemic curves","heading":"Cumulative incidence","text":"can easily produce plot cumulative incidence passing incidence object incidence2 command cumulate() plot(). also works facet_plot().See section farther page alternative method plot cumulative incidence ggplot2 - example overlay cumulative incidence line epicurve.","code":"\n# make weekly incidence object\nwkly_inci <- incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"week\"\n)## 256 missing observations were removed.\n# plot cumulative incidence\nwkly_inci %>% \n  cumulate() %>% \n  plot()"},{"path":"epidemic-curves.html","id":"rolling-average","chapter":"29 Epidemic curves","heading":"Rolling average","text":"can add rolling average incidence2 plot easily add_rolling_average() i2extras package. Pass incidence2 object function, plot(). Set = number previous days want included rolling average (default 2). data grouped, rolling average calculated per group.learn apply rolling averages generally data, see Handbook page [Rolling averages].","code":"\nrolling_avg <- incidence(                    # make incidence object\n  linelist,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = gender) %>% \n  \n  i2extras::add_rolling_average(before = 6)  # add rolling averages (in this case, by gender)\n\n# plot\nplot(rolling_avg, n_breaks = 3, format = \"%d %b\\n%Y\") # faceted automatically because rolling average on groups"},{"path":"epidemic-curves.html","id":"epicurves-with-ggplot2","chapter":"29 Epidemic curves","heading":"29.3 Epicurves with ggplot2","text":"Using ggplot() build epicurve allows flexibility, requires effort understanding ggplot() works. also easier accidentally make mistakes.Unlike using incidence2 package, must manually control aggregation cases time (weeks, months, etc) intervals labels date axis. must carefully managed.One advantage using ggplot2 can create histogram without lines bars. traditional epidemic curve.examples use subset linelist dataset - cases Central Hospital.produce epicurve ggplot() three main elements:histogram, linelist cases aggregated “bins” distinguished specific “break” pointsScales axes labelsThemes plot appearance, including titles, labels, captions, etc.","code":"\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")"},{"path":"epidemic-curves.html","id":"specify-case-bins","chapter":"29 Epidemic curves","heading":"Specify case bins","text":"show specify cases aggregated histogram bins (“bars”). important recognize aggregation cases histogram bins necessarily intervals dates appear x-axis.perhaps simple code produce daily weekly epicurves.-arching ggplot() command dataset provided data =. Onto foundation, geometry histogram added +. Within geom_histogram(), map aesthetics column date_onset mapped x-axis. Also within geom_histogram() within aes() set binwidth = histogram bins, days. ggplot2 syntax confusing, review page ggplot tips.CAUTION: Plotting weekly cases using binwidth = 7 starts first 7-day bin first case, day week! create specific weeks, see section .Let us note first case Central Hospital dataset symptom onset :manually specify histogram bin breaks, use binwidth = argument, instead supply vector dates breaks =.Create vector dates base R function seq.Date(). function expects arguments =, =, =. example, command returns monthly dates starting Jan 15 ending June 28.vector can provided geom_histogram() breaks =:simple weekly date sequence can returned setting = \"week\". example:alternative supplying specific start end dates write dynamic code weekly bins begin Monday first case. use date vectors throughout examples .Let’s unpack rather daunting code :“” value (earliest date sequence) created follows: minimum date value (min() na.rm=TRUE) column date_onset fed floor_date() lubridate package. floor_date() set “week” returns start date cases’s “week”, given start day week Monday (week_start = 1).Likewise, “” value (end date sequence) created using inverse function ceiling_date() return Monday last case.“” argument seq.Date() can set number days, weeks, months.Use week_start = 7 Sunday weeksAs use date vectors throughout page, also define one whole outbreak (Central Hospital ).seq.Date() outputs can used create histogram bin breaks, also breaks date labels, may independent bins. Read date labels later sections.TIP: simple ggplot() command, save bin breaks date label breaks named vectors advance, simply provide names breaks =.","code":"\n# daily \nggplot(data = central_data) +          # set data\n  geom_histogram(                      # add histogram\n    mapping = aes(x = date_onset),     # map date column to x-axis\n    binwidth = 1)+                     # cases binned by 1 day \n  labs(title = \"Central Hospital - Daily\")                # title\n\n# weekly\nggplot(data = central_data) +          # set data \n  geom_histogram(                      # add histogram\n      mapping = aes(x = date_onset),   # map date column to x-axis\n      binwidth = 7)+                   # cases binned every 7 days, starting from first case (!) \n  labs(title = \"Central Hospital - 7-day bins, starting at first case\") # title\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")## [1] \"Thursday 01 May, 2014\"\nmonthly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"), to = as.Date(\"2015-07-15\"), by = \"months\")\n\nmonthly_breaks   # print##  [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\" \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-10-01\" \"2014-11-01\" \"2014-12-01\"\r\n## [12] \"2015-01-01\" \"2015-02-01\" \"2015-03-01\" \"2015-04-01\" \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n# monthly \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+         # provide the pre-defined vector of breaks                    \n  labs(title = \"Monthly case bins\")   # title\nweekly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"), to = as.Date(\"2015-07-15\"), by = \"week\")\n# Sequence of weekly Monday dates for CENTRAL HOSPITAL\nweekly_breaks_central <- seq.Date(\n  from = as.Date(floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1)), # monday before first case\n  to   = as.Date(ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1)), # monday after last case\n  by   = \"week\")\n# Sequence for the entire outbreak\nweekly_breaks_all <- seq.Date(\n  from = as.Date(floor_date(min(linelist$date_onset, na.rm=T),   \"week\", week_start = 1)), # monday before first case\n  to   = as.Date(ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1)), # monday after last case\n  by   = \"week\")"},{"path":"epidemic-curves.html","id":"weekly-epicurve-example","chapter":"29 Epidemic curves","heading":"Weekly epicurve example","text":"detailed example code produce weekly epicurves Monday weeks, aligned bars, date labels, vertical gridlines. section user needs code quickly. understand aspect (themes, date labels, etc.) -depth, continue subsequent sections. note:histogram bin breaks defined seq.Date() explained begin Monday earliest case end Monday last caseThe interval date labels specified date_breaks = within scale_x_date()interval minor vertical gridlines date labels specified date_minor_breaks =expand = c(0,0) x y scales removes excess space side axes, also ensures date labels begin first bar.","code":"\n# TOTAL MONDAY WEEK ALIGNMENT\n#############################\n# Define sequence of weekly breaks\nweekly_breaks_central <- seq.Date(\n      from = as.Date(floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1)), # Monday before first case\n      to   = as.Date(ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1)), # Monday after last case\n      by   = \"week\")    # bins are 7-days \n\n\nggplot(data = central_data) + \n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    \n    # mapping aesthetics\n    mapping = aes(x = date_onset),  # date column mapped to x-axis\n    \n    # histogram bin breaks\n    breaks = weekly_breaks_central, # histogram bin breaks defined previously\n    \n    # bars\n    color = \"darkblue\",     # color of lines around bars\n    fill = \"lightblue\"      # color of fill within bars\n  )+ \n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),           # remove excess x-axis space before and after case bars\n    date_breaks       = \"4 weeks\",        # date labels and major vertical gridlines appear every 3 Monday weeks\n    date_minor_breaks = \"week\",           # minor vertical lines appear every Monday week\n    date_labels       = \"%a\\n%d %b\\n%Y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+             # remove excess y-axis space below 0 (align histogram flush with x-axis)\n  \n  # aesthetic themes\n  theme_minimal()+                # simplify plot background\n  \n  theme(\n    plot.caption = element_text(hjust = 0,        # caption on left side\n                                face = \"italic\"), # caption in italics\n    axis.title = element_text(face = \"bold\"))+    # axis titles in bold\n  \n  # labels including dynamic caption\n  labs(\n    title    = \"Weekly incidence of cases (Monday weeks)\",\n    subtitle = \"Note alignment of bars, vertical gridlines, and axis labels on Monday weeks\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"sunday-weeks","chapter":"29 Epidemic curves","heading":"Sunday weeks","text":"achieve plot Sunday weeks modifications needed, date_breaks = \"weeks\" work Monday weeks.break points histogram bins must set Sundays (week_start = 7)Within scale_x_date(), similar date breaks provided breaks = minor_breaks = ensure date labels vertical gridlines align Sundays.example, scale_x_date() command Sunday weeks look like :","code":"scale_x_date(\r\n    expand = c(0,0),\r\n    \r\n    # specify interval of date labels and major vertical gridlines\r\n    breaks = seq.Date(\r\n      from = as.Date(floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7)), # Sunday before first case\r\n      to   = as.Date(ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7)), # Sunday after last case\r\n      by   = \"4 weeks\"),\r\n    \r\n    # specify interval of minor vertical gridline \r\n    minor_breaks = seq.Date(\r\n      from = as.Date(floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7)), # Sunday before first case\r\n      to   = as.Date(ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7)), # Sunday after last case\r\n      by   = \"week\"),\r\n   \r\n    # date label format\r\n    date_labels = \"%a\\n%d %b\\n%Y\")+         # day, above month abbrev., above 2-digit year"},{"path":"epidemic-curves.html","id":"groupcolor-by-value","chapter":"29 Epidemic curves","heading":"Group/color by value","text":"histogram bars can colored group “stacked”. designate grouping column, make following changes. See ggplot tips page details.Within histogram aesthetic mapping aes(), map column name group = fill = argumentsRemove fill = argument outside aes(), override one insideArguments inside aes() apply group, whereas outside apply bars (e.g. may still want color = outside, bar border)aes() command look like group color bars gender:applied:","code":"\naes(x = date_onset, group = gender, fill = gender)\nggplot(data = linelist) +     # begin with linelist (many hospitals)\n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital,       # set data to be grouped by hospital\n      fill = hospital),       # bar fill (inside color) by hospital\n    \n    # bin breaks are Monday weeks\n    breaks = weekly_breaks_all,   # sequence of weekly Monday bin breaks for whole outbreak, defined in previous code       \n    \n    # Color around bars\n    color = \"black\")"},{"path":"epidemic-curves.html","id":"adjust-colors","chapter":"29 Epidemic curves","heading":"Adjust colors","text":"manually set fill group, use scale_fill_manual() (note: scale_color_manual() different!).\r\nUse values = argument apply vector colors.\r\nUse na.value = specify color NA values.\r\nchange text legend labels can use labels = argument scale_fill_manual(), dangerously easy accidentally give colors incorrect legend text! Instead, recommended change legend text converting grouping column class Factor adjusting labels described Factors page briefly .\r\nUse values = argument apply vector colors.Use na.value = specify color NA values.change text legend labels can use labels = argument scale_fill_manual(), dangerously easy accidentally give colors incorrect legend text! Instead, recommended change legend text converting grouping column class Factor adjusting labels described Factors page briefly .adjust colors via pre-defined color scale, see page ggplot tips.","code":"\nggplot(data = linelist)+           # begin with linelist (many hospitals)\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,          # cases grouped by hospital\n        fill = hospital),          # bar fill by hospital\n    \n    # bin breaks\n    breaks = weekly_breaks_all,        # sequence of weekly Monday bin breaks, defined in previous code\n    \n    # Color around bars\n    color = \"black\")+              # border color of each bar\n  \n  # manual specification of colors\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\")) # specify fill colors (\"values\") - attention to order!"},{"path":"epidemic-curves.html","id":"adjust-level-order-2","chapter":"29 Epidemic curves","heading":"Adjust level order","text":"order grouped bars stacked best adjusted classifying grouping column class Factor. can designate factor level order (display labels). See page Factors ggplot tips details.making plot, convert grouping column class Factor using as_factor() forcats package. can make adjustments levels, detailed page Factors.plot, differences previous column hospital consolidated , use guides() reverse legend order, “Missing” bottom legend.TIP: reverse order legend , add ggplot2 command: guides(fill = guide_legend(reverse = TRUE)).","code":"\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Define new dataset with hospital as factor\nplot_data <- linelist %>% \n  mutate(hospital = as_factor(hospital)) %>%                      # define hospital as factor\n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Set \"Missing\" and \"Other\" as top levels to appear on epicurve top\n\nlevels(plot_data$hospital) # print levels in order## [1] \"Missing\"                              \"Other\"                                \"St. Mark's Maternity Hospital (SMMH)\"\r\n## [4] \"Port Hospital\"                        \"Military Hospital\"                    \"Central Hospital\"\nggplot(plot_data) +                     # Use NEW dataset with hospital as re-ordered factor\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,               # cases grouped by hospital\n        fill = hospital),               # bar fill (color) by hospital\n    \n    breaks = weekly_breaks_all,         # sequence of weekly Monday bin breaks for whole outbreak, defined at top of ggplot section\n    \n    color = \"black\")+                   # border color around each bar\n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space before and after case bars\n    date_breaks       = \"3 weeks\",      # labels appear every 3 Monday weeks\n    date_minor_breaks = \"week\",         # vertical lines appear every Monday week\n    date_labels       = \"%d\\n%b\\n'%y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+                   # remove excess y-axis space below 0\n  \n  # manual specification of colors, ! attention to order\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"))+ \n  \n  # aesthetic themes\n  theme_minimal()+                      # simplify plot background\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # caption on left side in italics\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+   # axis titles in bold\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases by hospital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly cases\",\n    fill     = \"Hospital\")                        # title of legend"},{"path":"epidemic-curves.html","id":"adjust-legend","chapter":"29 Epidemic curves","heading":"Adjust legend","text":"Read legends ggplot tips page. highlights:labs(fill = \"Legend title\") edit legend title (grouping column set fill = aes())theme(legend.title = element_blank()) titletheme(legend.position = \"top\") (“bottom”, “left”, “right”, “none”)theme(legend.direction = \"horizontal\") horizontal legendguides(fill = guide_legend(reverse = TRUE)) reverse order legend","code":""},{"path":"epidemic-curves.html","id":"bars-side-by-side","chapter":"29 Epidemic curves","heading":"Bars side-by-side","text":"Side--side display group bars (opposed stacked) specified within geom_histogram() position = \"dodge\" (place outside aes()).two value groups, can become difficult read. Consider instead using faceted plot (small multiples). improve readability example, missing gender values removed.","code":"\nggplot(central_data)+             # begin with Central Hospital cases\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender,         # cases grouped by gender\n          fill = gender),         # bars filled by gender\n        \n        # histogram bin breaks\n        breaks = weekly_breaks_central,   # sequence of weekly dates for Central outbreak - defined at top of ggplot section\n        \n        color = \"black\",          # bar edge color\n        \n        position = \"dodge\")+      # SIDE-BY-SIDE bars\n                      \n  \n  # The labels on the x-axis\n  scale_x_date(expand            = c(0,0),         # remove excess x-axis space below and after case bars\n               date_breaks       = \"3 weeks\",      # labels appear every 3 Monday weeks\n               date_minor_breaks = \"week\",         # vertical lines appear every Monday week\n               date_labels       = \"%d\\n%b\\n'%y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+             # removes excess y-axis space between bottom of bars and the labels\n  \n  #scale of colors and legend labels\n  scale_fill_manual(values = c(\"brown\", \"orange\"),  # specify fill colors (\"values\") - attention to order!\n                    na.value = \"grey\" )+     \n\n  # aesthetic themes\n  theme_minimal()+                                               # a set of themes to simplify plot\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n        axis.title = element_text(face = \"bold\"))+               # axis titles in bold\n  \n  # labels\n  labs(title    = \"Weekly incidence of cases, by gender\",\n       subtitle = \"Subtitle\",\n       fill     = \"Gender\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\")"},{"path":"epidemic-curves.html","id":"axis-limits","chapter":"29 Epidemic curves","heading":"Axis limits","text":"can set maximum minimum date values using limits = c() within scale_x_date(). example:Likewise, want x-axis extend specific date (e.g. current date), even new cases reported, can use:CAUTION: Caution using limits! remove data outside limits, can impact y-axis max/min, modeling, statistics. Strongly consider instead using limits adding coord_cartesian( xlim= c(), ylim=c() ) plot, acts “zoom” without removing data. DANGER: cautious setting y-axis scale breaks limits (e.g. 0 30 5: seq(0, 30, 5)). static numbers can cut-plot short data changes exceed limit!.","code":"\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # sets a minimum date but leaves the maximum open.  scale_x_date(limits = c(NA, Sys.Date()) # ensures date axis will extend until current date  "},{"path":"epidemic-curves.html","id":"date-axis-labelsgridlines","chapter":"29 Epidemic curves","heading":"Date-axis labels/gridlines","text":"TIP: Remember date-axis labels independent aggregation data bars, visually can important align bins, date labels, vertical grid lines.modify date labels grid lines, use scale_x_date() one ways:histogram bins days, Monday weeks, months, years:\r\nUse date_breaks = specify interval labels major gridlines (e.g. “day”, “week”, “3 weeks”, “month”, “year”)\r\nUse date_minor_breaks = specify interval minor vertical gridlines (date labels)\r\nAdd expand = c(0,0) begin labels first bar\r\nUse date_labels = specify format date labels - see Dates page tips (use \\n new line)\r\nUse date_breaks = specify interval labels major gridlines (e.g. “day”, “week”, “3 weeks”, “month”, “year”)Use date_minor_breaks = specify interval minor vertical gridlines (date labels)Add expand = c(0,0) begin labels first barUse date_labels = specify format date labels - see Dates page tips (use \\n new line)histogram bins Sunday weeks:\r\nUse breaks = minor_breaks = providing sequence date breaks \r\ncan still use date_labels = expand = formatting described \r\nUse breaks = minor_breaks = providing sequence date breaks eachYou can still use date_labels = expand = formatting described aboveSome notes:See opening ggplot section instructions create sequence dates using seq.Date().See page Working dates page tips creating date labels.","code":""},{"path":"epidemic-curves.html","id":"demonstrations","chapter":"29 Epidemic curves","heading":"Demonstrations","text":"demonstration plots bins plot labels/grid lines aligned aligned:","code":"\n# 7-day bins + Monday labels\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,                 # 7-day bins with start at first case\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),               # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",       # Monday every 3 weeks\n    date_minor_breaks = \"week\",    # Monday weeks\n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+  # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+              # remove excess space under x-axis, make flush with labels\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"!CAUTION: 7-day bars start Thursdays at first case\\nDate labels and gridlines on Mondays\\nNote how ticks don't align with bars\")\n\n\n\n# 7-day bins + Months\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                  # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",           # 1st of month\n    date_minor_breaks = \"week\",       # Monday weeks\n    date_labels = \"%a\\n%d %b\\n%Y\")+    # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush with labels\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"!CAUTION: 7-day bars start Thursdays with first case\\nMajor gridlines and date labels at 1st of each month\\nMinor gridlines weekly on Mondays\\nNote uneven spacing of some gridlines and ticks unaligned with bars\")\n\n\n# TOTAL MONDAY ALIGNMENT: specify manual bin breaks to be mondays\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,    # defined earlier in this page\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"4 weeks\",           # Monday every 4 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%a\\n%d %b\\n%Y\")+      # label format\n  \n  labs(\n    title = \"ALIGNED Mondays\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels and gridlines on Mondays as well\")\n\n\n# TOTAL MONDAY ALIGNMENT WITH MONTHS LABELS:\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,            # defined earlier in this page\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",            # Monday every 4 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%b\\n%Y\")+          # label format\n  \n  theme(panel.grid.major = element_blank())+  # Remove major gridlines (fall on 1st of month)\n          \n  labs(\n    title = \"ALIGNED Mondays with MONTHLY labels\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels on 1st of Month\\nMonthly major gridlines removed\")\n\n\n# TOTAL SUNDAY ALIGNMENT: specify manual bin breaks AND labels to be Sundays\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Sunday before first case\n    breaks = seq.Date(from = as.Date(floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7)),\n                      to   = as.Date(ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7)),\n                      by   = \"7 days\"),\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # date label breaks and major gridlines set to every 3 weeks beginning Sunday before first case\n    breaks = seq.Date(from = as.Date(floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7)),\n                      to   = as.Date(ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7)),\n                      by   = \"3 weeks\"),\n    \n    # minor gridlines set to weekly beginning Sunday before first case\n    minor_breaks = seq.Date(from = as.Date(floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7)),\n                            to   = as.Date(ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7)),\n                            by   = \"7 days\"),\n    \n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+  # label format\n  \n  labs(title = \"ALIGNED Sundays\",\n       subtitle = \"7-day bins manually set to begin Sunday before first case (27 Apr)\\nDate labels and gridlines manually set to Sundays as well\")"},{"path":"epidemic-curves.html","id":"aggregated-data","chapter":"29 Epidemic curves","heading":"29.3.1 Aggregated data","text":"Often instead linelist, begin aggregated counts facilities, districts, etc. can make epicurve ggplot() code slightly different. section utilize count_data dataset imported earlier, data preparation section. dataset linelist aggregated day-hospital counts. first 50 rows displayed .","code":""},{"path":"epidemic-curves.html","id":"plotting-daily-counts","chapter":"29 Epidemic curves","heading":"Plotting daily counts","text":"can plot daily epicurve daily counts. differences code:Within aesthetic mapping aes(), specify y = counts column (case, column name n_cases)Add argument stat = \"identity\" within geom_histogram(), specifies bar height y = value, number rows default","code":"\nggplot(data = count_data)+\n     geom_histogram(\n       mapping = aes(x = date_hospitalisation, y = n_cases),\n       stat = \"identity\")+\n     labs(x = \"Date of report\", \n          y = \"Number of cases\",\n          Title = \"Daily case incidence, from daily count data\")"},{"path":"epidemic-curves.html","id":"plotting-weekly-counts","chapter":"29 Epidemic curves","heading":"Plotting weekly counts","text":"data already case counts week, might look like dataset (called count_data_weekly):first 50 rows count_data_weekly displayed . can see counts aggregated weeks. week displayed first day week (Monday default).Now plot x = epiweek column. Remember add y = counts column aesthetic mapping, add stat = \"identity\" explained .","code":"\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek,           # x-axis is epiweek (as class Date)\n      y = n_cases_weekly,    # y-axis height in the weekly case counts\n      group = hospital,      # we are grouping the bars and coloring by hospital\n      fill = hospital),\n    stat = \"identity\")+      # this is also required when plotting count data\n     \n  # labels for x-axis\n  scale_x_date(\n    date_breaks = \"2 months\",      # labels every 2 months \n    date_minor_breaks = \"1 month\", # gridlines every month\n    date_labels = '%b\\n%Y')+       #labeled by month with year below\n     \n  # Choose color palette (uses RColorBrewer package)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Week of onset\", \n    y = \"Weekly case incidence\",\n    fill = \"Hospital\",\n    title = \"Weekly case incidence, from aggregated count data by hospital\")"},{"path":"epidemic-curves.html","id":"moving-averages-2","chapter":"29 Epidemic curves","heading":"29.3.2 Moving averages","text":"See page Moving averages detailed description several options. one option calculating moving averages package slider. approach, moving average calculated dataset prior plotting:Aggregate data counts necessary (daily, weekly, etc.) (see Grouping data page)Create new column hold moving average, created slide_index() slider packagePlot moving average geom_line() top () epicurve histogramSee helpful online vignette slider package","code":"\n# load package\npacman::p_load(slider)  # slider used to calculate rolling averages\n\n# make dataset of daily counts and 7-day moving average\n#######################################################\nll_counts_7day <- linelist %>%    # begin with linelist\n  \n  ## count cases by date\n  count(date_onset, name = \"new_cases\") %>%   # name new column with counts as \"new_cases\"\n  filter(!is.na(date_onset)) %>%              # remove cases with missing date_onset\n  \n  ## calculate the average number of cases in 7-day window\n  mutate(\n    avg_7day = slider::slide_index(    # create new column\n      new_cases,                       # calculate based on value in new_cases column\n      .i = date_onset,                 # index is date_onset col, so non-present dates are included in window \n      .f = ~mean(.x, na.rm = TRUE),    # function is mean() with missing values removed\n      .before = 6,                     # window is the day and 6-days before\n      .complete = FALSE),              # must be FALSE for unlist() to work in next step\n    avg_7day = unlist(avg_7day))       # convert class list to class numeric\n\n\n# plot\n######\nggplot(data = ll_counts_7day) +  # begin with new dataset defined above \n    geom_histogram(              # create epicurve histogram\n      mapping = aes(\n        x = date_onset,          # date column as x-axis\n        y = new_cases),          # height is number of daily new cases\n        stat = \"identity\",       # height is y value\n        fill=\"#92a8d1\",          # cool color for bars\n        colour = \"#92a8d1\",      # same color for bar border\n        )+ \n    geom_line(                   # make line for rolling average\n      mapping = aes(\n        x = date_onset,          # date column for x-axis\n        y = avg_7day,            # y-value set to rolling average column\n        lty = \"7-day \\nrolling avg\"), # name of line in legend\n      color=\"red\",               # color of line\n      size = 1) +                # width of line\n    scale_x_date(                # date scale\n      date_breaks = \"1 month\",\n      date_labels = '%d/%m',\n      expand = c(0,0)) +\n    scale_y_continuous(          # y-axis scale\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y =\"Number of confirmed cases\",\n      fill = \"Legend\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank())  # removes title of legend"},{"path":"epidemic-curves.html","id":"facetingsmall-multiples","chapter":"29 Epidemic curves","heading":"29.3.3 Faceting/small-multiples","text":"ggplots, can create facetted plots (“small multiples”). explained ggplot tips page handbook, can use either facet_wrap() facet_grid(). demonstrate facet_wrap(). epicurves, facet_wrap() typically easier likely need facet one column.general syntax facet_wrap(rows ~ cols), left tilde (~) name column spread across “rows” facetted plot, right tilde name column spread across “columns” facetted plot. simply, just use one column name, right tilde: facet_wrap(~age_cat).Free axes\r\nneed decide whether scales axes facet “fixed” dimensions (default), “free” (meaning change based data within facet). scales = argument within facet_wrap() specifying “free_x” “free_y”, “free”.Number cols rows facets\r\ncan specified ncol = nrow = within facet_wrap().Order panels\r\nchange order appearance, change underlying order levels factor column used create facets.Aesthetics\r\nFont size face, strip color, etc. can modified theme() arguments like:strip.text = element_text() (size, colour, face, angle…)strip.background = element_rect() (e.g. element_rect(fill=“grey”))strip.position = (position strip “bottom”, “top”, “left”, “right”)Strip labels\r\nLabels facet plots can modified “labels” column factor, use “labeller”.Make labeller like , using function as_labeller() ggplot2. provide labeller labeller = argument facet_wrap() shown .example facetted plot - facetted column age_cat.See link information labellers.","code":"\nmy_labels <- as_labeller(c(\n     \"0-4\"   = \"Ages 0-4\",\n     \"5-9\"   = \"Ages 5-9\",\n     \"10-14\" = \"Ages 10-14\",\n     \"15-19\" = \"Ages 15-19\",\n     \"20-29\" = \"Ages 20-29\",\n     \"30-49\" = \"Ages 30-49\",\n     \"50-69\" = \"Ages 50-69\",\n     \"70+\"   = \"Over age 70\"))\n# make plot\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),    # arguments inside aes() apply by group\n      \n    color = \"black\",      # arguments outside aes() apply to all data\n        \n    # histogram breaks\n    breaks = weekly_breaks_central)+  # pre-defined date vector (see earlier in this page)\n                      \n  # The labels on the x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+                       # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+         # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"total-epidemic-in-facet-background","chapter":"29 Epidemic curves","heading":"Total epidemic in facet background","text":"show total epidemic background facet, add function gghighlight() empty parentheses ggplot. package gghighlight. Note y-axis maximum facets now based peak entire epidemic.","code":"\nggplot(central_data) + \n  \n  # epicurves by group\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),  # arguments inside aes() apply by group\n    \n    color = \"black\",    # arguments outside aes() apply to all data\n    \n    # histogram breaks\n    breaks = weekly_breaks_central)+     # pre-defined date vector (see top of ggplot section)                \n  \n  # add grey epidemic in background to each facet\n  gghighlight::gghighlight()+\n  \n  # labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space below 0\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+        # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,                          # each plot is one value of age_cat\n    ncol = 4,                          # number of columns\n    strip.position = \"top\",            # position of the facet title/strip\n    labeller = my_labels)+             # labeller defines above\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"one-facet-with-data","chapter":"29 Epidemic curves","heading":"One facet with data","text":"want one facet box contains data, duplicate entire dataset treat duplicates one faceting value. “helper” function CreateAllFacet() can assist (thanks blog post). run, number rows doubles new column called facet duplicated rows value “”, original rows original value faceting colum. Now just facet facet column.helper function. Run available .Now apply helper function dataset, column age_cat:Notable changes ggplot() command :data used now central_data2 (double rows, new column “facet”)Labeller need updated, usedOptional: achieve vertically stacked facets: facet column moved rows side equation right replaced “.” (facet_wrap(facet~.)), ncol = 1. may also need adjust width height saved png plot image (see ggsave() ggplot tips).","code":"\n# Define helper function\nCreateAllFacet <- function(df, col){\n     df$facet <- df[[col]]\n     temp <- df\n     temp$facet <- \"all\"\n     merged <-rbind(temp, df)\n     \n     # ensure the facet value is a factor\n     merged[[col]] <- as.factor(merged[[col]])\n     \n     return(merged)\n}\n# Create dataset that is duplicated and with new column \"facet\" to show \"all\" age categories as another facet level\ncentral_data2 <- CreateAllFacet(central_data, col = \"age_cat\") %>%\n  \n  # set factor levels\n  mutate(facet = factor(facet,\n                        levels = c(\"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\")))\n\n# check levels\ntable(central_data2$facet, useNA = \"always\")## \r\n##   all   0-4   5-9 10-14 15-19 20-29 30-49 50-69   70+  <NA> \r\n##   454    84    84    82    58    73    57     7     0     9\nggplot(central_data2) + \n  \n  # actual epicurves by group\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat),  # arguments inside aes() apply by group\n        color = \"black\",    # arguments outside aes() apply to all data\n        \n        # histogram breaks\n        breaks = weekly_breaks_central)+    # pre-defined date vector (see top of ggplot section)\n                     \n  # Labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # create facets\n  facet_wrap(facet~. ,                            # each plot is one value of facet\n             ncol = 1)+            \n\n  # labels\n  labs(title    = \"Weekly incidence of cases, by age category\",\n       subtitle = \"Subtitle\",\n       fill     = \"Age category\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\",\n       caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"tentative-data","chapter":"29 Epidemic curves","heading":"29.4 Tentative data","text":"recent data shown epicurves often marked tentative, subject reporting delays. can done adding vertical line /rectangle specified number days. two options:Use annotate():\r\nline use annotate(geom = \"segment\"). Provide x, xend, y, yend. Adjust size, linetype (lty), color.\r\nrectangle use annotate(geom = \"rect\"). Provide xmin/xmax/ymin/ymax. Adjust color alpha.\r\nline use annotate(geom = \"segment\"). Provide x, xend, y, yend. Adjust size, linetype (lty), color.rectangle use annotate(geom = \"rect\"). Provide xmin/xmax/ymin/ymax. Adjust color alpha.Group data tentative status color bars differentlyCAUTION: might try geom_rect() draw rectangle, adjusting transparency work linelist context. function overlays one rectangle observation/row!. Use either low alpha (e.g. 0.01), another approach. ","code":""},{"path":"epidemic-curves.html","id":"using-annotate","chapter":"29 Epidemic curves","heading":"Using annotate()","text":"Within annotate(geom = \"rect\"), xmin xmax arguments must given inputs class Date.Note data aggregated weekly bars, last bar extends Monday last data point, shaded region may appear cover 4 weeksHere annotate() online exampleThe black vertical line can achieved code , using geom_vline() lose ability control height:","code":"\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central,   # pre-defined date vector - see top of ggplot section\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"1 month\",           # 1st of month\n    date_minor_breaks = \"1 month\",     # 1st of month\n    date_labels = \"%b\\n'%y\")+          # label format\n  \n  # labels and theme\n  labs(\n    title = \"Using annotate()\\nRectangle and line showing that data from last 21-days are tentative\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()+\n  \n  # add semi-transparent red rectangle to tentative data\n  annotate(\n    \"rect\",\n    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # note must be wrapped in as.Date()\n    xmax  = as.Date(Inf),                                          # note must be wrapped in as.Date()\n    ymin  = 0,\n    ymax  = Inf,\n    alpha = 0.2,          # alpha easy and intuitive to adjust using annotate()\n    fill  = \"red\")+\n  \n  # add black vertical line on top of other layers\n  annotate(\n    \"segment\",\n    x     = max(central_data$date_onset, na.rm = T) - 21, # 21 days before last data\n    xend  = max(central_data$date_onset, na.rm = T) - 21, \n    y     = 0,         # line begins at y = 0\n    yend  = Inf,       # line to top of plot\n    size  = 2,         # line size\n    color = \"black\",\n    lty   = \"solid\")+   # linetype e.g. \"solid\", \"dashed\"\n\n  # add text in rectangle\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Subject to reporting delays\",\n    angle = 90)\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")"},{"path":"epidemic-curves.html","id":"bars-color","chapter":"29 Epidemic curves","heading":"Bars color","text":"alternative approach adjust color display tentative bars data . create new column data preparation stage use group data, aes(fill = ) tentative data can different color alpha bars.","code":"\n# add column\n############\nplot_data <- central_data %>% \n  mutate(tentative = case_when(\n    date_onset >= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # tenative if in last 7 days\n    TRUE                                       ~ \"Reliable\")) # all else reliable\n\n# plot\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histogram\n  geom_histogram(\n    breaks = weekly_breaks_central,   # pre-defined data vector, see top of ggplot page\n    color = \"black\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",           # Monday every 3 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%d\\n%b\\n'%y\")+      # label format\n  \n  # labels and theme\n  labs(title = \"Show days that are tentative reporting\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank())                 # remove title of legend"},{"path":"epidemic-curves.html","id":"multi-level-date-labels","chapter":"29 Epidemic curves","heading":"29.5 Multi-level date labels","text":"want multi-level date labels (e.g. month year) without duplicating lower label levels, consider one approaches :Remember - can can use tools like \\n within date_labels labels arguments put parts label new line . However, code helps take years months (example) lower line . notes code :Case counts aggregated weeks aesthetic reasons. See Epicurves page (aggregated data tab) details.geom_area() line used instead histogram, faceting approach work well histograms.Aggregate weekly countsMake plotsThe techniques adapted post stackoverflow.com.","code":"\n# Create dataset of case counts by week\n#######################################\ncentral_weekly <- linelist %>%\n  filter(hospital == \"Central Hospital\") %>%   # filter linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %>%  \n  count(week) %>%                              # summarize weekly case counts\n  filter(!is.na(week)) %>%                     # remove cases with missing onset_date\n  complete(week = seq.Date(\n    from = min(week),   # fill-in all weeks with no cases reported\n    to   = max(week),\n    by   = \"week\"))\n# plot with box border on year\n##############################\nggplot(central_weekly) +\n  geom_area(aes(x = week, y = n),    # make line, specify x and y\n            stat = \"identity\") +             # because line height is count number\n  scale_x_date(date_labels=\"%b\",             # date label format show month \n               date_breaks=\"month\",          # date labels on 1st of each month\n               expand=c(0,0)) +              # remove excess space\n  facet_grid(~lubridate::year(week), # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",                # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                   # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",         # facet labels placement\n        strip.background = element_rect(fill = NA, # facet labels no fill grey border\n                                        colour = \"grey50\"),\n        panel.spacing = unit(0, \"cm\"))+      # no space between facet panels\n  labs(title = \"Nested year labels, grey label border\")\n# plot with no box border on year\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) +              # establish x and y for entire plot\n  geom_line(stat = \"identity\",              # make line, line height is count number\n            color = \"#69b3a2\") +            # line color\n  geom_point(size=1, color=\"#69b3a2\") +     # make points at the weekly data points\n  geom_area(fill = \"#69b3a2\",               # fill area below line\n            alpha = 0.4)+                   # fill transparency\n  scale_x_date(date_labels=\"%b\",            # date label format show month \n               date_breaks=\"month\",         # date labels on 1st of each month\n               expand=c(0,0)) +             # remove excess space\n  facet_grid(~lubridate::year(week),   # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",               # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                  # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",                     # facet label placement\n          strip.background = element_blank(),            # no facet lable background\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_rect(colour=\"grey40\"),  # grey border to facet PANEL\n          panel.spacing=unit(0,\"cm\"))+                   # No space between facet panels\n  labs(title = \"Nested year labels - points, shaded, no label border\")"},{"path":"epidemic-curves.html","id":"dual-axis","chapter":"29 Epidemic curves","heading":"29.6 Dual-axis","text":"Although fierce discussions validity dual axes within data visualization community, many epi supervisors still want see epicurve similar chart percent overlaid second axis.One example, cowplot method shown :Two distinct plots made, combined cowplot package.plots must exact x-axis (set limits) else data labels alignEach uses theme_cowplot() one y-axis moved right side plotNow use cowplot overlay two plots. Attention paid x-axis alignment, side y-axis, use theme_cowplot().","code":"\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\n#######################################\nplot_cases <- linelist %>% \n  \n  # plot cases per week\n  ggplot()+\n  \n  # create histogram  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # bin breaks every week beginning monday before first case, going to monday after last case\n    breaks = weekly_breaks_all)+  # pre-defined vector of weekly dates (see top of ggplot section)\n        \n  # specify beginning and end of date axis to align with other plot\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  # labels\n  labs(\n      y = \"Daily cases\",\n      x = \"Date of symptom onset\"\n    )+\n  theme_cowplot()\n\n\n# make second plot of percent died per week\n###########################################\nplot_deaths <- linelist %>%                        # begin with linelist\n  group_by(week = floor_date(date_onset, \"week\")) %>%  # create week column\n  \n  # summarise to get weekly percent of cases who died\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %>% \n  \n  # begin plot\n  ggplot()+\n  \n  # line of weekly percent who died\n  geom_line(                                # create line of percent died\n    mapping = aes(x = week, y = pct_died),  # specify y-height as pct_died column\n    stat = \"identity\",                      # set line height to the value in pct_death column, not the number of rows (which is default)\n    size = 2,\n    color = \"black\")+\n  \n  # Same date-axis limits as the other plot - perfect alignment\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  \n  # y-axis adjustments\n  scale_y_continuous(                # adjust y-axis\n    breaks = seq(0,100, 10),         # set break intervals of percent axis\n    limits = c(0, 100),              # set extent of percent axis\n    position = \"right\")+             # move percent axis to the right\n  \n  # Y-axis label, no x-axis label\n  labs(x = \"\",\n       y = \"Percent deceased\")+      # percent axis label\n  \n  theme_cowplot()                   # add this to make the two plots merge together nicely\naligned_plots <- align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epidemic-curves.html","id":"cumulative-incidence-1","chapter":"29 Epidemic curves","heading":"29.7 Cumulative Incidence","text":"Note: using incidence2, see section can produce cumulative incidence simple function. page address calculate cumulative incidence plot ggplot().beginning case linelist, create new column containing cumulative number cases per day outbreak using cumsum() base R:first 10 rows shown :cumulative column can plotted date_onset, using geom_line():can also overlaid onto epicurve, dual-axis using cowplot method described ggplot tips page:Now use cowplot overlay two plots. Attention paid x-axis alignment, side y-axis, use theme_cowplot().","code":"\ncumulative_case_counts <- linelist %>% \n  count(date_onset) %>%                # count of rows per day (returned in column \"n\")   \n  mutate(                         \n    cumulative_cases = cumsum(n)       # new column of the cumulative number of rows at each date\n    )\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\nplot_cases <- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Daily cases\",\n    x = \"Date of symptom onset\"\n  )+\n  theme_cowplot()\n\n# make second plot of cumulative cases line\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cumulative cases\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\naligned_plots <- align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epidemic-curves.html","id":"resources-22","chapter":"29 Epidemic curves","heading":"29.8 Resources","text":"","code":""},{"path":"plot-continuous-data.html","id":"plot-continuous-data","chapter":"30 Plot continuous data","heading":"30 Plot continuous data","text":"page discuss appropriate plotting continuous data, age, clinical measurements, distance. ggplot2, part tidyverse family packages, fantastic versatile package visualising continuous data. usual, R also built-base functions, can helpful quick looks data.Visualisations covered include:Plots one continuous variable:\r\nHistograms, classic graph present distribution continuous variable.\r\nBox plots (also called box whisker), box represents 25th, 50th, 75th percentile continuous variable, line outside represent tail ends distribution continuous variable, dots represent outliers.\r\nViolin plots, similar histograms show distribution continuous variable based symettrical width ‘violin’.\r\nJitter plots, visualise distribution continuous variable showing values dots, rather collectively one larger shape. dot ‘jittered’ can (mostly) seen, even two value.\r\nSina plots, cross jitter violin plots, individual points can seen symmetrical shape distribution (note brings ggforce package).\r\nHistograms, classic graph present distribution continuous variable.Box plots (also called box whisker), box represents 25th, 50th, 75th percentile continuous variable, line outside represent tail ends distribution continuous variable, dots represent outliers.Violin plots, similar histograms show distribution continuous variable based symettrical width ‘violin’.Jitter plots, visualise distribution continuous variable showing values dots, rather collectively one larger shape. dot ‘jittered’ can (mostly) seen, even two value.Sina plots, cross jitter violin plots, individual points can seen symmetrical shape distribution (note brings ggforce package).Scatter plots two continuous variables.","code":""},{"path":"plot-continuous-data.html","id":"preparation-21","chapter":"30 Plot continuous data","heading":"30.1 Preparation","text":"","code":""},{"path":"plot-continuous-data.html","id":"load-packages-18","chapter":"30 Plot continuous data","heading":"Load packages","text":"Preparation includes loading relevant packages, ggplot2 dplyr, ensuring data correct class format.code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.Note: also load tidyverse, includes ggplot2 dplyr among packages (e.g. stringr, tidyr, forcats instance).","code":"\npacman::p_load(ggplot2, dplyr)"},{"path":"plot-continuous-data.html","id":"import-data-15","chapter":"30 Plot continuous data","heading":"Import data","text":"","code":""},{"path":"plot-continuous-data.html","id":"import-data-16","chapter":"30 Plot continuous data","heading":"Import data","text":"examples section, use dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed . focus continuous variables age, wt_kg (weight kilos), ct_blood (CT values), days_onset_hosp (difference onset date hospitalisation).","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"plot-continuous-data.html","id":"column-class","chapter":"30 Plot continuous data","heading":"Column class","text":"use mutate() confirm class columns important analysis.conducted various data checks point, including checking missingness data.","code":"\nlinelist <- linelist %>%  \n  mutate(age = as.numeric(age),       # Ensure vars are class numeric\n         ct_blood = as.numeric(ct_blood),\n         days_onset_hosp = as.numeric(days_onset_hosp),\n         wt_kg = as.numeric(wt_kg))  "},{"path":"plot-continuous-data.html","id":"plotting-with-ggplot2","chapter":"30 Plot continuous data","heading":"30.2 Plotting with ggplot2","text":"","code":""},{"path":"plot-continuous-data.html","id":"code-syntax-1","chapter":"30 Plot continuous data","heading":"Code syntax","text":"Ggplot2 extensive functionality, code syntax can used many different plot types.basic breakdown ggplot code follows:ggplot() starts function. can specify data aesthetics (see next point) within ggplot bracket, unless combining different data sources plot types oneaes() stands ‘aesthetics’, columns used visualisation specified. instance aes(x = col1, y = col2) specify data used x y values (y continuous variable examples).fill specifies colour boxplot areas. One also write color specify outline point colour.geom_XXX specifies type plot. Options include:\r\ngeom_boxplot() boxplot\r\ngeom_histogram histogram\r\ngeom_violin() violin plot\r\ngeom_jitter() jitter plot\r\ngeom_point() scatter plot\r\ngeom_sina() jitter plot width jitter controlled density distribution data within class\r\ngeom_boxplot() boxplotgeom_histogram histogramgeom_violin() violin plotgeom_jitter() jitter plotgeom_point() scatter plotgeom_sina() jitter plot width jitter controlled density distribution data within classNote aes() bracket can within ggplot() bracket within specific geom_XXX bracket. layering different ggplots diferent aesthetics, need specify within geom_XXX.see section ggplot tips. also walk customisation .","code":"ggplot(data = linelist)+  \r\n  geom_XXXX(aes(x = col1, y = col2),\r\n       fill = \"color\") "},{"path":"plot-continuous-data.html","id":"plotting-one-continuous-variable","chapter":"30 Plot continuous data","heading":"30.2.1 Plotting one continuous variable","text":"Box plotsBelow code creating box plots, show distribution CT values Ebola patients entire dataset sub group. Note subgroup breakdowns, ‘NA’ values also removed using dplyr, otherwise ggplot plots age distribution ‘NA’ separate boxplot.HistogramsBelow code generating histograms, show distribution CT values Ebola patients. Within aes() bracket, specify variable want see distribution . can supply either x y, change direction plot. y x respectively show count, represented columns referred ‘bins’.examples , R guessed appropriate way present data, issues message tell many bins (columns) went , prompt customise :used 30 bins, look spaced 0 values. relates way values rounded.change , can specify binwidth (e.g. range values bin counting) bins (number bins) within geom_histogram argument. evenly grouped, minimum maximum values histogram.Rather counts, can change stats within aes() bracket specify proportions - see (plot ) . can also layer different histograms different settings (plot B).Violin, jitter, sina plotsBelow code creating violin plots (geom_violin) jitter plots (geom_jitter) show age distributions. One can specify ‘fill’ ’color’also determined data, thereby inserting options within aes bracket.One can combine two using geom_sina option, actually part ggforce package. can easier visually interpret. ) left shows basic layering geom_violin geom_sina. B) shows slightly effort put appearance ggplot (see -line comments).","code":"\n# A) Simple boxplot of one numeric variable\nggplot(data = linelist, aes(y = ct_blood))+  # only y variable given (no x variable)\n  geom_boxplot()+\n  labs(title = \"A) Simple ggplot2 boxplot\")\n\n# B) Box plot by group\nggplot(data = linelist %>% filter(!is.na(outcome)), \n       aes(y = ct_blood,                            # Continous variable\n           x = outcome)) +                          # Grouping variable\n  geom_boxplot(fill = \"gold\")+                      # Create the boxplot and specify colour\n  labs(title = \"B) ggplot2 boxplot by gender\")      \n# A) Regular histogram\nggplot(data = linelist, aes(x = ct_blood))+  # provide x variable\n  geom_histogram()+\n  labs(title = \"A) Simple ggplot2 histogram\")\n\n# B) Histogram with values across y axis\nggplot(data = linelist, aes(y = ct_blood))+  # provide y variable \n  geom_histogram()+\n  labs(title = \"B) Simple ggplot2 histogram with axes swapped\")## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n# A) Histogram with specified bin number\nggplot(data = linelist, aes(x = ct_blood))+   # Provide x variable\n  geom_histogram(bins=10,                     # Add bin number\n                 color = \"white\")+            # Add white outline so bars can easily be distinguished\n  labs(title = \"A) Ggplot histogram with 10 bins\")\n\n# B) Histogram with specified bin width\nggplot(data = linelist, aes(x = ct_blood))+   # Provide y variable \n  geom_histogram(binwidth = 1,                # Each bar includes a CT value range of 1\n                 color = \"white\")+            # Add white outline so bars can easily be distinguished\n  labs(title = \"B) Ggplot histogram with bindwidth of 1\")\n# A) Histogram with proportion\nggplot(data = linelist, aes(x = ct_blood,           # provide x variable\n                            y = stat(density)))+    # Calculate proportion\n  geom_histogram(bins=10,                           # Add bin number\n                 color = \"white\")+ # Add white outline so bars can easily be distinguished\n  labs(title = \"A) Ggplot histogram showing proportion\")\n\n# B) Layered histograms with different bin widths\nggplot(data = linelist, aes(x = ct_blood))+         # provide x variable \n  geom_histogram(binwidth = 2) +                    # Underlying layer has binwidth of 2\n  geom_histogram(binwidth = 1,                      # Top layer has binwidth of 1\n                 alpha = 0.4,                       # Set top layer to be slightly see through\n                 fill = \"blue\")+ \n  labs(title = \"B) Layered ggplot histograms\")\n# A) Violin plot by group\nggplot(data = linelist %>% filter(!is.na(outcome)), \n       aes(y = age,                                # Continuous variable\n           x = outcome,                            # Grouping variable\n           fill = outcome))+                       # fill variable (color of boxes)\n  geom_violin()+                                   # create the violin plot\n  labs(title = \"A) ggplot2 violin plot by gender\")    \n\n\n# B) Jitter plot by group\nggplot(data = linelist %>% filter(!is.na(outcome)), \n       aes(y = age,                               # Continuous variable\n           x = outcome,                           # Grouping variable\n           color = outcome))+ # Color variable\n  geom_jitter()+                                  # Create the violin plot\n  labs(title = \"B) ggplot2 jitter plot by gender\")     \npacman::p_load(ggforce)\n\n# A) Sina plot by group\nggplot(data = linelist %>% filter(!is.na(outcome)), \n       aes(y = age,             # numeric variable\n           x = outcome)) +      # group variable\n  geom_violin()+                # create the violin plot\n  geom_sina()+\n  labs(title = \"A) ggplot() violin and sina plot by gender\")      \n\n\n# A) Sina plot by group\nggplot(data = linelist %>% filter(!is.na(outcome)), \n       aes(y = age,             # numeric variable\n           x = outcome)) +      # group variable\n  geom_violin(aes(fill = outcome), # fill variable (color of violin background)\n              color = \"white\",  # Plot has white outline rather than default black \n              alpha = 0.2)+     # Alpha value where 0 transparent to 1 opaque\n  geom_sina(size=1,             # Change the size of the jitter\n            aes(color = outcome))+ # color variable (color of dots)\n  scale_fill_manual(values = c(\"Death\" = \"#bf5300\", \n                        \"Recover\" = \"#11118c\")) + # Define colours for death/recover \n                                                  # (but note they will come out a bit transparent)\n  scale_color_manual(values = c(\"Death\" = \"#bf5300\", \n                         \"Recover\" = \"#11118c\")) + # Define colours for death/recover\n  theme_minimal() +                                # Remove the gray background\n  theme(legend.position = \"none\") +                # Remove unnecessary legend\n  labs(title = \"B) ggplot() violin and sina plot by gender with formatting\")      "},{"path":"plot-continuous-data.html","id":"one-continuous-variable-within-facets","chapter":"30 Plot continuous data","heading":"One continuous variable within facets","text":"Faceting basicsTo examine subgroups, one can ‘facet’ graph. means plot recreated within specified subgroups. One can use:facet_wrap() - recreate sub-graphs present alphabetically (typically, unless stated otherwise). can invoke certain options determine look facets, e.g. nrow=1 ncol=1 control number rows columns faceted plots arranged within. See plot .facet_grid() - suited seeing subgroups particular combinations discrete variables. See plot B . nrow ncol relevant, subgroups presented grid, subgroups always x y axis (see notes code )can stipulate two faceting variables, ‘~’ . one faceting variable, ‘.’ used placeholder non-used second faceting variable - see code examples.faceting optionsThe scales used facetting consistent across subgroups, helpful comparisons, always appropriate optimal.using facet_wrap facet_grid, can add scales = \"free_y\" (plot ) heights faceted histograms standardised shapes easier compare. particularly useful actual counts small one subcategories trends otherwise hard see. Instead free_y can also write free_x x axis free axes. Note facet_grid, y scales facets row, x scales facets column.using facet_grid , can add space = \"free_y\" space = \"free_x\" actual height width facet weighted values figure within. works scales = \"free\" (y x) already applies.","code":"\n# A) Histogram of hospitalisation dates faceted by hospital\nggplot(data = linelist %>% \n         filter(hospital != \"Missing\"),               # filter removes unknown hospital\n       aes(x = date_hospitalisation ))+\n  geom_histogram(binwidth=7) +                        # Bindwidth = 7 days\n  labs(title = \"A) Ggplot 2 histogram of hospitalisation dates by hospital\")+\n  facet_wrap(hospital~.,                              # Facet by just hospital\n            ncol = 2)                                 # Facet in two columns\n\n# B) Boxplot of age faceted in a grid with two variables, gender and outcome\nggplot(data = linelist %>% \n         filter(!is.na(gender) & !is.na(outcome)),    # filter retains non-missing gender/outcome\n       aes(y = age))+\n  geom_boxplot()+\n  labs(title = \"A) A Ggplot2 boxplot by gender and outcome\")+\n  facet_grid(outcome~gender)                          # Outcome is the row, gender is the column\n# A) Facet hospitalsation date by hospital, free y axis\nggplot(data = linelist %>% filter(hospital != \"Missing\"), # filter removes unknown hospital\n       aes(x = date_hospitalisation ))+\n  geom_histogram(binwidth=7) + # Bindwidth = 7 days\n  labs(title = \"A) Histogram with free y axis scales\")+\n  facet_grid(hospital~., # Facet with hospital as the row \n             scales = \"free_y\") # Free the y scale of each facet\n\n# B) Facet hospitalisation date by hospital, free y axis and vertical spacing\nggplot(data = linelist %>% filter(hospital != \"Missing\"), # filter removes unknown hospital\n       aes(x = date_hospitalisation ))+\n  geom_histogram(binwidth=7) + # Bindwidth = 7 days\n  labs(title = \"B) Histogram with free y axis scales and spacing\")+\n  facet_grid(hospital~., # Facet with hospital as the row \n             scales = \"free_y\", # Free the y scale of each facet\n             space = \"free_y\") # Free the vertical spacing of each facet to optimise space"},{"path":"plot-continuous-data.html","id":"two-continuous-variables","chapter":"30 Plot continuous data","heading":"Two continuous variables","text":"Following similar syntax, geom_point() allow one plot two continuous variables eachother scatter plot. useful showing actual values rather distributions.basic scatter plot age vs weight shown (). (B) use facet_grid() show relationship two continuous variables linelist.","code":"\n# Basic scatter plot of weight and age\nggplot(data = linelist, \n       aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# Scatter plot of weight and age by gender and Ebola outcome\nggplot(data = linelist %>% filter(!is.na(gender) & !is.na(outcome)), # filter retains non-missing gender/outcome\n       aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender~outcome) "},{"path":"plot-continuous-data.html","id":"three-continuous-variables","chapter":"30 Plot continuous data","heading":"Three continuous variables","text":"","code":""},{"path":"plot-continuous-data.html","id":"plotting-with-base-graphics","chapter":"30 Plot continuous data","heading":"30.3 Plotting with base graphics","text":"Using base graphics can sometimes quicker ggplot, helpful initial first look.","code":""},{"path":"plot-continuous-data.html","id":"one-continuous-variable","chapter":"30 Plot continuous data","heading":"One continuous variable","text":"Box plots histogramsThe -built graphics package comes boxplot() hist() functions, allowing straight-forward visualisation continuous variable.customisationSubgroups can also shown, subgroup crossed groups. Note plot B , outcome gender written outcome*gender boxplots four combinations two columns. get facetted across different rows columns like ggplot2.specify linelist dataset need write age linelist$ageSome options boxplot() shown :Boxplot width proportional sample size ()Violin plots, notched representing median x around (B)Horizontal (C)","code":"\n# Boxplot\nboxplot(linelist$wt_kg,\n                  main = \"A) Base boxplot\") \n\n\n# Histogram\nhist(linelist$wt_kg,\n                  main = \"B) Base histogram\") \n# Box plot by subgroup\nboxplot(age ~ outcome,\n                  data = linelist, \n                  main = \"A) Base boxplot by subgroup\")\n\n# Box plot by crossed subgroups\nboxplot(age ~ outcome*gender,\n                  data = linelist, \n                  main = \"B) Base boxplot) by crossed groups\")\n# Varying width by sample size \nboxplot(linelist$age ~ linelist$outcome,\n                  varwidth = TRUE, # width varying by sample size\n                  main=\"A) Proportional boxplot() widths\")\n\n                  \n# Notched (violin plot), and varying width\nboxplot(age ~ outcome,\n        data=linelist,\n        notch=TRUE,      # notch at median\n        main=\"B) Notched boxplot()\",\n        col=(c(\"gold\",\"darkgreen\")),\n        xlab=\"Suppliment and Dose\")\n\n# Horizontal\nboxplot(age ~ outcome,\n        data=linelist,\n        horizontal=TRUE,  # flip to horizontal\n        col=(c(\"gold\",\"darkgreen\")),\n        main=\"C) Horizontal boxplot()\",\n        xlab=\"Suppliment and Dose\")"},{"path":"plot-continuous-data.html","id":"two-continuous-variables-1","chapter":"30 Plot continuous data","heading":"Two continuous variables","text":"Using base R, can quickly visualise relationship two continuous variables plot function.","code":"\nplot(linelist$age, linelist$wt_kg)"},{"path":"plot-continuous-data.html","id":"resources-23","chapter":"30 Plot continuous data","heading":"30.4 Resources","text":"huge amount help online, especially ggplot. See:http://r-statistics.co/ggplot2-cheatsheet.htmlhttps://biostats.w.uib./-ggplot2-cheat-sheet--rstudio/","code":""},{"path":"plot-categorical-data.html","id":"plot-categorical-data","chapter":"31 Plot categorical data","heading":"31 Plot categorical data","text":"appropriate plotting categorical data, e.g. distribution sex, symptoms, ethnic group, etc.","code":""},{"path":"plot-categorical-data.html","id":"overview-13","chapter":"31 Plot categorical data","heading":"31.1 Overview","text":"section cover use R’s built-functions functions ggplot2 package visualise categorical/categorical data. additional functionality ggplot2 compared R means recommend presentation-ready visualisations.cover visualising distributions categorical values, counts proportions.","code":""},{"path":"plot-categorical-data.html","id":"preparation-22","chapter":"31 Plot categorical data","heading":"31.2 Preparation","text":"Preparation includes loading relevant packages, namely ggplot2 examples covered . also load data.","code":""},{"path":"plot-categorical-data.html","id":"load-packages-19","chapter":"31 Plot categorical data","heading":"31.2.1 Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\n# Load packages we will be using repeatedly\npacman::p_load(ggplot2, # Package for visualisation\n       dplyr,           # Package for data management\n       forcats)         # Package for factors"},{"path":"plot-categorical-data.html","id":"import-data-17","chapter":"31 Plot categorical data","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"plot-categorical-data.html","id":"process-columns-for-analysis","chapter":"31 Plot categorical data","heading":"31.2.2 Process columns for analysis","text":"examples section, use simulated Ebola linelist, focusing categorical variables hospital, outcome. need correct class format.Let’s take look hospital column.can see values within characters, hospital names, default ordered alphabetically. ‘’ ‘missing’ values, prefer last subcategories presenting breakdowns. change column factor re-order . covered detail ‘factors’ data management section.","code":"\n# View class of hospital column - we can see it is a character\nclass(linelist$hospital)## [1] \"character\"\n# Look at values held within hospital column\ntable(linelist$hospital)## \r\n##                     Central Hospital                    Military Hospital                              Missing                                Other \r\n##                                  454                                  896                                 1469                                  885 \r\n##                        Port Hospital St. Mark's Maternity Hospital (SMMH) \r\n##                                 1762                                  422\n# Change hospital to factor variable\nlinelist <- linelist %>% \n  mutate(hospital = factor(hospital))\n\n# Define the levels of factor with forcats - so other and missing are last\nlinelist <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, \n                                c(\"St. Mark's Maternity Hospital (SMMH)\", \n                                  \"Port Hospital\", \n                                  \"Central Hospital\",\n                                  \"Military Hospital\",\n                                  \"Other\",\n                                  \"Missing\")))"},{"path":"plot-categorical-data.html","id":"ensure-correct-data-structure","chapter":"31 Plot categorical data","heading":"31.2.3 Ensure correct data structure","text":"displaying frequencies distributions categorical variables, option creating plots based :linelist data, one row per observation, orA summary table based linelist, one row per category. example show use dplyr create table case counts per hospital.Tables can created using ‘table’ method built-graphics. useNA = \"ifany\" arguments ensures missing values included, table otherwise automatically excludes .using data management packages dplyr. example add percentage column.","code":"\n#Table method\n  outcome_nbar <- table(linelist$outcome, \n                        useNA = \"ifany\")\n\n  outcome_nbar # View full table## \r\n##   Death Recover    <NA> \r\n##    2582    1983    1323\n#Dplyr method\n  outcome_n <- linelist %>% \n    group_by(outcome) %>% \n    count %>% \n    ungroup() %>% # Ungroup so proportion is out of total\n    mutate(proportion = n/sum(n)*100) # Caculate percentage\n  \n  \n   outcome_n #View full table## # A tibble: 3 x 3\r\n##   outcome     n proportion\r\n##   <chr>   <int>      <dbl>\r\n## 1 Death    2582       43.9\r\n## 2 Recover  1983       33.7\r\n## 3 <NA>     1323       22.5"},{"path":"plot-categorical-data.html","id":"filter-to-relevant-data","chapter":"31 Plot categorical data","heading":"31.2.4 Filter to relevant data","text":"may consider dropping rows needed analysis. instance, next examples want understand trends amongst persons known outcome, drop rows missing outcome column values.","code":"\n#Drop missing from full linelist\nlinelist <- linelist %>% \n  filter(!is.na(outcome))\n\n#Drop missing from dplyr table\noutcome_n <- outcome_n %>% \n  filter(!is.na(outcome))"},{"path":"plot-categorical-data.html","id":"plotting-with-ggplot2-1","chapter":"31 Plot categorical data","heading":"31.3 Plotting with ggplot2","text":"","code":""},{"path":"plot-categorical-data.html","id":"code-syntax-2","chapter":"31 Plot categorical data","heading":"31.3.1 Code syntax","text":"Ggplot extensive functionality, code syntax can used many different plot types.Similar plotting continuous data section, basic breakdown ggplot code follows:ggplot() starts function. can specify data aesthetics (see next point) within ggplot bracket, unless combining different data sources plot types oneaes() stands ‘aesthetics’, columns used visualisation specified. instance aes(x = col1, y = col2) specify data used x y values.fill specifies colour bars, subgroups specified within aes breacket.geom_XXX specifies type plot. Options include:\r\ngeom_bar() bar chart based linelist\r\ngeom_col() bar chart based table values (see preparation section)\r\ngeom_bar() bar chart based linelistgeom_col() bar chart based table values (see preparation section)Note aes() bracket can within ggplot() bracket within specific geom_XXX bracket. layering different ggplots diferent aesthetics, need specify within geom_XXX.see section ggplot tips.","code":"ggplot(data = linelist)+  \r\n  geom_XXXX(aes(x = col1, y = col2),\r\n       fill = \"color\") "},{"path":"plot-categorical-data.html","id":"bar-charts-using-raw-data","chapter":"31 Plot categorical data","heading":"31.3.2 Bar charts using raw data","text":"code using geom_bar creating simple bar charts show frequencies Ebola patient outcomes: ) cases, B) hospital.aes bracket, x needs specified - y want bars presented horizontally. Ggplot knows unspecified y (x) number observations fall categories.","code":"\n# A) Outcomes in all cases\nggplot(linelist) + \n  geom_bar(aes(x=outcome)) +\n  labs(title = \"A) Number of recovered and dead Ebola cases\")\n\n\n# B) Outcomes in all cases by hosptial\nggplot(linelist) + \n  geom_bar(aes(x=outcome, fill = hospital)) +\n  theme(axis.text.x = element_text(angle = 90)) + # Add preference to rotate the x axis text\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\")"},{"path":"plot-categorical-data.html","id":"bar-charts-using-processed-data","chapter":"31 Plot categorical data","heading":"31.3.3 Bar charts using processed data","text":"code using geom_col creating simple bar charts show distribution Ebola patient outcomes. geom_col, x y need specified. x categorical variable along x axis, y generated proportions column proportion.show breakdowns hospital, additional table needs created frequencies combined categories outcome hospital.create ggplot added formatting:Axis flip: Swapped axis around coord_flip() can read hospital names.Columns side--side: Added position = \"dodge\" argument bars death recover presented side side rather stacked. Note stacked bars default.Column width: Specified ‘width’, columns half thin full possible width.Column order: Reversed order categories y axis ‘’ ‘Missing’ bottom, scale_x_discrete(limits=rev). Note used rather scale_y_discrete hospital stated x argument aes(), even visually y axis. Ggplot seems present categories backwards unless tell .details: Labels/titles colours added within labs scale_fill_color respectively.Note proportions binary, may prefer drop ‘recover’ just show proportion died. just illustration purposes though.","code":"\n# Outcomes in all cases\nggplot(outcome_n) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\noutcome_n2 <- linelist %>% \n  group_by(hospital, outcome) %>% \n  count() %>% \n  group_by(hospital) %>% # Group so proportions are out of hospital total\n  mutate(proportion = n/sum(n)*100)\n\nhead(outcome_n2) #Preview data## # A tibble: 6 x 4\r\n## # Groups:   hospital [3]\r\n##   hospital                             outcome     n proportion\r\n##   <fct>                                <chr>   <int>      <dbl>\r\n## 1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\r\n## 2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\r\n## 3 Port Hospital                        Death     785       57.6\r\n## 4 Port Hospital                        Recover   579       42.4\r\n## 5 Central Hospital                     Death     193       53.9\r\n## 6 Central Hospital                     Recover   165       46.1\n# Outcomes in all cases by hospital\nggplot(outcome_n2) +  \n  geom_col(aes(x=hospital, \n               y = proportion, \n               fill = outcome),\n           width = 0.5,          # Make bars a bit thinner (out of 1)\n           position = \"dodge\") + # Bars are shown side by side, not stacked\n  scale_x_discrete(limits=rev) + # Reverse the order of the categories\n  theme_minimal() +              # Minimal theme \n  coord_flip() +\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",        # Legend title\n       x = \"Count\",             # X axis title\n       y = \"Hospital of admission\")  + # Y axis title\n  scale_fill_manual(values = c(\"Death\"= \"#3B1c8C\",\n                               \"Recover\" = \"#21908D\" )) "},{"path":"plot-categorical-data.html","id":"facetting","chapter":"31 Plot categorical data","heading":"31.3.4 Facetting","text":"can also use faceting create futher mini-graphs, detailed examples continuous data visualisation section. Specifically, one can use:facet_wrap() - recreate sub-graphs present alphabetically (typically, unless stated otherwise). can invoke certain options determine look facets, e.g. nrow=1 ncol=1 control number rows columns faceted plots arranged within.facet_grid() - suited seeing subgroups particular combinations categorical variables.","code":""},{"path":"plot-categorical-data.html","id":"plotting-with-base-graphics-1","chapter":"31 Plot categorical data","heading":"31.4 Plotting with base graphics","text":"Bar chartsTo create bar plots R, create frequency table using table function. creates object table class, R can recognise plotting. can create simple frequency graph showing Ebola case outcomes (), add colours present outcomes gender (B).Note NA values excluded plots default.","code":"\n# A) Outcomes in all cases\noutcome_nbar <- table(linelist$outcome)\nbarplot(outcome_nbar, main= \"A) Outcomes\")\n\n# B) Outcomes in all cases by gender of case\noutcome_nbar2 <- table(linelist$outcome, linelist$gender) # The first column is for groupings within a bar, the second is for the separate bars\nbarplot(outcome_nbar2, legend.text=TRUE, main = \"B) Outcomes by gender\") # Specify inclusion of legend"},{"path":"plot-categorical-data.html","id":"resources-24","chapter":"31 Plot categorical data","heading":"31.5 Resources","text":"huge amount help online, especially ggplot. see:http://r-statistics.co/ggplot2-cheatsheet.htmlhttps://biostats.w.uib./-ggplot2-cheat-sheet--rstudio/","code":""},{"path":"html-tables.html","id":"html-tables","chapter":"32 HTML tables","heading":"32 HTML tables","text":"section demonstrates create publication-ready tables, can inserted directly shareable documents, including R Markdown outputs.See Descriptive tables page instruction make tabulations, cross-tabulations, descriptive summary tables.","code":""},{"path":"html-tables.html","id":"overview-14","chapter":"32 HTML tables","heading":"32.1 Overview","text":"build previous sections basic statistics creating summary tables (e.g. using dplyr gtsummary show create publication-read tables. primary package use flextable, compatible multiple R Markdown formats, including html word documents.Example:Table Ebola patients outcome information: Number, proportion, CT values cases recovered died (Military hospital highlighted)HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0","code":""},{"path":"html-tables.html","id":"preparation-23","chapter":"32 HTML tables","heading":"32.2 Preparation","text":"","code":""},{"path":"html-tables.html","id":"load-packages-20","chapter":"32 HTML tables","heading":"Load packages","text":"Load, install necessary, flextable, use convert table fully formatted presentable table. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization"},{"path":"html-tables.html","id":"import-data-18","chapter":"32 HTML tables","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"html-tables.html","id":"prepare-table","chapter":"32 HTML tables","heading":"Prepare table","text":"beginning use flextable need create table contents. Use packages discussed sections janitor dplyr create table content interest, correct columns rows.example - create simple summary table patient outcomes. interested knowing number proportion patients recover died, well median CT values, hospital admission.","code":"\ntable <- linelist %>% \n  # filter\n  ########\n  filter(!is.na(outcome) & hospital != \"Missing\") %>%  # Remove cases with missing outcome or hospital\n  \n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T)) %>%           # median CT value per group\n  \n  # add totals\n  ############\n  bind_rows(                                           # Bind the previous table with this mini-table of totals\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # Number of rows for whole dataset     \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Median CT for whole dataset\n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                      # number with known outcome\n    Pct_Death = N_Death / N_Known * 100,               # percent cases who died\n    Pct_Recover = N_Recover/N_Known * 100) %>%         # percent who recovered\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known)                                    # Arrange rows from lowest to highest (Total row at bottom)\n\ntable  # print## # A tibble: 6 x 8\r\n## # Groups:   hospital [6]\r\n##   hospital                             N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death ct_value_Death\r\n##   <chr>                                  <int>     <int>       <dbl>            <dbl>   <int>     <dbl>          <dbl>\r\n## 1 St. Mark's Maternity Hospital (SMMH)     325       126        38.8               22     199      61.2             22\r\n## 2 Central Hospital                         358       165        46.1               22     193      53.9             22\r\n## 3 Other                                    685       290        42.3               21     395      57.7             22\r\n## 4 Military Hospital                        708       309        43.6               22     399      56.4             21\r\n## 5 Port Hospital                           1364       579        42.4               21     785      57.6             22\r\n## 6 Total                                   3440      1469        42.7               22    1971      57.3             22"},{"path":"html-tables.html","id":"basic-flextable","chapter":"32 HTML tables","heading":"32.3 Basic flextable","text":"Creating flextableTo create manage flextable objects, pass table object flextable() function progressively pipe object flextable formatting functions. general syntax line flextable code follows:function(table, = X, j = X, part = \"X\"), :\r\ntable = name table object, although need stated table piped function.\r\n‘function’ can one many different functions, width() determine column widths, bg() set background colours, align() set whether text centre/right/left aligned, .\r\npart = refers part table function applied . E.g. “header”, “body” “”.\r\n= specifies row apply function , ‘X’ row number. multiple rows, e.g. first third rows, one can specify: = c(1:3). Note ‘body’ selected, first row starts underneath header section.\r\nj = specifies column apply function , ‘x’ column number name. multiple columns, e.g. fifth sixth, one can specify: j = c(5,6).\r\ntable = name table object, although need stated table piped function.‘function’ can one many different functions, width() determine column widths, bg() set background colours, align() set whether text centre/right/left aligned, .part = refers part table function applied . E.g. “header”, “body” “”.= specifies row apply function , ‘X’ row number. multiple rows, e.g. first third rows, one can specify: = c(1:3). Note ‘body’ selected, first row starts underneath header section.j = specifies column apply function , ‘x’ column number name. multiple columns, e.g. fifth sixth, one can specify: j = c(5,6).can find complete list flextable formatting function review documentation ?flextable.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0Formatting cell contentWe can ensure proportion columns display one decimal place using function colformat_num(). Note also done data management stage round() function.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0Formatting column widthWe can use autofit() function, nicely stretches table cell one row text. function qflextable() convenient shorthand flextable() autofit().hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0However, might always appropriate, especially long values within cells, meaning table might fit page.Instead, can specify widths width() function. can take playing around know width value put. example , specify different widths column 1, column 2, columns 4 8.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0Column headersWe want clearer headers easier interpretation table contents.First can add extra header layer clarity. add_header_row() function top = set TRUE, columns covering subgroups can grouped together. provide new name column values =, leaving empty values \"\" column know merge together later.also rename now-second header. Finally use merge_at() merge column headers top header row.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0Formatting borders background can adjust borders, internal lines, etc. various flextable functions. often easier start removing existing borders border_remove()., can apply default border themes passing table theme_box(), theme_booktabs(), theme_alafoli().can add vertical horizontal lines variety functions. hline() vline() add lines specified row column, respectively. Within , must specify part = either “”, “body”, “header”. vertical lines, specify j = column, horizontal line =. functions like vline_right(), vline_left(), hline_top(), hline_bottom() add lines outsides .functions, actual line style must specified border = must output fp_border() function officer package. function helps define width color line. can define outside table, shown .HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0Font alignmentWe centre-align columns aside left-column hospital names, using align() function flextable.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0Additionally, can increase header font size change bold. can also change total row bold.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0Merged cellsJust merge cells horizontally header row, can also merge cells vertically using merge_at() specifying rows () column (j).BackgroundTo distinguish content table headers, may want add additional formatting. e.g. changing background colour. example change table body gray.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0","code":"\nmy_table <- flextable(table) \nmy_table\nmy_table <- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table\nmy_table %>% autofit()\nmy_table <- my_table %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table\nmy_table <- my_table %>% \n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %>% \n    set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\")     # Horizontally merge columns 6 to 8 in new header row\n\nmy_table  # print\n# define style for border line\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# add border lines to table\nmy_table <- my_table %>% \n\n  # Remove all existing borders\n  border_remove() %>%  \n  \n  # add horizontal lines via a pre-determined theme setting\n  theme_booktabs() %>% \n  \n  # add vertical lines to separate Recovered and Died sections\n  vline(part = \"all\", j = 2, border = border_style) %>%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style)       # at column 5\n\nmy_table\nmy_table <- my_table %>% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\nmy_table <-  my_table %>%  \n  fontsize(i = 1, size = 12, part = \"header\") %>%   # adjust font size of header\n  bold(i = 1, bold = TRUE, part = \"header\") %>%     # adjust bold face of header\n  bold(i = 6, bold = TRUE, part = \"body\")           # adjust bold face of total row (row 6)\n\nmy_table\nmy_table <- my_table %>% \n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\")\nmy_table <- my_table %>% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table "},{"path":"html-tables.html","id":"conditional-flextable-formatting","chapter":"32 HTML tables","heading":"32.4 Conditional flextable formatting","text":"can highlight values column meet certain rule, e.g. 55% cases died.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0Or, can higlight entire row meeting certain criterion, hospital interest. particularly helpful looping e.g. reports per geographical area, highlight tables current iteration compares geographies. just remove column (j) specification.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.822.019961.222.0Central Hospital35816546.122.019353.922.0Other68529042.321.039557.722.0Military Hospital70830943.622.039956.421.0Port Hospital1,36457942.421.078557.622.0Total3,4401,46942.722.01,97157.322.0","code":"\nmy_table %>% \n  bg(j=7, i= ~ Pct_Death >=55, part = \"body\", bg = \"red\") \nmy_table %>% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") "},{"path":"html-tables.html","id":"saving-your-table","chapter":"32 HTML tables","heading":"32.5 Saving your table","text":"different ways table can integrated output.Save single tableYou can export tables Word, PowerPoint HTML image (PNG) files. , one following functions used:save_as_docx()save_as_pptx()save_as_image()save_as_html()instance:Note packages webshot webshot2 required save flextable image. Images may come transparent backgrounds.want view ‘live’ versions flextable output intended document format, instance can see fits page can copy another document, can use print method argument preview set “pptx” “docx”. document pop .Save table R markdown documentThis table can integrated automated document, R markdown output, table object called within R markdown chunk. means table can updated part report data might change, numbers can refreshed.See detail R Markdown page handbook.","code":"\nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n# Edit the 'my table' as needed for the title of table. If not specified the whole file will be blank. \n\nsave_as_image(my_table, path = \"file.png\")\nprint(my_table, preview = \"docx\") # Word document example\nprint(my_table, preview = \"pptx\") # Powerpoint example"},{"path":"html-tables.html","id":"resources-25","chapter":"32 HTML tables","heading":"32.6 Resources","text":"full flextable book : https://ardata-fr.github.io/flextable-book/\r\nGithub site \r\nmanual flextable functions can found hereA gallery beautiful example flextable tables code can accessed ","code":""},{"path":"age-pyramids-and-likert-scales.html","id":"age-pyramids-and-likert-scales","chapter":"33 Age pyramids and Likert-scales","heading":"33 Age pyramids and Likert-scales","text":"Age pyramids can useful show patterns age group. can show gender, distribution characteristics. tabs demonstrate produce age pyramids using:Fast & easy: Using apyramid packageMore flexible: Using ggplot()baseline demographics displayed background pyramidUsing pyramid-style plots show types data (e.g responses Likert-style survey questions)","code":""},{"path":"age-pyramids-and-likert-scales.html","id":"overview-15","chapter":"33 Age pyramids and Likert-scales","heading":"33.1 Overview","text":"Age/gender demographic pyramids R generally made ggplot() creating two barplots (one gender), converting one’s values negative values, flipping x y axes display barplots vertically.offer quick approach apyramid package:customizable code using raw ggplot() commandsHow combine case demographic data compare baseline population (shown )Application methods show types data (e.g. responses Likert-style survey questions)","code":""},{"path":"age-pyramids-and-likert-scales.html","id":"preparation-24","chapter":"33 Age pyramids and Likert-scales","heading":"33.2 Preparation","text":"tab use linelist dataset cleaned Cleaning tab.make traditional age/sex demographic pyramid, data must first cleaned following ways:gender column must cleaned.Age age category column, class Factor (correctly ordered levels)","code":""},{"path":"age-pyramids-and-likert-scales.html","id":"load-packages-21","chapter":"33 Age pyramids and Likert-scales","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(rio,       # to import data\n               here,      # to locate files\n               tidyverse, # to clean, handle, and plot the data (includes ggplot2 package)\n               apyramid,  # a package dedicated to creating age pyramids\n               stringr)   # working with strings for titles, captions, etc."},{"path":"age-pyramids-and-likert-scales.html","id":"import-data-19","chapter":"33 Age pyramids and Likert-scales","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow along step--step, see instruction Download book data page.","code":"\nlinelist <- rio::import(\"linelist_cleaned.csv\")"},{"path":"age-pyramids-and-likert-scales.html","id":"check-column-classes","chapter":"33 Age pyramids and Likert-scales","heading":"Check column classes","text":"Ensure column want use age class Numeric.","code":"\nclass(linelist$age_years)## [1] \"numeric\""},{"path":"age-pyramids-and-likert-scales.html","id":"apyramid-package","chapter":"33 Age pyramids and Likert-scales","heading":"33.3 apyramid package","text":"package apyramid allows quickly make age pyramid. nuanced situations, see tab using ggplot() make age pyramids. can read apyramid package Help page entering ?age_pyramid R console.","code":""},{"path":"age-pyramids-and-likert-scales.html","id":"linelist-data","chapter":"33 Age pyramids and Likert-scales","heading":"33.3.1 Linelist data","text":"Using cleaned linelist dataset, can create age pyramid just one simple command. need help cleaning data, see handbook page Cleaning data core functions (LINK). command:data argument set linelist dataframeThe age_group argument set name (quotes) numeric category variable (case age_cat5)split_by argument (bar colors) binary column (case “gender”)result can shown percents cases, instead counts, setting proportional = TRUE.using agepyramid package, split_by column binary (e.g. male/female, yes/), result appear pyramid. However two values split_by column (including NA), pyramid appears faceted barplot empty bars background indicating range un-faceted data set age group. Values split_by appear labels top facet. example split_by variable “hospital”.Missing values\r\nRows missing values split_by age_group columns, coded NA, trigger faceting shown . default rows shown. However can specify appear, adjacent barplot separate age group top, specifying na.rm = FALSE.Proportions, colors, & aestheticsBy default, bars display counts (%), dashed mid-line group shown, colors green/purple. parameters can adjusted, shown :can also add additional ggplot() commands plot using standard ggplot() “+” syntax, aesthetic themes label adjustments:","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\",\n                      na.rm = FALSE)        # show a bar for patients missing age, (note: this changes the pyramid into a faceted barplot)\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # show patients missing age or gender\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE,                  # show percents, not counts\n                      show_midpoint = FALSE,                # remove bar mid-point line\n                      #pal = c(\"orange\", \"purple\")          # can specify alt. colors here (but not labels, see below)\n                      )+                 \n  \n  # additional ggplot commands\n  theme_minimal()+                                          # simplify the background\n  scale_fill_manual(values = c(\"orange\", \"purple\"),         # to specify colors AND labels\n                     labels = c(\"Male\", \"Female\"))+\n  labs(y = \"Percent of all cases\",                          # note that x and y labels are switched (see ggplot tab)\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                             # move legend to bottom\n    axis.text = element_text(size = 10, face = \"bold\"),     # fonts/sizes, see ggplot tips page\n    axis.title = element_text(size = 12, face = \"bold\"))"},{"path":"age-pyramids-and-likert-scales.html","id":"aggregated-data-1","chapter":"33 Age pyramids and Likert-scales","heading":"33.3.2 Aggregated data","text":"examples assume data linelist-like format, one row per observation. data already aggregated counts age category, can still use apyramid package, shown .code aggregates linelist data counts age category gender, “wide” format. Learn Grouping data Pivoting data respective pages:…makes dataset looks like : columns age category, male counts, female counts, missing counts.set-data age pyramid, pivot data “long” pivot_longer() function dplyr. ggplot() generally prefers “long” data, apyramid using ggplot().use split_by count arguments age_pyramid() specify respective columns:Note , factor order “m” “f” different (pyramid reversed). adjust order must re-define gender aggredated data Factor order levels desired.","code":"\ndemo_agg <- linelist %>% \n  count(age_cat5, gender, name = \"cases\") %>% \n  pivot_wider(id_cols = age_cat5, names_from = gender, values_from = cases) %>% \n  rename(`missing_gender` = `NA`)\n# pivot the aggregated data into long format\ndemo_agg_long <- demo_agg %>% \n  pivot_longer(c(f, m, missing_gender),            # cols to elongate\n               names_to = \"gender\",                # name for new col of categories\n               values_to = \"counts\") %>%           # name for new col of counts\n  mutate(gender = na_if(gender, \"missing_gender\")) # convert \"missing_gender\" to NA\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      count = \"counts\")      # give the column name for the aggregated counts"},{"path":"age-pyramids-and-likert-scales.html","id":"ggplot","chapter":"33 Age pyramids and Likert-scales","heading":"33.4 ggplot()","text":"Using ggplot() build age pyramid allows flexibility, requires effort understanding ggplot() works. also easier accidentally make mistakes.apyramid uses ggplot() background (accepts ggplot() commands added), page shows adjust recreate pyramid using ggplot(), wish.","code":""},{"path":"age-pyramids-and-likert-scales.html","id":"constructing-the-plot","chapter":"33 Age pyramids and Likert-scales","heading":"33.4.1 Constructing the plot","text":"First, understand make pyramid using ggplot() approach :Within ggplot(), create two graphs age category. Create one two grouping values (case gender). See filters applied data arguments geom_histogram() commands .Within ggplot(), create two graphs age category. Create one two grouping values (case gender). See filters applied data arguments geom_histogram() commands .using geom_histogram(), graphs operate numeric column (e.g. age_years), whereas using geom_barplot() graphs operate ordered Factor (e.g. age_cat5).using geom_histogram(), graphs operate numeric column (e.g. age_years), whereas using geom_barplot() graphs operate ordered Factor (e.g. age_cat5).One graph positive count values, counts converted negative values - allows graphs seen compared plot.One graph positive count values, counts converted negative values - allows graphs seen compared plot.command coord_flip() switches X Y axes, resulting graphs turning vertical creating pyramid.command coord_flip() switches X Y axes, resulting graphs turning vertical creating pyramid.Lastly, counts-axis labels must specified appear “positive” counts sides pyramid (despite underlying values one side negative).Lastly, counts-axis labels must specified appear “positive” counts sides pyramid (despite underlying values one side negative).simple version , using geom_histogram(), :DANGER: limits counts axis set low, counts bar exceeds , bar disappear entirely artificially shortened! Watch analyzing data routinely updated. Prevent count-axis limits auto-adjust data, .many things can change/add simple version, including:Auto adjust counts-axis count scale data (avoid errors discussed warning )Manually specify colors legend labelsConvert counts percents:Importantly save max min (max opposite direction) percents know tall scale . used ggplot() command .Finally make ggplot() percent data. specify scale_y_continuous() extend pre-defined lengths direction (positive “negative”). use floor() ceiling() round decimals appropriate direction () side axis.","code":"\n  # begin ggplot\n  ggplot(data = linelist, aes(x = age, fill = gender)) +\n  \n  # female histogram\n  geom_histogram(data = filter(linelist, gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # male histogram (values converted to negative)\n  geom_histogram(data = filter(linelist, gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 aes(y=..count..*(-1)),\n                 colour = \"white\") +\n  \n  # flip the X and Y axes\n  coord_flip() +\n  \n  # adjust counts-axis scale\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n# create dataset with proportion of total\npyramid_data <- linelist %>%\n  count(age_cat5, gender, name = \"counts\") %>% \n  ungroup() %>%                                   # ungroup so percent calculations are not by group\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)),1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent,\n            TRUE          ~ NA_real_))\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n\nmax_per## [1] 10.9\nmin_per## [1] -7.1\n# begin ggplot\n  ggplot()+  # default x-axis is age in years;\n\n  # case data graph\n  geom_bar(data = pyramid_data,\n           stat = \"identity\",\n           aes(x = age_cat5,\n               y = percent,\n               fill = gender),        # \n           colour = \"white\")+         # white around each bar\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n\n  # adjust the axes scales (remember they are flipped now!)\n  #scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(limits = c(min_per, max_per),\n                     breaks = seq(floor(min_per), ceiling(max_per), 2),\n                     labels = paste0(abs(seq(floor(min_per), ceiling(max_per), 2)), \"%\"))+\n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\"),\n  ) +\n  \n  # label values (remember X and Y flipped now)\n  labs(\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # optional aesthetic themes\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")) + \n  \n  ggtitle(paste0(\"Age and gender of cases\"))"},{"path":"age-pyramids-and-likert-scales.html","id":"compare-to-baseline","chapter":"33 Age pyramids and Likert-scales","heading":"33.4.2 Compare to baseline","text":"flexibility ggplot(), can second layer bars background represent true population pyramid. can provide nice visualization compare observed counts baseline.Import view population dataFirst data management steps:record order age categories want appear. Due quirks way ggplot() implemented, easiest store character vector use later plotting function.Combine population case data dplyr function bind_rows():First, ensure exact column names, age categories values, gender valuesMake data structure: columns age category, gender, counts, percent totalBind together, one -top (bind_rows())Review changed population datasetNow implement case linelist. Slightly different begins case-rows, counts.Review changed case datasetNow two datasets combined, one top (column names)Store maximum minimum percent values, used plotting funtion define extent plot (cut bars!)Now plot made ggplot():One bar graph population data (wider, transparent bars)One bar graph case data (small, solid bars)","code":"\n# import the population demographics data\npop <- rio::import(\"country_demographics.csv\")\n# record correct age cat levels\nage_levels <- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n# create/transform populaton data, with percent of total\n########################################################\npop_data <- pivot_longer(pop, c(m, f), names_to = \"gender\", values_to = \"counts\") %>% # pivot gender columns longer\n  mutate(data = \"population\",                                                         # add column designating data source\n         percent  = round(100*(counts / sum(counts, na.rm=T)),1),                     # calculate % of total\n         percent  = case_when(                                                        # if male, convert % to negative\n                            gender == \"f\" ~ percent,\n                            gender == \"m\" ~ -percent,\n                            TRUE          ~ NA_real_))\n# create case data by age/gender, with percent of total\n#######################################################\ncase_data <- linelist %>%\n  group_by(age_cat5, gender) %>%  # aggregate linelist cases into age-gender groups\n  summarize(counts = n()) %>%     # calculate counts per age-gender group\n  ungroup() %>% \n  mutate(data = \"cases\",                                          # add column designating data source\n         percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculate % of total for age-gender groups\n         percent = case_when(                                     # convert % to negative if male\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent,\n            TRUE          ~ NA_real_))\n# combine case and population data (same column names, age_cat values, and gender values)\npyramid_data <- bind_rows(case_data, pop_data)\n# Define extent of percent axis, used for plot limits\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n# begin ggplot\n##############\nggplot()+  # default x-axis is age in years;\n\n  # population data graph\n  geom_bar(data = filter(pyramid_data, data == \"population\"),\n           stat = \"identity\",\n           aes(x = age_cat5,\n               y = percent,\n               fill = gender),        \n           colour = \"black\",                               # black color around bars\n           alpha = 0.2,                                    # more transparent\n           width = 1)+                                     # full width\n  \n  # case data graph\n  geom_bar(data = filter(pyramid_data, data == \"cases\"), \n           stat = \"identity\",                              # use % as given in data, not counting rows\n           aes(x = age_cat5,                               # age categories as original X axis\n               y = percent,                                # % as original Y-axis\n               fill = gender),                             # fill of bars by gender\n           colour = \"black\",                               # black color around bars\n           alpha = 1,                                      # not transparent \n           width = 0.3)+                                   # half width\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n  # adjust axes order, scale, and labels (remember X and Y axes are flipped now)\n  # manually ensure that age-axis is ordered correctly\n  scale_x_discrete(limits = age_levels)+ \n  \n  # set percent-axis \n  scale_y_continuous(limits = c(min_per, max_per),                                          # min and max defined above\n                     breaks = seq(floor(min_per), ceiling(max_per), by = 2),                # from min% to max% by 2 \n                     labels = paste0(                                                       # for the labels, paste together... \n                       abs(seq(floor(min_per), ceiling(max_per), by = 2)),                  # ...rounded absolute values of breaks... \n                       \"%\"))+                                                               # ... with \"%\"\n                                                                                            # floor(), ceiling() round down and up \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # assign colors to values in the data\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # change labels that appear in legend, note order\n  ) +\n\n  # plot labels, titles, caption    \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # optional aesthetic themes\n  theme(\n    legend.position = \"bottom\",                             # move legend to bottom\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))"},{"path":"age-pyramids-and-likert-scales.html","id":"likert-scale","chapter":"33 Age pyramids and Likert-scales","heading":"33.5 Likert scale","text":"techniques used make population pyramid ggplot() can also used make plots Likert-scale survey data.Import dataStart data looks like , categorical classification respondent (status) answers 8 questions 4-point Likert-type scale (“poor”, “Poor”, “Good”, “good”).First, data management steps:Pivot data longerCreate new column direction depending whether response generally “positive” “negative”Set Factor level order status column Response columnStore max count value limits plot appropriateJust like ggplot() age pyramid, save max value dynamically calibrate axis scale.Now make plot:","code":"\n# import the likert survey response data\nlikert_data <- rio::import(\"likert_data.csv\")\nmelted <- pivot_longer(likert_data, Q1:Q8, names_to = \"Question\", values_to = \"Response\") %>% \n     mutate(direction = case_when(\n               Response %in% c(\"Poor\",\"Very Poor\") ~ \"Negative\",\n               Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n               TRUE ~ \"Unknown\"),\n            status = factor(status, levels = rev(c(\n                 \"Senior\", \"Intermediate\", \"Junior\"))),\n            Response = factor(Response, levels = c(\"Very Good\", \"Good\",\n                                             \"Very Poor\", \"Poor\"))) # must reverse Very Poor and Poor for ordering to work\n\nmelted_max <- melted %>% \n   group_by(status, Question) %>% \n   summarize(n = n())\nmelted_max <- max(melted_max$n, na.rm=T)\nmelted_max## [1] 18\n# make plot\nggplot()+\n     # bar graph of the \"negative\" responses \n     geom_bar(data = filter(melted,\n                            direction == \"Negative\"), \n              aes(x = status,\n                        y=..count..*(-1),    # counts inverted to negative\n                        fill = Response),\n                    color = \"black\",\n                    closed = \"left\", \n                    position = \"stack\")+\n     \n     # bar graph of the \"positive responses\n     geom_bar(data = filter(melted, direction == \"Positive\"),\n              aes(x = status, fill = Response),\n              colour = \"black\",\n              closed = \"left\",\n              position = \"stack\")+\n     \n     # flip the X and Y axes\n     coord_flip()+\n  \n     # Black vertical line at 0\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # convert labels to all positive numbers\n    scale_y_continuous(limits = c(-ceiling(melted_max/10)*11, ceiling(melted_max/10)*10),   # seq from neg to pos by 10, edges rounded outward to nearest 5\n                       breaks = seq(-ceiling(melted_max/10)*10, ceiling(melted_max/10)*10, 10),\n                       labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # color scales manually assigned \n    scale_fill_manual(values = c(\"Very Good\"  = \"green4\", # assigns colors\n                                  \"Good\"      = \"green3\",\n                                  \"Poor\"      = \"yellow\",\n                                  \"Very Poor\" = \"red3\"),\n                       breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # orders the legend\n     \n    \n     \n    # facet the entire plot so each question is a sub-plot\n    facet_wrap(~Question, ncol = 3)+\n     \n    # labels, titles, caption\n    labs(x = \"Respondent status\",\n          y = \"Number of responses\",\n          fill = \"\")+\n     ggtitle(str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"))+\n\n     # aesthetic settings\n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # facet sub-titles\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # black box around each facet"},{"path":"age-pyramids-and-likert-scales.html","id":"resources-26","chapter":"33 Age pyramids and Likert-scales","heading":"33.6 Resources","text":"","code":""},{"path":"diagrams-and-charts.html","id":"diagrams-and-charts","chapter":"34 Diagrams and charts","heading":"34 Diagrams and charts","text":"","code":""},{"path":"diagrams-and-charts.html","id":"overview-16","chapter":"34 Diagrams and charts","heading":"34.1 Overview","text":"page covers:Flow diagrams using DiagrammeRAlluvial/Sankey diagramsEvent timelinesGANTT chartsDendrogram organizational trees (e.g. folder contents)DAGs (Directed Acyclic Graphs)","code":""},{"path":"diagrams-and-charts.html","id":"preparation-25","chapter":"34 Diagrams and charts","heading":"34.2 Preparation","text":"","code":""},{"path":"diagrams-and-charts.html","id":"load-packages-22","chapter":"34 Diagrams and charts","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  DiagrammeR,     # for flow diagrams\n  networkD3,      # For alluvial/Sankey diagrams\n  tidyverse)      # data management and visualization"},{"path":"diagrams-and-charts.html","id":"import-data-20","chapter":"34 Diagrams and charts","heading":"Import data","text":"content page require dataset. However, Sankey diagram section, use case linelist simulated Ebola epidemic. want download data follow step--step, see instruction Download book data page. previewed .first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"diagrams-and-charts.html","id":"flow-diagrams","chapter":"34 Diagrams and charts","heading":"34.3 Flow diagrams","text":"One can use R package DiagrammeR create charts/flow charts. can static, can adjust somewhat dynamically based changes dataset.ToolsThe function grViz() used create “Graphviz” diagram. function accepts character string input containing instructions making diagram. Within string, instructions written different language, called DOT - quite easy learn basics.Basic structureOpen instructions grViz(\"Specify directionality name graph, open brackets, e.g. digraph my_flow_chart {Graph statement (layout, rank direction)Nodes statements (create nodes)Edges statements (gives links nodes)Close instructions }\")","code":""},{"path":"diagrams-and-charts.html","id":"simple-examples","chapter":"34 Diagrams and charts","heading":"34.3.1 Simple examples","text":"two simple examplesA minimal example:example applied public health context:","code":"\n# A minimal plot\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -> b -> c\n}\")\ngrViz(\"                           # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  # nodes\n  #######\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]               # width of circles\n  \n  Primary                         # names of nodes\n  Secondary\n  Tertiary\n\n  # edges\n  #######\n  Primary   -> Secondary [label = ' case transfer']\n  Secondary -> Tertiary [label = ' case transfer']\n}\n\")"},{"path":"diagrams-and-charts.html","id":"syntax","chapter":"34 Diagrams and charts","heading":"34.3.2 Syntax","text":"Basic syntaxNode names, edge statements, can separated spaces, semicolons, newlines.Rank directionA plot can re-oriented move left--right adjusting rankdir argument within graph statement. default TB (top--bottom), can LR (left--right), RL, BT.Node namesNode names can single words, simple example . use multi-word names special characters (e.g. parentheses, dashes), put node name within single quotes (’ ’). may easier short node name, assign label, shown within brackets [ ]. want newline within node’s name, must via label - use \\n node label within single quotes, shown .Subgroups\r\nWithin edge statements, subgroups can created either side edge curly brackets ({ }). edge applies nodes bracket - shorthand.Layoutsdot (set rankdir either TB, LR, RL, BT, )neatotwopicircoNodes - editable attributeslabel (text, single quotes multi-word)fillcolor (many possible colors)fontcoloralpha (transparency 0-1)shape (ellipse, oval, diamond, egg, plaintext, point, square, triangle)stylesidesperipheriesfixedsize (h x w)heightwidthdistortionpenwidth (width shape border)x (displacement left/right)y (displacement /)fontnamefontsizeiconEdges - editable attributesarrowsizearrowhead (normal, box, crow, curve, diamond, dot, inv, none, tee, vee)arrowtaildir (direction, )style (dashed, …)coloralphaheadport (text front arrowhead)tailport (text behind arrowtail)fontnamefontsizefontcolorpenwidth (width arrow)minlen (minimum length)Color names: hexadecimal values ‘X11’ color names, see X11 details","code":""},{"path":"diagrams-and-charts.html","id":"complex-examples","chapter":"34 Diagrams and charts","heading":"34.3.3 Complex examples","text":"example expands surveillance_diagram, adding complex node names, grouped edges, colors stylingSub-graph clustersTo group nodes boxed clusters, put within named subgraph (subgraph name {}). subgraph identified within bounding box, begin name subgraph “cluster”, shown 4 boxes .Node shapesThe example , borrowed tutorial, shows applied node shapes shorthand serial edge connections","code":"DiagrammeR::grViz(\"               # All instructions are within a large character string\r\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \r\n  \r\n  # graph statement\r\n  #################\r\n  graph [layout = dot,\r\n         rankdir = TB,            # layout top-to-bottom\r\n         fontsize = 10]\r\n  \r\n\r\n  # nodes (circles)\r\n  #################\r\n  node [shape = circle,           # shape = circle\r\n       fixedsize = true\r\n       width = 1.3]                      \r\n  \r\n  Primary   [label = 'Primary\\nFacility'] \r\n  Secondary [label = 'Secondary\\nFacility'] \r\n  Tertiary  [label = 'Tertiary\\nFacility'] \r\n  SC        [label = 'Surveillance\\nCoordination',\r\n             fontcolor = darkgreen] \r\n  \r\n  # edges\r\n  #######\r\n  Primary   -> Secondary [label = ' case transfer',\r\n                          fontcolor = red,\r\n                          color = red]\r\n  Secondary -> Tertiary [label = ' case transfer',\r\n                          fontcolor = red,\r\n                          color = red]\r\n  \r\n  # grouped edge\r\n  {Primary Secondary Tertiary} -> SC [label = 'case reporting',\r\n                                      fontcolor = darkgreen,\r\n                                      color = darkgreen,\r\n                                      style = dashed]\r\n}\r\n\")DiagrammeR::grViz(\"             # All instructions are within a large character string\r\ndigraph surveillance_diagram {  # 'digraph' means 'directional graph', then the graph name \r\n  \r\n  # graph statement\r\n  #################\r\n  graph [layout = dot,\r\n         rankdir = TB,            \r\n         overlap = true,\r\n         fontsize = 10]\r\n  \r\n\r\n  # nodes (circles)\r\n  #################\r\n  node [shape = circle,                  # shape = circle\r\n       fixedsize = true\r\n       width = 1.3]                      # width of circles\r\n  \r\n  subgraph cluster_passive {\r\n    Primary   [label = 'Primary\\nFacility'] \r\n    Secondary [label = 'Secondary\\nFacility'] \r\n    Tertiary  [label = 'Tertiary\\nFacility'] \r\n    SC        [label = 'Surveillance\\nCoordination',\r\n               fontcolor = darkgreen] \r\n  }\r\n  \r\n  # nodes (boxes)\r\n  ###############\r\n  node [shape = box,                     # node shape\r\n        fontname = Helvetica]            # text font in node\r\n  \r\n  subgraph cluster_active {\r\n    Active [label = 'Active\\nSurveillance'] \r\n    HCF_active [label = 'HCF\\nActive Search']\r\n  }\r\n  \r\n  subgraph cluster_EBD {\r\n    EBS [label = 'Event-Based\\nSurveillance (EBS)'] \r\n    'Social Media'\r\n    Radio\r\n  }\r\n  \r\n  subgraph cluster_CBS {\r\n    CBS [label = 'Community-Based\\nSurveillance (CBS)']\r\n    RECOs\r\n  }\r\n\r\n  \r\n  # edges\r\n  #######\r\n  {Primary Secondary Tertiary} -> SC [label = 'case reporting']\r\n\r\n  Primary   -> Secondary [label = 'case transfer',\r\n                          fontcolor = red]\r\n  Secondary -> Tertiary [label = 'case transfer',\r\n                          fontcolor = red]\r\n  \r\n  HCF_active -> Active\r\n  \r\n  {'Social Media' Radio} -> EBS\r\n  \r\n  RECOs -> CBS\r\n}\r\n\")\r\n\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n# define the global styles of the nodes. We can override these in box if we wish\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'Dataset 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'Dataset 2', shape = folder, fillcolor = Beige]\nprocess [label =  'Process \\n Data']\nstatistical [label = 'Statistical \\n Analysis']\nresults [label= 'Results']\n\n# edge definitions with the node IDs\n{data1 data2}  -> process -> statistical -> results\n}\")"},{"path":"diagrams-and-charts.html","id":"outputs","chapter":"34 Diagrams and charts","heading":"34.3.4 Outputs","text":"handle save outputsOutputs appear RStudio’s Viewer pane, default lower-right alongside Files, Plots, Packages, Help.export can “Save image” “Copy clipboard” Viewer. graphic adjust specified size.","code":""},{"path":"diagrams-and-charts.html","id":"parameterized-figures","chapter":"34 Diagrams and charts","heading":"34.3.5 Parameterized figures","text":"section yet complete. quote tutorial: https://mikeyharper.uk/flowcharts--r-using-diagrammer/“Parameterized figures: great benefit designing figures within R able connect figures directly analysis reading R values directly flowcharts. example, suppose created filtering process removes values stage process, can figure show number values left dataset stage process. , can use @@X symbol directly within figure, refer footer plot using [X]:, X unique numeric index.”Much adapted tutorial siteAnother -depth tutorial: http://rich-iannone.github.io/DiagrammeR/","code":"\n# Define some sample data\ndata <- list(a=1000, b=800, c=600, d=400)\n\n\nDiagrammeR::grViz(\"\ndigraph graph2 {\n\ngraph [layout = dot]\n\n# node definitions with substituted label text\nnode [shape = rectangle, width = 4, fillcolor = Biege]\na [label = '@@1']\nb [label = '@@2']\nc [label = '@@3']\nd [label = '@@4']\n\na -> b -> c -> d\n\n}\n\n[1]:  paste0('Raw Data (n = ', data$a, ')')\n[2]: paste0('Remove Errors (n = ', data$b, ')')\n[3]: paste0('Identify Potential Customers (n = ', data$c, ')')\n[4]: paste0('Select Top Priorities (n = ', data$d, ')')\n\")"},{"path":"diagrams-and-charts.html","id":"consort-diagram","chapter":"34 Diagrams and charts","heading":"34.3.6 CONSORT diagram","text":"SECTION CONSTRUCTIONhttps://scriptsandstatistics.wordpress.com/2017/12/22/--draw--consort-flow-diagram-using-r--graphviz/Note date via DiagrammeR","code":""},{"path":"diagrams-and-charts.html","id":"alluvialsankey-diagrams","chapter":"34 Diagrams and charts","heading":"34.4 Alluvial/Sankey Diagrams","text":"","code":""},{"path":"diagrams-and-charts.html","id":"load-packages-23","chapter":"34 Diagrams and charts","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.load networkD3 package produce diagram, also tidyverse data preparation steps.","code":"\npacman::p_load(\n  networkD3,\n  tidyverse)"},{"path":"diagrams-and-charts.html","id":"plotting-from-dataset","chapter":"34 Diagrams and charts","heading":"34.4.1 Plotting from dataset","text":"Plotting connections dataset. demonstrate using package case linelist. online tutorial.begin getting case counts unique age category hospital combination. ’ve removed values missing age category clarity. also re-label hospital age_cat columns source target respectively. two sides alluvial diagram.dataset now look like :Now create data frame diagram nodes, column name. consists values hospital age_cat. Note ensure class Character combining . adjust ID columns numbers instead labels:edit links data frame, created count(). add two numeric columns IDsource IDtarget actually reflect/create links nodes. columns hold rownumbers (position) source target nodes. 1 subtracted position numbers begin 0 (1).links dataset now looks like :Now plot Sankey diagram sankeyNetwork(). can read argument running ?sankeyNetwork console. Note unless set iterations = 0 order nodes may expected.example patient Outcome included well. Note data preparation step calculate counts cases age hospital, separately hospital outcome - bind counts together bind_rows().https://www.displayr.com/sankey-diagrams-r/Timeline Sankey - LTFU cohort… application/rejections… etc.","code":"\n# counts by hospital and age category\nlinks <- linelist %>% \n  filter(!is.na(age_cat)) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = hospital,\n         target = age_cat)\n# The unique node names\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\nnodes  # print##                                    name\r\n## 1                      Central Hospital\r\n## 2                     Military Hospital\r\n## 3                               Missing\r\n## 4                                 Other\r\n## 5                         Port Hospital\r\n## 6  St. Mark's Maternity Hospital (SMMH)\r\n## 7                                   0-4\r\n## 8                                   5-9\r\n## 9                                 10-14\r\n## 10                                15-19\r\n## 11                                20-29\r\n## 12                                30-49\r\n## 13                                50-69\r\n## 14                                  70+\n# match to numbers, not names\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n# plot\n######\np <- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0)        # ensure node order is as in data\np\n# counts by hospital and age category\nage_hosp_links <- linelist %>% \n  filter(!is.na(age_cat)) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = age_cat,          # re-name\n         target = hospital)\n\nhosp_out_links <- linelist %>% \n    filter(!is.na(age_cat)) %>% \n    select(hospital, outcome) %>% \n    count(hospital, outcome) %>% \n    rename(source = hospital,       # re-name\n           target = outcome)\n\n# combine links\nlinks <- bind_rows(age_hosp_links, hosp_out_links)\n\n# The unique node names\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\n# Create id numbers\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n\n# plot\n######\np <- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np"},{"path":"diagrams-and-charts.html","id":"event-timelines","chapter":"34 Diagrams and charts","heading":"34.5 Event timelines","text":"make timeline showing specific events, can use vistime package.See vignetteHere events dataset begin :","code":"\n# load package\npacman::p_load(vistime,  # make the timeline\n               plotly    # for interactive visualization\n               )\np <- vistime(data)    # apply vistime\n\nlibrary(plotly)\n\n# step 1: transform into a list\npp <- plotly_build(p)\n\n# step 2: Marker size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size <- 10\n}\n\n# step 3: text size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size <- 10\n}\n\n\n# step 4: text position\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition <- \"right\"\n}\n\n#print\npp"},{"path":"diagrams-and-charts.html","id":"dags","chapter":"34 Diagrams and charts","heading":"34.6 DAGs","text":"can build DAG manually using DiagammeR package DOT language, described another tab. Alternatively, packages like ggdag daggityhttps://cran.r-project.org/web/packages/ggdag/vignettes/intro--dags.htmlhttps://www.r-bloggers.com/2019/08/causal-inference--dags--r/#:~:text=%20a%20DAG%20all%20the,%20drawing%20and%20analyzing%20DAGs.","code":""},{"path":"diagrams-and-charts.html","id":"resources-27","chapter":"34 Diagrams and charts","heading":"34.7 Resources","text":"Links online tutorials resources.","code":""},{"path":"combinations-analysis.html","id":"combinations-analysis","chapter":"35 Combinations analysis","heading":"35 Combinations analysis","text":"","code":""},{"path":"combinations-analysis.html","id":"overview-17","chapter":"35 Combinations analysis","heading":"35.1 Overview","text":"analysis plots frequency different combinations values/responses. example, plot frequency symptom combinations.analysis often called:Multiple response analysisSets analysisCombinations analysisThe first method shown uses package ggupset, second using package UpSetR.example plot . Five symptoms shown. vertical bar line dots indicating combination symptoms reflected bar . right, horizontal bars reflect frequency individual symptom.","code":""},{"path":"combinations-analysis.html","id":"preparation-26","chapter":"35 Combinations analysis","heading":"35.2 Preparation","text":"","code":""},{"path":"combinations-analysis.html","id":"load-packages-24","chapter":"35 Combinations analysis","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  tidyverse,     # data management and visualization\n  UpSetR,        # special package for combination plots\n  ggupset)       # special package for combination plots"},{"path":"combinations-analysis.html","id":"import-data-21","chapter":"35 Combinations analysis","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instruction Download book data page.linelist includes five “yes/” variables reported symptoms. need transform variables bit use ggupset package make plot.View data (scroll right see symptoms variables). first 50 rows shown.","code":""},{"path":"combinations-analysis.html","id":"re-format-values","chapter":"35 Combinations analysis","heading":"Re-format values","text":"align format expected ggupset convert “yes” “actual symptom name, using case_when() dplyr. ”\", set value blank.Now make two final variables:\r\n1. Pasting together symptoms patient (character variable)\r\n2. Convert class list, can accepted ggupset make plotView new data. Note two columns end - pasted combined values, list","code":"\n# create column with the symptoms named, separated by semicolons\nlinelist_sym_1 <- linelist_sym %>% \n  \n  # convert the \"yes\" and \"no\" values into the symptom name itself\n  mutate(fever = case_when(fever == \"yes\" ~ \"fever\",          # if old value is \"yes\", new value is \"fever\"\n                           TRUE           ~ NA_character_),   # if old value is anything other than \"yes\", the new value is NA\n         \n         chills = case_when(chills == \"yes\" ~ \"chills\",\n                           TRUE           ~ NA_character_),\n         \n         cough = case_when(cough == \"yes\" ~ \"cough\",\n                           TRUE           ~ NA_character_),\n         \n         aches = case_when(aches == \"yes\" ~ \"aches\",\n                           TRUE           ~ NA_character_),\n         \n         shortness_of_breath = case_when(shortness_of_breath == \"yes\" ~ \"shortness_of_breath\",\n                           TRUE           ~ NA_character_))\nlinelist_sym_1 <- linelist_sym_1 %>% \n  mutate(\n         # combine the variables into one, using paste() with a semicolon separating any values\n         all_symptoms = paste(fever, chills, cough, aches, shortness_of_breath, sep = \"; \"),\n         \n         # make a copy of all_symptoms variable, but of class \"list\" (which is required to use ggupset() in next step)\n         all_symptoms_list = as.list(strsplit(all_symptoms, \"; \"))\n         )"},{"path":"combinations-analysis.html","id":"ggupset","chapter":"35 Combinations analysis","heading":"35.3 ggupset","text":"Load packageCreate plot. begin ggplot() geom_bar(), add special scale_x_upset() package.information ggupset can found online offline package documentation RStudio Help tab ?ggupset.","code":"\npacman::p_load(ggupset)\nggplot(\n  data = linelist_sym_1,\n  aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"shortness_of_breath\"))+\n  labs(title = \"Signs & symptoms\",\n       subtitle = \"10 most frequent combinations of signs and symptoms\",\n       caption = \"Caption here.\",\n       x = \"Symptom combination\",\n       y = \"Frequency in dataset\")"},{"path":"combinations-analysis.html","id":"upsetr","chapter":"35 Combinations analysis","heading":"35.4 UpSetR","text":"UpSetR package allows customization plot, can difficult execute:Load packageData cleaningWe must convert linelist symptoms values 1/0.Now make plot using custom function upset() - using symptoms columns. must designate “sets” compare (names symptom columns). Alternatively, use nsets = order.= \"freq\" show top X combinations.","code":"\npacman::p_load(UpSetR)\n# Make using upSetR\n\nlinelist_sym_2 <- linelist_sym %>% \n  \n  # convert the \"yes\" and \"no\" values into the symptom name itself\n  mutate(fever = case_when(fever == \"yes\" ~ 1,          # if old value is \"yes\", new value is \"fever\"\n                           TRUE           ~ 0),   # if old value is anything other than \"yes\", the new value is NA\n         \n         chills = case_when(chills == \"yes\" ~ 1,\n                           TRUE           ~ 0),\n         \n         cough = case_when(cough == \"yes\" ~ 1,\n                           TRUE           ~ 0),\n         \n         aches = case_when(aches == \"yes\" ~ 1,\n                           TRUE           ~ 0),\n         \n         shortness_of_breath = case_when(shortness_of_breath == \"yes\" ~ 1,\n                           TRUE           ~ 0))\n# Make the plot\nUpSetR::upset(\n  select(linelist_sym_2, fever, chills, cough, aches, shortness_of_breath),\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"shortness_of_breath\"),\n  order.by = \"freq\",\n  sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # optional colors\n  empty.intersections = \"on\",\n  # nsets = 3,\n  number.angles = 0,\n  point.size = 3.5,\n  line.size = 2, \n  mainbar.y.label = \"Symptoms Combinations\",\n  sets.x.label = \"Patients with Symptom\")"},{"path":"combinations-analysis.html","id":"resources-28","chapter":"35 Combinations analysis","heading":"35.5 Resources","text":"https://github.com/hms-dbmi/UpSetR read \r\nhttps://gehlenborglab.shinyapps.io/upsetr/ Shiny App version - can upload data\r\nhttps://cran.r-project.org/web/packages/UpSetR/UpSetR.pdf documentation - difficult interpret","code":""},{"path":"heat-tiles.html","id":"heat-tiles","chapter":"36 Heat tiles","heading":"36 Heat tiles","text":"Heat tiles (“heatmaps”) can useful visualizations trying display 3 variables (x-axis, y-axis, fill). demonstrate two examples:visual matrix transmission events age (“infected ”)Tracking reporting metrics across many facilities/jurisdictions time","code":""},{"path":"heat-tiles.html","id":"preparation-27","chapter":"36 Heat tiles","heading":"36.1 Preparation","text":"","code":""},{"path":"heat-tiles.html","id":"load-packages-25","chapter":"36 Heat tiles","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.DatasetsThis page utilizes case linelist simulated outbreak transmission matrix section, separate dataset daily malaria case counts facility metrics tracking section. loaded cleaned individual sections.","code":"\npacman::p_load(\n  tidyverse,       # data manipulation and visualization\n  rio,             # importing data \n  lubridate        # working with dates\n  )"},{"path":"heat-tiles.html","id":"transmission-matrix","chapter":"36 Heat tiles","heading":"36.2 Transmission matrix","text":"Heat tiles can useful visualize matrices. One example display “-infected-” outbreak. assumes information transmission events linelist.begin case linelist:one row per caseThere column contains case_id infector, also case linelistWe import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist shown demonstration:","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"heat-tiles.html","id":"convert-to-long","chapter":"36 Heat tiles","heading":"Convert to “long”","text":"Objective: need achieve “long”-style dataframe contains frequency transmission events age category. take several data manuipulation steps achieve.","code":""},{"path":"heat-tiles.html","id":"make-cases-data-frame","chapter":"36 Heat tiles","heading":"Make cases data frame","text":"begin, create dataframe cases, ages, infectors - call data frame case_ages. first rows displayed .","code":"\ncase_ages <- linelist %>% \n  select(case_id, infector, age_cat) %>% \n  rename(\"case_age_cat\" = \"age_cat\")"},{"path":"heat-tiles.html","id":"make-infectors-data-frame","chapter":"36 Heat tiles","heading":"Make infectors data frame","text":"Next, create dataframe infectors - moment consists single column. infector IDs linelist. every case known infector, remove missing values. first rows displayed .Next, use joins procure ages infectors. simple, linelist, infector’s ages listed . achieve result joining case linelist infectors. begin infectors, left_join() (add) case linelist infector id column left-side “baseline” data frame joins case_id column right-side linelist data frame.Thus, data infector’s case record linelist (including age) added infector row. first rows displayed ., combine cases ages infectors ages. dataframe column infector, used join. first rows displayed :, simple cross-tabulation counts case infector age groups. Labels added clarity.can convert table dataframe data.frame() base R, also automatically converts “long” format, desired ggplot(). first rows shown .apply prop.table() base R table instead counts get proportion values. first rows shown .Now finally can create heatmap ggplot2 package, using geom_tile() function.aesthetics aes() geom_tile() set x y case age infector ageAlso aes() set argument fill = Freq column - value converted tile colorSet scale color scale_fill_gradient() - can specify high/low colors\r\nNote scale_color_gradient() different! case want fill\r\nNote scale_color_gradient() different! case want fillBecause color made via “fill”, can use fill = argument labs() change legend title","code":"\ninfectors <- linelist %>% \n  select(infector) %>% \n  filter(!is.na(infector))\ninfector_ages <- infectors %>%             # begin with infectors\n  left_join(                               # add the linelist data to each infector  \n    linelist,\n    by = c(\"infector\" = \"case_id\")) %>%    # match infector to their information as a case\n  select(infector, age_cat) %>%            # keep only columns of interest\n  rename(\"infector_age_cat\" = \"age_cat\")   # rename for clarity\nages_complete <- case_ages %>%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %>%        # each has the column infector\n  drop_na()                     # drop rows with any missing data\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)##        infectors\r\n## cases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\r\n##   0-4   105 156   105   114   143   117    13   0\r\n##   5-9   102 132   110   102   117    96    12   5\r\n##   10-14 104 109    91    79   120    80    12   4\r\n##   15-19  85 105    82    39    75    69     7   5\r\n##   20-29 101 127   109    80   143   107    22   4\r\n##   30-49  72  97    56    54    98    61     4   5\r\n##   50-69   5   6    15     9     7     5     2   0\r\n##   70+     1   0     2     0     0     0     0   0\nlong_counts <- data.frame(table(\n    cases     = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\nlong_prop <- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = cases,         # x-axis is case age\n      y = infectors,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  labs(                         # labels\n    x = \"Case age\",\n    y = \"Infector age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )"},{"path":"heat-tiles.html","id":"reporting-metrics-over-time","chapter":"36 Heat tiles","heading":"36.3 Reporting metrics over time","text":"Often public health, one objective assess trends time many entities (facilities, jurisdictions, etc.). One way visualize trends time heatmap x-axis time y-axis many entities.","code":""},{"path":"heat-tiles.html","id":"preparation-28","chapter":"36 Heat tiles","heading":"Preparation","text":"begin importing dataset daily malaria reports many facilities. reports contain date, province, district, malaria counts. See page Download book data informaton download data. first 30 rows:","code":"\nfacility_count_data <- import(\"facility_count_data.rds\")"},{"path":"heat-tiles.html","id":"aggregate-and-summarize","chapter":"36 Heat tiles","heading":"Aggregate and summarize","text":"objective example transform daily facility total malaria case counts (seen previous tab) weekly summary statistics facility reporting performance - case proportion days per week facility reported data. example show data Spring District April-May 2019.achieve following data management steps:Filter data appropriate (place, date)Create week column using floor_date() package lubridate\r\nfunction returns start-date given date’s week, using specified start date week (e.g. “Mondays”)\r\nfunction returns start-date given date’s week, using specified start date week (e.g. “Mondays”)data grouped columns “location” “week” create analysis units “facility-week”function summarise() creates new columns reflecting summary statistics per facility-week group:\r\nNumber days per week (7 - static value)\r\nNumber reports received facility-week (7!)\r\nSum malaria cases reported facility-week (just interest)\r\nNumber unique days facility-week data reported\r\nPercent 7 days per facility-week data reported\r\nNumber days per week (7 - static value)Number reports received facility-week (7!)Sum malaria cases reported facility-week (just interest)Number unique days facility-week data reportedPercent 7 days per facility-week data reportedThe dataframe joined (right_join()) comprehensive list possible facility-week combinations, make dataset complete. matrix possible combinations created applying expand() two columns dataframe moment pipe chain (represented “.”). right_join() used, rows expand() dataframe kept, added agg_weeks necessary. new rows appear NA (missing) summarized values.demonstrate step--step:Now dataset 584 rows, previously 3038Next create week column reflecting start date week record. achieved lubridate package function floor_date(), set “week” weeks begin Mondays (day 1 week - Sundays 7). top rows shown .new week column can seen far right dataframeNow group data facility-weeks summarise produce statistics per facility-week. See page Descriptive tables tips. grouping doesn’t change dataframe, impacts subsequent summary statistics calculated.top rows shown . Note columns completely changed reflect desired summary statistics. row reflects one facility-week.Finally, run command ensure possible facility-weeks present data, even missing .using right_join() (dataset represented “.”) expanded include possible combinations columns week location_name. See documentation expand() function page [Pivoting]. running code dataset contains 97 rows.running code dataset contains 165 rows.","code":"\n# Create weekly summary dataset\nagg_weeks <- facility_count_data %>% \n  \n  # filter the data as appropriate\n  filter(\n    District == \"Spring\",\n    data_date < as.Date(\"2019-06-01\")) \nagg_weeks <- agg_weeks %>% \n  # Create week column from data_date\n  mutate(\n    week = lubridate::floor_date(                     # create new column of weeks\n      data_date,                                      # date column\n      unit = \"week\",                                  # give start of the week\n      week_start = 1))                                # weeks to start on Mondays \nagg_weeks <- agg_weeks %>%   \n\n  # Group into facility-weeks\n  group_by(\n    location_name, week) %>%\n  \n  # Create summary statistics columns on the grouped data\n  summarize(\n    n_days          = 7,                                          # 7 days per week           \n    n_reports       = dplyr::n(),                                 # number of reports received per week (could be >7)\n    malaria_tot     = sum(malaria_tot, na.rm = T),                # total malaria cases reported\n    n_days_reported = length(unique(data_date)),                  # number of unique days reporting per week\n    p_days_reported = round(100*(n_days_reported / n_days)))      # percent of days reporting\n# Create dataframe of every possible facility-week\nexpanded_weeks <- agg_weeks %>% \n  mutate(week = as.factor(week)) %>%         # convert date to a factor so expand() works correctly\n  tidyr::expand(., week, location_name) %>%  # expand dataframe to include all possible facility-week combinations\n                                             # note: \".\" represents the dataset at that moment in the pipe chain\n  mutate(week = as.Date(week))               # re-convert week to class Date so the subsequent right_join works\n                                             \n\n# Use right-join with the expanded facility-week list to fill-in the missing gaps in the data\nagg_weeks <- agg_weeks %>%      \n  right_join(expanded_weeks) %>%                            # Ensure every possible facility-week combination appears in the data\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # convert missing values to 0                           "},{"path":"heat-tiles.html","id":"create-heatmap","chapter":"36 Heat tiles","heading":"Create heatmap","text":"ggplot() made using geom_tile() ggplot2 package:Weeks x-axis transformed dates, allowing use scale_x_date()location_name y-axis show facility namesThe fill performance facility-week (numeric)scale_fill_gradient() used numeric fill, specifying colors high, low, NAscale_x_date() used x-axis specifying labels every 2 weeks formatAesthetic themes labels can adjusted necessary","code":""},{"path":"heat-tiles.html","id":"basic","chapter":"36 Heat tiles","heading":"Basic","text":"basic heatmap produced ,using default colors, scales, etc. Within aes() geom_tile() must provide x-axis column, y-axis column, column fill = - numeric values converted tile color.","code":"\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))"},{"path":"heat-tiles.html","id":"cleaned-plot","chapter":"36 Heat tiles","heading":"Cleaned plot","text":"can make plot look better adding additional ggplot2 functions, shown . See page ggplot tips details.","code":"\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-tiles.html","id":"ordered-y-axis","chapter":"36 Heat tiles","heading":"Ordered y-axis","text":"Currently, facilities ordered “alphabetically” bottom top. want adjust order y-axis facilities, convert class factor provide order. See page Factors tips., column location_name converted factor, order levels set based total number reporting days filed facility across whole time-span., create dataframe represents total number reports per facility, arranged ascending order. can use vector order factor levels plot.See dataframe :Now use vector (facility_order$location_name) order factor levels location_name dataframe agg_weeks:now data re-plotted, location_name ordered factor:","code":"\nfacility_order <- agg_weeks %>% \n  group_by(location_name) %>% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %>% \n  arrange(tot_reports) # ascending order\n# load package \npacman::p_load(forcats)\n\n# create factor and define levels manually\nagg_weeks <- agg_weeks %>% \n  mutate(location_name = as_factor(location_name),\n         location_name = fct_relevel(location_name, \n                                     levels = facility_order$location_name))\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-tiles.html","id":"display-values","chapter":"36 Heat tiles","heading":"Display values","text":"can add geom_text() layer top tiles, display actual numbers tile. aware may look pretty many small tiles!following code added: geom_text(aes(label = p_days_reported)). adds text onto every tile. text displayed value assigned argument label =, case set numeric column p_days_reported used create color gradient.","code":"\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  # text\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+          # add text on top of tile\n  \n  # fill scale\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-tiles.html","id":"resources-29","chapter":"36 Heat tiles","heading":"36.4 Resources","text":"","code":""},{"path":"transmission-chains.html","id":"transmission-chains","chapter":"37 Transmission chains","heading":"37 Transmission chains","text":"","code":""},{"path":"transmission-chains.html","id":"overview-18","chapter":"37 Transmission chains","heading":"37.1 Overview","text":"primary tool handle, analyse visualise transmission chains contact\r\ntracing data package epicontacts, developed folks \r\nRECON. Try interactive plot hovering nodes \r\ninformation, dragging move clicking highlight downstream cases.","code":""},{"path":"transmission-chains.html","id":"preparation-29","chapter":"37 Transmission chains","heading":"37.2 Preparation","text":"","code":""},{"path":"transmission-chains.html","id":"load-packages-26","chapter":"37 Transmission chains","heading":"Load packages","text":"First load standard packages required data import manipulation. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.require development version epicontacts, can \r\ninstalled github using remotes package. need run code\r\n, every time use package.","code":"\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   remotes       # Package installation from github\n)\nremotes::install_github(\"reconhub/epicontacts@timeline\")"},{"path":"transmission-chains.html","id":"import-data-22","chapter":"37 Transmission chains","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed . particular interest columns case_id, generation, infector, source.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"transmission-chains.html","id":"creating-an-epicontacts-object","chapter":"37 Transmission chains","heading":"37.2.1 Creating an epicontacts object","text":"need create epicontacts object, requires two types \r\ndata:linelist documenting cases columns variables rows correspond unique casesa list edges defining links cases basis unique IDs (can contacts,\r\ntransmission events, etc.)already linelist, just need create list edges \r\ncases, specifically IDs. can extract transmission links \r\nlinelist linking infector column case_id column. point can also add “edge\r\nproperties”, mean variable describing link two\r\ncases, cases . illustration, add location\r\nvariable describing location transmission event, duration\r\nvariable describing duration contact days.code , dplyr function transmute similar mutate, except keeps\r\ncolumns specified within function. drop_na function \r\nfilter rows specified columns NA value; \r\ncase, want keep rows infector known.can now create epicontacts object using make_epicontacts\r\nfunction. need specify column linelist points unique case\r\nidentifier, well columns contacts point unique\r\nidentifiers cases involved link. links directional \r\ninfection going infector case, need specify\r\narguments accordingly. therefore also set directed\r\nargument TRUE, affect future operations.Upon examining epicontacts objects, can see case_id column\r\nlinelist renamed id case_id infector\r\ncolumns contacts renamed . ensures\r\nconsistency subsequent handling, visualisation analysis operations.","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %>%\n  drop_na(infector)\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n## view epicontacts object\nepic## \r\n## /// Epidemiological Contacts //\r\n## \r\n##   // class: epicontacts\r\n##   // 5,888 cases in linelist; 3,800 contacts; directed \r\n## \r\n##   // linelist\r\n## \r\n## # A tibble: 5,888 x 30\r\n##    id     generation date_infection date_onset date_hospitalis~ date_outcome outcome gender   age age_unit age_years age_cat age_cat5 hospital   lon\r\n##    <chr>       <dbl> <date>         <date>     <date>           <date>       <chr>   <chr>  <dbl> <chr>        <dbl> <fct>   <fct>    <chr>    <dbl>\r\n##  1 5fe599          4 2014-05-08     2014-05-13 2014-05-15       NA           <NA>    m          2 years            2 0-4     0-4      Other    -13.2\r\n##  2 8689b7          4 NA             2014-05-13 2014-05-14       2014-05-18   Recover f          3 years            3 0-4     0-4      Missing  -13.2\r\n##  3 11f8ea          2 NA             2014-05-16 2014-05-18       2014-05-30   Recover m         56 years           56 50-69   55-59    St. Mar~ -13.2\r\n##  4 b8812a          3 2014-05-04     2014-05-18 2014-05-20       NA           <NA>    f         18 years           18 15-19   15-19    Port Ho~ -13.2\r\n##  5 893f25          3 2014-05-18     2014-05-21 2014-05-22       2014-05-29   Recover m          3 years            3 0-4     0-4      Militar~ -13.2\r\n##  6 be99c8          3 2014-05-03     2014-05-22 2014-05-23       2014-05-24   Recover f         16 years           16 15-19   15-19    Port Ho~ -13.2\r\n##  7 07e3e8          4 2014-05-22     2014-05-27 2014-05-29       2014-06-01   Recover f         16 years           16 15-19   15-19    Missing  -13.2\r\n##  8 369449          4 2014-05-28     2014-06-02 2014-06-03       2014-06-07   Death   f          0 years            0 0-4     0-4      Missing  -13.2\r\n##  9 f393b4          4 NA             2014-06-05 2014-06-06       2014-06-18   Recover m         61 years           61 50-69   60-64    Missing  -13.2\r\n## 10 1389ca          4 NA             2014-06-05 2014-06-07       2014-06-09   Death   f         27 years           27 20-29   25-29    Missing  -13.3\r\n## # ... with 5,878 more rows, and 15 more variables: lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>,\r\n## #   chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>, time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\r\n## \r\n##   // contacts\r\n## \r\n## # A tibble: 3,800 x 4\r\n##    from   to     location   duration\r\n##    <chr>  <chr>  <chr>         <int>\r\n##  1 f547d6 5fe599 Community         2\r\n##  2 f90f5f b8812a Community         8\r\n##  3 11f8ea 893f25 Nosocomial        2\r\n##  4 aec8ec be99c8 Nosocomial        8\r\n##  5 893f25 07e3e8 Nosocomial        9\r\n##  6 133ee7 369449 Nosocomial        3\r\n##  7 996f3a 2978ac Community         1\r\n##  8 133ee7 57a565 Nosocomial        9\r\n##  9 37a6f6 fc15ef Nosocomial        5\r\n## 10 9f6884 2eaa9a Nosocomial        1\r\n## # ... with 3,790 more rows"},{"path":"transmission-chains.html","id":"handling","chapter":"37 Transmission chains","heading":"37.3 Handling","text":"","code":""},{"path":"transmission-chains.html","id":"subsetting","chapter":"37 Transmission chains","heading":"37.3.1 Subsetting","text":"subset() method epicontacts objects allows , among things,\r\nfiltering networks based properties linelist (“node attributes”) contacts\r\ndatabase (“edge attributes”). values must passed named lists \r\nrespective argument. example, code keeping \r\nmale cases linelist infection date April \r\nJuly 2014 (dates specified ranges), transmission links occured\r\nhospital.can use thin function either filter linelist include cases\r\nfound contacts setting argument = \"linelist\", \r\nfilter contacts include cases found linelist setting\r\nargument = \"contacts\". code , filtering \r\nepicontacts object keep transmission links involving male cases\r\ninfected April July filtered . can see \r\ntwo known transmission links fit specification.addition subsetting node edge attributes, networks can pruned \r\ninclude components connected certain nodes. cluster_id\r\nargument takes vector case IDs returns linelist individuals \r\nlinked, directly indirectly, IDs. code , can see\r\ntotal 13 linelist cases involved clusters containing\r\n2ae019 71577a.subset() method epicontacts objects also allows filtering cluster\r\nsize using cs, cs_min cs_max arguments. code , \r\nkeeping cases linked clusters 10 cases larger, can see \r\n271 linelist cases involved clusters.","code":"\nsub_attributes <- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes## \r\n## /// Epidemiological Contacts //\r\n## \r\n##   // class: epicontacts\r\n##   // 69 cases in linelist; 1,882 contacts; directed \r\n## \r\n##   // linelist\r\n## \r\n## # A tibble: 69 x 30\r\n##    id     generation date_infection date_onset date_hospitalis~ date_outcome outcome gender   age age_unit age_years age_cat age_cat5 hospital   lon\r\n##    <chr>       <dbl> <date>         <date>     <date>           <date>       <chr>   <chr>  <dbl> <chr>        <dbl> <fct>   <fct>    <chr>    <dbl>\r\n##  1 5fe599          4 2014-05-08     2014-05-13 2014-05-15       NA           <NA>    m          2 years            2 0-4     0-4      Other    -13.2\r\n##  2 893f25          3 2014-05-18     2014-05-21 2014-05-22       2014-05-29   Recover m          3 years            3 0-4     0-4      Militar~ -13.2\r\n##  3 2978ac          4 2014-05-30     2014-06-06 2014-06-08       2014-06-15   Death   m         12 years           12 10-14   10-14    Port Ho~ -13.2\r\n##  4 57a565          4 2014-05-28     2014-06-13 2014-06-15       NA           Death   m         42 years           42 30-49   40-44    Militar~ -13.3\r\n##  5 fc15ef          6 2014-06-14     2014-06-16 2014-06-17       2014-07-09   Recover m         19 years           19 15-19   15-19    Missing  -13.2\r\n##  6 99e8fa          7 2014-06-24     2014-06-28 2014-06-29       2014-07-09   Recover m         19 years           19 15-19   15-19    Port Ho~ -13.2\r\n##  7 f327be          6 2014-06-14     2014-07-12 2014-07-13       2014-07-14   Death   m         31 years           31 30-49   30-34    St. Mar~ -13.2\r\n##  8 90e5fe          5 2014-06-18     2014-07-13 2014-07-14       2014-07-16   <NA>    m         67 years           67 50-69   65-69    Port Ho~ -13.3\r\n##  9 a47529          5 2014-06-13     2014-07-17 2014-07-18       2014-07-26   Death   m         45 years           45 30-49   45-49    Militar~ -13.2\r\n## 10 da8ecb          5 2014-06-20     2014-07-18 2014-07-20       2014-08-01   <NA>    m         12 years           12 10-14   10-14    Missing  -13.2\r\n## # ... with 59 more rows, and 15 more variables: lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>,\r\n## #   chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>, time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\r\n## \r\n##   // contacts\r\n## \r\n## # A tibble: 1,882 x 4\r\n##    from   to     location   duration\r\n##    <chr>  <chr>  <chr>         <int>\r\n##  1 11f8ea 893f25 Nosocomial        2\r\n##  2 aec8ec be99c8 Nosocomial        8\r\n##  3 893f25 07e3e8 Nosocomial        9\r\n##  4 133ee7 369449 Nosocomial        3\r\n##  5 133ee7 57a565 Nosocomial        9\r\n##  6 37a6f6 fc15ef Nosocomial        5\r\n##  7 9f6884 2eaa9a Nosocomial        1\r\n##  8 a75c7f 7f5a01 Nosocomial        1\r\n##  9 8e104d ddddee Nosocomial        9\r\n## 10 b799eb bc2adf Nosocomial        7\r\n## # ... with 1,872 more rows\nsub_attributes <- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)## [1] 3\nsub_id <- subset(epic, cluster_id = c(\"2ae019\",\"71577a\"))\nnrow(sub_id$linelist)## [1] 13\nsub_cs <- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)## [1] 271"},{"path":"transmission-chains.html","id":"accessing-ids","chapter":"37 Transmission chains","heading":"37.3.2 Accessing IDs","text":"get_id() function retrieves information case IDs \r\ndataset, can parameterized follows:linelist: IDs line list datacontacts: IDs contact dataset (“” “” combined): IDs “” column contact datsetto IDs “” column contact datasetall: IDs appear anywhere either datasetcommon: IDs appear contacts dataset line listFor example, first ten IDs contacts dataset?many IDs found linelist contacts?","code":"\ncontacts_ids <- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)##  [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\" \"9f6884\" \"4802b1\"\nlength(get_id(epic, \"common\"))## [1] 4352"},{"path":"transmission-chains.html","id":"visualization","chapter":"37 Transmission chains","heading":"37.4 Visualization","text":"","code":""},{"path":"transmission-chains.html","id":"basic-plotting","chapter":"37 Transmission chains","heading":"37.4.1 Basic plotting","text":"visualisations epicontacts objects handled plot\r\nfunction. first filter epicontacts object include \r\ncases onset dates June 2014 using subset function, \r\ninclude contacts linked cases using thin function.can create basic, interactive plot simply follows:can move nodes around dragging , hover \r\ninformation click highlight connected cases.large number arguments modify plot. cover\r\nmain ones , check documentation via ?vis_epicontacts (\r\nfunction called using plot epicontacts object) get full\r\ndescription function arguments.","code":"\n## subset epicontacts object\nsub <- epic %>%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %>%\n thin(\"contacts\")\n## plot epicontacts object\nplot(\n  sub,\n  width = 700,\n  height = 700\n)"},{"path":"transmission-chains.html","id":"visualising-node-attributes","chapter":"37 Transmission chains","heading":"37.4.1.1 Visualising node attributes","text":"Node color, node shape node size can mapped given column linelist\r\nusing node_color, node_shape node_size arguments. similar\r\naes syntax may recognise ggplot2.specific colors, shapes sizes nodes can specified follows:Colors via col_pal argument, either providing name list manual\r\nspecification color done , providing color palette\r\nfunction colorRampPalette(c(\"black\", \"red\", \"orange\")), \r\nprovide gradient colours ones specified.Colors via col_pal argument, either providing name list manual\r\nspecification color done , providing color palette\r\nfunction colorRampPalette(c(\"black\", \"red\", \"orange\")), \r\nprovide gradient colours ones specified.Shapes passing named list shapes argument, specifying one shape\r\nunique element linelist column specified node_shape\r\nargument. See codeawesome available shapes.Shapes passing named list shapes argument, specifying one shape\r\nunique element linelist column specified node_shape\r\nargument. See codeawesome available shapes.Size passing size range nodes size_range argument.Size passing size range nodes size_range argument.example, color represents outcome, shape gender size\r\nage:","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"visualising-edge-attributes","chapter":"37 Transmission chains","heading":"37.4.1.2 Visualising edge attributes","text":"Edge color, width linetype can mapped given column contacts\r\ndataframe using edge_color, edge_width edge_linetype\r\narguments. specific colors widths edges can specified follows:Colors via edge_col_pal argument, manner used col_pal.Colors via edge_col_pal argument, manner used col_pal.Widths passing size range nodes width_range argument.Widths passing size range nodes width_range argument.example:","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  edge_col_pal = c(Community = \"orange\", Nosocomial = \"purple\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"temporal-axis","chapter":"37 Transmission chains","heading":"37.4.2 Temporal axis","text":"can also visualise network along temporal axis mapping x_axis\r\nargument column linelist. example , x-axis\r\nrepresents date symptom onset. also specified arrow_size\r\nargument ensure arrows large, set label = FALSE make\r\nfigure less cluttered.large number additional arguments futher specify \r\nnetwork visualised along temporal axis, can check \r\nvia ?vis_temporal_interactive (function called using plot \r\nepicontacts object x_axis specified). ’ll go \r\n.","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"specifying-transmission-tree-shape","chapter":"37 Transmission chains","heading":"37.4.2.1 Specifying transmission tree shape","text":"two main shapes transmission tree can assume, specified using\r\nnetwork_shape argument. first branching shape shown ,\r\nstraight edge connects two nodes. intuitive\r\nrepresentation, however can result overlapping edges densely connected\r\nnetwork. second shape rectangle, produces tree resembling \r\nphylogeny. example:case node can assigned unique vertical position toggling \r\nposition_dodge argument. position unconnected cases (.e. \r\nreported contacts) specified using unlinked_pos argument.position parent node relative children nodes can \r\nspecified using parent_pos argument. default option place \r\nparent node middle, however can placed bottom (parent_pos = 'bottom') top (parent_pos = 'top').","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"saving-plots-and-figures","chapter":"37 Transmission chains","heading":"37.4.2.2 Saving plots and figures","text":"can save plot interactive, self-contained html file \r\nvisSave function VisNetwork package:Saving network outputs image unfortunately less easy requires\r\nsave file html take screenshot file using\r\nwebshot package. code , converting html file saved\r\nPNG:","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %>%\n  visNetwork::visSave(\"network.html\")\nwebshot(url = \"network.html\", file = \"network.png\")"},{"path":"transmission-chains.html","id":"timelines","chapter":"37 Transmission chains","heading":"37.4.3 Timelines","text":"can also case timelines network, represented x-axis\r\ncase. can used visualise case locations, example, time\r\noutcome. generate timeline, need create data.frame least\r\nthree columns indicating case ID, start date “event” end\r\ndate “event”. can also add number columns can\r\nmapped node edge properties timeline. code ,\r\ngenerate timeline going date symptom onset date \r\noutcome, keep outcome hospital variables use define \r\nnode shape colour. Note can one timeline row/event\r\nper case, example case transferred multiple hospitals.pass timeline element timeline argument. can map\r\ntimeline attributes timeline node colours, shapes sizes way\r\ndefined previous sections, except two nodes: start end\r\nnode timeline, seperate arguments. example,\r\ntl_start_node_color defines timeline column mapped colour \r\nstart node, tl_end_node_shape defines timeline column \r\nmapped shape end node. can also map colour, width, linetype \r\nlabels timeline edge via tl_edge_* arguments.See ?vis_temporal_interactive (function called plotting \r\nepicontacts object) detailed documentation arguments. argument\r\nannotated code :","code":"\n## generate timeline\ntimeline <- linelist %>%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n## define shapes\nshapes <- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## define colours\ncolours <- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## make plot\nplot(\n  sub,\n  ## max x coordinate to date of onset\n  x_axis = \"date_onset\",\n  ## use rectangular network shape\n  network_shape = \"rectangle\",\n  ## mape case node shapes to gender column\n  node_shape = \"gender\",\n  ## we don't want to map node colour to any columns - this is important as the\n  ## default value is to map to node id, which will mess up the colour scheme\n  node_color = NULL,\n  ## set case node size to 30 (as this is not a character, node_size is not\n  ## mapped to a column but instead interpreted as the actual node size)\n  node_size = 30,\n  ## set transmission link width to 4 (as this is not a character, edge_width is\n  ## not mapped to a column but instead interpreted as the actual edge width)\n  edge_width = 4,\n  ## provide the timeline object\n  timeline = timeline,\n  ## map the shape of the end node to the outcome column in the timeline object\n  tl_end_node_shape = \"outcome\",\n  ## set the size of the end node to 15 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## node size)\n  tl_end_node_size = 15,\n  ## map the colour of the timeline edge to the hospital column\n  tl_edge_color = \"hospital\",\n  ## set the width of the timeline edge to 2 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## edge width)\n  tl_edge_width = 2,\n  ## map edge labels to the hospital variable\n  tl_edge_label = \"hospital\",\n  ## specify the shape for everyone node attribute (defined above)\n  shapes = shapes,\n  ## specify the colour palette (defined above)\n  col_pal = colours,\n  ## set the size of the arrow to 0.5\n  arrow_size = 0.5,\n  ## use two columns in the legend\n  legend_ncol = 2,\n  ## set font size\n  font_size = 15,\n  ## define formatting for dates\n  date_labels = c(\"%d %b %Y\"),\n  ## don't plot the ID labels below nodes\n  label = FALSE,\n  ## specify height\n  height = 1000,\n  ## specify width\n  width = 1200,\n  ## ensure each case node has a unique y-coordinate - this is very important\n  ## when using timelines, otherwise you will have overlapping timelines from\n  ## different cases\n  position_dodge = TRUE\n)## Warning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed as ID not found in linelist or start/end date is NA"},{"path":"transmission-chains.html","id":"analysis","chapter":"37 Transmission chains","heading":"37.5 Analysis","text":"","code":""},{"path":"transmission-chains.html","id":"summarising","chapter":"37 Transmission chains","heading":"37.5.1 Summarising","text":"can get overview network properties using \r\nsummary function.example, can see 57% contacts cases \r\nlinelist; means linelist data significant\r\nnumber cases involved transmission chains.","code":"\n## summarise epicontacts object\nsummary(epic)## \r\n## /// Overview //\r\n##   // number of unique IDs in linelist: 5888\r\n##   // number of unique IDs in contacts: 5511\r\n##   // number of unique IDs in both: 4352\r\n##   // number of contacts: 3800\r\n##   // contacts with both cases in linelist: 56.9 %\r\n## \r\n## /// Degrees of the network //\r\n##   // in-degree summary:\r\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n##   0.000   0.000   1.000   0.539   1.000   1.000 \r\n## \r\n##   // out-degree summary:\r\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n##    0.00    0.00    0.00    0.54    1.00    6.00 \r\n## \r\n##   // in and out degree summary:\r\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n##    0.00    1.00    1.00    1.08    1.00    7.00 \r\n## \r\n## /// Attributes //\r\n##   // attributes in linelist:\r\n##  generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\r\n## \r\n##   // attributes in contacts:\r\n##  location duration"},{"path":"transmission-chains.html","id":"pairwise-characteristics","chapter":"37 Transmission chains","heading":"37.5.2 Pairwise characteristics","text":"get_pairwise() function allows processing variable(s) line list\r\naccording pair contact dataset. following example, date\r\nonset disease extracted line list order compute \r\ndifference disease date onset pair. value \r\nproduced comparison represents serial interval (si).get_pairwise() interpret class column used \r\ncomparison, adjust method comparing values accordingly. \r\nnumbers dates (like si example ), function subtract\r\nvalues. applied columns characters categorical,\r\nget_pairwise() paste values together. function also allows\r\narbitrary processing (see “f” argument), discrete combinations can \r\neasily tabulated analyzed., see significant association transmission links gender.","code":"\nsi <- get_pairwise(epic, \"date_onset\")   \nsummary(si)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \r\n##       0       5       9      11      15      99    1820\ntibble(si = si) %>%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Serial interval\",\n    y = \"Frequency\"\n  )## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 1820 rows containing non-finite values (stat_bin).\nhead(get_pairwise(epic, \"gender\"), n = 10)##  [1] \"f -> m\" NA       \"m -> m\" NA       \"m -> f\" \"f -> f\" NA       \"f -> m\" NA       \"m -> f\"\nget_pairwise(epic, \"gender\", f = table)##            values.to\r\n## values.from   f   m\r\n##           f 464 516\r\n##           m 510 468\nfisher.test(get_pairwise(epic, \"gender\", f = table))## \r\n##  Fisher's Exact Test for Count Data\r\n## \r\n## data:  get_pairwise(epic, \"gender\", f = table)\r\n## p-value = 0.04\r\n## alternative hypothesis: true odds ratio is not equal to 1\r\n## 95 percent confidence interval:\r\n##  0.688 0.989\r\n## sample estimates:\r\n## odds ratio \r\n##      0.825"},{"path":"transmission-chains.html","id":"identifying-clusters","chapter":"37 Transmission chains","heading":"37.5.3 Identifying clusters","text":"get_clusters() function can used identify connected components\r\nepicontacts object. First, use retrieve data.frame\r\ncontaining cluster information:Let us look largest clusters. , add cluster information \r\nepicontacts object subset keep largest clusters:","code":"\nclust <- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)## \r\n##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 \r\n## 1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Cluster size\",\n    y = \"Frequency\"\n  )\nepic <- get_clusters(epic)\nmax_size <- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))"},{"path":"transmission-chains.html","id":"calculating-degrees","chapter":"37 Transmission chains","heading":"37.5.4 Calculating degrees","text":"degree node corresponds number edges connections \r\nnodes. get_degree() provides easy method calculating value \r\nepicontacts networks. high degree context indicates individual\r\ncontact many others. type argument indicates want\r\ncount -degree -degree, only_linelist argument\r\nindicates want calculate degree cases linelist.individuals ten contacts?mean number contacts?","code":"\ndeg_both <- get_degree(epic, type = \"both\", only_linelist = TRUE)\nhead(sort(deg_both, decreasing = TRUE), 10)## 916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \r\n##      7      6      6      6      5      5      5      5      5      5\nmean(deg_both)## [1] 1.08"},{"path":"transmission-chains.html","id":"resources-30","chapter":"37 Transmission chains","heading":"37.6 Resources","text":"\r\nepicontacts page\r\nprovides overview package functions includes -depth\r\nvignettes.github page can used raise\r\nissues request features.","code":""},{"path":"phylogenetic-trees.html","id":"phylogenetic-trees","chapter":"38 Phylogenetic trees","heading":"38 Phylogenetic trees","text":"Phylogenetic trees used visualize describe relatedness evolution organisms based sequence genetic code. can constructed genetic sequences using distance-based methods (neighbor-joining method) character-based methods (maximum likelihood Bayesian Markov Chain Monte Carlo method). Next-generation sequencing (NGS) become affordable becoming widely used public health describe pathogens causing infectious diseases. Portable devices decrease turn around time make data available support outbreak investigation real-time. NGS data can used identify origin source outbreak strain propagation, well determine presence antimicrobial resistance genes. visualize genetic relatedness samples phylogenetic tree constructed. page learn use ggtree() package, allows combination phylogenetic trees additional sample data form dataframe order help observe patterns improve understanding outbreak dynamic.","code":""},{"path":"phylogenetic-trees.html","id":"preparation-30","chapter":"38 Phylogenetic trees","heading":"38.1 Preparation","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.several different formats phylogenetic tree can stored (eg. Newick, NEXUS, Phylip). common one, also use example Newick file format (.nwk), standard representing trees computer-readable form. means, entire tree can expressed string format “((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59);” listing nodes tips relationship (branch length) .important understand phylogenetic tree file contain sequencing data, merely result distances sequences. therefore extract sequencing data tree file.use ape() package import phylogenetic tree file store list object class “phylo”. inspect tree object see contains 299 tips (samples) 236 nodes.Second import table additional information sequenced sample gender, country origin attributes antimicrobial resistance:first 30 rows data:clean inspect data: order assign correct sample data phylogenetic tree, Sample_IDs sample_data file need match tip.labels tree file:Upon inspection can see format sample_ID dataframe corresponds format sample names tree tips. sorted order matched.ready go!","code":"\n# load/install packages\npacman::p_load(here, ggplot2, dplyr, ape, ggtree, treeio, ggnewscale)\n# read in the tree: we use the here package to specify the location of our R project and data files:\ntree <- ape::read.tree(here::here(\"data\", \"Shigella_tree.nwk\"))\n\n# inspect the tree file:\ntree## \r\n## Phylogenetic tree with 299 tips and 236 internal nodes.\r\n## \r\n## Tip labels:\r\n##   SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\r\n## Node labels:\r\n##   17, 29, 100, 67, 100, 100, ...\r\n## \r\n## Rooted; includes branch lengths.\n# We read in a csv file into a dataframe format:\nsample_data <- read.csv(\"sample_data_Shigella_tree.csv\", sep = \",\", na.strings = c(\"NA\"), head = TRUE, stringsAsFactors=F)\n# We clean the data: we select certain columns to be protected from cleaning in order to main tain their formating (eg. for the sample names, as they have to match the names in the phylogenetic tree file)\n#sample_data <- linelist::clean_data(sample_data, protect = c(1, 3:5)) \n\n# We check the formatting of the tip labels in the tree file: \n\nhead(tree$tip.label) # these are the sample names in the tree - we inspect the first 6 with head()## [1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\" \"S17BD05939\"\n# We make sure the first column in our dataframe are the Sample_IDs:\ncolnames(sample_data)   ##  [1] \"Sample_ID\"                  \"serotype\"                   \"Country\"                    \"Continent\"                 \r\n##  [5] \"Travel_history\"             \"Year\"                       \"Belgium\"                    \"Source\"                    \r\n##  [9] \"Gender\"                     \"gyrA_mutations\"             \"macrolide_resistance_genes\" \"MIC_AZM\"                   \r\n## [13] \"MIC_CIP\"\n# We look at the sample_IDs in the dataframe to make sure the formatting is the same than in the tip.labels (eg. letters are all capital, no extra _ between letters and numbers etc.)\nhead(sample_data$Sample_ID) # we inspect only the first 6 using head()## [1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\" \"S18BD02657\""},{"path":"phylogenetic-trees.html","id":"simple-tree-visualization","chapter":"38 Phylogenetic trees","heading":"38.2 Simple tree visualization","text":"","code":""},{"path":"phylogenetic-trees.html","id":"different-tree-layouts","chapter":"38 Phylogenetic trees","heading":"Different tree layouts","text":"ggtree() offers many different layout formats may suitable specific purpose others:","code":"\n# Examples:\nggtree(tree) # most simple linear tree\nggtree(tree,  branch.length = \"none\") # most simple linear tree with all tips aligned\nggtree(tree, layout=\"circular\") # most simple circular tree\nggtree(tree, layout=\"circular\", branch.length = \"none\") # most simple circular tree with all tips aligned\n\n# for other options see online: http://yulab-smu.top/treedata-book/chapter4.html"},{"path":"phylogenetic-trees.html","id":"simple-tree-with-addition-of-sample-data","chapter":"38 Phylogenetic trees","heading":"Simple tree with addition of sample data","text":"easy annotation tree addition sample names tips, well coloring tip points desired branches:","code":"\n# A: Plot Circular tree:\nggtree(tree, layout=\"circular\", branch.length='none') %<+% sample_data + # the %<+% is used to add your dataframe with sample data to the tree\n  aes(color=I(Belgium))+     # color the branches according to a variable in your dataframe\n  scale_color_manual(\n    name = \"Sample Origin\",  # name of your color scheme (will show up in the legend like this)\n    breaks = c(\"Yes\", \"No\"), # the different options in your variable\n    labels = c(\"NRCSS Belgium\", \"Other\"), # how you want the different options named in your legend, allows for formatting\n    values= c(\"blue\", \"grey\"),            # the color you want to assign to the variable if its \"nrc_bel\"\n    na.value=\"grey\")+     # for the NA values we choose the color grey\n  new_scale_color()+      # allows to add an additional color scheme for another variable\n     geom_tippoint(       # color the tip point by continent, you may change shape adding \"shape = \"\n       aes(color=Continent),\n       size=1.5)+ \n  scale_color_brewer(\n    name = \"Continent\",   # name of your color scheme (will show up in the legend like this)\n    palette=\"Set1\",       # we choose a premade set of colors coming with the brewer package\n    na.value=\"grey\")+     # for the NA values we choose the color grey\n  geom_tiplab(            # add the name of the sample to the tip of its branch (you can add as many text lines as you like with the + , you just need to change the offset value to place them next to each other)\n    color='black',\n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    align=TRUE)+ \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+ # title of your graph\n  theme(\n    axis.title.x=element_blank(), # removes x-axis title\n    axis.title.y=element_blank(), # removes y-axis title\n    legend.title=element_text(face=\"bold\", size =12),  # defines font size and format of the legend title\n    legend.text=element_text(face=\"bold\", size =10),   # defines font size and format of the legend text\n    plot.title = element_text(size =12, face=\"bold\"),  # defines font size and format of the plot title\n    legend.position=\"bottom\", # defines placement of the legend\n    legend.box=\"vertical\",\n    legend.margin=margin())   # defines placement of the legend\n# Export your tree graph:\nggsave(here::here(\"images\", \"example_tree_circular_1.png\"), width = 12, height = 14)"},{"path":"phylogenetic-trees.html","id":"manipulation-of-phylogenetic-trees","chapter":"38 Phylogenetic trees","heading":"38.3 Manipulation of phylogenetic trees","text":"Sometimes may large phylogenetic tree interested one part tree. example produced tree including historical international samples get large overview dataset might fit bigger picture. look closer data want inspect portion bigger tree.Since phylogenetic tree file just output sequencing data analysis, can manipulate order nodes branches file . already determined previous analysis raw NGS data. able though zoom parts, hide parts seven subset part tree.","code":""},{"path":"phylogenetic-trees.html","id":"zooming-in-on-one-part-of-the-tree","chapter":"38 Phylogenetic trees","heading":"38.3.1 Zooming in on one part of the tree:","text":"don’t want “cut” tree, inspect part closely can zoom view specific part:want zoom branch sticking , node number 452 get closer look:","code":"\n# First we plot the whole tree:\np <- ggtree(tree,) %<+% sample_data +\n  geom_tiplab(size =1.5) + # labels the tips of all branche with the sample name in the tree file\n  geom_text2(aes(subset=!isTip, label=node), size =5, color = \"darkred\", hjust=1, vjust =1) # labels all the nodes in the tree\np\nviewClade(p , node=452)"},{"path":"phylogenetic-trees.html","id":"collapsing-one-part-of-the-tree","chapter":"38 Phylogenetic trees","heading":"38.3.2 Collapsing one part of the tree:","text":"way around may want ignore branch sticking can collapsing node (indicated blue square):","code":"\n#First we collapse at node 452\np_collapsed <- collapse(p, node=452)\n\n#To not forget that we collapsed this node we assign a symbol to it:\np_collapsed + geom_point2(aes(subset=(node == 452)), size=5, shape=23, fill=\"steelblue\")"},{"path":"phylogenetic-trees.html","id":"subsetting-a-tree","chapter":"38 Phylogenetic trees","heading":"Subsetting a tree","text":"want make permanent change create new tree work can subset part even save new newick tree file.can also save new tree Newick file:","code":"\n# To do so you can add the node and tip labels to your tree to see which part you want to subset:\nggtree(tree, branch.length='none', layout='circular') %<+% sample_data +\n  geom_tiplab(size =1) +       # labels the tips of all branche with the sample name in the tree file\n  geom_text2(                  # labels all the nodes in the tree\n    aes(subset = !isTip, label=node),\n    size = 3,\n    color = \"darkred\")+  \n theme(\n   legend.position = \"none\", # removes the legend all together\n   axis.title.x = element_blank(),\n   axis.title.y=element_blank(),\n   plot.title = element_text(size =12, face=\"bold\"))\n\n# A: Subset tree based on node:\nsub_tree1 <- tree_subset(\n  tree,\n  node = 528) # we subset the tree at node 528\n\n# lets have a look at the subset tree:\nggtree(sub_tree1)+\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\n\n# B: Subset the same part of the tree based on a samplem in this case S17BD07692:\nsub_tree2 <- tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels back defines how many nodes backwards from the sample tip you want to go\n\n# lets have a look at the subset tree:\nggtree(sub_tree2)+\n  geom_tiplab(size = 3)+\n  ggtitle(\"Subset tree 2\")\nape::write.tree(sub_tree2, file='data/Shigelle_subtree_2.nwk')"},{"path":"phylogenetic-trees.html","id":"rotating-nodes-in-a-tree","chapter":"38 Phylogenetic trees","heading":"Rotating nodes in a tree","text":"mentioned change order tips nodes tree, based genetic relatedness subject visual manipulation. can rote branches around nodes eases visualization.First plot new subsetted tree node labels choose node want manipulate:choose manipulate node number 39: applying ggtree::rotate() ggtree::flip() indirectly node 36 node 39 moves bottom nodes 37 38 move top:","code":"\np <- ggtree(sub_tree2) +\n  geom_tiplab(size = 4) +\n  geom_text2(                       # label all the nodes in the tree\n    aes(subset=!isTip, label=node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1) \np\n# \n# p1 <- p + geom_hilight(39, \"steelblue\", extend =0.0015)+ # highlights the node 39 in blue\n#    geom_hilight(37, \"yellow\", extend =0.0015)  + # highlights the node 37 in yellow\n#   ggtitle(\"Original tree\")\n# \n# # we want to rotate node 36 so node 39 is on the bottom and nodes 37 and 38 move to the top:\n# # \n# rotate(p1, 39) %>% rotate(37)+\n#   ggtitle(\"Rotated Node 36\")\n# \n# # #or we can use the flip command to achieve the same thing:\n# flip(p1, 39, 37)"},{"path":"phylogenetic-trees.html","id":"example-subtree-with-sample-data-annotation","chapter":"38 Phylogenetic trees","heading":"38.3.3 Example subtree with sample data annotation:","text":"Lets say investigating cluster cases clonal expansion occured 2017 2018 node 39 sub-tree. add year strain isolation well travel history color country see origin closely related strains:observation points towards import strains Asia, circulated Belgium years seem caused latest outbreak.","code":"\n# Add sample data:\nggtree(sub_tree2) %<+% sample_data + \n  geom_tiplab(                      # labels the tips of all branches with the sample name in the tree file\n    size =2.5,\n    offset = 0.001, \n    align = TRUE) + \n  theme_tree2()+\n  xlab(\"genetic distance\")+ # add a label to the x-azis\n  xlim(0, 0.015)+           # set the x-axis limits of our tree\n  geom_tippoint(            # color the tip point by continent\n    aes(color=Country),\n    size=1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette=\"Set1\", \n    na.value=\"grey\")+\n  geom_tiplab(              # add isolation year\n    aes(label = Year),\n    color='blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\", \n    align=TRUE)+\n  geom_tiplab(              # add travel history\n    aes(label = Travel_history),\n    color='red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    align=TRUE)+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+ # add plot title\n  theme(\n    axis.title.x=element_blank(),\n    axis.title.y=element_blank(),\n    legend.title=element_text(face=\"bold\", size =12),\n    legend.text=element_text(face=\"bold\", size =10),\n    plot.title = element_text(size =12, face=\"bold\"))"},{"path":"phylogenetic-trees.html","id":"more-complex-trees-adding-heatmaps-of-sample-data","chapter":"38 Phylogenetic trees","heading":"38.4 More complex trees: adding heatmaps of sample data","text":"can add complex information, categorical presence antimicrobial resistance genes numeric values actually measured resistance antimicrobials form heatmap using ggtree::gheatmap() function.First need plot tree (can either linear circular): use sub_stree part 3.)Second prepare data. visualize different variables new color schemes, subset dataframe desired variable.example want look gender mutations confer resistance ciprofloxacin:create first plot adding binary heatmap gender phylogenetic tree:add information ciprofloxacin resistance genes:Next add continuous data actual resistance determined laboratory\r\nminimum inhibitory concentration (MIC) ciprofloxacin:can exercise linear tree:","code":"\n# A: Circular tree:\np <- ggtree(sub_tree2, branch.length='none', layout='circular') %<+% sample_data +\n  geom_tiplab(size =3) + \n  theme(\n    legend.position = \"none\",\n    axis.title.x=element_blank(),\n    axis.title.y=element_blank(),\n    plot.title = element_text(size =12, face=\"bold\",hjust = 0.5, vjust = -15))\n\np\n# Create your gender dataframe:\ngender <- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\n\n# Its important to add the Sample_ID as rownames otherwise it cannot match the data to the tree tip.labels:\nrownames(gender) <- sample_data$Sample_ID\n\n# Create your ciprofloxacin dataframe based on mutations in the gyrA gene:\ncipR <- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) <- sample_data$Sample_ID\n\n# Create your ciprofloxacin dataframe based on the measured minimum inhibitory concentration (MIC) from the laboratory:\nMIC_Cip <- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) <- sample_data$Sample_ID\n# First we add gender:\nh1 <-  gheatmap(\n  p,\n  gender,\n  offset = 12,        # offset shifts the heatmap to the right\n  width=0.10,         # width defines the width of the heatmap column\n  color=NULL,         # color defines the border of the heatmap columns\n  colnames = FALSE)+  # hides column names for the heatmap\n  scale_fill_manual(  # define the coloring scheme and legend for gender\n    name = \"Gender\", \n    values = c(\"#00d1b1\", \"purple\"),\n    breaks = c(\"Male\", \"Female\"),\n    labels = c(\"Male\", \"Female\"))+\n  theme(\n    legend.position=\"bottom\",\n    legend.title = element_text(size=12),\n    legend.text = element_text(size =10),\n    legend.box=\"vertical\", legend.margin=margin())\nh1\n# First we assigng a new color scheme to our existing plot, this enables us to define and change the colors for our second variable\nh2 <- h1 + new_scale_fill() \n\n# then we combine these into a new plot:\nh3 <- gheatmap(\n  h2,\n  cipR,\n  offset = 14,\n  width=0.10, # adds the second row of heatmap describing ciprofloxacin resistance genes\n  colnames = FALSE)+\n  scale_fill_manual(\n    name = \"Ciprofloxacin resistance \\n conferring mutation\",\n    values = c(\"#fe9698\",\"#ea0c92\"),\n    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n  theme(\n    legend.position=\"bottom\",\n    legend.title = element_text(size=12),\n    legend.text = element_text(size =10),\n    legend.box = \"vertical\",\n    legend.margin = margin())+\n  guides(\n    fill = guide_legend(nrow=2,byrow=TRUE))\n\nh3\n# First we add the new coloring scheme:\nh4 <- h3 + new_scale_fill()\n\n# then we combine the two into a new plot:\nh5 <- gheatmap(\n  h4,\n  MIC_Cip,\n  offset = 16,\n  width=0.10,\n  colnames = FALSE)+\n  scale_fill_continuous(\n    name = \"MIC for ciprofloxacin\",\n    low = \"yellow\",\n    high = \"red\",\n    breaks = c(0, 0.50, 1.00),\n    na.value = \"white\")+\n  guides(\n    fill = guide_colourbar(barwidth = 5, barheight = 1))+\n  theme(\n    legend.position=\"bottom\",\n    legend.title = element_text(size=12),\n    legend.text = element_text(size =10),\n    legend.box=\"vertical\",\n    legend.margin=margin())\nh5\n# B: Lineartree:\np <- ggtree(sub_tree2) %<+% sample_data +\n  geom_tiplab(size =3) + # labels the tips\n  theme_tree2()+\n  xlab(\"genetic distance\")+\n  xlim(0, 0.015)+\n theme(\n   legend.position = \"none\",\n   axis.title.y=element_blank(),\n   plot.title = element_text(size =12, face=\"bold\",hjust = 0.5, vjust = -15))\n\n\n# First we add gender:\n\nh1 <- gheatmap(\n  p, gender,\n  offset = 0.003,\n  width=0.1,\n  color=\"black\", \n  colnames = FALSE)+\n  scale_fill_manual(\n    name = \"Gender\",\n    values = c(\"#00d1b1\", \"purple\"),\n    breaks = c(\"Male\", \"Female\"),\n    labels = c(\"Male\", \"Female\"))+\n   theme(\n     legend.position=\"bottom\",\n     legend.title = element_text(size=12),\n     legend.text = element_text(size =10),\n     legend.box=\"vertical\", legend.margin=margin())\n# h1\n\n# Then we add ciprofloxacin after adding another colorscheme layer:\n\nh2 <- h1 + new_scale_fill()\nh3 <- gheatmap(\n  h2, cipR,\n  offset = 0.004,\n  width=0.1,\n  color=\"black\",\n  colnames = FALSE)+\n  scale_fill_manual(\n    name = \"Ciprofloxacin resistance \\n conferring mutation\",\n    values = c(\"#fe9698\",\"#ea0c92\"),\n    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n  theme(\n    legend.position=\"bottom\",\n    legend.title = element_text(size=12),\n    legend.text = element_text(size =10),\n    legend.box=\"vertical\",\n    legend.margin=margin())+\n  guides(\n    fill=guide_legend(nrow=2,byrow=TRUE))\n# h3\n\n# Then we add the minimum inhibitory concentration determined by the lab (MIC):\nh4 <- h3 + new_scale_fill()\nh5 <- gheatmap(\n  h4, MIC_Cip,\n  offset = 0.005,\n  width=0.1,\n  color=\"black\",\n  colnames = FALSE)+\n  scale_fill_continuous(\n    name = \"MIC for ciprofloxacin\",\n    low = \"yellow\",\n    high = \"red\",\n    breaks = c(0,0.50,1.00),\n    na.value = \"white\")+\n   guides(\n     fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(\n     legend.position=\"bottom\",\n     legend.title = element_text(size=10),\n     legend.text = element_text(size =8),\n     legend.box=\"horizontal\", legend.margin=margin())+\n  guides(\n    shape = guide_legend(override.aes = list(size = 2)))\nh5"},{"path":"phylogenetic-trees.html","id":"resources-31","chapter":"38 Phylogenetic trees","heading":"38.5 Resources","text":"http://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colors\r\nhttps://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html\r\nhttps://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html\r\nhttps://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html","code":""},{"path":"interactive-plots.html","id":"interactive-plots","chapter":"39 Interactive plots","heading":"39 Interactive plots","text":"Data visualisation increasingly required interrogable audience. Consequently, becoming common create interactive plots. several ways include two common plotly shiny.page focus converting existing ggplot() plot interactive plot plotly. can read shiny Shiny dashboards page.basic epicurve transformed interactive using integration ggplot2 plotly (hover mouse plot, click items legend).","code":""},{"path":"interactive-plots.html","id":"preparation-31","chapter":"39 Interactive plots","heading":"39.1 Preparation","text":"","code":""},{"path":"interactive-plots.html","id":"load-packages-27","chapter":"39 Interactive plots","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,       # import/export\n  here,      # filepaths\n  lubridate, # working with dates\n  plotly,    # interactive plots\n  scales,    # quick percents\n  tidyverse  # data management and visualization\n  ) "},{"path":"interactive-plots.html","id":"start-with-a-ggplot","chapter":"39 Interactive plots","heading":"Start with a ggplot()","text":"page assume beginning ggplot() plot want convert interactive. build several plots page, using case linelist used many pages handbook.","code":""},{"path":"interactive-plots.html","id":"import-data-23","chapter":"39 Interactive plots","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"interactive-plots.html","id":"plot-with-ggplotly","chapter":"39 Interactive plots","heading":"39.2 Plot with ggplotly()","text":"function ggplotly() plotly package makes easy convert ggplot() interactive. Simply save ggplot() pipe ggplotly() function., plot simple line representing proportion cases died given week:begin creating summary dataset epidemiological week, percent cases known outcome died.first 50 rows weekly_deaths dataset.create plot ggplot2, using geom_line().can make interactive simply passing plot ggplotly(), . Hover mouse line show x y values. can zoom plot, drag around. can also see icons upper-right plot. order, allow :Download current view PNG imageZoom select box“Pan”, move across plot clicking dragging plotZoom , zoom , return default zoomReset axes defaultsToggle /“spike lines” dotted lines interactive point extending x y axesAdjustments whether data show hovering lineGrouped data work ggplotly() well. , weekly epicurve made, grouped outcome. stacked bars interactive. Try clicking different items legend (appear/disappear).","code":"\nweekly_deaths <- linelist %>%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %>%  # create and group data by epiweek column\n  summarise(                                           # create new summary data frame:\n    n_known_outcome = sum(!is.na(outcome), na.rm=T),     # number of cases per group with known outcome\n    n_death  = sum(outcome == \"Death\", na.rm=T),         # number of cases per group who died\n    pct_death = 100*(n_death / n_known_outcome)          # percent of cases with known outcome who died\n  )\ndeaths_plot <- ggplot(data = weekly_deaths)+    # begin with weekly deaths data\n  geom_line(                                    # create line\n    mapping = aes(x = epiweek, y = pct_death),  # map epiweek to x-axis, and pct_death to y-axis\n    stat = \"identity\")                          # line height reflects y value, not number of rows (default)\n\ndeaths_plot   # print\ndeaths_plot %>% plotly::ggplotly()\n# Make epidemic curve with incidence2 pacakge\np <- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %>% plot(fill = outcome)\n# Plot interactively  \np %>% ggplotly()"},{"path":"interactive-plots.html","id":"modifications","chapter":"39 Interactive plots","heading":"39.3 Modifications","text":"","code":""},{"path":"interactive-plots.html","id":"file-size","chapter":"39 Interactive plots","heading":"File size","text":"exporting Rmarkdown generated HTML (like book!) want make plot small data size possible (negative side effects cases). , just pipe interactive plot partial_bundle(), also plotly.","code":"\np <- p %>% \n  ggploty() %>% \n  partial_bundle()"},{"path":"interactive-plots.html","id":"buttons","chapter":"39 Interactive plots","heading":"Buttons","text":"buttons standard plotly superfluous can distracting, can remove . can simply piping output config() plotly specifying buttons remove. example specify advance names buttons remove, provide argument modeBarButtonsToRemove =. also set displaylogo = FALSE remove plotly logo.","code":"\n## these buttons are distracting and we want to remove them\nplotly_buttons_remove <- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np <- p %>%          # re-define interactive plot without these buttons\n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"heat-tiles-1","chapter":"39 Interactive plots","heading":"39.4 Heat tiles","text":"can make almost ggplot() plot interactive, including heat tiles. page Heat tiles can read make plot, displays proportion days per week certain facilities reported data province.code, although describe depth ., make interactive modify simple buttons file size.","code":"\n# import data\nfacility_count_data <- rio::import(here::here(\"data\", \"facility_count_data.rds\"))\n\n# aggregate data into Weeks for Spring district\nagg_weeks <- facility_count_data %>% \n  filter(District == \"Spring\",\n         data_date < as.Date(\"2019-06-01\")) %>% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %>% \n  group_by(location_name, week, .drop = F) %>%\n  summarize(\n    n_days          = 7,\n    n_reports       = dplyr::n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %>% \n  right_join(tidyr::expand(., week, location_name)) %>% \n  mutate(week = aweek::week2date(week))\n\n# create plot\nmetrics_plot <- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\nmetrics_plot # print\nmetrics_plot %>% \n  ggplotly() %>% \n  partial_bundle() %>% \n  config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"maps","chapter":"39 Interactive plots","heading":"Maps","text":"can also make ggplot() GIS maps interactive, although makes bit care.SECTION CONSTRUCTIONAlthough plotly works well ggplot2::geom_sf RStudio, try include outputs Rmarkdown HTML files (like book), doesn’t work well.instead can use {plotly}’s mapping tools can tricky easy know . Read …’re going use Covid-19 incidence across African countries example. data used can found World Health Organisation website.’ll also need new type file, GeoJSON, sort similar shp file familiar GIS. book, used one .GeoJSON files stored R complex lists ’ll need maipulate little.tricky part. {plotly} match incidence data GeoJSON, countries geoJSON need id specific place list lists. need build basic function:","code":"\n## You need two new packages: {rjson} and {purrr}\npacman::p_load(plotly, rjson, purrr)\n\n## This is a simplified version of the WHO data\ndf <- rio::import(here::here(\"data\", \"covid_incidence.csv\"))\n\n## Load your geojson file\ngeoJSON <- rjson::fromJSON(file=here::here(\"data\", \"africa_countries.geo.json\"))\n\n## Here are some of the properties for each element of the object\nhead(geoJSON$features[[1]]$properties)## $scalerank\r\n## [1] 1\r\n## \r\n## $featurecla\r\n## [1] \"Admin-0 country\"\r\n## \r\n## $labelrank\r\n## [1] 6\r\n## \r\n## $sovereignt\r\n## [1] \"Burundi\"\r\n## \r\n## $sov_a3\r\n## [1] \"BDI\"\r\n## \r\n## $adm0_dif\r\n## [1] 0\n## The property column we need to choose here is \"sovereignt\" as it is the names for each country\ngive_id <- function(x){\n  \n  x$id <- x$properties$sovereignt  ## Take sovereignt from properties and set it as the id\n  \n  return(x)\n}\n\n## Use {purrr} to apply this function to every element of the features list of the geoJSON object\ngeoJSON$features <- purrr::map(.x = geoJSON$features, give_id)"},{"path":"interactive-plots.html","id":"maps---plot","chapter":"39 Interactive plots","heading":"39.4.1 Maps - plot","text":"","code":"\nplotly::plot_ly() %>% \n  plotly::add_trace(                    #The main plot mapping functionn\n    type=\"choropleth\",\n    geojson=geoJSON,\n    locations=df$Name,          #The column with the names (must match id)\n    z=df$Cumulative_incidence,  #The column with the incidence values\n    zmin=0,\n    zmax=57008,\n    colorscale=\"Viridis\",\n    marker=list(line=list(width=0))\n  ) %>%\n  plotly::colorbar(title = \"Cases per million\") %>%\n  plotly::layout(title = \"Covid-19 cumulative incidence\",\n                 geo = list(scope = 'africa')) %>% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"resources-32","chapter":"39 Interactive plots","heading":"39.5 Resources","text":"Plotly just R, also works well Python (really data science language ’s built JavaScript). can read plotly website","code":""},{"path":"directory-interactions.html","id":"directory-interactions","chapter":"40 Directory interactions","heading":"40 Directory interactions","text":"page cover common scenarios create, interact , save, import directories (folders).","code":""},{"path":"directory-interactions.html","id":"preparation-32","chapter":"40 Directory interactions","heading":"40.1 Preparation","text":"","code":""},{"path":"directory-interactions.html","id":"fs-package","chapter":"40 Directory interactions","heading":"fs package","text":"fs package tidyverse package facilitate directory interactions, improving base R functions. sections often use functions fs.","code":"\npacman::p_load(\n  fs,             # file/directory interactions\n  rio,            # import/export\n  here,           # relative file pathways\n  tidyverse)      # data management and visualization"},{"path":"directory-interactions.html","id":"print-directory-as-a-dendrogram-tree","chapter":"40 Directory interactions","heading":"Print directory as a dendrogram tree","text":"Use function dir_tree() fs.Provide folder filepath path = decide whether want show one level (recurse = FALSE) files sub-levels (recurse = TRUE). use (\"data) shorthand R project ’s sub-folder “data”, contains data used R handbook. set display files within “data” sub-folders (e.g. “cache”, “epidemic models”, “population”, “shp”, “weather”).","code":"\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)## C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook/data\r\n## +-- africa_countries.geo.json\r\n## +-- cache\r\n## |   \\-- epidemic_models\r\n## |       +-- 2015-04-30\r\n## |       |   +-- estimated_reported_cases_samples.rds\r\n## |       |   +-- estimate_samples.rds\r\n## |       |   +-- latest_date.rds\r\n## |       |   +-- reported_cases.rds\r\n## |       |   +-- summarised_estimated_reported_cases.rds\r\n## |       |   +-- summarised_estimates.rds\r\n## |       |   \\-- summary.rds\r\n## |       +-- epinow_res.rds\r\n## |       +-- epinow_res_small.rds\r\n## |       +-- generation_time.rds\r\n## |       \\-- incubation_period.rds\r\n## +-- campylobacter_germany.xlsx\r\n## +-- Central Hospital.csv\r\n## +-- cleaning_dict.csv\r\n## +-- country_demographics.csv\r\n## +-- country_demographics_2.csv\r\n## +-- covid_incidence.csv\r\n## +-- covid_incidence_map.R\r\n## +-- district_count_data.xlsx\r\n## +-- example_script.R\r\n## +-- facility_count_data.rds\r\n## +-- fluH7N9_China_2013.csv\r\n## +-- hospital_linelists.xlsx\r\n## +-- likert_data.csv\r\n## +-- linelists\r\n## |   +-- 20201007linelist.csv\r\n## |   +-- case_linelist20201006.csv\r\n## |   +-- case_linelist_2020-10-02.csv\r\n## |   +-- case_linelist_2020-10-03.csv\r\n## |   +-- case_linelist_2020-10-04.csv\r\n## |   +-- case_linelist_2020-10-05.csv\r\n## |   \\-- case_linelist_2020-10-08.xlsx\r\n## +-- linelist_cleaned.rds\r\n## +-- linelist_cleaned.xlsx\r\n## +-- linelist_cleaned_with_adm3.rds\r\n## +-- linelist_raw.xlsx\r\n## +-- make_evd_dataset.R\r\n## +-- Military Hospital.csv\r\n## +-- Missing.csv\r\n## +-- Other.csv\r\n## +-- population\r\n## |   +-- sle_admpop_adm3_2020.csv\r\n## |   \\-- sle_population_statistics_sierraleone_2020.xlsx\r\n## +-- Port Hospital.csv\r\n## +-- sample_data_Shigella_tree.csv\r\n## +-- Shigella_tree.nwk\r\n## +-- Shigelle_subtree_2.nwk\r\n## +-- shp\r\n## |   +-- README.txt\r\n## |   +-- sle_adm3.CPG\r\n## |   +-- sle_adm3.dbf\r\n## |   +-- sle_adm3.prj\r\n## |   +-- sle_adm3.sbn\r\n## |   +-- sle_adm3.sbx\r\n## |   +-- sle_adm3.shp\r\n## |   +-- sle_adm3.shp.xml\r\n## |   +-- sle_adm3.shx\r\n## |   +-- sle_hf.CPG\r\n## |   +-- sle_hf.dbf\r\n## |   +-- sle_hf.prj\r\n## |   +-- sle_hf.sbn\r\n## |   +-- sle_hf.sbx\r\n## |   +-- sle_hf.shp\r\n## |   \\-- sle_hf.shx\r\n## +-- St. Mark's Maternity Hospital (SMMH).csv\r\n## +-- test\r\n## +-- test.rds\r\n## +-- weather\r\n## |   +-- germany_weather2002.nc\r\n## |   +-- germany_weather2003.nc\r\n## |   +-- germany_weather2004.nc\r\n## |   +-- germany_weather2005.nc\r\n## |   +-- germany_weather2006.nc\r\n## |   +-- germany_weather2007.nc\r\n## |   +-- germany_weather2008.nc\r\n## |   +-- germany_weather2009.nc\r\n## |   +-- germany_weather2010.nc\r\n## |   \\-- germany_weather2011.nc\r\n## \\-- world_standard_population_by_sex.csv"},{"path":"directory-interactions.html","id":"list-files-in-a-directory","chapter":"40 Directory interactions","heading":"40.2 List files in a directory","text":"list just file names directory can use dir() base R. example, command lists file names files “population” subfolder “data” folder R project. relative filepath provided using () (can read Import export page.list full file paths directory’s files, can use can use dir_ls() fs.get metadata information file directory, (e.g. path, modification date, etc.) can use dir_info() fs. can particularly useful want extract last modification time file, example want import recent version file. exampleHere data frame returned. Scroll right see columns.","code":"\n# file names\ndir(here(\"data\", \"population\"))## [1] \"sle_admpop_adm3_2020.csv\"                        \"sle_population_statistics_sierraleone_2020.xlsx\"\n# file paths\ndir_ls(here(\"data\", \"population\"))## C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook/data/population/sle_admpop_adm3_2020.csv\r\n## C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook/data/population/sle_population_statistics_sierraleone_2020.xlsx\n# file info\ndir_info(here(\"data\", \"population\"))"},{"path":"directory-interactions.html","id":"file-information","chapter":"40 Directory interactions","heading":"40.3 File information","text":"extract metadata information specific file, can use file_info() fs (file.info() base R).use $ index result return modification_time value.","code":"\nfile_info(here(\"data\", \"linelist_cleaned.rds\"))\nfile_info(here(\"data\", \"linelist_cleaned.rds\"))$modification_time## [1] \"2021-03-30 21:14:54 EDT\""},{"path":"directory-interactions.html","id":"check-if-exists","chapter":"40 Directory interactions","heading":"40.4 Check if exists","text":"","code":""},{"path":"directory-interactions.html","id":"r-objects","chapter":"40 Directory interactions","heading":"R objects","text":"can use exists() base R check whether R object exists within R (supply object name quotes).Note base R packages use generic object names like “data” behind scenes, appear TRUE unless inherit = FALSE specified. one reason name dataset “data”.writing function, use missing() base R check argument present , instead exists().","code":"\nexists(\"linelist\")## [1] TRUE\nexists(\"data\")## [1] TRUE\nexists(\"data\", inherit = FALSE)## [1] FALSE"},{"path":"directory-interactions.html","id":"directories","chapter":"40 Directory interactions","heading":"Directories","text":"check whether directory exists, provide file path (file name) is_dir() fs. Scroll right see TRUE printed.alternative file.exists() base R.","code":"\nis_dir(here(\"data\"))## C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook/data \r\n##                                                                                                        TRUE"},{"path":"directory-interactions.html","id":"files","chapter":"40 Directory interactions","heading":"Files","text":"check specific file exists, use is_file() fs. Scroll right see TRUE printed.base R alternative file.exists().","code":"\nis_file(here(\"data\", \"linelist_cleaned.rds\"))## C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook/data/linelist_cleaned.rds \r\n##                                                                                                                             TRUE"},{"path":"directory-interactions.html","id":"create","chapter":"40 Directory interactions","heading":"40.5 Create","text":"","code":""},{"path":"directory-interactions.html","id":"directories-1","chapter":"40 Directory interactions","heading":"Directories","text":"create new directory (folder) can use dir_create() fs. directory already exists, overwritten error returned.alternative dir.create() base R, show error directory already exists. contrast, dir_create() scenario silent.","code":"\ndir_create(here(\"data\", \"test\"))"},{"path":"directory-interactions.html","id":"files-1","chapter":"40 Directory interactions","heading":"Files","text":"can create (empty) file file_create() fs. file already exists, -written changed.base R alternative file.create(). file already exists, option truncate . use file_create() file left unchanged.","code":"\nfile_create(here(\"data\", \"test.rds\"))"},{"path":"directory-interactions.html","id":"create-if-does-not-exists","chapter":"40 Directory interactions","heading":"Create if does not exists","text":"example creating folder already exist:","code":""},{"path":"directory-interactions.html","id":"delete","chapter":"40 Directory interactions","heading":"40.6 Delete","text":"","code":""},{"path":"directory-interactions.html","id":"r-objects-1","chapter":"40 Directory interactions","heading":"R objects","text":"Use rm() base R remove R object.","code":""},{"path":"directory-interactions.html","id":"directories-2","chapter":"40 Directory interactions","heading":"Directories","text":"Use dir_delete() fs.","code":""},{"path":"directory-interactions.html","id":"files-2","chapter":"40 Directory interactions","heading":"Files","text":"can delete files file_delete() fs.","code":""},{"path":"directory-interactions.html","id":"running-other-files","chapter":"40 Directory interactions","heading":"40.7 Running other files","text":"","code":""},{"path":"directory-interactions.html","id":"source","chapter":"40 Directory interactions","heading":"source()","text":"run one R script another R script, can use source() command (base R).equivalent viewing R script clicking “Source” button upper-right script. execute script silently (output R console) unless specifically intended. See page [Interactive console] examples using source() interact user via R console question--answer mode.","code":"\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))"},{"path":"directory-interactions.html","id":"render","chapter":"40 Directory interactions","heading":"render()","text":"render() variation source() often used R markdown scripts. provide input = R markdown file, also output_format = (typically either “html_document”, “pdf_document”, “word_document”, \"\")See page R markdown details. Also see documentation render() entering ?render.","code":""},{"path":"directory-interactions.html","id":"run-files-in-a-directory","chapter":"40 Directory interactions","heading":"Run files in a directory","text":"can create loop use source() every file directory, identified dir().want run certain scripts, can identify name like :comparison fs base R functions.","code":"\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) {   # for each script name in the R Project's \"scripts\" folder (with .R extension)\n  source(here(\"scripts\", script))                        # source the file with the matching name that exists in the scripts folder\n}\nscripts_to_run <- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}"},{"path":"directory-interactions.html","id":"import-files-in-a-directory","chapter":"40 Directory interactions","heading":"Import files in a directory","text":"See page Import export importing exporting individual files.\r\nSee page Iteration loops example package purrr demonstrating:Splitting dataframe saving multiple CSV filesSplitting dataframe saving part separate sheet within one Excel workbookImporting multiple CSV files combining one dataframeImporting Excel workbook multiple sheets combining one dataframe","code":""},{"path":"directory-interactions.html","id":"base-r-5","chapter":"40 Directory interactions","heading":"40.8 base R","text":"See functions list.files() dir(), perform operation listing files within specified directory. can specify ignore.case = specific pattern look .file currently “open”, display tilde front, like “~$hospital_linelists.xlsx”.","code":"\nlist.files(path = here(\"data\"))\n\nlist.files(path = here(\"data\"), pattern = \".csv\")\n# dir(path = here(\"data\"), pattern = \".csv\")\n\nlist.files(path = here(\"data\"), pattern = \"evd\", ignore.case = TRUE)"},{"path":"directory-interactions.html","id":"resources-33","chapter":"40 Directory interactions","heading":"40.9 Resources","text":"https://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html","code":""},{"path":"r-markdown-1.html","id":"r-markdown-1","chapter":"41 R Markdown","heading":"41 R Markdown","text":"R Markdown fantastic tool creating automated, reproducible, share-worthy outputs. can generate static interactive outputs, form html, word, pdf, powerpoint, others.","code":""},{"path":"r-markdown-1.html","id":"overview-19","chapter":"41 R Markdown","heading":"41.1 Overview","text":"Using markdown allow easily recreate entire formatted document, including tables/figures/text, using new data (e.g. daily surveillance reports) /subsets data (e.g. reports specific geographies).guide go basics. See ‘resources’ tab info.","code":""},{"path":"r-markdown-1.html","id":"preparation-33","chapter":"41 R Markdown","heading":"41.2 Preparation","text":"Background MarkdownTo explain concepts packages involved:Markdown lightweight markup language, syntax allows plain text formatting can converted html formats. specific R, usually markdown file ‘.md’ extension.R Markdown - language: extension markdown specific R, file extensions ‘.Rmd’. allows R code embedded ‘chunks’ code can run, rather just text document.Rmarkdown - package: used R render .Rmd file desire output. However focus markdown (text) syntax, also need…Knitr: package read code chunks, execute , ‘knit’ back document. tables graphs included alongside text.Pandoc: Finally, pandoc needed actually convert documents e.g. word/pdf/powerpoint etc. separate R.R Studio website describes link together (https://rmarkdown.rstudio.com/authoring_quick_tour.html):Creating documents R Markdown starts .Rmd file contains combination markdown (content simple text formatting) R code chunks. .Rmd file fed knitr, executes R code chunks creates new markdown (.md) document includes R code output.markdown file generated knitr processed pandoc responsible creating finished web page, PDF, MS Word document, slide show, handout, book, dashboard, package vignette format.may sound complicated, R Markdown makes extremely simple encapsulating processing single render function. Better still, RStudio includes “Knit” button enables render .Rmd preview using single click keyboard shortcut.InstallationTo create R Markdown, need following installed:Rmarkdown package, described : install.packages('rmarkdown')Pandoc, come RStudio. using RStudio, can download : http://pandoc.org.want generate PDF output (bit trickier), need install LaTeX. R Markdown users installed LaTeX , recommend install TinyTeX (https://yihui.name/tinytex/):WorkflowPreparation R Markdown workflow involves ensuring set R project folder structure suits desired workflow.instance, may want ‘output’ folder rendered documents, ‘input’ folder new cleaned data files, well subfolders within date-stamped reflect subgeographies interest. markdown can go ‘rmd’ subfolder, particularly multiple Rmd files within project.can set code create output subfolders time run reports (see “Producing output”), overall design mind.R Markdown can run pandoc issues running shared network drive, recommended folder local machine, e.g. project within ‘Documents’. use Git (much recommended!), familiar.","code":"install.packages('tinytex')\r\ntinytex::install_tinytex()  # install TinyTeX"},{"path":"r-markdown-1.html","id":"the-r-markdown-file","chapter":"41 R Markdown","heading":"41.3 The R Markdown file","text":"R Markdown document looks like can edited just like standard R script, R Studio. However, contains just usual R code hashed comments. three basic components:1. Metadata: referred ‘YAML metadata’ top R Markdown document two ‘- - -‘s. tell Rmd file type output produce, formatting preferences, metadata sucsh document title, author, date. uses mentioned (referred ‘Producing output’). Note indentation matters.2. Text: narrative document, including titles. written markdown language, used across many different programmes. means can add basic formatting, instance:_text_ *text* italicise**text** bold text# start new line title (## second-level title, ## third-level title etc)* start new line bullet pointstext display text code ()actual appearance font can set using specific templates (specified YAML metadata; see example tabs).can also include minimal R code within backwards ticks, within-text values. See example .3. Code chunks: R code goes, actual data management visualisation. note:\r\n‘chunks’ appear slightly different background colour narrative part document.chunk always starts three backticks chunk information within squiggly brackets, ends three backticks.notes content squiggly brackets:start ‘r’ indicate language name within chunk rFollowed chunk name - note ALWAYS unique name else R complain try render.can include options , many can configured point--click using setting buttons top right chunk. , can specify parts chunk want rendered document include, namely code, outputs, warnings. come written preferences within squiggly brackets, e.g. ‘echo=FALSE’ specify want ‘Show output ’.also two arrows top right chunk, useful run code within chunk, code prior chunks.General notesEverything used markdown must referenced within Rmd file. instance, need load required packages data.single test run within R MarkdownTo render single document, instance testing need produce one rendered document time, can within open R Markdown file. Click “knit” button\" top document.‘R Markdown’ tab start processing show overall progress, complete document automatically open complete. document also saved folder markdown, file name aside file extension. obviously ideal version control, rename file .single run separate scriptTo run markdown date-stamped file produced, can create separate script call Rmd file within . can also specify folder file name, include dynamic date time, file date stamped production.Routine runs newly created date-stamped sub foldersAdd couple lines code define date running report (e.g. using Sys.Date example ) create new sub folders. want date reflect specific date rather current date, can also enter object.may want dynamic information included markdown . addressed next section.","code":"rmarkdown::render((\"rmd_reports/create_RED_report.Rmd\"),  \r\n                        output_file = paste0(\"outputs/Report_\", Sys.Date, \".docx\")) # Use 'paste0' to combine text and code for a dynamic file name# Set the date of report\r\nrefdate <- as.Date(\"2020-12-21\")\r\n\r\n# Create the folders\r\noutputfolder <- paste0(\"outputs/\", refdate) # This is the new folder name\r\ndir.create(outputfolder) # Creates the folder (in this case assumed 'outputs' already exists)\r\n\r\n#Run the loop\r\nrmarkdown::render((\"rmd_reports/create_report.Rmd\"),  \r\n                        output_file = paste0(outputfolder, \"/Report_\", refdate, \".docx\")) #Dyanmic folder name now included"},{"path":"r-markdown-1.html","id":"parametrised-reports","chapter":"41 R Markdown","heading":"41.4 Parametrised reports","text":"Parameterised reports next step content R Markdown can also dynamic. example, title can change according subgeography running, data can filter subgeography interest.Let’s say want run markdown produce report surveillance data Area1 Area2. :Edit R Markdown:Change YAML metadata include ‘params’ section, specifies dynamic object.Refer parameterised object within code needed. E.g. filter(area == params$areanumber) rather filter(area==\"Area1\").instance (simplified version include setup code library/data loading):can change content editing YAML needed, set loop separate script iterate areas. previous section, can set folders well.can see , set list includes areas interest (arealist), rendering markdown specify parameterized areanumber specific iteration Nth value arealist. instance, first iteration, areanumber equate “Area1”. code also specifies Nth area name included output file name.Note work even area date specified within YAML - YAML information get overwritten loop.","code":"# Set the date of report\r\nrefdate <- as.Date(\"2020-12-21\")\r\n\r\n# Set the list (note that this can also be an imported list)\r\narealist <- c(\"Area1\", \"Area2\", \"Area3\", \"Area4\", \"Area5\")\r\n\r\n# Create the folders\r\noutputfolder <- paste0(\"outputs/\", refdate) # This is the new folder name\r\ndir.create(outputfolder) # Creates the folder (in this case assumed 'outputs' already exists)\r\n\r\n#Run the loop\r\n\r\nfor(i in 1:length(arealist))  { # This will loop through from the first value to the last value in 'arealist'\r\n\r\nrmarkdown::render(here(\"rmd_reports/create_report.Rmd\"), \r\n                        params = list(areanumber = arealist[1], #Assigns the nth value of arealist to the current areanumber\r\n                                      refdate = refdate),\r\n                        output_file = paste0(outputfolder, \"/Report_\", arealist[1], refdate, \".docx\")) \r\n                        \r\n}\r\n\r\n"},{"path":"r-markdown-1.html","id":"resources-34","chapter":"41 R Markdown","heading":"41.5 Resources","text":"information can found via:https://bookdown.org/yihui/rmarkdown/https://rmarkdown.rstudio.com/articles_intro.htmlA good explainer markdown vs knitr vs Rmarkdown : https://stackoverflow.com/questions/40563479/relationship--r-markdown-knitr-pandoc--bookdown","code":""},{"path":"routine-reports.html","id":"routine-reports","chapter":"42 Routine reports","heading":"42 Routine reports","text":"CONSTRUCTIONThis page cover reportfactory package tips routinizing data flows reports. reportfactory package developed RECON (R Epidemics Consortium). “facilitates workflows handling multiple .Rmd reports, compiling one several reports one go, storing outputs well-organised, timestamped folders.”","code":"\npacman::p_load(reportfactory)"},{"path":"routine-reports.html","id":"resources-35","chapter":"42 Routine reports","heading":"42.1 Resources","text":"See package’s Github page","code":""},{"path":"errors-warnings-1.html","id":"errors-warnings-1","chapter":"43 Errors & warnings","heading":"43 Errors & warnings","text":"page lists common errors suggests solutions troubleshooting ","code":""},{"path":"errors-warnings-1.html","id":"data-management-errors","chapter":"43 Errors & warnings","heading":"43.1 Data management errors","text":"see error like try export import: Check spelling file filepath, path contains slashes make sure forward / backward \\. Also make sure used correct file extension (e.g. .csv, .xlsx).likely column class Factor (contains pre-defined levels) tried add new value . Convert class Character adding new value.","code":"No such file or directory:#Tried to add a value (\"Missing\") to a factor (with replace_na operating on a factor)\r\nProblem with `mutate()` input `age_cat`.\r\ni invalid factor level, NA generated\r\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated"},{"path":"errors-warnings-1.html","id":"package-masked-errors","chapter":"43 Errors & warnings","heading":"43.2 Package masked errors","text":"think using dplyr::select() select() function masked MASS::select() - specify dplyr:: re-order package loading dplyr others.common masking errors stem : plyr::summarise() stats::filter(). Consider using conflicted package.","code":"Error in select(data, var) : unused argument (var)"},{"path":"errors-warnings-1.html","id":"plotting-errors","chapter":"43 Errors & warnings","heading":"43.3 Plotting errors","text":"Error: Insufficient values manual scale. 3 needed 2 provided.\r\nggplot() scale_fill_manual() values = c(“orange”, “purple”) … insufficient number factor levels … consider whether NA now factor level…see “unexpected symbol” check missing commasconsider whether re-arranged dplyr verbs didn’t replace pipe middle, didn’t remove pipe end.Can’t add x object … + end ggplot command need delete.","code":"# ran recode without re-stating the x variable in mutate(x = recode(x, OLD = NEW)\r\nError: Problem with `mutate()` input `hospital`.\r\nx argument \".x\" is missing, with no default\r\ni Input `hospital` is `recode(...)`.Error: unexpected symbol in:\r\n\"  geom_histogram(stat = \"identity\")+\r\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\""},{"path":"errors-warnings-1.html","id":"resources-36","chapter":"43 Errors & warnings","heading":"43.4 Resources","text":"https://www.r-bloggers.com/2016/06/common-r-programming-errors-faced--beginners/","code":""},{"path":"advanced-rstudio.html","id":"advanced-rstudio","chapter":"44 Advanced RStudio","heading":"44 Advanced RStudio","text":"PAGE CONSTRUCTION","code":""},{"path":"advanced-rstudio.html","id":"find-in-files","chapter":"44 Advanced RStudio","heading":"44.1 Find in Files","text":"advanced search function allows “Find replace” terms across many scripts one time.","code":""},{"path":"advanced-rstudio.html","id":"keyboard-shortcuts-1","chapter":"44 Advanced RStudio","heading":"44.2 Keyboard shortcuts","text":"https://www.dataquest.io/blog/rstudio-tips-tricks-shortcuts/","code":""},{"path":"advanced-rstudio.html","id":"connections","chapter":"44 Advanced RStudio","heading":"44.3 Connections","text":"Query SQL","code":""},{"path":"advanced-rstudio.html","id":"customize-appearance","chapter":"44 Advanced RStudio","heading":"44.4 Customize appearance","text":"","code":""},{"path":"advanced-rstudio.html","id":"package-management-with-renv","chapter":"44 Advanced RStudio","heading":"44.5 Package management with renv","text":"renv package replacing Packrat package RStudio used maintain.","code":""},{"path":"advanced-rstudio.html","id":"view-function-source-code","chapter":"44 Advanced RStudio","heading":"44.6 View function source code","text":"","code":""},{"path":"advanced-rstudio.html","id":"environments","chapter":"44 Advanced RStudio","heading":"44.7 Environments","text":"","code":""},{"path":"advanced-rstudio.html","id":"rstudio-connect-and-cloud","chapter":"44 Advanced RStudio","heading":"44.8 RStudio Connect and Cloud","text":"","code":""},{"path":"advanced-rstudio.html","id":"using-python-with-rstudio","chapter":"44 Advanced RStudio","heading":"44.9 Using Python with RStudio","text":"","code":""},{"path":"advanced-rstudio.html","id":"github","chapter":"44 Advanced RStudio","heading":"44.10 Github","text":"See page Collaboration Github tips use RStudio Github.","code":""},{"path":"advanced-rstudio.html","id":"resources-37","chapter":"44 Advanced RStudio","heading":"44.11 Resources","text":"","code":""},{"path":"relational-databases.html","id":"relational-databases","chapter":"45 Relational databases","heading":"45 Relational databases","text":"PAGE CONSTRUCTION","code":""},{"path":"relational-databases.html","id":"resources-38","chapter":"45 Relational databases","heading":"45.1 Resources","text":"","code":""},{"path":"shiny-and-dashboards.html","id":"shiny-and-dashboards","chapter":"46 Shiny and dashboards","heading":"46 Shiny and dashboards","text":"PAGE CONSTRUCTION","code":""},{"path":"shiny-and-dashboards.html","id":"resources-39","chapter":"46 Shiny and dashboards","heading":"46.1 Resources","text":"tab stay name “Resources”.\r\nLinks online tutorials resources.","code":""},{"path":"collaboration-with-github.html","id":"collaboration-with-github","chapter":"47 Collaboration with Github","heading":"47 Collaboration with Github","text":"","code":""},{"path":"collaboration-with-github.html","id":"overview-20","chapter":"47 Collaboration with Github","heading":"47.1 Overview","text":"Package managementUsing Github R","code":""},{"path":"collaboration-with-github.html","id":"using-github-and-r-to-contribute","chapter":"47 Collaboration with Github","heading":"47.2 Using Github and R to contribute","text":"online guide using Github R. text adapted guide.","code":""},{"path":"collaboration-with-github.html","id":"overview-of-github","chapter":"47 Collaboration with Github","heading":"47.2.1 Overview of GitHub","text":"Github website supports collaborative projects version control. nutshell, project’s files exist Github repository “master” version (called “branch”). want make change files must create different branch (version) build test changes . Master remains unaffected changes branch merged (verification steps) master branch. “commit” saving smaller group changes make within branch. Pull Request request merge changes master branch.way RStudio Github interact follows:REMOTE version Epi_R_handbook R project lives Github website repository - master branches exist viewable Github repository. Pull requests, issue tracking, de-conflicting merges happens online .LOCAL computer, clone version entire Github repository (R project files, branches/versions). Locally, can make changes files branch “commit” changes (save explanatory note). changes stored locally computer …LOCAL repository/Rproject interacts REMOTE one 1) pulling (updating local files remote ones branch) pushing (pushing local changes branch remote repository)software Git computer underlies , used RStudio. don’t interact Git except RStudio. can write Git command-line RStudio terminal, easier just interact Git RStudio point--click buttons. noted , may occasionally write Git commands RStudio terminal.Image source","code":""},{"path":"collaboration-with-github.html","id":"first-steps","chapter":"47 Collaboration with Github","heading":"47.2.2 First steps","text":"Register free account GithubHave R RStudio installed/updatedInstall Git computer (remember Git software computer accessed RStudio, Github website)Familiarize Github workflow reading itBecome contributor Epi_R_handbook Github repository (email neale.batra@gmail.com)Clone Github repository computer\r\nRStudio start new project File > New Project > Version Control > Git\r\n“Repository URL”, paste URL https://github.com/nsbatra/Epi_R_handbook.git (link also available repo main page, green “Code” button, HTTPS)\r\nAccept default project directory name Epi_R_handbook\r\nTake charge – least notice! – Project saved locally\r\nCheck “Open new session” click “Create project”\r\nnow new local RStudio project clone Epi_R_handbook repository Github\r\nRStudio start new project File > New Project > Version Control > GitIn “Repository URL”, paste URL https://github.com/nsbatra/Epi_R_handbook.git (link also available repo main page, green “Code” button, HTTPS)Accept default project directory name Epi_R_handbookTake charge – least notice! – Project saved locallyCheck “Open new session” click “Create project”now new local RStudio project clone Epi_R_handbook repository GithubIn RStudio now Git tab tab R Environment:Button begin “commiting” changes branch (open new window)Arrows PULL (update local version branch changes made branch others) PUSH (send completed commits stored local version branch remote/Github version branch)Git tab RStudioButton create NEW branch whichever version listed right. almost always want branch master (PULL update master first).branch currently working ., changes make code files begin appear","code":""},{"path":"collaboration-with-github.html","id":"to-work-on-your-handbook-page","chapter":"47 Collaboration with Github","heading":"47.2.3 To work on your Handbook page:","text":"Note: Last heard, Github soon change terminology “master” “main”, unnecessary reference slaveryCreate branchBe master branch click branch button/icon.Name branch one-word descriptive name (can use underscores needed). see locally, still project Epi_R_handbook, longer working master branch. created, new branch also appear Github website branch.Make changes… files, code, etc. changes tracked.Commit changes. Every series changes make substantial (e.g. adding updating section, etc.), stop commit changes. Think commit “batch” changes related common purpose.\r\nPress “Commit” git tab, opens new window\r\nReview changes made (green, red etc.)\r\nHighlight changes commit “stage” checking boxes highlighting rows clicking “stage ”\r\nWrite commit message short descriptive (required)\r\nPress “commit” right side\r\nPress “Commit” git tab, opens new windowReview changes made (green, red etc.)Highlight changes commit “stage” checking boxes highlighting rows clicking “stage ”Write commit message short descriptive (required)Press “commit” right sideMake commit changes, many times likePULL - click PULL icon (downward arrow) updates branch version local computer changes made stored remote/Github version\r\nPULL often. Don’t hesitate. Always pull pushing.\r\nPULL often. Don’t hesitate. Always pull pushing.PUSH changes remote/Github version branch.\r\nmay asked enter Github username password.\r\nfirst time asked, may need enter two Git command lines Terminal (tab next R Console):\r\ngit config –global user.email “@example.com” (Github email address), \r\ngit config –global user.name “Github username”\r\n\r\nmay asked enter Github username password.first time asked, may need enter two Git command lines Terminal (tab next R Console):\r\ngit config –global user.email “@example.com” (Github email address), \r\ngit config –global user.name “Github username”\r\ngit config –global user.email “@example.com” (Github email address), andgit config –global user.name “Github username”Request merge branch masterOnce done commits pushed everything remote Github repository, may want request branch merged master branch.Go Epi_R_handbook Github repositoryUse branch drop-view branch, masterAt top see green button saying “Compare Pull Request” branch. , look another button says pull request.Write detailed comment click “Create Pull Request”right, request review members project’s core team. need least one review able complete merge.completed, delete branch explained belowDelete branch GithubGO repository Github click button view branches (next drop-select branches). Now find branch click trash icon next . Read hereBe sure also delete branch locally computer:RStudio, make sure Master branchSwitch typing “terminal” (tab adjacent R console), enter : git branch -d branch_name , “branch_name” name branch deletedRefresh Git tab branch gone.TEST \r\ncan test ability make changes, commits, pull requests, etc. modifying R script saved main Rproject folder: test_your_abilities.RAsked provide password often??\r\nInstructions connecting repository via SSH key (complicated):\r\nSee chapters 10 11 tutorial","code":""},{"path":"collaboration-with-github.html","id":"resources-40","chapter":"47 Collaboration with Github","heading":"47.3 Resources","text":"https://happygitwithr.com/reset.htmlhttps://ohi-science.org/news/github-going-back--time","code":""},{"path":"writing-functions.html","id":"writing-functions","chapter":"48 Writing functions","heading":"48 Writing functions","text":"PAGE CONSTRUCTION","code":""},{"path":"writing-functions.html","id":"preparation-34","chapter":"48 Writing functions","heading":"48.1 Preparation","text":"","code":""},{"path":"writing-functions.html","id":"load-packages-28","chapter":"48 Writing functions","heading":"Load packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics, \n  gtsummary,    # summary statistics and tests\n  janitor,      # adding totals and percents to tables\n  scales,       # easily convert proportions to percents  \n  flextable     # converting tables to HTML\n  )"},{"path":"writing-functions.html","id":"import-data-24","chapter":"48 Writing functions","heading":"Import data","text":"import dataset cases simulated Ebola epidemic. want download data follow step--step, see instructions Download book data page. dataset imported using import() function rio package. See page Import export various ways import data.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"writing-functions.html","id":"functions-1","chapter":"48 Writing functions","heading":"48.2 Functions","text":"functions? use ? R emphasize ?R Data Science link\r\nhttps://r4ds..co.nz/functions.html","code":""},{"path":"writing-functions.html","id":"tertiary-header","chapter":"48 Writing functions","heading":"Tertiary header","text":"","code":""},{"path":"writing-functions.html","id":"tertiary-header-1","chapter":"48 Writing functions","heading":"Tertiary header","text":"","code":""},{"path":"writing-functions.html","id":"major-header","chapter":"48 Writing functions","heading":"48.3 Major header","text":"","code":""},{"path":"writing-functions.html","id":"resources-41","chapter":"48 Writing functions","heading":"48.4 Resources","text":"List links cheatsheets references .","code":""},{"path":"r-on-network-drives.html","id":"r-on-network-drives","chapter":"49 R on network drives","heading":"49 R on network drives","text":"","code":""},{"path":"r-on-network-drives.html","id":"overview-21","chapter":"49 R on network drives","heading":"49.1 Overview","text":"Using R network “company” shared drives can extremely frustrating. page contains approaches, common errors, suggestions troubleshooting, including particularly delicate situations involving Rmarkdown.Using R Network Drives: Overarching principlesMust administrator access computer. Setup RStudio specifically run administrator.Use “\\\" package library little possible, save packages ”C:\" library possible.rmarkdown package must \"\\\" library, can’t talk TinyTex Pandoc.","code":""},{"path":"r-on-network-drives.html","id":"preparation-35","chapter":"49 R on network drives","heading":"49.2 Preparation","text":"Using R Network Drives: Overarching principlesMust administrator access computer. Setup RStudio specifically run administrator.Use “\\\" package library little possible, save packages ”C:\" library possible.rmarkdown package must \"\\\" library, can’t talk TinyTex Pandoc.Useful commands","code":"\n# Find libraries\n.libPaths()                   # Your library paths, listed in order that R installs/searches. \n                              # Note: all libraries will be listed, but to install to some (e.g. C:) you \n                              # may need to be running RStudio as an administrator (it won't appear in the \n                              # install packages library drop-down menu) \n\n# Switch order of libraries\n# this can effect the priority of R finding a package. E.g. you may want your C: library to be listed first\nmyPaths <- .libPaths() # get the paths\nmyPaths <- c(myPaths[2], myPaths[1]) # switch them\n.libPaths(myPaths) # reassign them\n\n# Find Pandoc\nSys.getenv(\"RSTUDIO_PANDOC\")  # Find where RStudio thinks your Pandoc installation is\n\n# Find a package\n# gives first location of package (note order of your libraries)\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\")) "},{"path":"r-on-network-drives.html","id":"troubleshooting-common-errors","chapter":"49 R on network drives","heading":"49.3 Troubleshooting common errors","text":"“Failed compile…tex rmarkdown”check/install tinytex, C: locationInternet routines loadedFor example, “Error tools::startDynamicHelp() : internet routines loaded”Try selecting 32-bit version RStudio via Tools/Global Options.\r\nnote: 32-bit version appear menu, make sure using RStudio v1.2.\r\nnote: 32-bit version appear menu, make sure using RStudio v1.2.try uninstalling R re-installing different bit (32 instead 64)C: library appear option try install packages manuallyMust run RStudio administrator, appear.set-RStudio always run administrator (advantageous using Rproject don’t click RStudio icon open)… right-click Rstudio icon, open properties, compatibility, click checkbox Run Administrator.Pandoc 1 errorIf getting pandoc error 1 knitting Rmarkdowns network drives:can help (two library locations, one lettered drive listed first)worked knitting local drive network internet connectionSee https://ciser.cornell.edu/rmarkdown-knit--html-word-pdf/Pandoc Error 83 (can’t find file…rmarkdown…lua…)\r\nmeans unable find file.See https://stackoverflow.com/questions/58830927/rmarkdown-unable--locate-lua-filter--knitting--wordPossibilities:Rmarkdown package installedRmarkdown package findablean admin rights issue.R able find ‘rmarkdown’ package file, check library rmarkdown package lives.\r\nlibrary inaccessible (e.g. starts \"\\\") consider manually moving C: named drive library.\r\naware rmarkdown package able reach tinytex, rmarkdown package can’t live network drive.Pandoc Error 61\r\nexample: “Error: pandoc document conversion failed error 61”“fetch…”Try running RStudio administrator (right click icon, select run admin, see instructions)Also see specific package unable reached can moved C: library.LaTex error (see )“! Package pdftex.def Error: File `cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png’ found: using draft setting.”“Error: LaTeX failed compile file_name.tex.”\r\nSee https://yihui.org/tinytex/r/#debugging debugging tips.\r\nSee file_name.log info.Pandoc Error 127\r\nRAM (space) issue. Re-start R session try .Mapping network drivesHow one open file “mapped network drive”?First, ’ll need know network location ’re trying access.Next, Windows file manager, need right click “PC” right hand pane, select “Map network drive”.Go dialogue define network location earlier lettered drive.Now two ways get file ’re opening. Using drive-letter path work.: https://stackoverflow.com/questions/48161177/r-markdown-openbinaryfile---exist---file--directory/55616529?noredirect=1#comment97966859_55616529ISSUES SHARED LIBRARY LOCATION NETWORK DRIVEError install.packages()Try removing… /../…/00LOCK (directory)Manually delete 00LOCK folder directory package library. Try installing .can try command pacman::p_unlock() (can also put command Rprofile runs every time project opens.)try installing package . may take several tries.else fails, install package another library manually copy .","code":"\n# check/install tinytex, to C: location\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # should return TRUE (note three colons)\nmyPaths <- .libPaths() # get the library paths\nmyPaths <- c(myPaths[2], myPaths[1]) # switch them\n.libPaths(myPaths) # reassign them"},{"path":"r-on-network-drives.html","id":"resources-42","chapter":"49 R on network drives","heading":"49.4 Resources","text":"tab stay name “Resources”.\r\nLinks online tutorials resources.","code":""}]
