---
knit: "bookdown::render_book"
title: "The Epidemiologist R Handbook"
description: "The Epi R Handbook is a R reference manual for applied epidemiology and public health."
author: "the handbook team"
date: "`r Sys.Date()`"
#url: 'https://github.com/nsbatra/Epi_R_handbook'
github-repo: epirhandbook/Epi_R_handbook
#twitter-handle: 
#cover-image: images/R_Handbook_Logo.png
site: bookdown::bookdown_site
# output: bookdown::gitbook:
#      config:
#           sharing:
#                twitter: yes
#                facebook: yes
#                whatsapp: yes
#                github: yes
documentclass: book
---


#  {-}

```{r, out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "R Handbook Logo.png"))
```

<meta name="description" content="The Epi R Handbook is a R reference manual for applied epidemiology and public health.">

<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<span style="color: red;">**THIS IS A DRAFT.  REVIEWERS GIVE FEEDBACK AT THIS [LINK](https://forms.gle/4RNdRRLGx67xW9yq9)**.</span>

<span style="color: darkgreen;">**DO YOU LIKE THIS HANDBOOK? SHOULD SOMETHING BE CHANGED? PLEASE TELL US!**</span>

<form target="_blank" action="https://forms.gle/A5SnRVws7tPD15Js9">
    <input type="submit" value="FEEDBACK" />
</form>

<!-- ======================================================= -->
## About this handbook {-}

<span style="color: brown;">**The Epi R Handbook is a R reference manual for applied epidemiology and public health.**</span>

**This book strives to:**  

* Serve as a quick R code reference manual  
* Provide task-centered examples for addressing common epidemiologic problems  
* Assist epidemiologists transitioning to R from SAS, STATA, SPSS, and Excel  
* Be accessible in settings with low internet-connectivity via an **offline version** ([instructions here][Download handbook and data])  

**How is this different than other R books?**  

* It is written by epidemiologists, for epidemiologists - leveraging experience in local, national, academic, and emergency settings  
* It provides examples of epidemic curves, transmission chains, automated reports and dashboards, epidemic modeling and projections, demographic pyramids and standardization, record matching, outbreak detection, survey analysis, causal diagrams, survival analysis, GIS basics, phylogenetic trees,  etc...  



<!-- ======================================================= -->
## How to read this handbook {-} 

**Online version**  

* Search via the search box above the Table of Contents 
* Click the "copy" icons to copy code  
* See the "Resources" section of each page for further resources  
* "Follow-along" by [downloading the example data][Download handbook and data]  

**Offline version**  

See instructions to download the offline version of the handbook in the [Download book and data] page.  

**Languages**  

We are seeking to translate this book into languages other than English. If you can help, please contact us.  


<!-- ======================================================= -->
## Edit or contribute {-}

We welcome your comments and suggestions at the [feedback link](https://forms.gle/A5SnRVws7tPD15Js9), by email to **epiRhandbook@gmail.com** or via issue/pull request at our [Github repository](https://github.com/nsbatra/R_epi_handbook).  



<!-- ======================================================= -->
## Acknowledgements {-}  

This handbook is produced by a collaboration of epidemiologists from around the world in their spare time, drawing upon experiences with organizations including local, state/provincial, and national health agencies, the World Health Organization (WHO), MSF (Médecins Sans Frontières / Doctors without Borders), hospital systems, and academic institutions.

This handbook is **not** an approved product of any specific organization. Although we strive for accuracy, we provide no guarantee of the content in this book.  


### Contributors {-}  

**Editor-in-Chief:** Neale Batra 

**Project core team:** Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay Campbell  

**Authors**: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Daniel Molling, Isha Berry, Emma Buajitti, Chris Bailey, Wen Lin, Sara Hollis  

**Reviewers**: Pat Keating, Mathilde Mousset, Annick Lenglet, Margot Charette, Isha Berry, Paula Blomquist, Natalie Fischer, Daniely Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Daniel Molling, Kate Kelsey, Wayne Enanoria, John Rossow, Berhe Etsay, Mackenzie Zendt, James Wright, Flavio Finger, Tim Taylor, Tim Lee, Manual Albela Miranda, Priscilla Spencer, Pattama Ulrich, Joseph Timothy, Olivia Varsaneux, Nienke Meeuwissen, Adam Vaughan, Lionel Monteiro, Joao Muianga  

### Funding and support {-}  

The handbook project received supportive funding via a COVID-19 emergency capacity-building grant from Training Programs in Epidemiology and Public Health Interventions Network ([TEPHINET](https://www.tephinet.org/)). *This handbook was supported by Cooperative Agreement number NU2GGH001873, funded by the Centers for Disease Control and Prevention through TEPHINET, a program of The Task Force for Global Health. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the Centers for Disease Control and Prevention, the Department of Health and Human Services, The Task Force for Global Health, Inc. or TEPHINET.*

Administrative support was provided by the EPIET Alumni Network ([EAN](https://epietalumni.net/)), with special thanks to Annika Wendland. EPIET is the European Programme for Intervention Epidemiology Training.  





### Inspiration {-}  

The multitude of tutorials and vignettes that provided knowledge for development of handbook content are credited within their respective pages.  

More generally, the following sources provided inspiration and laid the groundwork for this handbook:  
[The "R4Epis" project](https://r4epis.netlify.app/) (a collaboration between MSF and RECON)  
[R Epidemics Consortium (RECON)](https://www.repidemicsconsortium.org/)  
[R for Data Science book (R4DS)](https://r4ds.had.co.nz/)  
[bookdown: Authoring Books and Technical Documents with R Markdown](https://bookdown.org/yihui/bookdown/)  
[Netlify](https://www.netlify.com) hosts this website  


### Image credits {-}  

Images in logo from US CDC Public Health Image Library) include [2013 Yemen looking for mosquito breeding sites](https://phil.cdc.gov/Details.aspx?pid=19623), [Ebola virus](https://phil.cdc.gov/Details.aspx?pid=23186), and [Survey in Rajasthan](https://phil.cdc.gov/Details.aspx?pid=19838).  


## Terms of Use and License {-}  

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.


Universities and academic courses are welcome to use this handbook with their students. If you have questions about your intended use, email **epirhandbook@gmail.com**.  
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)
```

<!--chapter:end:index.Rmd-->

# (PART) Preview pages {-}
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)
```

<!--chapter:end:new_pages/cat_preview.Rmd-->


# Contact tracing { }

THIS PAGE IS UNDER CONSTRUCTION

This page walks through some key considerations when analyzing and visualizing contact tracing data. Many core R competencies and tools are covered in other sections as the same desired functionalities apply (i.e. data cleaning; pivoting; tables; epi-curves) but we will highlight key examples specific to contact tracing that have been useful for operational decision making (i.e. visualizing contact tracing follow-up data over time or across geographic areas).

For demonstration purposes we will be reading in sample contact tracing data from the [Go.Data](https://www.who.int/tools/godata) platform; although the same principles could apply for other structured contact tracing data. You can read more about the Go.Data project on the [Github Documentation site](https://worldhealthorganization.github.io/godata/) or [Community of Practice](https://community-godata.who.int/). 


include static images or GIFs like this:

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "flexdashboard_output.png"))
```


Link to other pages by exact name in brackets like the [Import and export] page. Or give them a custom link text like this, with brackets following brackets:   See [the importing page][Import and export]  

Please place {-} after any heading level-3 or more (###) so the numbers don't appear in the TOC

Please include a preparation section like below. You can display interactive data frames/tibbles with DT as shown below.

If you want to preview the page, you can just press Knit. Or use the combination of bookdown_runfile.R and bookdown_small.yml in the root folder to see website layout. Ping me with questions.  


## Preparation

This code chunk shows the loading of packages required for the analyses. In this handbook we emphasize `p_load()` from **pacman**, which installs the package if necessary *and* loads it for use. You can also load installed packages with  `library()` from **base** R. See the page on [R basics] for more information on R packages.  

```{r, message = F}
pacman::p_load(
  rio,        # importing data  
  here,       # relative file pathways  
  janitor,    # data cleaning and tables
  lubridate,  # working with dates
  epikit,     # age_categories() function
  apyramid,   # age pyramids
  tidyverse,  # data manipulation and visualization
  RColorBrewer # color palettes
)
```


### Import data {-}

We will import the sample datasets of contacts and contact followups that have been retrieved and un-nested from the Go.Data API and stored as .rds output files.

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "godata_api_github.png"))
```

If you want to download the data to follow step-by-step, see instructions in the [Download handbook and data] page. The dataset is imported using the `import()` function from the **rio** package. See the page on [Import and export] for various ways to import data. For the full steps on how to retrieve data collections from your Go.Data instance, view the Github documentation [here](https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting)

Below we import the .rds files, located in the 'godata' sub-folder within the 'data' folder.  

```{r, echo=F}
# import the data collections
cases <- rio::import(here::here("data", "godata", "cases_clean.rds"))
contacts <- rio::import(here::here("data", "godata", "contacts_clean.rds"))
followups <- rio::import(here::here("data", "godata", "followups_clean.rds"))
relationships <- rio::import(here::here("data", "godata", "relationships_clean.rds"))
```

Let's start with the contact linelist - the first 50 rows of the registered linelist are displayed below.

```{r, message=FALSE, echo=F}
# display the first 50 rows of contact linelist data as a table
DT::datatable(head(contacts, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

### Basic Demographics {-}

Following instructions from previous pages, we can view some basic tables and plots of case and contact demographics. For instance, we can see age/sex breakdown (using *apyramid* package described earlier)

```{r, warning=F, message=F}
contact_unknown_age <- sum(contacts$age_class == "unknown") # count unknown

contact_age_pyramid <-
apyramid::age_pyramid(data = contacts,
                      age_group = "age_class",
                      split_by = "gender") +
       labs(
       fill = "Gender",
       title = "Age/Sex Pyramid of COVID-19 contacts",
       subtitle = paste0("n = ", contact_unknown_age," without age recorded,")) +
     theme_minimal() # cleaner theme

contact_age_pyramid

```

We can also view other demographics such as occupational breakdown of registered contacts (in form of a pie chart).

```{r, warning=F, message=F}
contacts$occupation <- as.factor(contacts$occupation) # ensure occupation is a factor
contact_unknown_occupation <- sum(is.na(contacts$occupation) | contacts$occupation == "UNKNOWN") # count unknown
getPalette = colorRampPalette(brewer.pal(9, "Set1"))
color_count = length(unique(contacts$occupation)) # for color palette

contact_occupation_breakdown <- contacts %>%
  group_by(occupation) %>%
  count() 

contact_occupation_pie_chart <-
  ggplot(subset(contact_occupation_breakdown, !is.na(occupation)), aes(x = "", y = n, fill = occupation)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  theme_minimal() +
  scale_fill_manual(values = getPalette(color_count)) +
  labs(
       fill = "Occupation",
       title = "Occupational breakdown of COVID-19 contacts",
       subtitle = paste0("n = ", contact_unknown_occupation," without occupation recorded,")
       ) +
  theme(axis.line = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank())

contact_occupation_pie_chart

```

#### Contact Follow Up Data {-}

We can also view the longitudinal follow-up data by summarizing it for a given contact or looking at the discrete follow up events over time. This could be viewed by contact tracer, supervision team and geographic area; and also by day and week.

A sample follow-up list could look like this, with one row for each follow-up generated.

```{r, message=FALSE, echo=FALSE}
# display the first 50 rows of contact linelist data as a table
DT::datatable(head(followups, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```
It is important to consider duplicates - perhaps a contact tracer filled out a follow-up form early on in the day and could not reach them, and filled out a second form where they were then reached. It will depend on the operational scenario and context how you want to handle duplicates, but for simplicity sake here, let's de-duplicate so that there is only one follow-up per person per day, and we keep the row with the most recent submission.

```{r, warning=F, message=F}

followups <- followups %>%
  arrange(contact_uuid, desc(date_of_followup)) %>%    # arrange by date of follow-up; most recent first
  distinct(contact_uuid, .keep_all = TRUE)             # distinct to grab first row per unique contact uuid

```

For each follow-up, we have a follow-up STATUS (such as whether it was performed and if so, did they have symptoms or not). We can group by `followup_status` to see the frequency of each:

```{r, warning=F, message=F}

followup_status <- followups %>%
     group_by(followup_status) %>%
     count()

```

Another thing to keep in mind - you need to prepare for all graphs to show similarly even with varying levels of data completion or data composition, for a given deployment or region. Although not the case for this sample dataset, there may be the scenario where not all follow-up statuses are present in the data at a given time, but we still want the categories to appear the legends and tables. 

In order to force the followup status columns to always be the same, we can set an array below `statuscols` and then use this later. For demonstration I will add in another category "OTHER_RANDOM_STATUS".

```{r, warning=F, message=F}

statuscols <- c(MISSED  = 0, 
                SEEN_NOT_OK = 0, 
                SEEN_OK = 0,
                NOT_PERFORMED = 0,
                NOT_ATTEMPTED = 0,
                OTHER_RANDOM_STATUS = 0)

```


We can visualize a simple plot to show, over time, the status of all follow-ups, of those that were generated. 
*ggplot2* works best with "long" format, which it already is, but if we need to force in the extra status column one option is widening first with `pivot_wider()`; add in column via `add_column()`; then to again `pivot_longer()`.

```{r, warning=F, message=F}


followup_status_daily <- followups %>%
     group_by(followup_status, date_of_followup) %>%
     count() %>%
     pivot_wider(names_from = followup_status, 
                 values_from = n, 
                 values_fill = list(n=0)) 

```

Here we have for each day, the count of each follow-up status. In order to guard against categories being dropped, we ca add the `statuscols` using `add_column()` - it will will be forced to 0 if no rows match this status.

```{r, warning=F, message=F}


followup_status_daily <- followups %>%
     group_by(followup_status, date_of_followup) %>%
     count() %>%
     pivot_wider(names_from = followup_status, 
                 values_from = n, 
                 values_fill = list(n=0)) %>%
     add_column(!!!statuscols[!names(statuscols)%in% names(.)])  # check and add columns if one status doesn't exist

```

Now we can transform back to "long" format to prepare for plotting using `pivot_longer()`.

```{r, warning=F, message=F}


followup_status_daily_long <- followups %>%
     group_by(followup_status, date_of_followup) %>%
     count() %>%
     pivot_wider(names_from = followup_status, 
                 values_from = n, 
                 values_fill = list(n=0)) %>%
     add_column(!!!statuscols[!names(statuscols)%in% names(.)]) %>% # check and add columns if one status doesn't exist
     pivot_longer(cols = -date_of_followup,             # pivot to long version but retain date_of_followup column
                  names_to = "daily_status", 
                  values_to = "counts") 

```

Now we can plot to show this over time.

```{r, warning=F, message=F}

graph_followup_status_daily_long <- followup_status_daily_long %>%
    ggplot(aes(x = date_of_followup, y = counts, fill = daily_status)) +
    geom_col(position = "stack") +
    theme_classic() +
    labs(x = "",
         y = "Number of contacts",
         title = "Daily Contact Followup Status",
         fill = "Followup Status",
         subtitle = paste0("Data as of ", Sys.Date(), "\n")) 

```


Perhaps this is being viewed on a daily of weekly basis for operational decision-making, and it's better to do some more meaningful disaggregations by geographic area or team. We can do this following same approach as before, just swapping out `group_by()` variables.

```{r, warning=F, message=F}

followup_status_regional <- followups %>%
     group_by(followup_status, admin_2_name, admin_1_name) %>%    # here instead we are using location var
     count() %>%
     pivot_wider(names_from = followup_status, 
                 values_from = n, 
                 values_fill = list(n=0)) %>%
     add_column(!!!statuscols[!names(statuscols)%in% names(.)]) %>%  # check and add columns if one status doesn't exist
     pivot_longer(cols = -(admin_2_name:admin_1_name),             # pivot to long version but retain location columns
                  names_to = "daily_status", 
                  values_to = "counts") 

```

Now we can graph and facet appropriately:

```{r, warning=F, message=F}

graph_followup_status_regional <- followup_status_regional %>%
    ggplot(aes(x = reorder(admin_2_name,counts), 
               y = counts, 
               fill = daily_status,
               label = ifelse(counts>0, counts, NA)  # add in label of counts for easier reading
               )) +
    geom_col(position = "stack") +
    geom_text(size = 3, position = position_stack(vjust = 0.5), 
               color = "white", check_overlap = TRUE, fontface = "bold") + # formatting for text labeling
    coord_flip() +
    theme_classic() +
    labs(x = "",
         y = "Number of contacts",
         title = "Contact Followup Status, by Region",
         fill = "Followup Status",
         subtitle = paste0("Data as of ", Sys.Date(), "\n")) +
     facet_wrap(~admin_1_name, strip.position = "right", scales = "free_y", ncol = 1)  # add admin_1 names on right

```

If this was disaggregated by contact tracer, perhaps we would want to add a threshold line to display total # contacts that normally one person or area/team can handle, and how the current workload compares. We just do this by using `geom_hline()` function.

```{r, warning=F, message=F}

graph_followup_status_regional <- 
     graph_followup_status_regional + 
     geom_hline(aes(yintercept=25), color="#C70039", linetype = "dashed") # fictitious threshold at 25 contacts

```


#### KPI Tables {-}

There are a number of different KPIs that can be calculated and tracked at varying levels of disaggregations and across different time periods. Once you have the calculations down and the basic table format; it is fairly easy to swap in and out different KPIs. Below we will walk through a sample exercise of creating a nice table visual to show contact follow-up across contact tracers using *formattable* package.

```{r, warning=F, message=F}

```

#### Transmission Matrices {-}

As discussed in the [Heat plots] page, you can view a matrix of "who infected whom".

When new contacts are created, Go.Data stores this relationship information in the "relationships" API endpoint; and we can see the dataset below. This means that we can create a heatmap with relatively few steps given each contact is already joined to it's source case.

```{r, warning=F, message=F}
# display the first 50 rows of relationships data as a table
DT::datatable(head(relationships, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

We can grab the few variables we need and add age-categories for sources (cases) and targets (contacts).


```{r}
heatmap_ages <- relationships %>% 
  filter(!is.na(source_visualid) & !is.na(target_visualid)) %>%
  select(source_visualid, source_age, target_visualid, target_age) %>% 
  # WHO recommended age categories, updated Sept 2020
  mutate(
    source_age_class = factor(
      case_when(
        source_age <= 4 ~ "0-4",
        source_age <= 9 ~ "5-9",
        source_age <= 14 ~ "10-14",
        source_age <= 19 ~ "15-19",
        source_age <= 29 ~ "20-29",
        source_age <= 39 ~ "30-39",
        source_age <= 49 ~ "40-49",
        source_age <= 59 ~ "50-59",
        source_age <= 64 ~ "60-64",
        source_age <= 69 ~ "65-69",
        source_age <= 74 ~ "70-74",
        source_age <= 79 ~ "75-79",
        is.finite(source_age) ~ "80+",
        TRUE ~ "unknown"
      ), levels = c(
        "0-4",
        "5-9",
        "10-14",
        "15-19",
        "20-29",
        "30-39",
        "40-49",
        "50-59",
        "60-64",
        "65-69",
        "70-74",
        "75-79",
        "80+",
        "unknown"
      )),
    source_age_class = factor(
      source_age_class,
      levels = rev(levels(source_age_class)))) %>%
     
     mutate(
    target_age_class = factor(
      case_when(
        target_age <= 4 ~ "0-4",
        target_age <= 9 ~ "5-9",
        target_age <= 14 ~ "10-14",
        target_age <= 19 ~ "15-19",
        target_age <= 29 ~ "20-29",
        target_age <= 39 ~ "30-39",
        target_age <= 49 ~ "40-49",
        target_age <= 59 ~ "50-59",
        target_age <= 64 ~ "60-64",
        target_age <= 69 ~ "65-69",
        target_age <= 74 ~ "70-74",
        target_age <= 79 ~ "75-79",
        is.finite(target_age) ~ "80+",
        TRUE ~ "unknown"
      ), levels = c(
        "0-4",
        "5-9",
        "10-14",
        "15-19",
        "20-29",
        "30-39",
        "40-49",
        "50-59",
        "60-64",
        "65-69",
        "70-74",
        "75-79",
        "80+",
        "unknown"
      )),
    target_age_class = factor(
      target_age_class,
      levels = rev(levels(target_age_class))))

```

```{r message=FALSE, echo=F}
# display the shapefile as a table
DT::datatable(head(heatmap_ages, 50), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )
```

As described previously, we create cross-tabulation; 

```{r, warning=F, message=FALSE}

cross_tab <- 
      table(source_cases = heatmap_ages$source_age_class,
      target_cases = heatmap_ages$target_age_class)

```

convert into long format with proportions;

```{r, warning=FALSE, message=FALSE}

long_prop <- data.frame(prop.table(cross_tab))

```

and create a heat-map.


```{r, warning=F, message=F}

ggplot(data = long_prop)+       # use long data, with proportions as Freq
  geom_tile(                    # visualize it in tiles
    aes(
      x = target_cases,         # x-axis is case age
      y = source_cases,     # y-axis is infector age
      fill = Freq))+            # color of the tile is the Freq column in the data
  scale_fill_gradient(          # adjust the fill color of the tiles
    low = "blue",
    high = "orange")+
  labs(                         # labels
    x = "Target case age",
    y = "Source case age",
    title = "Who infected whom - Go.Data Relationships Linelist",
    subtitle = "Frequency matrix of transmission events",
    fill = "Proportion of all\ntranmsission events"     # legend title
  )

```


## Resources  

https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reporting

https://worldhealthorganization.github.io/godata/

https://community-godata.who.int/
```{r include=FALSE, cache=FALSE}

# clear workspace
rm(list = ls(all = TRUE))

# clear all packages except base
#lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))

# to ensure that tidyverse packages prevail
filter <- dplyr::filter
select <- dplyr::select
summarise <- dplyr::summarise
summary <- base::summary
incidence <- incidence2::incidence

#load core packages
pacman::p_load(
     rio,
     here,
     DT,
     stringr,
     lubridate,
     tidyverse
)

# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "case_linelists", "linelist_cleaned.rds"))

# import the count data - facility level
#count_data <- rio::import(here::here("data", "facility_count_data.rds"))

# Settings

options(scipen=1, digits=7)
```

<!--chapter:end:new_pages/contact_tracing.Rmd-->

