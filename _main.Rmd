---
knit: "bookdown::render_book"
title: "R Handbook for Epidemiologists"
author: "the handbook team"
description: "Description here......................"
date: "`r Sys.Date()`"
#url: 'https://github.com/nsbatra/Epi_R_handbook'
#github-repo: nsbatra/Epi_R_handbook
#twitter-handle: 
cover-image: images/R_Handbook_Logo.png
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
---

<!-- ---  -->
<!-- title: "A Minimal Book Example" -->
<!-- author: "Yihui Xie" -->
<!-- date: "`r Sys.Date()`" -->
<!-- site: bookdown::bookdown_site -->
<!-- output: bookdown::gitbook -->
<!-- documentclass: book -->
<!-- bibliography: [book.bib, packages.bib] -->
<!-- biblio-style: apalike -->
<!-- link-citations: yes -->
<!-- github-repo: rstudio/bookdown-demo -->
<!-- description: "This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." -->
<!-- --- -->

# Welcome

```{r, out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "R Handbook Logo.png"))
```


<!-- ======================================================= -->
## About this handbook

**Objective**  

**A free open-access digital R reference book catered to epidemiologists and public health practitioners that is usable offline and addresses common epidemiological tasks via clear text explanations, step-by-step instructions, and best practice R code examples**

Epis using R must often Google search and read dozens of forum pages to complete common data manipulation and visualization epi tasks. However, field epidemiologists often work in low internet-connectivity environments and have limited technical support. This handbook aims to fill this gap.  

  
**How to read this handbook:**  

* The is an HTML file which *can* be viewed offline, and is best viewed with Google Chrome.  

* Search via the search box above the Table of Contents. Ctrl+f will search across the current page.  

* Click the "clipboard" icon in the upper-right of each code chunk to copy it.    



**Version**  
The latest version of this handbook can be found at this [github repository](https://github.com/nsbatra/R_epi_handbook).  





<!-- ======================================================= -->
## Acknowledgements


### Contributors  

**Editor-in-Chief:** Neale Batra (neale.batra@gmail.com)

**Editorial core team:**  ...  

**Authors:** ...

**Reviewers:** ...  

**Advisers**  ...  


### Funding and programmatic support  

TEPHINET  
EAN


### Data sources  

*outbreaks* R package  


### Inspiration and templates  

R4Epis  
RECON packages  
R4DS book (Hadley)  
Bookdown book (Yihui)  
Rmarkdown book (Yihui)  

### Image credits  

Logo: CDC Public Image gallery; R Graph Gallery  



<!--chapter:end:index.Rmd-->

# (PART) About this book {-}

<!--chapter:end:raw_pages/cat_about_book.Rmd-->

# Style and editorial notes {.tabset .tabset-fade}


## Style  


### Text style


**Package and function names**  

Package names are written in bold (e.g. **dplyr**) and functions are written like this: `mutate()`. Packages referenced either in text or within code like this: `dplyr::mutate()`  



**Types of notes**  

<span style="color: black;">**_NOTE:_** This is a note</span>

<span style="color: darkgreen;">**_TIP:_** This is a tip.</span>

<span style="color: orange;">**_CAUTION:_** This is a cautionary note.</span>

<span style="color: red;">**_DANGER:_** This is a warning.</span>



### **tidyverse**  

This handbook generally uses **tidyverse** R coding style. Read more [here](https://www.tidyverse.org/)



### Code readability  

We chose to frequently write code on new lines, in order to offer more understandable comments. As a result, code that *could* be written like this:  

```{r, eval=F}
obs %>% 
  group_by(name) %>%                    # group the rows by 'name'
  slice_max(date, n = 1, with_ties = F) # if there's a tie (of date), take the first row
```

...is often written like this:  

```{r, eval=F}
obs %>% 
  group_by(name) %>%   # group the rows by 'name'
  slice_max(
    date,              # keep row per group with maximum date value 
    n = 1,             # keep only the single highest row 
    with_ties = F)     # if there's a tie (of date), take the first row
```




## Editorial decisions  

Below, we track significant editorial decisions around package and function choice. If you disagree or want to offer a new tool, please join/start a conversation on our Github page.    


**Table of package, function, and other editorial decisions**  



Subject           |     Considered      |   Outcome & date    |    Brief rationale   
----------------- | --------------------|---------------------|--------------------------------------------------    
Epiweeks          | aweek, lubridate    | lubridate, Dec 2020 | consistency, package maintenance prospects  
   





<!--chapter:end:raw_pages/editorial_style.Rmd-->

# Datasets used

Here the datasets used in this handbook will be described and will be downloadable  

* Linelist (...)
* Aggregated case counts (...)  
* GIS shapefile (...)  
* modeling dataset? (...)

<!--chapter:end:raw_pages/data_used.Rmd-->

# (PART) Basics {-}

<!--chapter:end:raw_pages/cat_basics.Rmd-->

# R Basics {.tabset .tabset-fade}

<!-- ======================================================= -->
## Overview

**This section is not meant as a comprehensive "learn basic R" tutorial**. However, it does cover some of the fundamentals that can be useful for reference or for refreshing your memory. 

See the tab on recommended training for more comprehensive tutorials.  

```{r, echo=F}
# import the cleaned ebola linelist
linelist <- rio::import(here::here("data", "linelist_cleaned.rds"))
pacman::p_load(apyramid)
```

<!-- ======================================================= -->
## Why use R?
<h2> Why use R? </h2>

As stated on the [R project website](https://www.r-project.org/about.html), R is a programming language and environment for statistical computing and graphics. It is highly versatile, extensible, and community-driven.  

**Cost**

R is free to use! There is a strong ethic in the community of free and open-source material.  

**Reproducibility**  

Conducting your data management and analysis through a programming language (compared to Excel or other primarily manual tool) enhances **reproducibility**, makes **error-detection** easier, and eases your workload.  

**Community**  

The broad R community is enormous and collaborative. New packages and tools are developed daily, and vetted by the community. Perhaps the largest organization of R users is [R-Ladies](https://rladies.org/), which likely has a chapter near you.   




<!-- ======================================================= -->
## Packages
<h2> Packages </h2>




Below we load some of the packages used in this page:  

```{r}
pacman::p_load(
  tidyverse,
  rio,
  here
)
```


<!-- ======================================================= -->
## Installation {#install .tabset .tabset-fade }
<h2> Installation </h2>

**How to install R**  

Visit this website [https://www.r-project.org/](https://www.r-project.org/) and download the latest version of R suitable for your computer.  

**How to install R Studio**  

Visit this website [https://rstudio.com/products/rstudio/download/](https://rstudio.com/products/rstudio/download/) and download the latest free Desktop version of RStudio suitable for your computer.

**How to update R and RStudio**  


**Other things you may need to install:**  

* TinyTeX (*for compiling an RMarkdown document to PDF*)  
* Pandoc  (*for compiling RMarkdown documents*)  
* RTools  (*for building packages for R*)  


### TinyTex {.tabset .tabset-fade }
<h3> TinyTex </h3>

See [https://yihui.org/tinytex/](https://yihui.org/tinytex/)  

To install from R:  

```{r, eval=F}
install.packages('tinytex')
tinytex::install_tinytex()
# to uninstall TinyTeX, run tinytex::uninstall_tinytex()
```


### Pandoc {.tabset .tabset-fade }
<h3> Pandoc </h3>

Pandoc is a document converter, a separate software from R. **It comes bundled with RStudio.** It helps the process of converting Rmarkdown documents to formats like .pdf and adding complex functionality.  


### RTools {.tabset .tabset-fade }
<h3> TinyTex </h3>

RTools is a collection of software for building packages for R

Install from this website: [https://cran.r-project.org/bin/windows/Rtools/](https://cran.r-project.org/bin/windows/Rtools/)  




<!-- ======================================================= -->
## RStudio {#rstudio .tabset .tabset-fade }
<h2> RStudio </h2>


### RStudio Orientation
**First, open RStudio.** As their icons can look very similar, be sure you are opening *RStudio* and not R.  


For RStudio to function you must also have R installed on the computer (see [this section](#install) for installation instructions).  

**RStudio** is an interface (GUI) for easier use of **R**. You can think of R as being the engine of a vehicle, doing the crucial work, and RStudio as the body of the vehicle (with seats, accessories, etc.) that helps you actually use the engine to move forward!  

By default RStudio displays four rectangle panes. 

```{r out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "RStudio_overview.png"))
```


<span style="color: black;">**_TIP:_** If your RStudio displays only one left pane it is because you have no scripts open yet.</span>


**The R Console Pane**  

The R Console, by default the left or lower-left pane in R Studio, is the home of the R "engine". This is where the commands are actually run and non-graphic outputs and error/warning messages appear. You can directly enter and run commands in the R Console, but realize that these commands are not saved as they are when running commands from a script.  

If you are familiar with Stata, the R Console is like the Command Window and also the Results Window.

**The Source Pane**  
This pane, by default in the upper-left, is space to edit and run your scripts. This pane can also display datasets (data frames) for viewing.  

For Stata users, this pane is similar to your Do-file and Data Editor windows.


**The Environment Pane**  
This pane, by default the upper-right, is most often used to see brief summaries of objects in the R Environment in the current session. These [objects](#objects) could include imported, modified, or created datasets, parameters you have defined (e.g. a specific epi week for the analysis), or vectors or lists you have defined during analysis (e.g. names of regions). Click on the arrow next to a dataframe name to see its variables.  

In Stata, this is most similar to Variables Manager window.


**Plots, Packages, and Help Pane**  
The lower-right pane includes several tabs including plots (display of graphics including maps), help, a file library, and available R packages (including installation/update options).  

This pane contains the Stata equivalents of the Plots Manager and Project Manager windows.

### RStudio settings  

Change RStudio settings and appearance in the *Tools* drop-down menu, by selecting *Global Options*. There you can change the default settings, including appearance/background color.  

```{r basics_RStudio, out.width = "100%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "RStudio_tools_options.png"))
```



<!-- ======================================================= -->
## Scripts {#scripts .tabset .tabset-fade }
<h2> Scripts </h2>

Scripts are a fundamental part of programming. Storing your code in a script (vs. typing in the console) has many advantages:  

* Reproducibility  
* Version control  
* Commenting  


<!-- ======================================================= -->
### Rmarkdown {#rmd .tabset .tabset-fade }
<h3> Rmarkdown </h3>

Rmarkdown is a type of script in which the script itself *becomes* a document (PDF, Word, HTML, Powerpoint, etc.). See the handbook page on Rmarkdown documents.  


<!-- ======================================================= -->
### R notebooks {#rnotebooks .tabset .tabset-fade }
<h3> R notebooks </h3>

There is no difference between writing in a Rmarkdown vs an R notebook. However the execution of the document differs slightly. See this [site](http://uc-r.github.io/r_notebook) for more details.

<!-- ======================================================= -->
### R Shiny {#shinyscripts .tabset .tabset-fade }
<h3> R Shiny </h3>

Shiny apps are contained within one script, which must be named `app.R`. This file has three components:  

1) A user interface (ui)  
2) A server function  
3) A call to the `shinyApp` function  

See the handbook page on Shiny basics, or this online tutorial: [Shiny tutorial](https://shiny.rstudio.com/tutorial/written-tutorial/lesson1/)

*In older versions, the above file was split into two files (`ui.R` and `server.R`)*




<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Working directory {#workingdirectory}
<h2> Working directory </h2>

These tabs cover how to use R working directories, and how this changes when you are working within an R project. 
**The working directory is the root file location used by R for your work.**  
By default, it will save new files and outputs to this location, and will look for files to import (e.g. datasets) here as well.  

```
NOTE: If using an [R project](#rproject), the working directory will default to the R project root folder **IF** you open RStudio by clicking open the R project (the file with .rproj extension))

```

<!-- ======================================================= -->
### Set by command

Use the command `setwd()` with the filepath in quotations, for example: `setwd("C:/Documents/R Files")`


<span style="color: orange;">**_CAUTION:_** If using an RMarkdown script be aware of the following:</span>

In an [R Markdown](#rmarkdown) script, the default working directory is the folder the Rmarkdown file (`.Rmd`) is saved to. If you want to change this, you can use `setwd()` as above, but know the change will only apply to that specific code chunk.  

To change the working directory for all code chunks in an R markdown, edit the setup chunk to add the `root.dir = ` parameter, such as below:

```{r, eval=F}
knitr::opts_knit$set(root.dir = 'desired/filepath/here')
```


<!-- ======================================================= -->
### Set Manually

Setting your working directory manually (point-and-click)  

From RStudio click: Session / Set Working Directory / Choose Directory (you will have to do this each time you open RStudio)


<!-- ======================================================= -->
### In an R project

If you are working in an R project, your working directory will by default be the root folder. This is convenient to maximize with the **here** package (LINK).  




<!-- ======================================================= -->
## Objects {#objects .tabset .tabset-fade }
<h2> Objects </h2>

Everything in R is an object. These sections will explain:  

* How to create objects (`<-`) 
* Types of objects (e.g. data frames, vectors..)  
* How to access subparts of objects (e.g. variables in a dataset)  
* Classes of objects (e.g. numeric, character, factor)  



<!-- ======================================================= -->
### Everything is an object 
<h3> Everything is an object </h3>

Everything you store in R - datasets, variables, a list of village names, a total population number, even outputs such as graphs - are **objects** which are **assigned a name** and **can be referenced** in later commands.  

An object exists when you have assigned it a value (see the assignment section below). When it is assigned a value, the object appears in the Environment (see the upper right pane of RStudio). It can then be operated upon, manipulated, changed, and re-defined.

<!-- ======================================================= -->
### Defining objects (`<-`)
<h3> Defining objects </h3>

**Create objects *by assigning them a value* with the <- operator.**  
You can think of the assignment operator `<-` as the words "is defined as". Assignment commands generally follow a standard order:
 
**object_name**  <-  **value** (or process/calculation that produce a value)

> **EXAMPLE:** You may want to record the current epidemiological reporting week as an object for reference in later code. In this example, the object `reporting_week` is created when it is assigned the character value `"2018-W10"` (the quote marks make these a character value).  
The object `reporting_week` will then appear in the RStudio Environment pane (upper-right) and can be referenced in later commands.  


See the R commands and their output in the boxes below. 

```{r basics_objects_assignment}
reporting_week <- "2018-W10"   # this command creates the object reporting_week by assigning it a value
reporting_week                 # this command prints the current value of reporting_week object in the console
```

<span style="color: black;">**_NOTE:_** Note the `[1]` in the R console output is simply indicating that you are viewing the first item of the output</span>


<span style="color: orange;">**_CAUTION:_** **An object's value can be over-written** at any time by running an assignment command to re-define its value. Thus, the **order of the commands run is very important**.</span>

The following command will re-define the value of `reporting_week`: 

```{r basics_objects_reassignment}
reporting_week <- "2018-W51"   # assigns a NEW value to the object reporting_week
reporting_week                 # prints the current value of reporting_week in the console
```

**Datasets are also objects and must be assigned names when they are imported.**  

In the code below, the object `linelist` is created and assigned the value of a CSV file imported with the **rio** package.  

```{r basics_objects_dataframes, eval=FALSE}
# linelist is created and assigned the value of the imported CSV file
linelist <- rio::import("my_linelist.csv")
```

You can read more about importing and exporting datasets with the section on [importing data](#importdata).

<span style="color: orange;">**_CAUTION:_** A quick note on naming of objects:</span>

  * Object names must not contain spaces, but you should use underscore (_) or a period (.) instead of a space.  
  * Object names are case-sensitive (meaning that Dataset_A is different from dataset_A). 
  * Object names must begin with a letter (cannot begin with a number like 1, 2 or 3). 

 

<!-- ======================================================= -->
### Object structure {#objectstructure}  
<h3> Object structure </h3>

**Objects can be a single piece of data (e.g. `my_number <- 24`), or they can consist of structured data.**  

The graphic below, sourced from [this online R tutorial](http://venus.ifca.unican.es/Rintro/dataStruct.html) shows some common data structures and their names. Not included in this image is spatial data, which is discussed in the [GIS section](#gis).  


```{r basics_objects_structures, echo=F, out.width = "75%", out.height="50%", fig.align = "center"}
knitr::include_graphics(here::here("images", "R_data_structures.png"))
```  

In epidemiology (and particularly field epidemiology), you will *most commonly* encounter data frames and vectors:  


Common structure | Explanation | Example
------------------- | ------------------------------------ | ------------------------  
Vectors | A container for a sequence of singular objects, all of the same class (e.g. numeric, character). | **"Variables" (columns) in data frames are vectors** (e.g. the variable `age_years`).  
Data Frames | Vectors (e.g. columns) that are bound together that all have the same number of rows. | `linelist` is a data frame.  

Note that to create a vector that "stands alone", or is not part of a data frame (such as a list of location names), the function `c()` is often used:  

`list_of_names <- c("Ruhengeri", "Gisenyi", "Kigali", "Butare")`  


<!-- ======================================================= -->
### Object classes  {#objectclasses}
<h3> Object classes </h3>

All the objects stored in R have a *class* which tells R how to handle the object. There are many possible classes, but common ones include:

Class |	Explanation | Examples
------ | ------------------------------------------ |  -----------------------------
Character	| These are text/words/sentences **"within quotation marks"**. Math cannot be done on these objects.	| "Character objects are in quotation marks"  
Numeric	| These are numbers and **can include decimals**. If within quotation marks the will be considered character. | 23.1 or 14  
Integer | Numbers that are **whole only** (no decimals) | -5, 14, or 2000  
Factor | These are vectors that have a **specified order** or hierarchy of values | Variable `msf_involvement` with ordered values N, S, SUB, and U.  
Date | **Once R is told that certain data are Dates**, these data can be manipulated and displayed in special ways. See the page on Dates for more information. | 2018-04-12 or 15/3/1954 or Wed 4 Jan 1980  
Logical | Values must be one of the two special values TRUE or FALSE (note these are **not** "TRUE" and "FALSE" in quotation marks) | TRUE or FALSE  
data.frame | A data frame is how R stores a **typical dataset**. It consists of vectors (columns) of data bound together, that all have the same number of observations (rows). | The example AJS dataset named `linelist_raw` contains 68 variables with 300 observations (rows) each.  

**You can test the class of an object by feeding it to the function `class()`**. Note: you can reference a specific column within a dataset using the `$` notation to separate the name of the dataset and the name of the column.

```{r basics_objects_class, echo=TRUE, eval=T}
class(linelist$age)     # class should be numeric

class(linelist$gender)  # class should be character
```

**Often, you will need to convert objects or variables to another class.**

Function | Action  
----------------- | --------------------------------------------------------------    
`as.character()` | Converts to character class  
`as.numeric()` | Converts to numeric class  
`as.integer()` | Converts to integer class
`as.Date()` | Converts to Date class - Note: see section on [dates](#dates) for details  
`as.factor()` | Converts to factor - Note: re-defining order of value levels requires extra arguments

Here is [more online material on classes and data structures in R](https://swcarpentry.github.io/r-novice-inflammation/13-supp-data-structures/).


<!-- ======================================================= -->
### Columns/Variables (`$`) {#dollarsign}  
<h3> Columns/Variables </h3>

**Vectors within a data frame (variables in a dataset) can be called, referenced, or created using the `$` symbol.** The `$` symbol connects the name of the column to the name of its data frame. The `$` symbol must be used, otherwise R will not know where to look for or create the column.  

In this handbook, we use the word "column" instead of "variable".  


```{r basics_objects_call, eval=F}
# Retrieve the length of the vector age_years
length(linelist$age) # (age is a variable in the linelist data frame)

```

By typing the name of the data frame followed by `$` you will also see a list of all variables in the data frame. You can scroll through them using your arrow key, select one with your Enter key, and avoid spelling mistakes!  

```{r basics_objects_callGIF, out.width = "100%", fig.align = "center"}
knitr::include_graphics(here::here("images", "Calling_Names.gif"))
```  



<span style="color: darkgreen;">**_ADVANCED TIP:_** Some more complex objects (e.g. an `epicontacts` object may have multiple levels which can be accessed through multiple dollar signs. For example `epicontacts$linelist$date_onset`) .</span>



<!-- ======================================================= -->
### Access with brackets (`[]`) {#brackets}  
<h3> Access with brackets (`[]`) </h3>

You may need to view parts of objects, which is often done using the square brackets `[ ]`.  

To view specific rows and columns of a dataset, you can do this using the syntax `dataframe[rows, columns]`:  

```{r basics_objects_access, eval=F}
# View a specific row (2) from dataset, with all columns
linelist[2,]

# View all rows, but just one column
linelist[, "date_onset"]

# View values from row 2 and columns 5 through 10
linelist[2, 5:10] 

# View values from row 2 and columns 5 through 10 and 18
linelist[2, c(5:10, 18)] 

# View rows 2 through 20, and specific columns
linelist[2:20, c("date_onset", "outcome", "age")]

# View rows and columns based on criteria
# *** Note the dataframe must still be names in the criteria!
linelist[linelist$age > 25 , c("date_onset", "date_birth", "age")]

# Use View() to see the outputs in the RStudio Viewer pane (easier to read) 
# *** Note the capital "V" in View() function
View(linelist[2:20, "date_onset"])

# Save as a new object
new_table <- linelist[2:20, c("date_onset")] 
```

The square brackets also work to call specific parts of an object, such as output of a `summary()` function, or a vector: 

```{r}
# All of the summary
summary(linelist$age)

#Just one part
summary(linelist$age)[2]  

my_vector <- c("a", "b", "c", "d", "e", "f")  # define the vector
my_vector[5]                                  # print the 5th element
```



<!-- ======================================================= -->
## Functions and packages {#functions .tabset .tabset-fade }
<h2> Functions and packages </h2>


This section on functions explains:  

* What a function is and how they work  
* What arguments are  
* What packages are  
* How to get help understanding a function  


<!-- ======================================================= -->
### Simple functions  
<h3> Simple functions </h3>

**A function is like a machine that receives inputs, does some action with those inputs, and produces an output.**  
What the output is depends on the function.    

**Functions typically operate upon some object placed within the function's parentheses**. 
For example, the function `sqrt()` calculates the square root of a number:  

```{r basics_function_sqrt}
sqrt(49)
```

Functions can also be applied to variables in a dataset. For example, when the function `summary()` is applied to the numeric variable `age` in the dataset `linelist` ([what's the `$` symbol?](#objects)), the output is a summary of the variable's numeric and missing values.

```{r basics_functions_summary}
summary(linelist$age)
```

<span style="color: black;">**_NOTE:_** Behind the scenes, a function represents complex additional code that has been wrapped up for the user into one easy command.</span>



<!-- ======================================================= -->
### Functions with multiple arguments  
<h3> Functions with multiple arguments </h3>

Functions often ask for several inputs, called ***arguments***, located within the parentheses of the function, usually separated by commas. 

* Some arguments are required for the function to work correctly, others are optional.  
* Optional arguments have default settings if they are not specified.
* Arguments can take character, numeric, logical (TRUE/FALSE), and other inputs.  


```{r basics_functions_image, echo=F, out.width = "75%", fig.align = "center"}
knitr::include_graphics(here::here("images", "Function_Bread_Example.png"))
```


>**For example**, this `age_pyramid()` command produces an age pyramid graphic based on defined age groups and a binary split variable, such as `gender`. The function is given three arguments within the parentheses, separated by commas. The values supplied to the arguments establish `linelist` as the data frame to use, `age_group` as the variable to count, and `gender` as the binary variable to use for splitting the pyramid by color.

```{r basics_functions_arguments, include=FALSE, results='hide', message=FALSE, warning=FALSE, eval=T}
## create an age group variable by specifying categorical breaks
linelist$age_group <- cut(linelist$age, breaks = c(0, 5, 10, 15, 20, 30, 45, 60))
```

<span style="color: black;">**_NOTE:_** For this example, in the background we have created a new variable called "age_group". To learn how to create new variable see [that section of this handbook](#newvars) </span>


```{r basics_functions_pyramid, message=FALSE, warning=FALSE, eval=T, out.width = "75%", out.height="75%"}
# Creates an age pyramid by specifying the dataframe, age group variable, and a variable to split the pyramid
apyramid::age_pyramid(data = linelist, age_group = "age_group", split_by = "gender")
```

> The first half of an argument assignment (e.g. `data = `) does not need to be specified if the arguments are written in a specific order (specified in the function's documentation). The below code produces the exact same pyramid as above, because the function expects the argument order: data frame, `age_group` variable, `split_by` variable.  

```{r, basics_functions_pyramid2, eval = FALSE, warning=FALSE, message=FALSE, , out.width = "75%", out.height="75%", eval=F}
# This command will produce the exact same graphic as above
apyramid::age_pyramid(linelist, "age_group", "gender")
```

**A more complex `age_pyramid()` command might include the *optional* arguments to:**  

* Show proportions instead of counts (set `proportional = TRUE` when the default is `FALSE`)  
* Specify the two colors to use (`pal = ` is short for "palette" and is supplied with a vector of two color names. See the [objects](#objectstructure) page for how the function `c()` makes a vector)  


<span style="color: black;">**_NOTE:_** For arguments specified with an equals symbol (e.g. `coltotals = ...`), their order among the arguments is not important (must still be within the parentheses and separated by commas).</span>


```{r message=FALSE, warning=FALSE, out.width = "75%", out.height="75%"}
age_pyramid(linelist, "age_group", "gender", proportional = TRUE, pal = c("orange", "purple"))
```

<!-- ======================================================= -->
### Packages {#packages}  
<h3> Packages </h3>

**Packages contain functions.**  

On installation, R contains "base" functions that perform common elementary tasks. But many R users create specialized functions, which are verified by the R community and which you can download as a **package** for your own use.  

One of the more challenging aspects of R is that there are often many functions or packages to choose from to complete a given task.  

*Functions* are contained within **packages** which can be downloaded ("installed") to your computer from the internet. Once a package is downloaded, you access its functions by loading the package with the `library()` command at the beginning of each R session.

```{r basics_packages_load, eval=F}
# this loads the package "tidyverse" for use in the current R session
library(tidyverse)
```

<span style="color: black;">**_NOTE:_** While you only have to install a package once, you must load it at the beginning of every R session using `library()` command, or an alternative like **pacman**'s `p_load()` function.</span>

Think of R as your personal library: When you download a package your library gains a book of functions, but each time you want to use a function in that book, you must borrow that book from your library.  

For clarity in this handbook, functions are usually preceeded by the name of their package using the `::` symbol in the following way:  

`package_name::function_name()`  

Once a package is loaded for a session, this explicit style is not necessary. One can just use `function_name()`. However giving the package name is useful when a function name is common and may exist in multiple packages (e.g. `plot()`).  
Using the package name will also load the package if it is not already loaded.
 
```{r eval=FALSE}
# This command uses the package "rio" and its function "import()" to import a dataset
linelist <- rio::import("linelist.xlsx", which = "Sheet1")
```

**Dependencies**  
Packages often depend on other packages, and these are called "dependencies". When a package is installed from CRAN, it will typically also install its dependenices.  



<!-- ======================================================= -->
### Function help  
<h3> Function help </h3>

To read more about a function, you can try searching online for resources OR search in the Help tab of the lower-right RStudio pane.  


<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Piping (`%>%`) {#piping .tabset .tabset-fade}
<h2> Piping (`%>%`) </h2> 

**Two general approaches to working with objects are:**  

1) **Tidyverse/piping** - sends an object from function to function - emphasizes the *action*, not the object  
2) **Define intermediate objects** - emphasis the object, as it is re-defined again and again  


<!-- ======================================================= -->
### **Pipes** 
<h3> Pipes </h3>  

**Simply explained, the pipe operator (`%>%`) passes an intermediate output from one function to the next.**  
You can think of it as saying "then". Many functions can be linked together with `%>%`.  

* **Piping emphasizes a sequence of actions, not the object the actions are being performed on**  
* Best when a sequence of actions must be performed on one object  

* From **magrittr**. Included in **dplyr** and **tidyverse**
* Makes code more clean and easier to read, intuitive
* Express a sequence of operations  
* The object is altered and then passed on to the next function  

Read more on this approach in the tidyverse [style guide](https://style.tidyverse.org/pipes.html
)  

Example:

```{r piping_example_pipe, eval=F}
# A fake example of how to bake a care using piping syntax

cake <- flour %>%       # to define cake, start with flour, and then...
  left_join(eggs) %>%   # add eggs
  left_join(oil) %>%    # add oil
  left_join(water) %>%  # add water
  mix_together(utensil = spoon, minutes = 2) %>%                # mix together
  bake(degrees = 350, system = "fahrenheit", minutes = 35) %>%  # bake
  let_cool()            # let it cool down
```

https://cfss.uchicago.edu/notes/pipes/#:~:text=Pipes%20are%20an%20extremely%20useful,code%20and%20combine%20multiple%20operations.

Piping is not a base function. To use piping, the **dplyr** package must be installed and loaded. Near the top of every template script is a code chunk that installs and loads the necessary packages, including **dplyr**. You can [read more about piping in the documentation](https://magrittr.tidyverse.org/).

<span style="color: orange;">**_CAUTION:_** Remember that even when using piping to link functions, if the assignment operator (`<-`) is present, the object to the left will still be over-written (re-defined) by the right side.</span>


**`%<>%`**  
This is an "assignment pipe" from the **magritter** package, which pipes an object forward and also re-defines the object. It must be the first pipe operator in the chain. It is shorthand, so `object %<>% function() %>% function()` is the same as `object <- object %>% function() %>% function()`.  


<!-- ======================================================= -->
### Define intermediate objects
<h3> Define intermediate objects </h3>  

This approach to changing objects/dataframes may be better if:  

* You need to manipulate multiple objects  
* There are intermediate steps that are meaningful and deserve separate object names


**Risks:**  

* Creating new objects for each step means creating lots of objects. If you use the wrong one you might not realize it!  
*Naming all the objects can be confusing  
* Errors may not be easily detectable  

Either name each intermediate object, or overwrite the original, or combine all the functions together. All come with their own risks.  

Below are some examples:  


```{r piping_example_redefine, eval=F}
# a fake example of how to bake a cake using this method (defining intermediate objects)
batter_1 <- left_join(flour, eggs)
batter_2 <- left_join(batter_1, oil)
batter_3 <- left_join(batter_2, water)

batter_4 <- mix_together(object = batter_3, utensil = spoon, minutes = 2)

cake <- bake(batter_4, degrees = 350, system = "fahrenheit", minutes = 35)

cake <- let_cool(cake)
```

Combine all functions together - also difficult to read  

```{r piping_example_wide, eval=F}
# an example of combining/nesting mutliple functions together - difficult to read
cake <- let_cool(bake(mix_together(batter_3, utensil = spoon, minutes = 2), degrees = 350, system = "fahrenheit", minutes = 35))
```



<!-- ======================================================= -->
## Key operators and functions {#operators .tabset .tabset-fade }
<h2> Key operators and functions </h2>

This section details operators in R, such as:  

* Definitional operators  
* Relational operators (less than, equal too..)  
* Logical operators (and, or...)  
* Handling missing values  
* Mathematical operators and functions (+/-, >, sum(), median(), ...)  
* The `%in%` operator  



<!-- ======================================================= -->
### Assignment operators  
<h3> Assignment operators </h3>

**`<-`**  

The basic assignment operator in R is `<-`. Such that `object_name <- value` (see R Basics tab on "Defining an Object").  
This assignment operator can also be written as `=`. We advise use of `<-` for general R use.  
We also advise surrounding operators with spaces, for readability.  


**`<<-`**  

If writing functions (LINK TO PAGE), or using R in an interactive way with sourced scripts (LINK TO PAGE), then you may need to use this assignment operator `<<-` (**base** R). This operator is used to define an object in a higher 'parent' R `Environment` (LINK to tab on R environments). Also see this [online reference](https://stat.ethz.ch/R-manual/R-devel/library/base/html/assignOps.html).


**`%<>%`**  

This is an "assignment pipe" from the **magritter** package, which pipes an object forward and also re-defines the object. It must be the first pipe operator in the chain. It is shorthand, so `object %<>% function() %>% function()` is the same as `object <- object %>% function() %>% function()`.  


**`%<+%`**

Used to add data to phylogenetic trees with the **ggtree** package. See the (LINK TO PAGE) or this online [resource book](https://yulab-smu.top/treedata-book/).  


 

<!-- ======================================================= -->
### Relational and logical operators  
<h3> Relational and logical operators </h3>

**Relational operators compare values** and are often used when defining new variables and subsets of datasets. Here are the common relational operators in R:  

Function                |Operator     |Example       |Example Result
------------------------|-------------|--------------|---------------------------
Equal to                |`==`         |`"A" == "a"`  |`FALSE` (because R is case sensitive) *Note that == (double equals) is different from = (single equals), which acts like the assignment operator `<-`*
Not equal to            |`!=`         |`2 != 0`      |`TRUE`
Greater than            |`>`          |`4 > 2`       |`TRUE`
Less than               |`<`          |`4 < 2`       |`FALSE`
Greater than or equal to|`>=`         |`6 >= 4`      |`TRUE`
Less than or equal to   |`<=`         |`6 <= 4`      |`FALSE`
Value is missing        |`is.na()`    |`is.na(7)`    |`FALSE` (see section on missing values)
Value is not missing    |`!is.na()`   |`!is.na(7)`   |`TRUE`

**Logical operators, such as AND and OR, are often used to connect relational operators and create more complicated criteria**. Complex statements might require parentheses ( ) for grouping and order of application.  

Function   |Operator
-----------|------------------------
AND        |`&`
OR         |`|` (vertical bar)
Parentheses|`( )` Used to group criteria together and clarify order


For example, below, we have a linelist with two variables we want to use to create our case definition, `hep_e_rdt`, a test result and `other_cases_in_hh`, which will tell us if there are other cases in the household. The command below uses the function `case_when()` to create the new variable `case_def` such that:

```{r basics_operators_casewhen, eval=FALSE}
linelist_cleaned <- linelist_cleaned %>%
  mutate(case_def = case_when(
    is.na(hep_e_rdt) & is.na(other_cases_in_hh)           ~ NA_character_,
    hep_e_rdt == "Positive"                               ~ "Confirmed",
    hep_e_rdt != "Positive" & other_cases_in_hh == "Yes"  ~ "Probable",
    TRUE                                                  ~ "Suspected"
  ))
```

Criteria in example above               | Resulting value in new variable "case_def"
----------------------------------------|-------------------------------------
If the value for variables `hep_e_rdt` and `other_cases_in_hh` are missing | `NA` (missing)  
If the value in `hep_e_rdt` is "Positive" | "Confirmed"  
If the value in `hep_e_rdt` is NOT "Positive" AND the value in `other_cases_in_hh` is "Yes" | "Probable"  
If one of the above criteria are not met | "Suspected"  


*Note that R is case-sensitive, so "Positive" is different than "positive"...*  

 
<!-- ======================================================= -->
### Missing values
<h3> Missing values </h3>

**In R, missing values are represented by the special value `NA` (a "reserved" value)** (capital letters N and A - not in quotation marks). If you import data that records missing data in another way (e.g. 99, "Missing", or .), you may want to re-code those values to `NA`.
  
**To test whether a value is `NA`, use the special function `is.na()`**, which returns `TRUE` or `FALSE`.

```{r basics_operators_missing}
rdt_result <- c("Positive", "Suspected", "Positive", NA)   # two positive cases, one suspected, and one unknown
is.na(rdt_result)  # Tests whether the value of rdt_result is NA
```

Here is the [R documentation on missing values](https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html)  

**Variations on `NA`**  

`NA` is actually a logical value of length 1. You may also encounter `NA_character_`, `NA_real_`, `NA_complex_`, and `NA_integer_`, which correspond to specific classes.  

The most prominent application of one of these variants in common epidemiology work is using `case_when()`. The Right-Hand Side (RHS) values must all be of the same class. Thus, if you have character outcomes on the RHS like "Confirmed", "Suspect", "Probable" and `NA` - you will get an error. Instead of `NA` you must have `NA_character_`. Likewise for integers, use `NA_integer_`.  


**`NULL`**  

`NULL` is the null object in R, often used to represent a list of 0 length. Use `is.null()` to evaluate this status.  

More detail on the difference between `NA` and `NULL` is [here](https://www.r-bloggers.com/2010/04/r-na-vs-null/)  




<!-- ======================================================= -->
### Mathematics and statistics  
<h3> Mathematics and statistics </h3>

All the operators and functions in this page is automatically available using **base** R.  

#### Mathematical operators  

These are often used to perform addition, division, to create new columns, etc. Below are common mathematical operators in R. Whether you put spaces around the operators is not important.  


Objective          |Example in R
-------------------|-------------
addition           | 2 + 3
subtraction        | 2 - 3
multiplication     | 2 * 3
division           | 30 / 5
exponent           | 2^3
order of operations| ( )



#### Mathematical functions

Objective          |Function
-------------------|-------------
rounding           | round(x, digits = n)  
rounding           | janitor::round_half_up(x, digits = n)
ceiling (round up) | ceiling(x)
floor (round down) | floor(x)
absolute value     | abs(x)
square root        | sqrt(x)
exponent           | exponent(x)
natural logarithm  | log(x)

<span style="color: red;">**_DANGER:_** `round()` uses "banker's rounding" which rounds up from a .5 only if the upper number is even. Use `round_half_up()` from **janitor** to consistently round halves up to the nearest whole number. See [this](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#explore-records-with-duplicated-values-for-specific-combinations-of-variables-with-get_dupes) </span>  

```{r}
# use the appropriate rounding function for your work
round(c(2.5, 3.5))

janitor::round_half_up(c(2.5, 3.5))
```


#### Statistical functions:  

<span style="color: orange;">**_CAUTION:_** The functions below will by default include missing values in calculations. Missing values will result in an output of NA, unless the argument `na.rm=TRUE` is specified</span>


Objective                |Function
-------------------------|----------------------
mean (average)           | mean(x, na.rm=T)
median                   | median(x, na.rm=T)
standard deviation       | sd(x, na.rm=T)
quantiles*               | quantile(x, probs)
sum                      | sum(x, na.rm=T)
minimum value            | min(x, na.rm=T)
maximum value            | max(x, na.rm=T)
range of numeric values  | range(x, na.rm=T)
summmary**               | summary(x)

<span style="color: red;">**_DANGER:_** If providing a vector of numbers to one of the above functions, be sure to wrap the numbers within `c()` .</span>

```{r}
# If supplying raw numbers to a function, wrap them in c()
mean(1, 6, 12, 10, 5, 0)    # !!! INCORRECT !!!  

mean(c(1, 6, 12, 10, 5, 0)) # CORRECT
```

* `quantile()`: x is the numeric vector to examine, and probs is a numeric vector with probabilities within 0 and 1.0, e.g `c(0.5, 0.8, 0.85)`
** `summary()`: gives a summary on a numeric vector including mean, median, and common percentiles



#### Other useful functions:  


Objective                   |Function            |Example
----------------------------|--------------------|-----------------------------------------------
create a sequence           | seq(from, to, by)  |`seq(1, 10, 2)`
repeat x, n times           | rep(x, ntimes)     |`rep(1:3, 2)` or `rep(c("a", "b", "c"), 3)` 
subdivide a numeric vector  | cut(x, n)          |`cut(linelist$age, 5)`




<!-- ======================================================= -->
### `%in%`  
<h3> `%in%` </h3>

A very useful operator for matching values, and quickly assessing if a value is within a vector or dataframe.   

```{r}
my_vector <- c("a", "b", "c", "d")

"a" %in% my_vector
"h" %in% my_vector
```

To ask if a value is **not** `%in%`, put an exclamation mark (!) **in front** of the logic statement:  

```{r}
# to negate, put an exclamation in front
!"a" %in% my_vector
!"h" %in% my_vector
```

`%in%` is very useful when using the **dplyr** function `case_when()` to recode values in a column. For example:  

```{r eval=F}
linelist <- linelist %>% 
  mutate(hospital = case_when(
    hospital %in% c("St. Fr.", "Saint Francis") ~ "St. Francis")) # convert to correct spelling
```





<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Loading Packages {.tabset .tabset-fade }
<h2>Loading Packages </h2>


This section describes the several ways to install a package:  

* Via the online package repository (CRAN)  
* From a ZIP file  
* From Github  


<!-- ======================================================= -->
### CRAN {.tabset .tabset-fade }
<h3> CRAN </h3>

From the CRAN online repository of packages  

<!-- ======================================================= -->
### ZIP files {.tabset .tabset-fade }
<h3> ZIP files </h3>

Download a ZIP file of a package, unpack it, and save it.  

<!-- ======================================================= -->
### Github {.tabset .tabset-fade }
<h3> Github </h3>

Download a package under development from Github repository  

**remotes** package





<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Errors & Warnings {.tabset .tabset-fade }
<h2> Errors & Warnings </h2>

This section explains:  

* General syntax for writing R code  
* Code assists  
* the difference between errors and warnings  

Common errors and warnings and their solutions can be found in X section (TODO).
See the handbook page on common errors and warnings.  





<!-- ======================================================= -->
### Error versus Warning  
<h3> Error versus warning </h3>

When a command is run, the R Console may show you warning or error messages in red text.  

* A **warning** means that R has completed your command, but had to take additional steps or produced unusual output that you should be aware of.  

* An **error** means that R was not able to complete your command.  

Look for clues: 

* The error/warning message will often include a line number for the problem.  

* If an object "is unknown" or "not found", perhaps you spelled it incorrectly, forgot to call a package with library(), or forgot to re-run your script after making changes.  

If all else fails, copy the error message into Google along with some key terms - chances are that someone else has worked through this already!


<!-- ======================================================= -->
### General syntax tips
<h3> General syntax tips </h3>

A few things to remember when writing commands in R, to avoid errors and warnings:  

* Always close parentheses - tip: count the number of opening "(" and closing parentheses ")" for each code chunk
* Avoid spaces in column and object names. Use underscore ( _ ) or periods ( . ) instead
* Keep track of and remember to separate a function's arguments with commas
* R is case-sensitive, meaning `Variable_A` is *different* from `variable_A`


<!-- ======================================================= -->
### Code assists  
<h3> Code assists </h3>

Any script (RMarkdown or otherwise) will give clues when you have made a mistake. For example, if you forgot to write a comma where it is needed, or to close a parentheses, RStudio will raise a flag on that line, on the right side of the script, to warn you.  

(/images/Warnings_and_Errors.png)





<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
<h2>Recommended training</h2>
## Recommended training {.tabset .tabset-fade }

<!-- ======================================================= -->
### Cheatsheets
<h3> Cheatsheets </h3>

This is an online R resource specifically for [Excel users](https://jules32.github.io/r-for-excel-users/vlookup.html)  


<!-- ======================================================= -->
### Courses
<h3> Courses </h3>





<!--chapter:end:raw_pages/basics.Rmd-->

# Importing data {.tabset .tabset-fade}

<!-- ======================================================= -->
## Overview

Introduction to importing data


<!-- ======================================================= -->
## Packages {.tabset .tabset-fade}  
<h2> Packages </h2>

The key package we recommend for importing data is: **rio**. **rio** offers the useful function `import()` which can import many types of files into R.  

The alternative to using **rio** would be to use functions from several other packages that are specific to a type of file (e.g. `read.csv()`, `read.xlsx()`, etc.). While these alternatives can be difficult to remember, always using `rio::import()` is relatively easy. 

Optionally, the package **here** can be used in conjunction with **rio**. It locates files on your computer via *relative pathways*, usually within the context of an [R project](#rprojects).  Relative pathways are relative from a designated folder location, so that pathways listed in R code will not break when the script is run on a different computer.

This code chunk shows the loading of packages for importing data. 

```{r import_packages}
# Checks if package is installed, installs if necessary, and loads package for current session
pacman::p_load(rio, here)

```

<!-- ======================================================= -->
## `import()` {.tabset .tabset-fade}
<h2> `import()` </h2>

When you import a dataset, you are doing the following:  

1. Creating a new, named data frame object in your R environment  
2. *Defining the new object* **as** *the imported dataset*  

The function `import()` from the package **rio** makes it easy to import many types of data files.

```{r, eval=F}
# An example:
#############
library(rio)                                                     # ensure package rio is loaded for use

# New object is defined as the imported data
my_csv_data <- import("linelist.csv")                            # importing a csv file

my_Excel_data <- import("observations.xlsx", which = "February") # import an Excel file
```

`import()` uses the files extension (e.g. .xlsx, .csv, .dta, etc.) to appropriately import the file. Any optional arguments specific to the filetype can be supplied as well.  

You can read more about the **rio** package [in this online vignette](https://rdrr.io/cran/rio/f/vignettes/rio.Rmd)

https://cran.r-project.org/web/packages/rio/readme/README.html

<span style="color: orange;">**_CAUTION:_** In the example above, the datasets are assumed to be located in the *working directory*, or the same folder as the script.</span>  

TO DO

**import a specific range of cells**
**skip rows, in excel and csv**
**rio table of functions used for import/export/convert**
https://cran.r-project.org/web/packages/rio/vignettes/rio.html
**other useful function to know as backup**
EpiInfo
SAS
STATA
Google Spreadsheets
R files



<!-- ======================================================= -->
## Import from filepath {.tabset .tabset-fade}  
<h2> Import from filepath </h2>

A filepath can be provided in full (as below) or as a *relative filepath* (see next tab). Providing a full filepath can be fast and may be the best if referencing files from a shared/network drive).  

The function `import()` (from the package **rio**) accepts a filepath in quotes. A few things to note:  

* Slashes must be forward slashes, as in the code shown. This is *NOT* the default for Windows filepaths.  
* Filepaths that begin with double slashes (e.g. "//...") will likely **not be recognized by R** and will produce an error. Consider moving these files to a "named" or "lettered" drive that begins with a letter (e.g. "J:" or "C:"). See the section on using Network Drive for more details on this issue.

```{r import_filepath, eval=F}
# A demonstration showing how to import a specific Excel sheet
my_data <- rio::import("C:/Users/Neale/Documents/my_excel_file.xlsx")
```

<!-- ======================================================= -->
## Excel sheet {.tabset .tabset-fade}
<h2> Excel sheets </h2>

If importing a specific **sheet** from an Excel file, include the sheet name in the `which = ` argument of `import()`. For example:  

```{r import_sheet, eval=F}
# A demonstration showing how to import a specific Excel sheet
my_data <- rio::import("my_excel_file.xlsx", which = "Sheetname")
```

If using the `here()` method to provide a relative pathway to `import()`, you can still indicate a specific sheet by adding the `which = ` argument after the closing parenthese of the `here()` function.  

```{r import_sheet_here, eval=F}
# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package
linelist_raw <- import(here("data", "linelists", "linelist.xlsx"), which = "Sheet1")`  
```

<!-- ======================================================= -->
## Select file manually {.tabset .tabset-fade}
<h2> Select file manually </h2>

You can import data manually via one of these methods:  

* Environment RStudio Pane, click "Import Dataset", and select the type of data 
* Click File / Import Dataset / (select the type of data)  
* To hard-code manual selection, use the *base R* command `file.choose()` (leaving the parentheses empty) to trigger appearance of a **pop-up window** that allows the user to manually select the file from their computer. For example:  

```{r import_choose, eval=F}
# A demonstration showing manual selection of a file. When this command is run, a POP-UP window should appear. 
# The filepath of the selected file will be supplied to the import() command.

my_data <- rio::import(file.choose())
```

<span style="color: darkgreen;">**_TIP:_** The **pop-up window** may appear BEHIND your RStudio window.</span>


<!-- ======================================================= -->
## Relative filepaths (`here()`) {#here .tabset .tabset-fade}
<h2> Relative filepaths (`here()`) </h2>

*Relative filepaths* differ from static filepaths in that they are *relative from a [R project](#rproject) root directory*. For example:  

* A static filepath: `import("C:/Users/nsbatra/My Documents/R files/epiproject/data/linelists/ebola_linelist.xlsx")`  
  * Specific fixed path
  * Useful if multiple users are running a script hosted on a network drive
* A relative filepath: `import(here("data", "linelists", "ebola_linelist.xlsx"))`  
  * Path is given in relation to a root directory (typically the root folder of an R project)  
  * Best if working within an R project, or planning to zip and share entire project with others  
  
The package **here** and it's function `here()` facilitate relative pathways.

`here()` works best within [R projects](#rprojects). When the **here** package is first loaded (`library(here)`), it automatically considers the top-level folder of your R project as here - a **benchmark** for all other files in the project.  

Thus, in your script, if you want to import or reference a file saved in your R projects folders, you use the function `here()` to tell R where the file is ***in relation to that benchmark***.

If you are unsure where here is set to, run the function `here()` with the empty brackets:

```{r import_here, eval=F}
# This command tells you the folder path that "here" is set to 
here::here()
```

Below is an example of importing the file fluH7N9_China_2013.csv which is located in the benchmark here folder. All you have to do is provide the name of the file in quotes (with the appropriate ending).

```{r import_here_one, eval=F}
linelist <- import(here("fluH7N9_China_2013.csv"))
```

If the file is within a subfolder - lets say a data folder - write these folder names in quotes, separated by commas, as below:
```{r import_here_mutiple, eval=F}
linelist <- import(here("data", "fluH7N9_China_2013.csv"))
```

Using the `here()` command produces a character filepath, which can then processed by the `import()` function.

```{r import_here_path, eval=F}
# the filepath
here("data", "fluH7N9_China_2013.csv")

# the filepath is given to the import() function
linelist <- import(here("data", "fluH7N9_China_2013.csv"))
```


<span style="color: black;">**_NOTE:_** You can still import a specific sheet of an excel file as noted in the Excel tab. The `here()` command only supplies the filepath.</span>




<!-- ======================================================= -->
## Google sheets {.tabset .tabset-fade}
<h2> Google sheets </h2>

Code from WHO
API
Other live online data sources?
TBD




<!-- ======================================================= -->
## Websites {.tabset .tabset-fade}
<h2> Websites </h2>

Setting up to auto-import data stored on a website  
TBD




<!-- ======================================================= -->
## Skip rows  
<h2> Skip rows </h2>

Sometimes, you may want to avoid importing a row of data (e.g. the column names, which are row 1).  
you can do this with the argument `skip = ` if using `import()` from the **rio** package on a .xlsx or .csv file. Provide the number of rows you want to skip.  



```{r, eval=F}
linelist_raw <- import("linelist_raw.xlsx", skip = 1)  # does not import header row
```

Unfortunately `skip = ` only accepts one integer value, *not* a range (e.g. "2:10"). To skip import of specific rows that are not consecutive from the top, consider importing multiple times and using `bind_rows()` from **dplyr**. See the example below of skipping only row 2.  



### Removing a second header row  

Your data may have a *second* row of data, for example if it is a "data dictionary" row (see example below). 

```{r, echo=F}
# HIDDEN FROM READER
####################
# Create second header row of "data dictionary" and insert into row 2. Save as new dataframe.
linelist_2headers <- rio::import(here::here("data", "linelist_cleaned.rds")) %>%         
        mutate(across(everything(), as.character)) %>% 
        add_row(.before = 1,
                #row_num = "000",
                case_id = "case identification number assigned by MOH",
                generation = "transmission chain generation number",
                date_infection = "estimated date of infection, mm/dd/yyyy",
                date_onset = "date of symptom onset, YYYY-MM-DD",
                date_hospitalisation = "date of initial hospitalization, mm/dd/yyyy",
                date_outcome = "date of outcome status determination",
                outcome = "either 'Death' or 'Recovered' or 'Unknown'",
                gender = "either 'm' or 'f' or 'unknown'",
                hospital = "Name of hospital of first admission",
                lon = "longitude of residence, approx",
                lat = "latitude of residence, approx",
                infector = "case_id of infector",
                source = "context of known transmission event",
                age = "age number",
                age_unit = "age unit, either 'years' or 'months' or 'days'",
                fever = "presence of fever on admission, either 'yes' or 'no'",
                chills = "presence of chills on admission, either 'yes' or 'no'",
                cough = "presence of cough on admission, either 'yes' or 'no'",
                aches = "presence of aches on admission, either 'yes' or 'no'",
                vomit = "presence of vomiting on admission, either 'yes' or 'no'",
                time_admission = "time of hospital admission HH:MM")
```


```{r message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist_2headers, 5), rownames = FALSE, filter="top", options = list(pageLength = 4, scrollX=T) )
```

This situation can be problematic because it can result in all columns being imported as class "character". To solve this, you will likely need to import the data twice.  

1) Import the data in order to store the correct column names  
2) Import the data again, skipping the first *two* rows (header and second rows)  
3) Bind the correct names onto the reduced dataframe

The exact arguments used to bind the correct column names depends on the type of data file (.csv, .tsv, .xlsx, etc.). If using **rio**'s `import()` function, understand which function **rio** uses to import your data, and then give the appropriate argument to skip lines and/or designate the column names. See the handbook page on importing data (LINK) for details on **rio**.  

**For Excel files:**  

```{r, eval=F}
# For excel files (remove 2nd row)
linelist_raw_names <- import("linelist_raw.xlsx") %>% names()  # save true column names

# import, skip row 2, assign to col_names =
linelist_raw <- import("linelist_raw.xlsx", skip = 2, col_names = linelist_raw_names) 
```

**For CSV files:**  

```{r, eval=F}
# For csv files
linelist_raw_names <- import("linelist_raw.csv") %>% names() # save true column names

# note argument is 'col.names ='
linelist_raw <- import("linelist_raw.csv", skip = 2, col.names = linelist_raw_names) 
```

**Backup option** - changing column names as a separate command

```{r, eval=F}
# assign/overwrite headers using the base 'colnames()' function
colnames(linelist_raw) <- linelist_raw_names
```

Bonus! If you do have a second row that is a data dictionary, you can easily create a proper data dictionary from it using the `gather()` command from the **tidyr** package.  
source: https://alison.rbind.io/post/2018-02-23-read-multiple-header-rows/

TO DO
```{r, eval=F}
library(tidyr)
stickers_dict <- import("linelist_raw.xlsx") %>% 
  clean_names() %>% 
  gather(variable_name, variable_description)
stickers_dict
```



<!-- ======================================================= -->
## Manual data entry {.tabset .tabset-fade}
<h2> Manual data entry </h2>

### Entry by columns  
<h3> Entry by columns </h3>

Since a data frame is a combination of vertical vectors (columns), R by default expects manual entry of data to also be in vertical vectors (columns). 

```{r import_manual_col}
# define each vector (vertical column) separately, each with its own name
PatientID <- c(235, 452, 778, 111)
Treatment <- c("Yes", "No", "Yes", "Yes")
Death     <- c(1, 0, 1, 0)
```
<span style="color: orange;">**_CAUTION:_** All vectors must be the same length (same number of values).</span>

The vectors can then be bound together using the function `data.frame()`:  

```{r}
# combine the columns into a data frame, by referencing the vector names
manual_entry_cols <- data.frame(PatientID, Treatment, Death)
```

And now we display the new dataset:  

```{r import_manual_colShow}
# display the new dataset
DT::datatable(manual_entry_cols)
```


### Entry by rows  
<h3> Entry by rows </h3>

Use the `tribble` function from the **tibble** package from the tidverse ([onlinetibble reference](https://tibble.tidyverse.org/reference/tribble.html)).  
  
Note how column headers start with a *tilde* (`~`).  Also note that each column must contain only one class of data (character, numeric, etc.).  
You can use tabs, spacing, and new rows to make the data entry more intuitive and readable. For example:  

```{r import_manual_row}
# create the dataset manually by row
manual_entry_rows <- tibble::tribble(
                        ~colA, ~colB,
                        "a",   1,
                        "b",   2,
                        "c",   3
                      )
```

And now we display the new dataset:  

```{r import_manual_rowShow}
# display the new dataset
DT::datatable(manual_entry_rows)
```


**OR ADD ROWS dplyr**  TO DO

### Pasting from clipboard  
<h3> Pasting from clipboard </h3>


If you copy data from elsewhere and have it on your clipboard, you can try the following command to convert those data into an R data frame:  

```{r, eval=F}
manual_entry_clipboard <- read.table(file = "clipboard",
                                     sep = "t",           # separator could be tab, or commas, etc.
                                     header=TRUE)         # if there is a header row
```



<!--chapter:end:raw_pages/importing.Rmd-->

# (PART) Data Management {-}

<!--chapter:end:raw_pages/cat_data_management.Rmd-->

# Cleaning data {.tabset .tabset-fade}




<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Overview {.tabset .tabset-fade } 

This page demonstrates common steps necessary to clean a dataset. It uses a simulated Ebola case linelist, which is used throughout the handbook.  

```{r, out.width = "75%", fig.align = "center", echo=F}
knitr::include_graphics(here::here("images", "cleaning_dataset_snip.png"))
```

* Dealing with character case (upper, lower, title, etc.)
* Factor columns  

replace missing with
dealing with cases (all lower, etc)
case_when()
factors







<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Preparation
<h2> Preparation </h2>

### Load packages  

```{r, clean_packages}
pacman::p_load(tidyverse,  # data manipulation and visualization
               janitor,    # data cleaning
               rio,        # importing data
               epikit)     # age_categories() function  
```

### Load data  

Import the raw dataset using the `import()` function from the package **rio**.  (LINK HERE TO IMPORT PAGE)  

```{r, echo=F}
# HIDDEN FROM READER
# actually load the data using here()
linelist_raw <- rio::import(here::here("data", "linelist_raw.xlsx"))
```

```{r, eval=F}
linelist_raw <- import("linelist_raw.xlsx")
```

You can view the first 50 rows of the the original "raw" dataset below: 

```{r message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist_raw,50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```




<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Cleaning pipeline
<h2> Cleaning pipeline </h2>

In epidemiological analysis and data processing, cleaning steps are often performed together and sequentially. In R this often manifests as a cleaning "pipeline", where the raw dataset is passed or "piped" from one cleaning step to another. The chain utilizes **dplyr** verbs and the **magrittr** pipe operator (see handbook page on **dplyr** and tidyverse coding style (LINK HERE). The pipe begins with the "raw" data (`linelist_raw`) and ends with a "clean" dataset (`linelist`).  

In a cleaning pipeline the order of the steps is important. Cleaning steps might include:  

* Importing of data  
* Column names cleaned or changed  
* Rows filtered, added, or de-duplicated  
* Columns selected, added, transformed, or re-ordered  
* Values re-coded, cleaned, or grouped  



<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Column names {.tabset .tabset-fade } 
<h2> Column names </h2>

Column names are used very often so they need to have "clean" syntax. We suggest the following:  

* Short names
* No spaces (replaced with underscores (_), 
* No unusual characters (&, #...)  
* Similar style nomenclature (e.g. all date columns named like **date_**onset, **date_**report, **date_**death...)  

The columns names of `linelist_raw` are below. We can see that there are some with spaces. We also have different naming patterns for dates ('date onset' and 'infection date').  

Also note that in the raw data, the two final columns names were two merged cells with one name. The `import()` function used the name for the first of the two columns, and assigned the second column the name "...23" as it was then empty (referring to the 23rd column).  


```{r}
names(linelist_raw)
```

```
Note: For a column name that include spaces, surround the name with back-ticks, for example: linelist$`infection date`. On a keyboard, the back-tick (`) is different from the single quotation mark ('), and is sometimes on the same key as the tilde (~).
```

### Automatic colummn name cleaning  
<h3> Automatic column name cleaning </h3>

The function `clean_names()` from the package **janitor** standardizes column names and makes them unique by doing the following:  

* Converts all names to consist of only underscores, numbers, and letters  
* Accented characters are transliterated to ASCII (e.g. german o with umlaut becomes "o", spanish "enye" becomes "n")  
* Capitalization preference can be specified using the `case = ` argument ("snake" is default, alternatives include "sentence", "title", "small_camel"...)  
* You can designate specific name replacements with the `replace = ` argument (e.g. replace = c(onset = "date_of_onset"))  
* Here is an online [vignette](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#cleaning)  

Below, the cleaning pipeline begins by using `clean_names()` on the raw linelist.  

```{r clean_names}
# send the dataset through the function clean_names()
linelist <- linelist_raw %>% 
  janitor::clean_names()

# see the new names
names(linelist)
```

<span style="color: black;">**_NOTE:_** The column name "...28" was changed to "x28".</span>


### Manual column name cleaning  
<h3> Manual column name cleaning </h3>

Re-naming columns manually is often necessary. Below, re-naming is performed using the `rename()` function from the **dplyr** package, as part of a pipe chain. `rename()` uses the style "NEW = OLD", the new column name is given before the old column name.  

Below, a re-name command is added to the cleaning pipeline:  

```{r}
# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)
##################################################################################
linelist <- linelist_raw %>%
    
    # standardize column name syntax
    janitor::clean_names() %>% 
    
    # manually re-name columns
           # NEW name             # OLD name
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome)
```



**Now you can see that the columns names have been changed:**  

```{r message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist,50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

#### Rename by column position  

You can also rename by column position, instead of column name, for example:  

```{r, eval=F}
rename(newNameForFirstColumn = 1,
       newNameForSecondColumn = 2)
```

#### Empty Excel column names  

If you importing an Excel sheet with a missing column name, depending on the import function used, R will likely create a column name with a value like "...1" or "...2". You can clean these names manually by referencing their position number (see above), or their name (`linelist_raw$...1`).  


### Merged Excel column names  
<h3> Merged Excel column names </h3>

Merged cells in an Excel file are a common occurrence when receiving data from field level. Merged cells can be nice for human reading of data, but cause many problems for machine reading of data. R cannot accommodate merged cells. 

Remind people doing data entry that **human-readable data is not the same as machine-readable data**. Strive to train users about the princiles of [**tidy data**](https://r4ds.had.co.nz/tidy-data.html). If at all possible, try to change procedures so that data arrive in a tidy format without merged cells.  

* Each variable must have its own column.  
* Each observation must have its own row.  
* Each value must have its own cell.  

When using **rio**'s `import()` function, the value in a merged cell will be assigned to the first cell and subsequent cells will be empty.  

One solution to deal with merged cells is to import the data with the function `readWorkbook()` from package **openxlsx**. Set the argument `fillMergedCells = TRUE`. This gives the value in a merged cell to all cells within the merge range.

```{r, eval=F}
linelist_raw <- openxlsx::readWorkbook("linelist_raw.xlsx", fillMergedCells = TRUE)
```

<span style="color: red;">**_DANGER:_** If column names are merged, you will end up with duplicate column names, which you will need to fix manually - R does not work well with duplicate column names! You can re-name them by referencing their position (e.g. column 5), as explained in the section on manual column name cleaning..</span>


### Skip import of rows  
<h3> Skip import of rows </h3>

Sometimes, you may want to avoid importing a row of data (e.g. the column names, which are row 1).  
you can do this with the argument `skip = ` if using `import()` from the **rio** package on a .xlsx or .csv file. Provide the number of rows you want to skip.  



```{r, eval=F}
linelist_raw <- import("linelist_raw.xlsx", skip = 1)  # does not import header row
```

Unfortunately `skip = ` only accepts one integer value, *not* a range (e.g. "2:10"). To skip import of specific rows that are not consecutive from the top, consider importing multiple times and using `bind_rows()` from **dplyr**. See the example below of skipping only row 2.  





#### Removing a second header row  

Your data may have a *second* row of data, for example if it is a "data dictionary" row (see example below). 

```{r, echo=F}
# HIDDEN FROM READER
####################
# Create second header row of "data dictionary" and insert into row 2. Save as new dataframe.
linelist_2headers <- linelist %>%         
        mutate(across(everything(), as.character)) %>% 
        add_row(.before = 1,
                row_num = "000",
                case_id = "case identification number assigned by MOH",
                generation = "transmission chain generation number",
                date_infection = "estimated date of infection, mm/dd/yyyy",
                date_onset = "date of symptom onset, YYYY-MM-DD",
                date_hospitalisation = "date of initial hospitalization, mm/dd/yyyy",
                date_outcome = "date of outcome status determination",
                outcome = "either 'Death' or 'Recovered' or 'Unknown'",
                gender = "either 'm' or 'f' or 'unknown'",
                hospital = "Name of hospital of first admission",
                lon = "longitude of residence, approx",
                lat = "latitude of residence, approx",
                infector = "case_id of infector",
                source = "context of known transmission event",
                age = "age number",
                age_unit = "age unit, either 'years' or 'months' or 'days'",
                fever = "presence of fever on admission, either 'yes' or 'no'",
                chills = "presence of chills on admission, either 'yes' or 'no'",
                cough = "presence of cough on admission, either 'yes' or 'no'",
                aches = "presence of aches on admission, either 'yes' or 'no'",
                vomit = "presence of vomiting on admission, either 'yes' or 'no'",
                time_admission = "time of hospital admission HH:MM")
```


```{r message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist_2headers, 5), rownames = FALSE, filter="top", options = list(pageLength = 4, scrollX=T) )
```

This situation can be problematic because it can result in all columns being imported as class "character". To solve this, you will likely need to import the data twice.  

1) Import the data in order to store the correct column names  
2) Import the data again, skipping the first *two* rows (header and second rows)  
3) Bind the correct names onto the reduced dataframe

The exact arguments used to bind the correct column names depends on the type of data file (.csv, .tsv, .xlsx, etc.). If using **rio**'s `import()` function, understand which function **rio** uses to import your data, and then give the appropriate argument to skip lines and/or designate the column names. See the handbook page on importing data (LINK) for details on **rio**.  

**For Excel files:**  

```{r, eval=F}
# For excel files (remove 2nd row)
linelist_raw_names <- import("linelist_raw.xlsx") %>% names()  # save true column names

# import, skip row 2, assign to col_names =
linelist_raw <- import("linelist_raw.xlsx", skip = 2, col_names = linelist_raw_names) 
```

**For CSV files:**  

```{r, eval=F}
# For csv files
linelist_raw_names <- import("linelist_raw.csv") %>% names() # save true column names

# note argument is 'col.names ='
linelist_raw <- import("linelist_raw.csv", skip = 2, col.names = linelist_raw_names) 
```

**Backup option** - changing column names as a separate command

```{r, eval=F}
# assign/overwrite headers using the base 'colnames()' function
colnames(linelist_raw) <- linelist_raw_names
```

Bonus! If you do have a second row that is a data dictionary, you can easily create a proper data dictionary from it using the `gather()` command from the **tidyr** package.  
source: https://alison.rbind.io/post/2018-02-23-read-multiple-header-rows/

TO DO
```{r, eval=F}
library(tidyr)
stickers_dict <- import("linelist_raw.xlsx") %>% 
  clean_names() %>% 
  gather(variable_name, variable_description)
stickers_dict
```


### Combine two header rows  
<h3> Combine two header rows </h3>

In some cases, you may want to combine two header rows into one. This command will define the column names as the combination (pasting together) of the existing column names with the value underneath in the first row. Replace "df" with the name of your dataset.  

```{r, eval=F}
names(df) <- paste(names(df), df[1, ], sep = "_")
```







<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Select or re-order columns {.tabset .tabset-fade } 
<h2> Select or re-order columns </h2>

<span style="color: orange;">**_CAUTION:_** This tab may follow from previous tabs.</span>


Often the first step of cleaning data is selecting the columns you want to work with, and to set their order in the dataframe. In a **dplyr** chain of verbs, this is done with `select()`. *Note that in these examples we modify linelist with select(), but do not assign/overwrite. We just display the resulting new column names, for purpose of example.*   

<span style="color: orange;">**_CAUTION:_** In the examples below, `linelist` is modified with `select()` but not over-written. New column names are only displayed for purpose of example.</span>


**Here are all the column names in the linelist:**

```{r}
names(linelist)
```

### Select & re-order
<h3> Select & re-order </h3>


**Select only the columns you want to remain, *and their order of appearance***  

```{r}
# linelist dataset is piped through select() command, and names() prints just the column names
linelist %>% 
  select(case_id, date_onset, date_hospitalisation, fever) %>% 
  names() # display the column names
```
 

**Indicate which columns to remove** by placing a minus symbol "-" in front of the column name (e.g. `select(-outcome)`), or a vector of column names (as below). All other columns will be retained. Inside `select()` you can use normal operators such as `c()` to list several columns, `:` for consecutive columns, `!` for opposite, `&` for AND, and `|` for OR.  

```{r}
linelist %>% 
  select(-c(date_onset, fever:vomit)) %>% # remove onset and all symptom columns
  names()
```

**Re-order the columns** - use `everything()` to signify all other columns not specified in the `select()` command:  

```{r}
# move case_id, date_onset, date_hospitalisation, and gender to beginning
linelist %>% 
  select(case_id, date_onset, date_hospitalisation, gender, everything()) %>% 
  names()
```

As well as `everything()` there are several special functions that work *within* `select()`, namely:  

* `everything()`  - all other columns not mentioned  
* `last_col()`    - the last column  
* `where()`       - applies a function to all columns and selects those which are TRUE  
* `starts_with()` - matches to a specified prefix. Example: `select(starts_with("date"))`
* `ends_with()`   - matches to a specified suffix. Example: `select(ends_with("_end"))`  
* `contains()`    - columns containing a character string. Example: `select(contains("time"))` 
* `matches()`     - to apply a regular expression (regex). Example: `select(contains("[pt]al"))`  
* `num_range()`   - 
* `any_of()`      - matches if column is named. Useful if the name might not exist. Example: `select(any_of(date_onset, date_death, cardiac_arrest))`  

Here is an example using `where()`:  

```{r}
# select columns containing certain characters
linelist %>% 
  select(contains("date")) %>% 
  names()
```

```{r}
# searched for multiple character matches
linelist %>% 
  select(matches("onset|hosp|fev")) %>%   # note the OR symbol "|"
  names()
```



### `select()` as a stand-alone command
<h3> `select()` as a stand-alone command </h3>

Select can also be used as an independent command (not in a pipe chain). In this case, the first argument is the original dataframe to be operated upon.  

```{r}
# Create a new linelist with id and age-related columns
linelist_age <- select(linelist, case_id, contains("age"))

# display the column names
names(linelist_age)
```



### Add to the pipe chain  
<h3> Add to the pipe chain </h3>

In the linelist, there are a few columns we do not need: `row_num`, `merged_header`, and `x28`. Remove them by adding a `select()` command to the cleaning pipe chain:  

```{r}
# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)
##################################################################################

# begin cleaning pipe chain
###########################
linelist <- linelist_raw %>%
    
    # standardize column name syntax
    janitor::clean_names() %>% 
    
    # manually re-name columns
           # NEW name             # OLD name
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
    
    # remove column
    select(-c(row_num, merged_header, x28))
```






<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Modify class {.tabset .tabset-fade  #Classes}
<h2> Modify class </h2>

<span style="color: orange;">**_CAUTION:_** This tab may follow from previous tabs.</span>

See section on [object classes](#objectclasses)   

Often you will need to set the correct class for a column. The most common approach is to use `mutate()` to define the column as itself, but with a different class.  Generally, this looks like this:  

```{r, eval=F}
# Examples of modifying class
linelist <- linelist %>% 
  mutate(date_var      = as.Date(date_var, format = "MM/DD/YYYY"),  # format should be the format of the raw data
         numeric_var   = as.numeric(numeric_var),
         character_var = as.character(character_var),
         factor_var    = factor(factor_var, levels = c(), labels = c())
         )
```

### Pre-checks and errors  
<h3> Pre-checks and errors </h3>

First we run some checks on the classes of important columns.  

The class of the "age" column is character. To perform analysis, we need those numbers to be recognized as numeric! 

```{r}
class(linelist$age)
```

The class of the "date_onset" column is also character! To perform analysis, these dates must be recognized as dates! 
 
```{r}
class(linelist$date_onset)
```

However, if we try to classify the `date_onset` column as date, we would get an error. Use `table()` or *sort* or another method to examine all the values and identify different one. For example in our dataset we see that we see that one `date_onset` value was entered in a different format (15th April 2014) than all the other values!    

```{r, echo=F}
head(table(linelist$date_onset))
```

Before we can classify "date_onset" as a date, this value must be fixed to be the same format as the others. You can fix the date in the source data, or, we can do in the cleaning pipeline via `mutate()` and `recode()`. This must be done *before* the commands to convert to class Date. (LINK TO DATE SECTION).  

```{r, eval=F}
# fix incorrect values                 # old value       # new value
mutate(date_onset = recode(date_onset, "15th April 2014" = "2014-04-15"))
```

The `mutate()` line can be read as: "mutate date_onset to equal date_onset recoded so that OLD VALUE is changed to NEW VALUE". Note that this pattern (OLD = NEW) for `recode()` is the opposite of most R patterns (new = old). The R development community is working on revising this for recoding.

Especially after converting to class date, check your data visually or with `table()` to confirm that they were converted correctly! For `as.Date()`, the `format = ` argument is often a source of errors. 


### Modify multiple columns  
<h3> Modify multiple columns </h3>  


You can use The **dplyr** function `across()` with `mutate()` to convert several columns at once to a new class. `across()` allows you to specify which columns you want a function to apply to. Below, we want to mutate the columns where `is.POSIXct()` (a type of date/time class that shows unnecessary timestamps) is `TRUE`, and apply the function `is.Date()` to them, in order to convert them to class "date".   

* Note that within `across()` we also use the function `where()`.  
* Note that is.POSIXct is from the package **lubridate**. Other similar functions (`is.character()`, `is.numeric()`, and `is.logical()`) are from **base R**  
* Note that the functions in `across()` are written *without* the empty parentheses ()  


```{r, eval=F}
linelist <- linelist %>% 
  mutate(across(where(lubridate::is.POSIXct), as.Date))
```


**Below, the described cleaning steps are added to the pipe chain.**  

```{r}
# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)
##################################################################################

# begin cleaning pipe chain
###########################
linelist <- linelist_raw %>%
    
    # standardize column name syntax
    janitor::clean_names() %>% 
    
    # manually re-name columns
           # NEW name             # OLD name
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
  
    # remove column
    select(-c(row_num, merged_header, x28)) %>% 

  
# ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED
  ###################################################

    # fix incorrect values                 # old value       # new value
    mutate(date_onset = recode(date_onset, "15th April 2014" = "2014-04-15")) %>% 
  
    # correct the class of the columns
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) 
```


















<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Add columns and rows {.tabset .tabset-fade } 
<h2> Add columns and rows </h2>

See the tabs below to add columns and rows



<!-- ======================================================= -->
### Add columns  {.tabset .tabset-fade }
<h3> Add columns </h3>

#### `mutate()`  
<h4> `mutate()` </h4>

We advise creating new columns with **dplyr** functions as part of a chain of such verb functions (e.g. filter, mutate, etc.)  
If in need of a stand-alone command, you can use `mutate()` or the **base** R style to create a new column (see below).  

**The verb `mutate()` is used to add a new column, or to modify an existing one.** Below is an example of creating a new columns with `mutate()`. The syntax is: **new_column_name = value or function**. 

```{r}
linelist <- linelist %>% 
  mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset))
```

It is best practice to separate each new column with a comma and new line. Below, some practice columns are created:  

```{r}
linelist <- linelist %>%                       # creating new, or modifying old dataset
  mutate(new_var_dup    = case_id,             # new column = duplicate/copy another column
         new_var_static = 7,                   # new column = all values the same
         new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables
         new_var_paste  = stringr::str_glue("{hospital} on ({date_hospitalisation})") # new column = pasting together values from other columns
         ) 
```

***Scroll to the right to see the new columns (first 50 rows):***  

```{r message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist,50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

<span style="color: darkgreen;">**_TIP:_** The verb `transmute()` adds new columns just like `mutate()` but also drops/removes all other columns that you do not mention.</span>

```{r, echo=F}
# HIDDEN FROM READER
# removes new demo columns created above
linelist <- linelist %>% 
  select(-contains("new_var"))
```


#### New columns using **base** R  
<h4> New columns using **base** R </h4>


To define a new column (or re-define a column) using **base** R, just use the assignment operator as below.
Remember that when using **base** R you must specify the dataframe before writing the column name (e.g. `dataframe$column`). Here are two dummy examples:  

```{r, eval=F}
linelist$old_var <- linelist$old_var + 7
linelist$new_var <- linelist$old_var + linelist$age
```

<!-- ======================================================= -->
### Add rows  
<h3> Add rows </h3>

TO DO

Remember that each column must contain values of only one class (either character, numeric, logical, etc.). So adding a row requires nuance to maintain this. 

```{r, eval=F}
linelist <- linelist %>% 
  add_row(row_num = 666, case_id = "abc", generation = 4, `infection date` = as.Date("2020-10-10"), .before = 2)
```

use .before and .after. .before = 3 will put it before the 3rd row. Default is to add it to the end. columns not specified will be let empty.
  The new row number may look strange ("...23") but the row numbers have changed. So if using the command twice examine/test carefully.

If your class is off you will see an error like this: Error: Can't combine `..1$infection date` <date> and `..2$infection date` <character>.
(for a date value remember to wrap the date in the function`as.Date()` like `as.Date("2020-10-10")`)






### New columns using grouped values
<h3> New columns using grouped values </h3>

<span style="color: orange;">**_CAUTION:_** This tab may follow from previous tabs.</span>

Using mutate on GROUPED dataframes
https://dplyr.tidyverse.org/reference/mutate.html

Taken from website above:

```{r, eval=F}
#Because mutating expressions are computed within groups, they may yield different results on grouped tibbles. This will be the case as #soon as an aggregating, lagging, or ranking function is involved. Compare this ungrouped mutate:

starwars %>%
  select(name, mass, species) %>%
  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))
With the grouped equivalent:

starwars %>%
  select(name, mass, species) %>%
  group_by(species) %>%
  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))
The former normalises mass by the global average whereas the latter normalises by the averages within species levels.
```


### Add to pipe chain  

```{r}
# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)
##################################################################################

# begin cleaning pipe chain
###########################
linelist <- linelist_raw %>%
    
    # standardize column name syntax
    janitor::clean_names() %>% 
    
    # manually re-name columns
           # NEW name             # OLD name
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
  
    # remove column
    select(-c(row_num, merged_header, x28)) %>% 

    # fix incorrect values                 # old value       # new value
    mutate(date_onset = recode(date_onset, "15th April 2014" = "2014-04-15")) %>% 
    
    # correct the class of the columns
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) %>% 

  # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED
  ###################################################

  # create column: delay to hospitalisation
  mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset))
```








<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Recoding values {.tabset .tabset-fade  #recode}
<h2> Recoding values </h2>

For example, in `linelist` the values in the column "hospital" must be cleaned. There are several different spellings (often the word "Hospital" is missing an "s" and is written "Hopital"), and many missing values.

```{r}
table(linelist$hospital, useNA = "always")
```


<!-- ======================================================= -->
### Manual recoding {.tabset .tabset-fade }
<h3> Manual recoding </h3>

These tabs demonstrate re-coding values manually b providing specific spellings to be corrected:  

* Using `replace()` for specific rows  
* Using `recode()` for entire columns  
* Using **base** R  


#### `replace()`  

To manually change values for specific rows within a dataframe (from within a pipe chain), use `replace()` within `mutate()`.  
Use a logic condition to specify rows, for example an ID value of one row. The general syntax is:  

`mutate(col_to_change = replace(col_to_change, criteria for rows, new value))`.  

In the first example below, the gender value, in the row where id is "2195", is changed to "Female".  

```{r, eval=F}
# Example: change gender of one specific observation to "Female" 
mutate(gender = replace(gender, id == "2195", "Female")

# Example: chance gender of one specific observation to NA 
mutate(gender = replace(gender, id == "2195", NA)
```


#### `recode()`  
<h4> `recode()` </h4>

To change spellings manually, one-by-one, you can use the `recode()` function *within the `mutate()` function. The code is saying that the column "hospital" should be defined as the current column "hospital", but with certain changes (the syntax is OLD = NEW). **Don't forget commas!**  

```{r}
linelist <- linelist %>% 
  mutate(hospital = recode(hospital,
                      # OLD = NEW
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      ))
```

Now we see the values in the `hospital` column have been corrected:  

```{r}
table(linelist$hospital, useNA = "always")
```

<span style="color: darkgreen;">**_TIP:_** The number of spaces before and after an equals sign does not matter. Make your code easier to read by aligning the = for all or most rows. Also, consider adding a hashed comment row to clarify for future readers which side is OLD and which side is NEW. </span>  

<span style="color: darkgreen;">**_TIP:_** Sometimes a *blank* character value exists in a dataset (not recognized as R's value for missing - `NA`). You can reference this value with two quotation marks with no space inbetween ("").</span>  


#### **base** R  
<h4> **base** R </h4>


If necessary, you make manual changes to a specific value in a dataframe by referencing the row number of case ID. But remember it is better if you can make these changes permanently in the underlying data! 

Here is a fake example. It reads as "Change the value of the dataframe `linelist`'s column `onset_date` (for the row where `linelist`'s column `case_id` has the value  '9d4019') to `as.Date("2020-10-24")`".   

```{r, eval=F}
linelist$date_onset[linelist$case_id == "9d4019"] <- as.Date("2020-10-24")
```


<!-- ======================================================= -->
### Recoding by logic {.tabset .tabset-fade}
<h3> Recoding by logic </h3>

These tabs demonstrate re-coding values in a column using logic and conditions:  

* Using `case_when()`  
* Using `ifelse()` and `if_else()`  
* Using special **dplyr** recoding functions like:  
  * `replace_na()`  
  * `na_if()`  
  * `coalesnce()`  


#### `case_when()`  
<h4> `case_when()` </h4>


If you need to use logic statements to recode values, or want to use operators like `%in%`, use **dplyr**'s `case_when()` instead. **If you use `case_when()` please read the thorough explanation HERE LINK, as there are important differences from `recode()` in syntax and logic order!**   

Note that all Right-hand side (RHS) inputs must be of the same class (e.g. character, numeric, logical). Notice the use of the special value `NA_real_` instead of just `NA`.  

```{r}
linelist <- linelist %>% 
  dplyr::mutate(age_years = case_when(
            age_unit == "years"  ~ age,       # if age is given in years
            age_unit == "months" ~ age/12,    # if age is given in months
            is.na(age_unit)      ~ age,       # if age unit is missing, assume years
            TRUE                 ~ NA_real_)) # Any other circumstance
```



#### `ifelse()` and `if_else()`  
<h4> `ifelse()` and `if_else()` </h4>

For simple uses of logical re-coding or new variable creationgyou can use `ifelse()` or `if_else()`. Though in most cases it is better to use `case_when()`.  

These commands are simplified versions of an `if` and `else` statement. The general syntax is ifelse(**condition**, **value if condition evaluates to TRUE**, **value if condition evaluates to FALSE**). If used in a `mutate()`, each row is evaluated. `if_else()` is a special version from **dplyr** that handles dates in the condition.

It can be tempting to string together many ifelse commands... resist this and **use `case_when()` instead!** It is much more simple, easier to read, and easier to identify errors.  

IMAGE of ifelse string with X across is. 



You can reference other columns with the `ifelse()` function within `mutate()`:  

Example of `ifelse()`:  

```{r, eval=F}
linelist <- linelist %>% 
  mutate(source_known = ifelse(!is.na(source), "known", "unknown"))
```

Example of `if_else()` (using dates):
Note that if the 'true' value is a date, the 'false' value must also qualify a date, hence using the special character `NA_real_` instead of just `NA`.

```{r, eval=F}
linelist <- linelist %>% 
  mutate(date_death = if_else(outcome == "Death", date_outcome, NA_real_))
```

Note: If you want to alternate a value used in your code based on other circumstances, consider using `switch()` from **base** R. For example if... TO DO. See the section on using `switch()` in the page on R interactive console.


<!-- ======================================================= -->
### Recoding using special **dplyr** functions  
<h3> Recoding using special **dplyr** functions </h3>


#### Using `replace_na()`  

To change missing values (`NA`) to a specific character value, such as "Missing", use the function `replace_na()` within `mutate()`. Note that this is used in the same manner as `recode` above - the name of the variable must be repeated within `replace_na()`.  

```{r}
linelist <- linelist %>% 
  mutate(hospital = replace_na(hospital, "Missing"))
```


#### Using `na_if()`  

Likewise you can quickly convert a specific character value to `NA` using `na_if()`. The command below is the opposite of the one above. It converts any values of "Missing" to `NA`.

```{r}
linelist <- linelist %>% 
  mutate(hospital = na_if(hospital, "Missing"))
```

#### Using `coalesce()`  

This **dplyr** function finds the first non-missing value at each position. So, you provide it with columns and for each row it will fill the value with the first non-missing value in the columns you provided.  

For example, you might use `this`coalesce()` create a "location" variable from hypothetical variables "patient_residence" and "reporting_jurisdiction", where you prioritize patient residence information, if it exists.  

```{r, eval=F}
linelist <- linelist %>% 
  mutate(location = coalesce(patient_residence, reporting_jurisdiction))
```


TO DO
lead(), lag()
cumsum(), cummean(), cummin(), cummax(), cumany(), cumall(),  


<!-- ======================================================= -->
### Recoding using cleaning dictionaries
<h3> Recoding using cleaning dictionaries </h3>

<span style="color: orange;">**_CAUTION:_** This tab may follow from previous tabs.</span>

```{r, eval=F}
## load cleaning rules and only keep columns in mll
mll_cleaning_rules <- import(here("dictionaries/mll_cleaning_rules.xlsx")) %>%
  filter(column %in% c(names(mll_raw), ".global"))

## define columns that are not cleand
unchanged <- c(
  "epilink_relationship",
  "narratives",
  "epilink_relationship_detail"
)

mll_clean <- mll_raw %>%
  ## convert to tibble
  as_tibble() %>%
  ## clean columns using cleaning rules
  clean_data(
    wordlists = mll_cleaning_rules,
    protect = names(.) %in% unchanged
  )

```


<!-- ======================================================= -->
### Add to pipe chain  
<h3> Add to pipe chain </h3>

Here we add the described cleaning steps to the pipe chain.  

```{r}
# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)
##################################################################################

# begin cleaning pipe chain
###########################
linelist <- linelist_raw %>%
    
    # standardize column name syntax
    janitor::clean_names() %>% 
    
    # manually re-name columns
           # NEW name             # OLD name
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
  
    # remove column
    select(-c(row_num, merged_header, x28)) %>% 

    # fix incorrect values                 # old value       # new value
    mutate(date_onset = recode(date_onset, "15th April 2014" = "2014-04-15")) %>% 
    
    # correct the class of the columns
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) %>% 
  
    # create column: delay to hospitalisation
  mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% 

# ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED
  ###################################################

    # clean values of hospital column
    mutate(hospital = recode(hospital,
                      # OLD = NEW
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      )) %>% 
    
    mutate(hospital = replace_na(hospital, "Missing")) %>% 

    # create age_years column (from age and age_unit)
    mutate(age_years = case_when(
          age_unit == "years" ~ age,
          age_unit == "months" ~ age/12,
          is.na(age_unit) ~ age,
          TRUE ~ NA_real_))

```

<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Filter rows {.tabset .tabset-fade }
<h2> Filter rows </h2>

<span style="color: orange;">**_CAUTION:_** This tab may follow from previous tabs.</span>

A typical early cleaning step is to filter the dataframe for specific rows using the **dplyr** verb `filter()`. Within `filter()`, give the logic that must be `TRUE` for a row in the dataset to be kept. 

The tabs below show how to filter rows based on simple and complex logical conditions, and how to filter/subset rows as a stand-alone command and with **base** R

<!-- ======================================================= -->
### A simple `filter()`  
<h3> A simple `filter()` </h3>

This simple example re-defines the dataframe `linelist` as itself, having filtered the rows to meet a logical condition. **Only the rows where the logical statement within the parentheses is `TRUE` are kept.**  

In this case, the logical statement is `!is.na(case_id)`, which is asking whether the value in the column `case_id` is **not** missing (`NA`). Thus, rows where `case_id` is **not** missing are kept.  

Before the filter is applied, the number of rows in `linelist` is `r nrow(linelist)`.

```{r}
linelist <- linelist %>% 
  filter(!is.na(case_id))  # keep only rows where case_id is not missing
```

After the filter is applied, the number of rows in `linelist` is `r nrow(linelist)`. 



<!-- ======================================================= -->
### A complex `filter()` 
<h3> A complex `filter()` </h3>

A more complex example using `filter()`:  

#### Examine the data  

Below is a simple one-line command to create a histogram of onset dates. See that a second smaller outbreak from 2012-2013 is also included in this dataset. **For our analyses, we want to remove entries from this earlier outbreak.**  

```{r, out.width = "50%"}
hist(linelist$date_onset, breaks = 50)
```


#### How filters handle missing numeric and date values  

Can we just filter by `date_onset` to rows after June 2013? **Caution! Applying the code `filter(date_onset > as.Date("2013-06-01")))` would accidentally remove any rows in the later epidemic with a missing date of onset!**  

<span style="color: red;">**_DANGER:_** Filtering to greater than (>) or less than (<) a date or number can remove any rows with missing values (`NA`)! This is because `NA` is treated as infinitely large and small.</span>


#### Design the filter  

Examine a cross-tabulation to make sure we exclude only the correct rows:  

```{r}
table(Hospital  = linelist$hospital,                     # hospital name
      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset
      useNA     = "always")                              # show missing values
```

What other criteria can we filter on to remove the first outbreak from the dataset? We see that:  

* The first epidemic occurred at Hospital A, Hospital B, and that there were also 10 cases at Port Hospital.  
* Hospitals A & B did *not* have cases in the second epidemic, but Port Hospital did.  

We want to exclude:  

* The `r nrow(linelist %>% filter(hospital %in% c("Hospital A", "Hospital B") | date_onset < as.Date("2013-06-01")))` rows with onset in 2012 and 2013 at either hospital A, B, or Port:  
  * Exclude the `r nrow(linelist %>% filter(date_onset < as.Date("2013-06-01")))` rows with onset in 2012 and 2013
  * Exclude the `r nrow(linelist %>% filter(hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset)))` rows from Hospitals A & B with missing onset dates  
  * Do **not** exclude the `r nrow(linelist %>% filter(!hospital %in% c('Hospital A', 'Hospital B') & is.na(date_onset)))` other rows with missing onset dates.  

We start with a linelist of `nrow(linelist)`. Here is our filter statement:  

```{r}
linelist <- linelist %>% 
  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B
  filter(date_onset > as.Date("2013-06-01") | (is.na(date_onset) & !hospital %in% c("Hospital A", "Hospital B")))

nrow(linelist)
```

When we re-make the cross-tabulation, we see that Hospitals A & B are removed completely, and the 10 Port Hospital cases from 2012 & 2013 are removed, and all other values are the same - just as we wanted.  
 
```{r}
table(Hospital  = linelist$hospital,                     # hospital name
      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset
      useNA     = "always")                              # show missing values
```

Multiple statements can be included within one filter command (separated by commas), or you can always pipe to a separate filter() command for clarity.  


*Note: some readers may notice that it would be easier to just filter by `date_hospitalisation` because it is 100% complete. This is true. But for p`date_onset` is used for purposes of a complex filter example.* 


### Filter as a stand-alone command  
<h3> Filter as a stand-alone command </h3>

Filtering can also be done as a stand-alone command (not part of a pipe chain). Like other **dplyr** verbs, in this case the first argument must be the dataset itself.  

```{r, eval=F}
# dataframe <- filter(dataframe, condition(s) for rows to keep)

linelist <- filter(linelist, !is.na(case_id))
```

You can also use **base** R to subset using square brackets which reflect the [rows, columns] that you want to retain.  

```{r, eval=F}
# dataframe <- dataframe[row conditions, column conditions] (blank means keep all)

linelist <- linelist[!is.na(case_id), ]
```

<span style="color: darkgreen;">**_TIP:_** Use bracket-subset syntax with `View()` to quickly review a few records.</span>




### Filtering to quickly review data  
<h3> Filtering to quickly review data </h3>

This **base** R syntax can be handy when you want to quickly view a subset of rows and columns. Use the **base** R `View()` command (note the capital "V") around the [] subset you want to see. The result will appear as a dataframe in your RStudio viewer panel. For example, if I want to review onset and hospitalization dates of 3 specific cases:  

View the linelist in the viewer panel:  

```{r, eval=F}
View(linelist)
```

View specific data for three cases:  

```{r, eval=F}
View(linelist[linelist$case_id %in% c("11f8ea", "76b97a", "47a5f5"), c("date_onset", "date_hospitalisation")])
```

Note: the above command can also be written with **dplyr** verbs `filter()` and `select()` as below:  

```{r, eval=F}
View(linelist %>%
       filter(case_id %in% c("11f8ea", "76b97a", "47a5f5")) %>%
       select(date_onset, date_hospitalisation))
```





### Add to pipe chain  
<h3> Add to pipe chain </h3>


```{r}
# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)
##################################################################################

# begin cleaning pipe chain
###########################
linelist <- linelist_raw %>%
    
    # standardize column name syntax
    janitor::clean_names() %>% 
    
    # manually re-name columns
           # NEW name             # OLD name
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
  
    # remove column
        select(-c(row_num, merged_header, x28)) %>% 

    # fix incorrect values                 # old value       # new value
    mutate(date_onset = recode(date_onset, "15th April 2014" = "2014-04-15")) %>% 
    
    # correct the class of the columns
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) %>% 
  
    
    # create column: delay to hospitalisation
    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% 
    
    # clean values of hospital column
    mutate(hospital = recode(hospital,
                      # OLD = NEW
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      )) %>% 

    mutate(hospital = replace_na(hospital, "Missing")) %>% 

    # create age_years column (from age and age_unit)
    mutate(age_years = case_when(
          age_unit == "years"  ~ age,
          age_unit == "months" ~ age/12,
          is.na(age_unit)      ~ age,
          TRUE                 ~ NA_real_)) %>% 
    
  # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED
    ###################################################
    filter(
          # keep only rows where case_id is not missing
          !is.na(case_id),  
          
          # also filter to keep only the second outbreak
          date_onset > as.Date("2013-06-01") | (is.na(date_onset) & !hospital %in% c("Hospital A", "Hospital B")))

```






<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Numeric categories {#num_cats .tabset .tabset-fade}
<h2> Numeric categories </h2>

<span style="color: orange;">**_CAUTION:_** This tab may follow from previous tabs.</span>

Special approaches for creating numeric categories  

Common examples include age categories, groups of lab values, etc.  

There are several ways to create categories of a numeric column such as age. Here we will discuss:  

* `age_categories()`, from the **epikit** package  
* `cut()`, from **base** R  
* using percentiles to break your numbers  
* natural break points... ? TO DO  
* case_when()


Sometimes, numeric variables will import as class "character". This occurs if there are non-numeric characters in some of the values, for example an entry of "2 months" for age, or (depending on your R locale settings) if a comma is used in the decimals place (e.g. "4,5" to mean four and one half years).  

For this example we will create an `age_cat` column using the `age_years` column.  

```{r}
#check the class of the linelist variable age
class(linelist$age_years)

```


<!-- ======================================================= -->
### `age_categories()`**
<h3> `age_categories()` </h3>

With the **epikit** package, you can use the `age_categories()` function to easily categorize and label numeric columns (note: this can be applied to non-age numeric variables too). The output is an ordered factor.

The break values specified are included in the higher group, that is groups are open on the lower/left side. As shown below, you can add 1 to each break value to achieve groups that are open at the top/right.

Other *optional* arguments:  

* `lower = ` Default is 0). The lowest number you want considered.  
* `upper = ` The highest number you want considered.  
* `by = `    The number of years between groups.  
* `separator = ` Default is "-". Character between ages in labels.  
* `ceiling = ` Default FALSE. If TRUE, the highest break value is a ceiling and a category "XX+" is not included. Any values above highest break or `upper` (if defined) are categorized as `NA`.  

See the function's Help page for more details (enter `?age_categories` in the R console).  


```{r}
library(epikit)

# Simple example
################
linelist <- linelist %>% 
  mutate(age_cat = age_categories(age_years,
                                  breakers = c(0, 5, 10, 15, 20, 30, 50, 70)))
# show table
table(linelist$age_cat, useNA = "always")


# With ceiling set to TRUE
##########################
linelist <- linelist %>% 
  mutate(age_cat = age_categories(age_years, 
                                  breakers = c(0, 5, 10, 15, 20, 30, 50, 70),
                                  upper = max(linelist$age_years, na.rm=T),
                                  ceiling = TRUE)) # 70 is the ceiling
# show table
table(linelist$age_cat, useNA = "always")


# Include upper ends for the same categories
############################################
linelist <- linelist %>% 
  mutate(age_cat = age_categories(age_years, 
                                  upper = max(linelist$age_years, na.rm=T),
                                  breakers = c(0, 6, 11, 16, 21, 31, 51, 71, 76)))
# show table
table(linelist$age_cat, useNA = "always")
```

<!-- ======================================================= -->
### `cut()` {#cut .tabset .tabset-fade}
<h3> `cut()` </h3>

You can use the **base** R function `cut()`, which creates categories from a numeric variable. The differences from `age_categories()` are:  

* You do not need to install/load another package  
* You can specify whether groups are open/closed on the right/left  
* You must provide labels yourself (and ensure they are accurate to the groups)  
* If you want 0 included in the lowest group you must specify this  

The basic syntax within `cut()` is to first provide the numeric variable to be cut (age_years), and then the *breaks* argument, which is a numeric vector (`c()`) of break points. Using `cut()`, the resulting column is an ordered factor.

If used within `mutate()` (a **dplyr** verb) it is not necessary to specify the dataframe before the column name (e.g. `linelist$age_years`).


#### Simple `cut()` example  
<h3> Simple `cut()` example </h3>

Create new column of age categories (`age_cat`) by cutting the numeric `age_year` column at specified break points. The example below replicates the first `age_categories()` example.  

* Specify numeric vector of break points `c(0, 5, 10, 15, ...)`  
* Default behavior for `cut()` is that lower break values are *excluded* from each category, and upper break values are *included*. This is the opposite behavior from the `age_categories()` function.  
* Include 0 in the lowest category by adding `include.lowest = TRUE`  
* Add a vector of customized labels using the `labels = ` argument  
* Check your work with cross-tabulation of the numeric and category columns - be aware of missing values  


```{r}
linelist <- linelist %>% 
  mutate(age_cat = cut(age_years,                                       # numeric column
                        breaks = c(0, 5, 10, 15, 20, 30, 50, 70,        # break points...
                                   max(linelist$age_years, na.rm=T)),   # ... with dynamic last break as column max value
                        right = TRUE,                                   # lower breaks included and upper excluded [a,b)
                        include.lowest = TRUE,                          # 0 included in lowest category
                        labels = c("0-4", "5-9", "10-14", "15-19",      # manual labels - be careful!
                                   "20-29", "30-49", "50-69", "70+")))       

table(linelist$age_cat, useNA = "always")
```



#### `cut()` details  
<h3> `cut()` details </h3>


Below is a detailed description of the behavior of using `cut()` to make the `age_cat` column. Key points:    

* Inclusion/exclusion behavior of break points  
* Custom category labels  
* Handling missing values  
* **Check your work!**  

The most simple command of `cut()` applied to `age_years` to make the new variable `age_cat` is below:  

```{r}
# Create new variable, by cutting the numeric age variable
# by default, upper break is excluded and lower break excluded from each category
linelist <- linelist %>% 
  mutate(age_cat = cut(age_years, breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100)))

# tabulate the number of observations per group
table(linelist$age_cat, useNA = "always")

```

* **By default**, the categorization occurs so that the right/upper side is "open" and inclusive (and the left/lower side is "closed" or exclusive). The default labels use the notation "(A, B]", which means the group does not include A (the lower break value), but includes B (the upper break value). **Reverse this behavior by providing the `right = TRUE` argument**.  

* Thus, **by default** "0" values are excluded from the lowest group, and categorized as `NA`. "0" values could be infants coded as age 0. To change this **add the argument `include.lowest = TRUE`**. Then, any "0" values are included in the lowest group. The automatically-generated label for the lowest category will change from "(0,B]" to "[0,B]", which signifies that 0 values are included.  

* **Check your work!!!** Verify that each age value was assigned to the correct category by cross-tabulating the numeric and category columns. Examine assignment of boundary values (e.g. 15, if neighboring categories are 10-15 and 15-20).  

```{r class.source = 'fold-hide'}
# Cross tabulation of the numeric and category columns. 
table("Numeric Values" = linelist$age_years,   # names specified in table for clarity.
      "Categories"     = linelist$age_cat,
      useNA = "always")                        # don't forget to examine NA values
```

Read more about `cut()` in its Help page by entering `?cut` in the R console.  



**Reversing break inclusion behavior in `cut()`**  

Lower break values will be included in each category (and upper break values excluded) if the argument `right = ` is included and and set to `TRUE`. This is applied below - note how the values have shifted among the categories.  

<span style="color: black;">**_NOTE:_** If you include the `include.lowest = TRUE` argument **and** `right = TRUE`, the `include.lowest` will now apply to the *highest* break point value and category, not the lowest.</span>  

```{r class.source = 'fold-show'}
linelist <- linelist %>% 
  mutate(age_cat = cut(age_years,
                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),     # same breaks
                          right = FALSE,                                     # include each *lower* break point            
                          labels = c("0-4", "5-9", "10-14", "15-19",
                                     "20-29", "30-49", "50-69", "70-100")))  # now the labels must change

table(linelist$age_cat, useNA = "always")

```


**Re-labeling `NA` values with `cut()`**

Because `cut()` does not automatically label `NA` values, you may want to assign a label such as "Missing". This requires a few extra steps because `cut()` automatically classified the new column `age_cat` as a Factor (a rigid column class with specific value labels). 

First, convert `age_cut` from Factor to Character class, so you have flexibility to add new character values (e.g. "Missing"). Otherwise you will encounter an error. Then, use the **dplyr** verb `replace_na()` to replace `NA` values with a character value like "Missing". These steps can be combined into one step, as shown below.  

Note that Missing has been added, **but the order of the categories is now wrong (alphabetical).**  

```{r}
linelist <- linelist %>% 
  
  # cut() creates age_cat, automatically of class Factor      
  mutate(age_cat = cut(age_years,
                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          
                          right = FALSE,                                                      
                          labels = c("0-4", "5-9", "10-14", "15-19",
                                     "20-29", "30-49", "50-69", "70-100")),
         
         # convert to class Character, and replace NA with "Missing"
         age_cat = replace_na(as.character(age_cat), "Missing"))


table(linelist$age_cat, useNA = "always")
```

To fix this, re-convert `age_cat` to a factor, and define the order of the levels correctly.

```{r}
linelist <- linelist %>% 
  
  # cut() creates age_cat, automatically of class Factor      
  mutate(age_cat = cut(age_years,
                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          
                          right = FALSE,                                                      
                          labels = c("0-4", "5-9", "10-14", "15-19",
                                     "20-29", "30-49", "50-69", "70-100")),
         
         # convert to class Character, and replace NA with "Missing"
         age_cat = replace_na(as.character(age_cat), "Missing"),
         
         # re-classify age_cat as Factor, with correct level order and new "Missing" level
         age_cat = factor(age_cat, levels = c("0-4", "5-9", "10-14", "15-19", "20-29",
                                              "30-49", "50-69", "70-100", "Missing")))    
  

table(linelist$age_cat, useNA = "always")

```


If you want a fast way to make breaks and labels, you can use something like below (adjust to your specific situation). See the page on using seq() and rep() and c() TO DO

```{r, eval=F}
# Make break points from 0 to 90 by 5
age_seq = seq(from = 0, to = 90, by = 5)
age_seq

# Make labels for the above categories, assuming default cut() settings
age_labels = paste0(age_seq+1, "-", age_seq + 5)
age_labels

# check that both vectors are the same length
length(age_seq) == length(age_labels)

# # Use them in the cut() command
# cut(linelist$age, breaks = age_seq, labels = age_labels)
```


<!-- ======================================================= -->
### `case_when()`
<h3> `case_when()` </h3>

The dplyr function `case_when()` can also be used to create numeric categories.  

* Allows explicit setting of break point inclusion/exclusion  
* Allows designation of label for `NA` values in one step  
* More complicated code, *arguably* more prone to error  
* Allow more flexibility to include other variables in the logic  

**If using `case_when()` please review the in-depth page on it, as the logic and order of assignment are important understand to avoid errors.**

<span style="color: orange;">**_CAUTION:_** In `case_when()` all right-hand side values must be of the same class. Thus, if your categories are character values (e.g. "20-30 years") then any designated outcome for `NA` age values must also be character ("Missing", or the special `NA_character_` instead of `NA`).</span>

You will need to designate the column as a factor (by wrapping `case_when()` in the function `factor()`) and provide the ordering of the factor levels using the `levels = ` argument *after* the close of the `case_when()` function. When using `cut()`, the factor and ordering of levels is done automatically.  


```{r}
linelist <- linelist %>% 
  mutate(age_cat = factor(case_when(
          # provide the case_when logic and outcomes
          age_years >= 0 & age_years < 5     ~ "0-4",          # logic by age_year value
          age_years >= 5 & age_years < 10    ~ "5-9",
          age_years >= 10 & age_years < 15   ~ "10-14",
          age_years >= 15 & age_years < 20   ~ "15-19",
          age_years >= 20 & age_years < 30   ~ "20-29",
          age_years >= 30 & age_years < 50   ~ "30-49",
          age_years >= 50 & age_years < 70   ~ "50-69",
          age_years >= 45 & age_years <= 100 ~ "70-100",
          is.na(age_years)                   ~ "Missing",  # if age_years is missing
          TRUE                               ~ "Check value"   # catch-all alarm to trigger review
          ), levels = c("0-4","5-9", "10-14", "15-19", "20-29", "30-49", "50-69", "70-100", "Missing", "Check value"))
         )


table(linelist$age_cat, useNA = "always")
```


### Add to pipe chain  
<h3> Add to pipe chain </h3>

Below, code to create two categorical age columns is added to the cleaning pipe chain:  

```{r}
# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)
##################################################################################

# begin cleaning pipe chain
###########################
linelist <- linelist_raw %>%
    
    # standardize column name syntax
    janitor::clean_names() %>% 
    
    # manually re-name columns
           # NEW name             # OLD name
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
  
    # remove column
        select(-c(row_num, merged_header, x28)) %>% 

    # fix incorrect values                 # old value       # new value
    mutate(date_onset = recode(date_onset, "15th April 2014" = "2014-04-15")) %>% 
    
    # correct the class of the columns
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) %>% 
  
    
    # create column: delay to hospitalisation
    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% 
    
    # clean values of hospital column
    mutate(hospital = recode(hospital,
                      # OLD = NEW
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      )) %>% 

    mutate(hospital = replace_na(hospital, "Missing")) %>% 

    # create age_years column (from age and age_unit)
    mutate(age_years = case_when(
          age_unit == "years" ~ age,
          age_unit == "months" ~ age/12,
          is.na(age_unit) ~ age,
          TRUE ~ NA_real_)) %>% 
    
    filter(
          # keep only rows where case_id is not missing
          !is.na(case_id),  
          
          # also filter to keep only the second outbreak
          date_onset > as.Date("2013-06-01") | (is.na(date_onset) & !hospital %in% c("Hospital A", "Hospital B"))) %>% 
  
    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED
    ###################################################   
    mutate(
          # age categories: custom
          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),
        
          # age categories: 0 to 85 by 5s
          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))
        
```







<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## rowwise() **dplyr()**
<h2> rowwise() **dplyr** </h2>

https://cran.r-project.org/web/packages/dplyr/vignettes/rowwise.html


```{r eval=F}

linelist <- linelist %>%
  rowwise() %>%
  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == "yes"))

```







<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Transforming multiple variables at once
<h2> Transforming multiple variables at once </h2>

<span style="color: orange;">**_CAUTION:_** This tab may follow from previous tabs.</span>


A transformation can be applied to multiple variables at once using the `across()` function from the package **dplyr** (contained within **tidyverse** package).  

`across()` can be used with any **dplyr** verb, but commonly with as `mutate()`, `filter()`, or `summarise()`. Here are some examples to get started. 


Example of how one would change all columns to character class  

```{r, eval=F}
#to change all columns to character class
linelist <- linelist %>% 
  mutate(across(everything(), as.character))
```

Change only numeric columns

Here are a few online resources on using `across()`: [Hadley Wickham's thoughts/rationale](https://www.tidyverse.org/blog/2020/04/dplyr-1-0-0-colwise/)



<!-- ======================================================= -->
<!-- ======================================================= -->
<!-- ======================================================= -->
## Deduplication
<h2> Deduplication </h2>

<span style="color: orange;">**_CAUTION:_** This tab may follow from previous tabs.</span>

The package **dplyr** offers the `distinct()` function to reduce the dataframe to only unique rows - removing duplicates.  
In this case we just want to remove rows that are complete duplicates, so we just add the simple command `distinct()`.  

For more complex deduplications see the page on deduplicating.  

We begin with `r nrow(linelist)` rows in `linelist`. 
```{r}
linelist <- linelist %>% 
  distinct()
```

After deduplication there are `r nrow(linelist)` rows. 



Below, the `distinct()` command is added to the cleaning pipe chain:  

```{r}
# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)
##################################################################################

# begin cleaning pipe chain
###########################
linelist <- linelist_raw %>%
    
    # standardize column name syntax
    janitor::clean_names() %>% 
    
    # manually re-name columns
           # NEW name             # OLD name
    rename(date_infection       = infection_date,
           date_hospitalisation = hosp_date,
           date_outcome         = date_of_outcome) %>% 
  
    # remove column
        select(-c(row_num, merged_header, x28)) %>% 

    # fix incorrect values                 # old value       # new value
    mutate(date_onset = recode(date_onset, "15th April 2014" = "2014-04-15")) %>% 
  
    # correct the class of the columns
    mutate(across(contains("date"), as.Date), 
           generation = as.numeric(generation),
           age        = as.numeric(age)) %>% 
    
    # create column: delay to hospitalisation
    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% 
    
    # clean values of hospital column
    mutate(hospital = recode(hospital,
                      # OLD = NEW
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      )) %>% 

    mutate(hospital = replace_na(hospital, "Missing")) %>% 

    # create age_years column (from age and age_unit)
    mutate(age_years = case_when(
          age_unit == "years" ~ age,
          age_unit == "months" ~ age/12,
          is.na(age_unit) ~ age,
          TRUE ~ NA_real_)) %>% 
    
    filter(
          # keep only rows where case_id is not missing
          !is.na(case_id),  
          
          # also filter to keep only the second outbreak
          date_onset > as.Date("2013-06-01") | (is.na(date_onset) & !hospital %in% c("Hospital A", "Hospital B"))) %>% 
  
    mutate(
          # age categories: custom
          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),
        
          # age categories: 0 to 85 by 5s
          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% 
  
    distinct()
```








```{r echo=F}
# REARRANGE COLUMNS FOR EXPORT
linelist <- linelist %>% 
  select(case_id:gender, age, age_unit, age_years, age_cat, age_cat5, everything())
```

```{r echo=F}
# EXPORT CLEANED LINELIST FILE TO "DATA" FOLDER
rio::export(linelist, here::here("data", "linelist_cleaned.xlsx"))
rio::export(linelist, here::here("data", "linelist_cleaned.rds"))
```

<!--chapter:end:raw_pages/cleaning.Rmd-->


# Working with Dates {.tabset .tabset-fade}


<!-- ======================================================= -->
## Overview

Working with dates in `R` is notoriously difficult when compared to other object classes. `R` often interprets dates as character objects - this means they cannot be used for general date operations such as making time series and calculating time intervals. To make matters more difficult, there are many date formats, some of which can be confused for other formats. Luckily, dates can be wrangled easily with practice, and with a set of helpful packages.

Dates in `R` are their own class of object - the `Date` class. It should be noted that there is also a class that stores objects with date *and* time. Date time objects are formally referred to as  and/or `POSIXt`, `POSIXct`, and/or `POSIXlt` classes (the difference isn't important). These objects are informally referred to as *datetime* classes.

You can get the system date or system datetime by doing the following:

```{r eval=T}
# get the system date - this is a DATE class
Sys.Date()

# get the system time - this is a DATETIME class
Sys.time()

```

* It is important to make R recognize when a variable contains dates.  
* Dates are an object class and can be tricky to work with.  
* Here we present several ways to convert date variables to Date class.  


<!-- ======================================================= -->
## Packages

The following packages are recommended for working with dates:  

```{r dates_packages}
# Checks if package is installed, installs if necessary, and loads package for current session

pacman::p_load(aweek,      # flexibly converts dates to weeks, and vis-versa
               lubridate,  # for conversions to months, years, etc.
               linelist,   # function to guess messy dates
               ISOweek)    # another option for creating weeks
```



<!-- ======================================================= -->
## Converting objects to Date class

The standard, **base** R function to convert an object or variable to class Date is `as.Date()` (note capitalization).  

`as.Date()` requires that the user *specify the ***existing*** format of the date*, so it can understand, convert, and store each element (day, month, year, etc.) correctly. [Read more online about `as.Date()`](https://www.stat.berkeley.edu/~s133/dates.html).  

**If used on a variable, `as.Date()` therefore requires that all the character date values be in the same format before converting.** If your data are messy, try cleaning them or consider using `guess_dates()` from the **linelist** package.  

It can be easiest to first convert the variable to character class, and then convert to date class:  

  1. Turn the variable into character values using the function `as.character()`
```{r eval=F}
linelist_cleaned$date_of_onset <- as.character(linelist_cleaned$date_of_onset)
```
  2. Convert the variable from character values into date values, using the function `as.Date()`  
  (note the capital "D")  
  + Within the `as.Date()` function, you must use the `format=` argument to tell R the *current* format of the date components - which characters refer to the month, the day, and the year, and how they are separated. If your values are already in one of R's standard date formats (YYYY-MM-DD or YYYY/MM/DD) the `format=` argument is not necessary.  
    
    + The codes are:  
         %d = Day # (of the month e.g. 16, 17, 18...)  
         %a = abbreviated weekday (Mon, Tues, Wed, etc.)  
         %A = full weekday (Monday, Tuesday, etc.)  
         %m = # of month (e.g. 01, 02, 03, 04)  
         %b = abbreviated month (Jan, Feb, etc.)  
         %B = Full Month (January, February, etc.)  
         %y = 2-digit year  (e.g. 89)  
         %Y = 4-digit year  (e.g. 1989)  

For example, if your character dates are in the format DD/MM/YYYY, like "24/04/1968", then your command to turn the values into dates will be as below. **Putting the format in quotation marks is necessary.**  
```{r eval=F}
linelist_cleaned$date_of_onset <- as.Date(linelist_cleaned$date_of_onset, format = "%d/%m/%Y")
```
<span style="color: darkgreen;">**_TIP:_** The `format =` argument is *not* telling R the format you want the dates to be, but rather how to identify the date parts as they are *before* you run the command.</span>  

<span style="color: darkgreen;">**_TIP:_**Be sure that in the `format =` argument you use the *date-part separator* (e.g. /, -, or space) that is present in your dates.</span>  


Conveting character objects to dates can be made *far* easier by using the lubridate package. The `lubridate` package is a `tidyverse` package designed to make working with dates and time more simple and consistent than in base R. For these reasons, `lubridate` is often considered the gold-standard package for dates and time, and is recommended whenever working with them.

The `lubridate` package provides a number of different helper functions designed to convert character objects to dates in an intuitive, and more lenient way than specifying the format in `as.Date()`. These functions are specific to the rough date format, but allow for a variety of separators, and synonyms for dates (e.g. 01 vs Jan vs January) - they are named after abbreviations of date formats. 


```{r, eval = T}
# load packages 
library(lubridate)

# read date in year-month-day format
ymd("2020-10-11")
ymd("20201011")

# read date in month-day-year format
mdy("10/11/2020")
mdy("Oct 11 20")

# read date in day-month-year format
dmy("11 10 2020")
dmy("11 October 2020")
```

<!-- The `as.character()` and `as.Date()` commands can optionally be combined as:   -->

<!-- ```{r eval=F} -->
<!-- linelist_cleaned$date_of_onset <- as.Date(as.character(linelist_cleaned$date_of_onset), format = "%d/%m/%Y") -->
<!-- ``` -->

If using [piping](#piping) and the tidyverse, the converting a character column to dates might look like this:  

```{r, eval=F}
linelist_cleaned <- linelist_cleaned %>%
  mutate(date_of_onset = lubridate::dmy(date_of_onset))
```

Once complete, you can run a command to verify the class of the variable
```{r, eval=F}
# Check the class of the variable
class(linelist_cleaned$date_of_onset)  
```

Once the values are in class Date, R will by default display them in the standard format, which is YYYY-MM-DD.

<!-- ======================================================= -->
## Converting to `datetime` classes

As previously mentioned, R also supports a `datetime` class - a variable that contains date **and** time information. As with the `Date` class, these often need to be converted from `character` objects to `datetime` objects. 

A standard `datetime` object is formatted with the date first, which is followed by a time component - for example  _01 Jan 2020, 16:30_. As with dates, there are many ways this can be formatted, and there are numerous levels of precision (hours, minutes, seconds) that can be supplied. Luckily, lubridate helper functions also exist to help convert these strings to `datetime` objects. These functions are the same as the date helper functions, with `_h` (only hours supplied), `_hm` (hours and minutes supplied), or `_hms` (hours, minutes, and seconds supplied) appended to the end (e.g. `dmy_hms()`). These can be used as shown:

```{r, eval = TRUE}

# convert datetime with only hours to datetime object
ymd_h("2020-01-01 16hrs")
ymd_h("2020-01-01 4PM")


# convert datetime with hours and minutes to datetime object
dmy_hm("Jan 1st 2020 16:20")

# convert datetime with hours, minutes, and seconds to datetime object
mdy_hms("01 January 20, 16:20:40")
# you can supply time zone but it is ignored
mdy_hms("01 January 20, 16:20:40 PST")

```

When working with a linelist, time and date columns can be combined to create a datetime column using these functions:

```{r, eval = FALSE}
# time_admission is a variable in hours:minutes
linelist_cleaned <- linelist_cleaned %>%
  # assume that when time of admission is not given, it the median admission time
  mutate(
    time_admission_clean = ifelse(
      is.na(time_admission),
      median(time_admission),
      time_admission
  ) %>%
  # use paste0 to combine two columns to create a character vector, and use ymd_hm() to convert to datetime
  mutate(
    date_time_of_admission = paste0(
      date_hospitalisation, time_admission_clean, sep = " "
    ) %>% ymd_hm()
  )

```
<!-- ======================================================= -->
## lubridate  

`lubridate` can also be used for a variety of other functions, such as **extracting aspects of a date/datetime**, **performing date arithmetic**, or **calculating date intervals**

```{r, eval = T}
  # extract the month from this date
  
  example_date <- ymd("2020-03-01")
  
  # extract the month and year from this date
  month(example_date)
  year(example_date)
  
  # get the epiweek of this date (this will be expanded later)
  epiweek(example_date)
  # get the day of the week for this date (this will be expanded later)
  wday(example_date)
  
  # add 3 days to this date
  example_date + days(3)
  
  # add 7 weeks and subtract two days from this date
  example_date + weeks(7) - days(2)
  
  
  # find the interval between this date and Feb 20 2020 
  
  example_date - ymd("2020-02-20")
  
```

This can all be brought together to work with data - for example:

```{r, eval = F}
library(lubridate)

linelist_cleaned <- linelist_cleaned %>%
    # convert date of onset from character to date objects by specifying dmy format
    mutate(date_of_onset = dmy(date_of_onset),
           date_of_hospitalisation = dmy(date_of_hospitalisation)) %>%
    # filter out all cases without onset in march
    filter(month(date_of_onset) == 3) %>%
    # find the difference in days between onset and hospitalisation
    mutate(onset_to_hosp_days = date_of_hospitalisation - date_of_onset)

```



<!-- ======================================================= -->
## `guess_dates()` 

**The function `guess_dates()` attempts to read a "messy" date variable containing dates in many different formats and convert the dates to a standard format.** You can [read more online about `guess_dates()`](https://www.repidemicsconsortium.org/linelist/reference/guess_dates.html), which is in the **linelist** package.

>**For example:** `guess_dates` would see the following dates "03 Jan 2018", "07/03/1982", and "08/20/85" and convert them in the class Date to: 2018-01-03, 1982-03-07, and 1985-08-20.  

```{r, eval = F}
linelist::guess_dates(c("03 Jan 2018", "07/03/1982", "08/20/85")) # guess_dates() not yet available on CRAN for R 4.0.2
                                                                  # try install via devtools::install_github("reconhub/linelist")
```

*Some optional arguments for `guess_dates()` that you might include are:*  

* `error_tolerance` - The proportion of entries which cannot be identified as dates to be tolerated (defaults to 0.1 or 10%)
* `last_date` - the last valid date (defaults to current date)  
* `first_date` - the first valid date. Defaults to fifty years before the last_date.


```{r eval = FALSE}
# An example using guess_dates on the variable dtdeath
data_cleaned <- data %>% 
  mutate(
    dtdeath = linelist::guess_dates(
      dtdeath, error_tolerance = 0.1, first_date = "2016-01-01"
    )
```


<!-- ======================================================= -->
## Excel Dates

Excel stores dates as the number of days since December 30, 1899. If the dataset you imported from Excel shows dates as numbers or characters like "41369"... use the `as.Date()` or `as_date()` function to convert, but **instead of supplying a format as above, supply an origin date**. This will not work if the excel date is read as a character type, so be sure to ensure the date is a numeric class (or convert it to one)!

<span style="color: black;">**_NOTE:_** You should provide the origin date in R's default date format (`"YYYY-MM-DD"`).</span>


```{r, eval = FALSE}
library(lubridate)
library(dplyr)

# An example of providing the Excel 'origin date' when converting Excel number dates
data_cleaned <- data %>% 
  mutate(date_of_onset = as_date(as.double(date_of_onset), origin = "1899-12-30"))
```


<!-- ======================================================= -->
## How dates are displayed  

Once dates are the correct class, you often want them to display differently (e.g. in a plot, graph, or table). For example, to display as "Monday 05 Jan" instead of 2018-01-05. You can do this with the function `format()`, which works in a similar way as `as.Date()`. Read more [in this online tutorial](https://www.statmethods.net/input/dates.html). Remember that the output from `format()` is a character type, so is generally used for display purposes only!

%d = Day # (of the month e.g. 16, 17, 18...)
%a = abbreviated weekday (Mon, Tues, Wed, etc.)  
%A = full weekday (Monday, Tuesday, etc.)  
%m = # of month (e.g. 01, 02, 03, 04)  
%b = abbreviated month (Jan, Feb, etc.)  
%B = Full Month (January, February, etc.)  
%y = 2-digit year  (e.g. 89)  
%Y = 4-digit year  (e.g. 1989)  
%h = hours (24-hr clock)  
%m = minutes  
%s = seconds
%z = offset from GMT  
%Z = Time zone (character)

An example of formatting today's date:  

```{r}
# today's date, with formatting
format(Sys.Date(), format = "%d %B %Y")

# easy way to get full date and time (no formatting)
date()

# formatted date, time, and time zone (using paste0() function)
paste0(
  format(Sys.Date(), format = "%A, %b %d '%y, %z  %Z, "), 
  format(Sys.time(), format = "%H:%M:%S")
)
```

<!-- ======================================================= -->
## Calculating distance between dates

The difference between dates can be calculated by:  
  
  
1. Correctly formating *both* date variable as class date (see instructions above)  
2. Creating a new variable that is defined as one date variable subtracted from the other
3. Converting the result to numeric class (default is class "datediff"). This ensures that subsequent mathematical calculations can be performed.  


```{r, eval = TRUE}

# define variables as date classes
date_of_onset <- ymd("2020-03-16")
date_lab_confirmation <- ymd("2020-03-20")

# find the delay between onset and lab confirmation
days_to_lab_conf <- as.double(date_lab_confirmation - date_of_onset)
days_to_lab_conf

```

In a dataframe format (i.e. when working with a linelist), if either of the above dates is missing, the operation will fail for that row. This will result in an `NA` instead of a numeric value. When using this column for calculations, be sure to set the `na.rm` option to `TRUE`. For example:

```{r, eval = FALSE}

# add a new column
# calculating the number of days between symptom onset and patient outcome
linelist_delay <- linelist_cleaned %>%
  mutate(
    days_onset_to_outcome = as.double(date_of_outcome - date_of_onset)
  )

# calculate the median number of days to outcome for all cases where data are available
med_days_outcome <- median(linelist_delay$dats_onset_to_outcome, na.rm = T)

# often this operation might be done only on a subset of data cases, e.g. those who died
# this is easy to look at and will be explained later in the handbook

```

<!-- ======================================================= -->
## Converting dates/time zones

When data is present in different time time zones, it can often be important to standardise this data in a unified time zone. This can present a further challenge, as the time zone component of data must be coded manually in most cases.

In R, each *datetime* object has a timezone component. By default, all datetime objects will carry the local time zone for the computer being used - this is generally specific to a *location* rather than a named timezone, as time zones will often change in locations due to daylight savings time. It is not possible to accurately compensate for time zones without a time component of a date, as the event a date variable represents cannot be attributed to a specific time, and therefore time shifts measured in hours cannot be reasonably accounted for.

To deal with time zones, there are a number of helper functions in lubridate that can be used to change the time zone of a datetime object from the local time zone to a different time zone. Time zones are set by attributing a valid tz database time zone to the datetime object. A list of these can be found here - if the location you are using data from is not on this list, nearby large cities in the time zone are available and serve the same purpose. 

https://en.wikipedia.org/wiki/List_of_tz_database_time_zones


```{r}
# assign the current time to a variable
time_now <- Sys.time()
time_now

# use with_tz() to assign a new timezone to the variable, while CHANGING the clock time
time_london_real <- with_tz(time_now, "Europe/London")

# use force_tz() to assign a new timezone to the variable, while KEEPING the clock time
time_london_local <- force_tz(time_now, "Europe/London")


# note that as long as the computer that was used to run this code is NOT set to London time, there will be a difference in the times (the number of hours difference from the computers time zone to london)

time_london_real - time_london_local

```

This may seem largely abstract, and is often not needed if the user isn't working across time zones. One simple example of its implementation is:

```{r, eval = FALSE}
# TODO add when time variable is here
# set the time variable to time zone for ebola outbreak 

# "Africa/Lubumbashi" is the time zone for eastern DRC/Kivu Nord


```


<!-- ======================================================= -->
## Epidemiological weeks  

The templates use the very flexible package **aweek** to set epidemiological weeks. You can read more about it [on the RECON website](https://www.repidemicsconsortium.org/aweek/)


<!-- ======================================================= -->
## Dates in Epicurves 

See the section on [epicurves](#epicurves).

<!-- ======================================================= -->
## Dates miscellaneous  

* `Sys.Date( )` returns the current date of your computer  
* `Sys.Time()` returns the current time of your computer
* `date()` returns the current date and time.  


<!--chapter:end:raw_pages/dates.Rmd-->


# Characters/strings {.tabset .tabset-fade}  


<!-- ======================================================= -->
## Overview {.tabset .tabset-fade}


This tab demonstrates use of the **stringr** package to evaluate and manage character (strings).  

1. Evaluate and subset/extract - `str_length()`, `str_sub()`, `word()`  
2. Combine, order, arrange - `str_c()`, `str_glue()`, `str_order()`  
3. Modify and replace - `str_sub()`, `str_replace_all()`  
4. Adjust length - `str_pad()`, `str_trunc()`, `str_wrap()`  
5. Change case - `str_to_upper()`, `str_to_title()`, `str_to_lower()`, `str_to_sentence()`  
6. Search for patterns - `str_detect()`, `str_subset()`, `str_match()`  


For ease of display most examples are shown acting on a short defined character vector, however they can easily be applied/adapted to a column within a dataset.  

Much of this page is adapted from this [online vignette](
https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html)




<!-- ======================================================= -->
## Preparation {.tabset .tabset-fade}

Install or load the **stringr** package.  

```{r}
# install or load the stringr package
pacman::p_load(stringr,   # many functions for handling strings
               tidyverse,  # for optional data manipulation
               tools      # alternative for converting to title case
               )
```


A reference sheet for **stringr** functions can be found [here](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)





<!-- ======================================================= -->
## Evaluate and subset {.tabset .tabset-fade}


**Evaluate the length of a string**  

```{r}
str_length("abc")
```

Alternatively, use `nchar()` from **base** R



**Subset/extract string by position**  

Use `str_sub()` to return only a part of a string. The function takes three main arguments:  

1) the character vector(s)  
2) start position  
3) end position  

A few notes on position numbers:  

* If a position number is positive, the position is counted starting from the left end of the string.  
* If a position number is negative, it is counted starting from the right end of the string.  
* Position numbers are inclusive.  
* Positions extending beyond the string will be truncated (removed).  

Below are some examples applied to the string "pneumonia":  

```{r}
# third from left
str_sub("pneumonia", 3, 3)

# 0 is not present
str_sub("pneumonia", 0, 0)

# 6th from right, to the first from right
str_sub("pneumonia", 6, -1)

# fifth from right, to the first from right
str_sub("pneumonia", -5, -1)

# positions outside the string
str_sub("pneumonia", 4, 15)
```

**Subset string by word position**

To extract the nth 'word', use `word()`, also from **stringr**. Provide the string(s), then the first word position to extract, and the last word position to extract.  

By default, the separator between 'words' is assumed to be a space, unless otherwise indicated with `sep = ` (e.g. `sep = "_"` when words are separated by underscores.  


```{r}
# strings to evaluate
chief_complaints <- c("I just got out of the hospital 2 days ago, but still can barely breathe.",
                      "My stomach hurts",
                      "Severe ear pain")

# extract 1st-3rd words of each string
word(chief_complaints, start = 1, end = 3, sep = " ")
```



<!-- ======================================================= -->
## Combine, order, and arrange {.tabset .tabset-fade}


This section covers using `str_c()`, `str_glue()`, `str_order()`, to combine, arrange, and paste together strings.  


<!-- ======================================================= -->
### Combine strings

It is common to see **base** R functions `paste()` and `paste0()`, which concatenate vectors after converting all parts to character. The act similarly to `str_c()` but the syntax differs - the parts (either text or code/pre-defined objects) are separated by commas, for example: `paste("Regional hospital needs", n_beds, "beds and", n_masks, "masks.")`.  The `sep` and `collapse` arguments can be adjusted. By default `sep` is a space, unless using `paste0()` where there is no space between parts.  

To combine multiple strings into one string, you can use `str_c()`, which is the **stringr** version of `c()` (concatenate). 

```{r}
str_c("String1", "String2", "String3")
```

The argument `sep = ` inserts characters between each input vectors (e.g. a comma or newline `"\n"`)  

```{r}
str_c("String1", "String2", "String3", sep = ", ")
```

The argument `collapse = ` is relevant if producing multiple elements. The example below shows the combination of first and last names. The `sep` value goes between each first and last name, while the `collapse` value goes between the people.  

```{r}
first_names <- c("abdul", "fahruk", "janice") 
last_names  <- c("hussein", "akinleye", "musa")

# sep is between the respective strings, while collapse is between the elements produced
str_c(first_names, last_names, sep = " ", collapse = ";  ")

# For newlines to print correctly, the phrase may need to be wrapped in cat()
cat(str_c(first_names, last_names, sep = " ", collapse = ";\n"))
```


<!-- ======================================================= -->
### Glueing strings and other values

**str_glue()**  

You can also combine strings and other pre-defined values and characters with `str_glue()`. This is a very useful function for creating dynamic plot captions, as demonstrated below.  

* All content goes between quotation marks ("").  
* Any dynamic code or calls to pre-defined objects must be within curly brackets `{}`. There can be many curly brackets.  
* Within the outer quotation marks, use single quotes if necessary (e.g. when providing date format)  
* You can provide newlines (`\n`), use `format()` to display dates, use `Sys.Date()` to display the current date.  
* If using the `%>%` pipe operator, ensure the **tidyverse** package is loaded.  

A simple example:  

```{r}
str_glue("The linelist is current to {format(Sys.Date(), '%d %b %Y')} and includes {nrow(linelist)} cases.")
```

An alternative format is to use placeholders within the brackets and define the code in separate arguments at the end of the `str_glue()` function, as below. This can improve code readability if the codes are long.

```{r}
str_glue("Data source is the confirmed case linelist as of {current_date}.\nThe last case was reported hospitalized on {last_hospital}.\n{n_missing_onset} cases are missing date of onset and not shown",
         current_date = format(Sys.Date(), '%d %b %Y'),
         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),
         n_missing_onset = nrow(linelist %>% filter(is.na(date_onset)))
         )

```

Sometimes, it is useful to pull data from dataframe and have it pasted together in sequence. Below is an example using this dataset to make a summary output of jurisdictions and the new and total cases:  

```{r, echo=F}
case_table <- data.frame(zone      = c("Zone 1", "Zone 2", "Zone 3", "Zone 4", "Zone 5"),
                         new_cases = c(3, 0, 7, 0, 15),
                         total_cases = c(40, 4, 25, 10, 103))
```

```{r}
DT::datatable(case_table, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```
Use `str_c()` with the dataframe and column names (as in the example above with first & last names). Provide `sep` and `collapse` arguments.  

```{r}
str_c(case_table$zone, case_table$new_cases, sep = " = ", collapse = ";  ")
```

We add the text "New Cases: " to the beginning of the summary by using wrapping with a separate `str_c()`. If "New Cases" was added within the original `str_c()`, it would appear multiple times.  

```{r}
str_c("New Cases: ", str_c(case_table$zone, case_table$new_cases, sep = " = ", collapse = ";  "))
```

You can achieve a similar result with `str_glue()`, with newlines added automatically:  

```{r}
str_glue("{case_table$zone}: {case_table$new_cases} new cases ({case_table$total_cases} total cases)")
```

To use str_glue() but have more control (e.g. to use double newlines), wrap it within `str_c()` and adjust the `collapse` value. You may need to print using `cat()` to correctly print the newlines.  

```{r}
case_summary <- str_c(str_glue("{case_table$zone}: {case_table$new_cases} new cases ({case_table$total_cases} total cases)"), collapse = "\n\n")

cat(case_summary) # print
```




<!-- ======================================================= -->
### Sorting

Several strings can be sorted by alphabetical order. `str_order()` returns the order, while `str_sort()` returns the strings in that order.  

```{r}
# strings
health_zones <- c("Alba", "Takota", "Delta")

# return the alphabetical order
str_order(health_zones)

# return the strings in alphabetical order
str_sort(health_zones)
```

To use a different alphabet, add the argument `locale = `. See the full list of locales by entering `stringi::stri_locale_list()` in the R console.  



<!-- ======================================================= -->
### base R functions

It is common to see **base** R functions `paste()` and `paste0()`, which concatenate vectors after converting all parts to character. The act similarly to `str_c()` but the syntax differs - the parts (either text or code/pre-defined objects) are separated by commas, for example: `paste("Regional hospital needs", n_beds, "beds and", n_masks, "masks.")`.  The `sep` and `collapse` arguments can be adjusted. By default `sep` is a space, unless using `paste0()` where there is no space between parts.  



<!-- ======================================================= -->
## Modify and replace {.tabset .tabset-fade}


**Replace specific character positions**  

`str_sub()` paired with the assignment operator (`<-`) can be used to modify a part of a string: 

```{r}
word <- "pneumonia"

# convert the third and fourth characters to X 
str_sub(word, 3, 4) <- "XX"

word
```

An example applied to multiple strings (e.g. a column). Note the expansion in length of "HIV".  

```{r}
words <- c("pneumonia", "tubercolosis", "HIV")

# convert the third and fourth characters to X 
str_sub(words, 3, 4) <- "XX"

words
```

**Replace patterns**  

Use `str_replace_all()` as a "find and replace" tool. First, provide the strings to be evaluated, then the pattern to be replaced, and then the replacement value. The example below replaces all instances of "dead" with "deceased". Note, this IS case sensitive.  

```{r}
outcome <- c("Karl: dead",
            "Samantha: dead",
            "Marco: not dead")

str_replace_all(outcome, "dead", "deceased")
```

To replace a pattern with `NA`, use `str_replace_na()`.  The function `str_replace()` replaces only the first instance of the pattern within each evaluated string.  



<!-- ======================================================= -->
## Adjust length {.tabset .tabset-fade}


**Increase minimum length (pad)**  

Use `str_pad()` to add characters to a string, to a minimum length.  

By default spaces are added, but you can also pad with other characters using the `pad = ` argument.  


```{r}
# ICD codes of differing length
ICD_codes <- c("R10.13",
               "R10.819",
               "R17")

# ICD codes padded to 7 characters on the right side
str_pad(ICD_codes, 7, "right")

# Pad with periods instead of spaces
str_pad(ICD_codes, 7, "right", pad = ".")
```

For example, to pad numbers with leading zeros (such as for hours or minutes), you can pad the number to minimum length of 2 with `pad = "0"`.

```{r}
# Add leading zeros to two digits (e.g. for times minutes/hours)
str_pad("4", 2, pad = "0") 

# example using a numeric column named "hours"
# hours <- str_pad(hours, 2, pad = "0")
```


**Truncate/shorten**  

`str_trunc()` sets a maximum length for each string. If a string exceeds this length, it is truncated (shortened) and an ellipsis (...) is included to indicate that the string was previously longer. Note that the ellipsis *is* counted in the length. The ellipsis characters can be changed with the argument `ellipsis = `.  The optional `side = ` argument specifies which where the ellipsis will appear within the truncated string ("left", "right", or "center").  

```{r}
original <- "Symptom onset on 4/3/2020 with vomiting"
str_trunc(original, 10, "center")
```

**To ensure each value is the same length**  

Use `str_trunc()` to set a maximum length, and then use `str_pad()` to expand the very short strings to that truncated length. In the example below, 6 is set as the maximum length (one value is truncated), and then a very short value is padded to achieve length of 6.    

```{r}
# ICD codes of differing length
ICD_codes   <- c("R10.13",
                 "R10.819",
                 "R17")

# truncate to maximum length of 6
ICD_codes_2 <- str_trunc(ICD_codes, 6)
ICD_codes_2

# expand to minimum length of 6
ICD_codes_3 <- str_pad(ICD_codes_2, 6, "right")
ICD_codes_3
```


**Remove leading/trailing whitespace**  

Use `str_trim()` to remove spaces, newlines (`\n`) or tabs (`\t`) on sides of a string input.  
Add `"right"` `"left"`, or `"both"` to the command to specify which side to trim (e.g. `str_trim(x, "right")`. 

```{r}
# ID numbers with excess spaces on right
IDs <- c("provA_1852  ", # two excess spaces
         "provA_2345",   # zero excess spaces
         "provA_9460 ")  # one excess space

# IDs trimmed to remove excess spaces on right side only
str_trim(IDs)
```


**Remove repeated whitespace *within* strings**  

Use `str_squish()` to remove repeated spaces that appear *inside* a string. For example, to convert double spaces into single spaces. It also removes spaces, newlines, or tabs on the outside of the string like `str_trim()`.  


```{r}
# original contains excess spaces within string
str_squish("  Pt requires   IV saline\n") 
```

Enter `?str_trim`, `?str_pad` in your R console to see further details.  


**Wrap lines into paragraphs**  

Use `str_wrap()` to wrap a long unstructured text into a structured paragraph with fixed line length. Provide the ideal character length for each line, and it applies an algorithm to insert newlines (`\n`) within the paragraph, as seen in the example below.   

```{r}
pt_course <- "Symptom onset 1/4/2020 vomiting chills fever. Pt saw traditional healer in home village on 2/4/2020. On 5/4/2020 pt symptoms worsened and was admitted to Lumta clinic. Sample was taken and pt was transported to regional hospital on 6/4/2020. Pt died at regional hospital on 7/4/2020."

str_wrap(pt_course, 40)
```

The **base** function `cat()` can be wrapped around the above command in order to print the output, displaying the new lines added.  

```{r}
cat(str_wrap(pt_course, 40))
```





<!-- ======================================================= -->
## Change case {.tabset .tabset-fade}

Often one must alter the case/capitalization of a string value, for example names of jursidictions. Use `str_to_upper()`, `str_to_upper()`, and `str_to_title()`, as shown below:  

```{r}
str_to_upper("California")

str_to_lower("California")
```

Using *base** R, the above can also be achieved with `toupper()`, `tolower()`.  


**Title case**
Transforming the string so each word is capitalized can be achieved with `str_to_title()`:  

```{r}
str_to_title("go to the US state of california ")
```

Use `toTitleCase()` from the **tools** package to achieve more nuanced capitalization (words like "to", "the", and "of" are not capitalized).  

```{r}
tools::toTitleCase("This is the US state of california")
```

You can also use `str_to_sentence()`, which capitalizes only the first letter of the string.

```{r}
str_to_sentence("the patient must be transported")
```


 


<!-- ======================================================= -->
## Patterns {.tabset .tabset-fade}

Many **stringr** functions work to detect, locate, extract, match, replace, and split based on a specified *pattern*.  



<!-- ======================================================= -->
### Detect presence/absence of a pattern

Use `str_detect()` as below. Note that by default the search *is case sensitive*!

```{r}
str_detect("primary school teacher", "teach")
```

The argument `negate = ` can be included and set to `TRUE` if you want to know if the pattern is NOT present.  
 
```{r}
str_detect("primary school teacher", "teach", negate = TRUE)
```

To ignore case/capitalization, wrap the pattern within `regex()` and *within* `regex()` add the argument `ignore_case = T`.  

```{r}
str_detect("Teacher", regex("teach", ignore_case = T))
```

When `str_detect()` is applied to a character vector/column, it will return a TRUE/FALSE for each of the values in the vector. 

```{r}
# a vector/column of occupations 
occupations <- c("field laborer",
                 "university professor",
                 "primary school teacher & tutor",
                 "tutor",
                 "nurse at regional hospital",
                 "lineworker at Amberdeen Fish Factory",
                 "physican",
                 "cardiologist",
                 "office worker",
                 "food service")

# Detect presence of pattern "teach" in each string - output is vector of TRUE/FALSE
str_detect(occupations, "teach")
```

If you need to count these, apply `sum()` to the output. This counts the number TRUE.  

```{r}
sum(str_detect(occupations, "teach"))
```

To search inclusive of multiple terms, include them separated by OR bars (|) within the pattern, as shown below:  
```{r}
sum(str_detect(occupations, "teach|professor|tutor"))
```

If you need to make a long list of search terms, you can combine them using `str_c()` and `sep = |`, define this is a character object, and reference it later more succinctly. The example below includes possible occupation search terms for frontline medical providers.     

```{r}
# search terms
occupation_med_frontline <- str_c("medical", "medicine", "hcw", "healthcare", "home care", "home health",
                                "surgeon", "doctor", "doc", "physician", "surgery", "peds", "pediatrician",
                               "intensivist", "cardiologist", "coroner", "nurse", "nursing", "rn", "lpn",
                               "cna", "pa", "physician assistant", "mental health",
                               "emergency department technician", "resp therapist", "respiratory",
                                "phlebotomist", "pharmacy", "pharmacist", "hospital", "snf", "rehabilitation",
                               "rehab", "activity", "elderly", "subacute", "sub acute",
                                "clinic", "post acute", "therapist", "extended care",
                                "dental", "dential", "dentist", sep = "|")

occupation_med_frontline
```

This command returns the number of occupations which contain any one of the search terms for front-line medical providers (`occupation_med_frontline`):  

```{r}
sum(str_detect(occupations, occupation_med_frontline))
```

**Base R string search functions**  

The **base** function `grepl()` works similarly to `str_detect()`, in that it searches for matches to a pattern and returns a logical vector. The basic syntax is `grepl(pattern, strings_to_search, ignore.case = FALSE, ...)`. One advantage is that the `ignore.case` argument is easier to write (there is no need to involve `regex()` function).  

Likewise, the **base** functions `sub()` and `gsub()` act similarly to `str_replace()`. Their basic syntax is: `gsub(pattern, replacement, strings_to_search, ignore.case = FALSE)`. `sub()` will replace the first instance of the pattern, whereas `gsub()` will replace all instances of the pattern.  



<!-- ======================================================= -->
### Detects patterns in conditional logic

**Within `case_when()`**  

`str_detect()` is often used within `case_when()` (from **dplyr**). Let's say the occupations are a column in the linelist called `occupations`. The `mutate()` below creates a new column called `is_educator` by using conditional logic via `case_when()`. See the page on data cleaning to learn more about `case_when()`.  


```{r, eval=F}
df <- df %>% 
  mutate(is_educator = case_when(
    # term search within occupation, not case sensitive
    str_detect(occupations,
               regex("teach|prof|tutor|university",
                     ignore_case = TRUE))              ~ "Educator",
    # all others
    TRUE                                               ~ "Not an educator"))
```

As a reminder, it may be important to add exclusion criteria to the conditional logic (`negate = F`):  

```{r, eval=F}
df <- df %>% 
  # value in new column is_educator is based on conditional logic
  mutate(is_educator = case_when(
    
    # occupation column must meet 2 criteria to be assigned "Educator":
    # it must have a search term AND NOT any exclusion term
    
    # Must have a search term AND
    str_detect(occupations,
               regex("teach|prof|tutor|university", ignore_case = T)) &              
    # Must NOT have an exclusion term
    str_detect(occupations,
               regex("admin", ignore_case = T),
               negate = T)                          ~ "Educator"
    
    # All rows not meeting above criteria
    TRUE                                            ~ "Not an educator"))
```


<!-- ======================================================= -->
### Locate pattern position  

To locate the *first* position of a pattern, use `str_locate()`. It outputs a start and end position.   

```{r}
str_locate("I wish", "sh")
```

Like other `str` functions, there is an "_all" version (`str_locate_all()`) which will return the positions of *all* instances of the pattern within each string. This outputs as a `list`.  

```{r}
phrases <- c("I wish", "I hope", "he hopes", "He hopes")

str_locate(phrases, "h" )     # position of *first* instance of the pattern
str_locate_all(phrases, "h" ) # position of *every* instance of the pattern
```


<!-- ======================================================= -->
### Extract a match  

`str_extract_all()` returns the matching patterns themselves, which is most useful when you have offered several patterns via "OR" conditions. For example, looking in the string vector of occupations (see previous tab) for *either* "teach", "prof", or "tutor".

`str_extract_all()` returns a `list` which contains *all matches* for each evaluated string. See below how occupation 3 has two pattern matches within it.  

```{r}
str_extract_all(occupations, "teach|prof|tutor")
```


`str_extract()` extracts *only the first match* in each evaluated string, producing a character vector with one element for each evaluated string. It returns `NA` where there was no match. The `NA`s can be removed by wrapping the returned vector with `na.exclude()`. Note how the second of occupation 3's matches is not shown.  

```{r}
str_extract(occupations, "teach|prof|tutor")
```

<!-- ======================================================= -->
### Subset and Count  

**Subset, Count**  

Aligned functions include `str_subset()` and `str_count()`.  

`str_subset()` returns the actual values which contained the pattern: 

```{r}
str_subset(occupations, "teach|prof|tutor")
```

`str_count() returns a vector of numbers: the **number of times** a search term appears in each evaluated value.  

```{r}
str_count(occupations, regex("teach|prof|tutor", ignore_case = TRUE))
```


<!-- ======================================================= -->
### Splitting  

To split a string based on a pattern, use `str_split()`. It evaluates the strings and returns a list of character vectors consisting of the newly-split values.

The simple example below evaluates one string, and produces a list with one element - a character vector with three values:

```{r}
str_split("jaundice, fever, chills", ",", simplify = T)
```

You can assign this as a named object, and access the nth symptom:  

```{r}
pt1_symptoms <- str_split("jaundice, fever, chills", ",", simplify = T)

pt1_symptoms[2]
```

If multiple strings are evaluated, there will be more than one element in the returned list.  

```{r}
symptoms <- c("jaundice, fever, chills",     # patient 1
              "chills, aches, pains",        # patient 2 
              "fever",                       # patient 3
              "vomiting, diarrhoea",         # patient 4
              "bleeding from gums, fever",   # patient 5
              "rapid pulse, headache")       # patient 6

str_split(symptoms, ",")                     # split each patient's symptoms
```

To access a specific symptom you can use syntax like this: `the_split_return_object[[2]][1]`, which would access the first symptom from the second evaluated string ("chills"). See the R basics page for more detail on accessing elements.  


To return a "character matrix" instead, which may be useful if creating dataframe columns, set the argument `simplify = TRUE` as shown below:  

```{r}
str_split(symptoms, ",", simplify = T)
```

You can also adjust the number of splits to create with the `n = ` argument. For example, this restricts the number of splits (from the left side) to 2 splits. The further commas remain within the second split. 

```{r}
str_split(symptoms, ",", simplify = T, n = 2)
```

*Note - the same outputs can be achieved with `str_split_fixed()`, in which you do *not* give the `simplify` argument, but must instead designate the number of columns (`n`).* 

```{r, eval=F}
str_split_fixed(symptoms, ",", n = 2)
```


**Splitting a column within a dataframe**  

Within a dataframe, to split one character column into other columns use use `separate()` from **dplyr**.  

If we have a simple dataframe `df` consisting of a case ID column, one character column with symptoms, and one outcome column:  

```{r, echo=F}
df <- data.frame(case_ID = c(1:6),
                 symptoms  = 
                   c("jaundice, fever, chills",     # patient 1
                     "chills, aches, pains",        # patient 2 
                     "fever",                       # patient 3
                     "vomiting, diarrhoea",         # patient 4
                     "bleeding from gums, fever",   # patient 5
                     "rapid pulse, headache"),      # patient 6
                 outcome = c("Success", "Failure", 
                             "Failure", "Success",
                             "Success", "Success"))
```

```{r, echo=F}
DT::datatable(df, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

First provide the column to be separated, then provide a vector (`c()`) of new columns names to the argument `into = `, as shown below. The argument `sep = ` can be a character, or a number (interpreted as the character position to split at). 

Optional arguments include `remove = ` (FALSE by default, removes the input column) and `convert = ` (FALSE by default, will cause string "NA"s to become `NA`).  

`extra = ` will control what happens if there are more many values created by the separation than new columns named. Setting `extra` equal to `"warn"` means R will return a warning but proceed and drop the values (the default). `"drop"` means the values will be dropped with no warning.  

**Setting `extra = "merge"` will only split to the number of new columns listed in `into` - *this setting will preserve all your data*.**  

```{r}
# third symptoms combined into second new column
df %>% 
  separate(symptoms, into = c("sym_1", "sym_2"), sep=",", extra = "merge")
```

```{r}
# third symptoms are lost
df %>% 
  separate(symptoms, into = c("sym_1", "sym_2", "sym_3"), sep=",")
```
```{r}
# third symptoms given their own column
separated <- df %>% 
  separate(symptoms, into = c("sym_1", "sym_2", "sym_3"), sep=",")

separated
```

<span style="color: orange;">**_CAUTION:_** If you do not provide enough `into` values for the new columns, your data may be truncated.</span>  

One solution to automatically make as many columns as needed could be:  





**`unite()`**  

Within a dataframe, bringing together multiple columns (the opposite of `separate()`) can be achieved with `unite()` from **tidyr**.  

Provide the name of the new united column. Then provide the names of the columns you wish to unite. By default the separator used in the united column is "_", but this can be changed with the `sep` argument. Other optional arguments include `remove = ` (TRUE by default, removes the input columns from the data frame), and `na.rm = ` (FALSE by default, it removes missing values while uniting).  

Below, we re-unite the dataframe that was separated above.  

```{r}
separated %>% 
  unite(
    col = "all_symptoms",         # name of the new united column
    c("sym_1", "sym_2", "sym_3"), # columns to unite
    sep = ", ",                   # separator to use in united column
    remove = TRUE,                # if TRUE, removes input cols from the data frame
    na.rm = TRUE                  # if TRUE, missing values are removed before uniting
  )
```



<!-- ======================================================= -->
### Regex groups


**Groups within strings**  

`str_match()`   TBD


<!-- ======================================================= -->
## Regex and special characters {.tabset .tabset-fade} 

Regular expressions, or "regex", is a concise language for describing patterns in strings.

*Much of this tab is adapted from [this tutorial](https://towardsdatascience.com/a-gentle-introduction-to-regular-expressions-with-r-df5e897ca432) and [this cheatsheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)*  



<!-- ======================================================= -->
### Special characters

**Backslash `\` as escape**  

The backslash `\` is used to "escape" the meaning of the next character. This way, a backslash can be used to have a quote mark display *within* other quote marks (`\"`) - the middle quote mark will not "break" the surrounding quote marks.  

Note - thus, if you want to *display* a backslash, you must escape it's meaning with *another backslash. So you must write two backslashes `\\` to display one.  

**Special characters**  

Special character | Represents  
----------------- | --------------------------------------------------------------    
`"\\"` | backslash  
`"\n"` | a new line (newline)   
`"\""` | double-quote *within* double quotes  
`'\''` | single-quote *within* single quotes  
`"\`"` | grave accent  
`"\r"` | carriage return  
`"\t"` | tab  
`"\v"` | vertical tab 
`"\b"` | backspace  


Run `?"'"` in the R Console to display a complete list of these special characters (it will appear in the RStudio Help pane). 



<!-- ======================================================= -->
### Regular expressions (regex)

 If you are not familiar with it, a regular expression can look like an alien language:  

```{r, eval=F}

```

A regular expression is applied to extract specific patterns from unstructured text - for example medical notes, chief complaint, matient history, or other free text columns in a dataset.  

There are four basic tools one can use to create a basic regular expression:  

1) Character sets  
2) Meta characters  
3) Quantifiers  
4) Groups  


**Character sets**  

Character sets, are a way of expressing listing options for a character match, within brackets. So any a match will be triggered if any of the characters within the brackets are found in the string. For example, to look for vowels one could use this character set: "[aeiou]". Some other common character sets are:  

Character set | Matches for  
----------------- | --------------------------------------------------------------    
`"[A-Z]"` | any single capital letter  
`"[a-z]"` | any single lowercase letter  
`"[0-9]"` | any digit  
`[:alnum:]` | any alphanumeric character  
`[:digit:]` | any numeric digit  
`[:alpha:]` | any letter (upper or lowercase)  
`[:upper:]` | any uppercase letter  
`[:lower:]` | any lowercase letter  


Character sets can be combined within one bracket (no spaces!), such as `"[A-Za-z]"` (any upper or lowercase letter), or another example `"[t-z0-5]"` (lowercase t through z OR number 0 through 5).  



**Meta characters**  

Meta characters are shorthand for character sets. Some of the important ones are listed below:  

Meta character | Represents  
----------------- | --------------------------------------------------------------    
`"\\s"` | a single space  
`"\\w"` | any single alphanumeric character (A-Z, a-z, or 0-9)  
`"\\d"` | any single numeric digit (0-9)  


**Quantifiers**  

Typically you do not want to search for a match on only one character. Quantifiers allow you to designate the length of letters/numbers to allow for the match.  

Quantifiers are numbers written within curly brackets `{ }` *after* the character they are quantifying, for example,  

* `"A{2}"` will return instances of **two** capital A letters.  
* `"A{2,4}"` will return instances of **between two and four** capital A letters *(do not put spaces!)*.  
* `"A{2,}"` will return instances of **two or more** capital A letters.  
* `"A+"` will return instances of **one or more** capital A letters (group extended until a different character is encountered).  
* Precede with an `*` asterisk to return **zero or more** matches (useful if you are not sure the pattern is present)  


Using the `+` plus symbol as a quantifier, the match will occur until a different character is encountered. For example, this expression will return all *words* (alpha characters: `"[A-Za-z]+"`  


```{r}
# test string for quantifiers
test <- "A-AA-AAA-AAAA"
```

When a quantifier of {2} is used, only pairs of consecutive A's are returned. Two pairs are identified within `AAAA`.  

```{r}
str_extract_all(test, "A{2}")
```

When a quantifier of {2,4} is used, groups of consecutive A's that are two to four in length are returned.  

```{r}
str_extract_all(test, "A{2,4}")
```

With the quantifier `+`, groups of **one or more** are returned:  

```{r}
str_extract_all(test, "A+")
```

**Relative position**  

These express requirements for what precedes or follows a pattern. For example, to extract sentences, "two numbers that are followed by a period" (`""`).  (?<=\\.)\\s(?=[A-Z]) 

```{r}
str_extract_all(test, "")
```

Position statement | Matches to  
----------------- | --------------------------------------------------------------    
`"(?<=b)a"` | "a" that **is preceded** by a "b"  
`"(?<!b)a"` | "a" that **is NOT preceded** by a "b"  
`"a(?=b)"` | "a" that **is followed** by a "b"  
`"a(?!b)"` | "a" that **is NOT followed** by a "b"  





**Groups**  

Capturing groups in your regular expression is a way to have a more organized output upon extraction.  




**Regex examples**  

Below is a free text for the examples. We will try to extract useful information from it using a regular expression search term.  

```{r}
pt_note <- "Patient arrived at Broward Hospital emergency ward at 18:00 on 6/12/2005. Patient presented with radiating abdominal pain from LR quadrant. Patient skin was pale, cool, and clammy. Patient temperature was 99.8 degrees farinheit. Patient pulse rate was 100 bpm and thready. Respiratory rate was 29 per minute."
```

This expression matches to all words (any character until hitting non-character such as a space):  

```{r}
str_extract_all(pt_note, "[A-Za-z]+")
```

The expression `"[0-9]{1,2}"` matches to consecutive numbers that are 1 or 2 digits in length. It could also be written `"\\d{1,2}"`, or `"[:digit:]{1,2}"`.  

```{r}
str_extract_all(pt_note, "[0-9]{1,2}")
```

```{r}
str_split(pt_note, ".")
```

This expression will extract all sentences (assuming first letter is capitalized, and the sentence ends with a period). The pattern reads in English as: "A capital letter followed by some lowercase letters, a space, some letters, a space,    

```{r}
str_extract_all(pt_note, "[A-Z][a-z]+\\s\\w+\\s\\d{1,2}\\s\\w+\\s*\\w*")
```


You can view a useful list of regex expressions and tips on page 2 of [this cheatsheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)  

Also see this [tutorial](https://towardsdatascience.com/a-gentle-introduction-to-regular-expressions-with-r-df5e897ca432).  




<!-- ======================================================= -->
## Resources {.tabset .tabset-fade}

A reference sheet for **stringr** functions can be found [here](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)


A vignette on **stringr** can be found [here](
https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html)


<!--chapter:end:raw_pages/character_regex.Rmd-->


# De-duplication {.tabset}  

```{r, out.width=c("50%"), echo=F}
knitr::include_graphics(here::here("images", "deduplication2.png"))
```

<!-- ======================================================= -->
## Overview {.tabset }

This page covers the following subjects:  

1. Identifying and removing duplicate rows  
2. "Slicing" and keeping only certain rows (min, max, random...), also from each group  
3. "Rolling-up", or combining values from multiple rows into one  


<!-- ======================================================= -->
## Preparation {.tabset }


**Load packages**  

```{r}
pacman::p_load(tidyverse,   # deduplication, grouping, and slicing functions
               janitor,     # function for reviewing duplicates
               stringr      # for string searches, can be used in "rolling-up" values
               )     
```


**Example dataset**  

For demonstration, we will use the fake dataset below. It is a record of COVID-19 phone encounters, including with contacts and with cases.  

* The first two records are 100% complete duplicates including duplicate `recordID` (computer glitch)  
* The second two rows are duplicates, in all columns *except for `recordID`*  
* Several people had multiple phone encounters, at various dates/times and as contacts or cases  
* At each encounter, the person was asked if they had **ever** had symptoms, and some of this information is missing.  


```{r, echo=F}
obs <- data.frame(
  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),
  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),
  name      = c("adam", "adam", "amrish", "amrish", "mariah", "amrish", "nikhil", "brian", "smita", "raquel", "amrish",
                "adam", "mariah", "mariah", "nikhil", "brian", "brian", "raquel", "natalie"),
  date      = c("1/1/2020", "1/1/2020", "2/1/2020", "2/1/2020", "5/1/2020", "5/1/2020", "5/1/2020", "5/1/2020", "5/1/2020","5/1/2020", "2/1/2020",
                "5/1/2020", "6/1/2020", "6/1/2020", "6/1/2020", "6/1/2020", "7/1/2020", "7/1/2020", "7/1/2020"),
  time      = c("09:00", "09:00", "14:20", "14:20", "12:00", "16:10", "13:01", "15:20", "14:20", "12:30", "10:24",
                "09:40", "07:25", "08:32", "15:36", "15:31", "07:59", "11:13", "17:12"),
  encounter = c(1,1,1,1,1,3,1,1,1,1,2,
                2,2,3,2,2,3,2,1),
  purpose   = c("contact", "contact", "contact", "contact", "case", "case", "contact", "contact", "contact", "contact", "contact",
                "case", "contact", "contact", "contact", "contact", "case", "contact", "case"),
  symptoms_ever = c(NA, NA, "No", "No", "No", "Yes", "Yes", "No", "Yes", NA, "Yes",
                    "No", "No", "No", "Yes", "Yes", "No","No", "No"))
  #age       = c(19, 19, 6, 55, 19, 44, 50, 51, 70, 19, 6, 55, 55, 44, 50, 50, 70, 32)
   
  #mutate(date = format(as.Date(date, "%d/%m/%Y"), "%d %b")) %>% 
  #mutate(time = lubridate::hm(time)) %>% 
  #arrange(date)
```


```{r message=FALSE, echo=F}
DT::datatable(obs, rownames = FALSE, options = list(pageLength = nrow(obs), scrollX=T) )
```


<!-- ======================================================= -->
## Deduplication {.tabset }


This tab uses the dataset from the Preparation tab to describe how to review and remove duplicate rows in a dataframe. It also show how to handle duplicate elements in a vector.  


<!-- ======================================================= -->
### Examine duplicate rows  


To quickly review rows that have duplicates, you can use `get_dupes()` from the **janitor** package. *By default*, all columns are considered when duplicates are evaluated - rows returned are 100% duplicates considering the values in *all* columns.  

In the `obs` dataframe, the first two rows that are *100% duplicates* - they have the same value in every column (including the `recordID` column, which is *supposed* to be unique - it must be some computer glitch). The returned dataframe automatically includes a new column `dupe_count`, showing the number of rows with that combination of duplicate values. 

```{r, eval=F}
# 100% duplicates across all columns
obs %>% 
  janitor::get_dupes()
```

```{r message=FALSE, echo=F}
obs %>% 
  janitor::get_dupes() %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = nrow(obs), scrollX=T) )
```

However, if we choose to ignore `recordID`, the 3rd and 4th rows rows are also duplicates. That is, they have the same values in all columns *except* for `recordID`. You can specify specific columns to be ignored in the function using a `-` minus symbol.  

```{r, eval=F}
# Duplicates when column recordID is not considered
obs %>% 
  janitor::get_dupes(-recordID)         # if multiple columns, wrap them in c()
```

```{r message=FALSE, echo=F}
obs %>% 
  janitor::get_dupes(-recordID) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = nrow(obs), scrollX=T) )
```

You can also positively specify the columns to consider. Below, only rows that have the same values in the `name` and `purpose` columns are returned. Notice how "amrish" now has `dupe_count` equal to 3 to reflect his three "contact" encounters.  

*Scroll left for more rows**  

```{r, eval=F}
# duplicates based on name and purpose columns ONLY
obs %>% 
  janitor::get_dupes(name, purpose)
```

```{r message=FALSE, echo=F}
obs %>% 
  janitor::get_dupes(name, purpose) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 7, scrollX=T) )
```

See `?get_dupes` for more details, or see this [online reference](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#explore-records-with-duplicated-values-for-specific-combinations-of-variables-with-get_dupes)  






<!-- ======================================================= -->
### Keep only unique rows  


To keep only unique rows of a dataframe, use `distinct()` from **dplyr**. Rows that are duplicates are removed such that only the first of such rows is kept. By default, "first" means the highest `rownumber` (order of rows top-to-bottom). Only unique rows are kept. In the example below, **one duplicate row (the first row, for "adam") has been removed** (n is now `r nrow(obs)-1`, not `r nrow(obs)` rows).  

*Scroll to the left to see the entire dataframe*  


```{r, eval=F}
# added to a chain of pipes (e.g. data cleaning)
obs %>% 
  distinct(across(-recordID), # reduces dataframe to only unique rows (keeps first one of any duplicates)
           .keep_all = TRUE) 

# if outside pipes, include the data as first argument 
# distinct(obs)
```

```{r message=FALSE, echo=F}
obs %>% 
  distinct(across(-recordID), # reduces dataframe to only unique rows (keeps first one of any duplicates)
           .keep_all = TRUE) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 6, scrollX=T) )
```

<span style="color: orange;">**_CAUTION:_** If using `distinct()` on grouped data, the function will apply to each group.</span>


**Deduplicate based on specific columns**  

You can also specify columns to be the basis for de-duplication. In this way, the de-duplication only applies to rows that are duplicates within the specified columns. Unless specified with `.keep_all = TRUE`, all columns not mentioned will be dropped.  

In the example below, the de-duplication only applies to rows that have identical values for `name` and `purpose` columns. Thus, "brian" has only 2 rows instead of 3 - his *first* "contact" encounter and his only "case" encounter. To adjust so that brian's *latest* encounter of each purpose is kept, see the tab on Slicing within groups.  

*Scroll to the left to see the entire dataframe*  

```{r, eval=F}
# added to a chain of pipes (e.g. data cleaning)
obs %>% 
  distinct(name, purpose, .keep_all = TRUE) %>%  # keep rows unique by name and purpose, retain all columns
  arrange(name)                                  # arrange for easier viewing
```

```{r message=FALSE, echo=F}
obs %>% 
  distinct(name, purpose, .keep_all = TRUE) %>%  # keep rows unique by name and purpose, retain all columns
  arrange(name) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 6, scrollX=T) )
```
<!-- ======================================================= -->
### Duplicate elements in a vector  


The function `duplicated()` from **base** R will evaluate a vector (column) and return a logical vector of the same length (TRUE/FALSE). The first time a value appears, it will return FALSE (not a duplicate), and subsequent times that value appears it will return TRUE. Note how `NA` is treated the same as any other value.    

```{r}
x <- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)
duplicated(x)
```

To return only the duplicated elements, you can use brackets to subset the original vector: 

```{r}
x[duplicated(x)]
```

To return only the unique elements, use `unique()` from **base** R. To remove `NA`s from the output, nest `na.omit()` within `unique()`.  

```{r}
unique(x)           # alternatively, use x[!duplicated(x)]
unique(na.omit(x))  # remove NAs 
```


<!-- ======================================================= -->
### with **base** R 

**To return duplicate rows**  

In **base** R, you can also see which rows are 100% duplicates in a dataframe `df` with the command `duplicated(df)` (returns a logical vector of the rows).  

Thus, you can also use the base subset `[ ]` on the dataframe to see the *duplicated* rows with `df[duplicated(df),]` (don't forget the comma, meaning that you want to see all columns!). 

**To return unique rows**  

See the notes above. To see the *unique* rows you add the logical negator `!` in front of the `duplicated()` function:  
`df[!duplicated(df),]`  


**To return rows that are duplicates of only certain columns**  

Subset the `df` that is *within the `duplicated()` parentheses*, so this function will operate on only certain columns of the `df`.  

To specify the columns, provide column numbers or names after a comma (remember, all this is *within* the `duplicated()` function).  

Be sure to keep the comma `,` *outside* after the `duplicated()` function as well! 

For example, to evaluate only columns 2 through 5 for duplicates:  `df[!duplicated(df[, 2:5]),]`  
To evaluate only columns `name` and `purpose` for duplicates: `df[!duplicated(df[, c("name", "purpose)]),]`  





<!-- ======================================================= -->
## Slicing {.tabset }


To "slice" a dataframe is useful in de-duplication if you have multiple rows per functional group (e.g. per "person") and you only want to analyze one or some of them. Think of slicing a filter on the rows, by row number/position. 

**The basic `slice()` function** accepts a number `n`. If positive, only the *nth* row is returned. If negative, all rows *except the nth* are returned.   

**Variations** include:    

* `slice_min()` and `slice_max()`  - to keep only the row with the minimium or maximum value of the specified column. Also worked with ordered factors.    
* `slice_head()` and `slice_tail` - to keep only the *first* or *last* row  
* `slice_sample()`  - to keep only a random sample of the rows  

Use arguments `n = ` or `prop = ` to specify the number or proportion of rows to keep. If not using the function in a pipe chain, provide the data argument first (e.g. `slice(df, n = 2)`). See `?slice` for more information.  

Other arguments:  

`.order_by = ` - used in `slice_min()` and `slice_max()` this is a column to order by before slicing.  
`with_ties = ` - TRUE by default, meaning ties are kept.  
`.preserve = ` - FALSE by default. If TRUE then the grouping structure is re-calculated after slicing.  
`weight_by = ` - Optional, numeric column to weight by (bigger number more likely to get sampled).  Also `replace = ` for whether sampling is done with/without replacement.  

<span style="color: darkgreen;">**_TIP:_** When using `slice_max()` and `slice_min()`, be sure to specify/write the `n = `  (e.g. `n = 2`, not just `2`). Otherwise you may get an error `Error: `...` is not empty.` </span>

<span style="color: black;">**_NOTE:_** You may encounter the function [`top_n()`](https://dplyr.tidyverse.org/reference/top_n.html), which has been superseded by the `slice` functions.</span>

Here, the basic `slice()` function is used to keep only the 4th row:  

```{r, eval=F}
obs %>% 
  slice(4)  # keeps the 4th row only
```

```{r message=FALSE, echo=F}
obs %>% 
  slice(4) %>%   # keeps the 4th row only
  DT::datatable(rownames = FALSE, options = list(pageLength = 1, scrollX=T) )
```


<!-- ======================================================= -->
### Slice with groups  

The `slice_*()` functions can be very useful if applied to a grouped dataframe, as the slice operation is performed on each group separately. Use the **function** `group_by()` in conjunction with `slice()` to group the data and then take a slice from each group.   
This is helpful for de-duplication if you have multiple rows per person but only want to keep one of them. You first use `group_by()` with key columns that are the same, and then use a slice function on a column that will differ among the grouped rows.  

In the example below, to keep only the *latest* encounter *per person*, we group the rows by `name` and then use `slice_max()` with `n = 1` on the `date` column. Be aware! To apply a function like `slice_max()` on dates, the date column must be class Date.   

By default, "ties" (e.g. same date in this scenario) are kept, and we would still get multiple rows for some people (e.g. adam). To avoid this we set `with_ties = FALSE`. We get back only one row per person.  

<span style="color: orange;">**_CAUTION:_** If using `arrange()`, specify `.by_group = TRUE` to have the data arranged within each group.</span>

<span style="color: red;">**_DANGER:_** If `with_ties = FALSE`, the first row of a tie is kept. This may be deceptive. See how for Mariah, she has two encounters on her latest date (6 Jan) and the first (earliest) one was kept. Likely, we want to keep her later encounter on that day. See how to "break" these ties in the next example. </span>  




```{r, eval=F}
obs %>% 
  group_by(name) %>%       # group the rows by 'name'
  slice_max(date,          # keep row per group with maximum date value 
            n = 1,         # keep only the single highest row 
            with_ties = F) # if there's a tie (of date), take the first row
```

```{r message=FALSE, echo=F}
obs %>% 
  group_by(name) %>%       # group the rows by 'name'
  slice_max(date,          # keep row per group with maximum date value 
            n = 1,         # keep only the single highest row 
            with_ties = F) %>%  # if there's a tie (of date), take the first row
  DT::datatable(rownames = FALSE, options = list(pageLength = 8, scrollX=T) )
```

**Breaking "ties"**  

Multiple slice statements can be run to "break ties". In this case, if a person has multiple encounters on their latest *date*, the encounter with the latest *time* is kept (`lubridate::hm()` is used to convert the character times to a sortable time class).  
Note how now, the one row kept for "Mariah" on 6 Jan is encounter 3 from 08:32, not encounter 2 at 07:25.  

```{r, eval=F}
# Example of multiple slice statements to "break ties"
obs %>%
  group_by(name) %>%
  
  # FIRST - slice by latest date
  slice_max(date, n = 1, with_ties = TRUE) %>% 
  
  # SECOND - if there is a tie, select row with latest time; ties prohibited
  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)
```
```{r message=FALSE, echo=F}
# Example of multiple slice statements to "break ties"
obs %>%
  group_by(name) %>%
  
  # FIRST - slice by latest date
  slice_max(date, n = 1, with_ties = TRUE) %>% 
  
  # SECOND - if there is a tie, select row with latest time; ties prohibited
  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE) %>% 
  
  DT::datatable(rownames = FALSE, options = list(pageLength = 8, scrollX=T) )
```

*In the example above, it would also have been possible to slice by `encounter` number, but we showed the slice on `date` and `time` for example purposes.*  

<span style="color: darkgreen;">**_TIP:_** To use `slice_max()` or `slice_min()` on a "character" column, mutate it to an *ordered* factor class!</span>



<!-- ======================================================= -->
### Keep all but mark them  

If you want to keep all records but mark only some for analysis, consider a two-step approach utilizing a unique recordID/encounter number:  

1) Reduce/slice the orginal dataframe to only the rows for analysis. Save/retain this reduced dataframe.  
2) In the original dataframe, mark rows as appropriate with `case_when()`, based on whether their record unique identifier (recordID in this example) is present in the reduced dataframe.  


```{r, eval=F}
# 1. Define dataframe of rows to keep for analysis
obs_keep <- obs %>%
  group_by(name) %>%
  slice_max(encounter, n = 1, with_ties = FALSE) # keep only latest encounter per person


# 2. Mark original dataframe
obs_marked <- obs %>%

  # make new dup_record column
  mutate(dup_record = case_when(
    
    # if record is in obs_keep dataframe
    recordID %in% obs_keep$recordID ~ "For analysis", 
    
    # all else marked as "Ignore" for analysis purposes
    TRUE                            ~ "Ignore"))

# print
obs_marked
```

<!-- ======================================================= -->
### Calculate row completeness  

Create a column that contains a metric for the row's completeness (non-missingness). This could be helpful when deciding which rows to prioritize over others when de-duplicating/slicing.  

In this example, "key" columns over which you want to measure completeness are saved in a vector of column names.  

Then the new column `key_completeness` is created with `mutate()`. The new value in each row is defined as a calculated fraction: the number of non-missing values in that row among the key columns, divided by the number of key columns.  

This involves the function `rowSums()` from **base** R. Also used is `.`, which within piping refers to the dataframe at that point in the pipe (in this case, it is being subset with brackets `[]`).  

*Scroll to the right to see more rows**  

```{r, eval=F}
# create a "key variable completeness" column
# this is a *proportion* of the columns designated as "key_vars" that have non-missing values

key_cols = c("personID", "name", "symptoms_ever")

obs %>% 
  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) 
```

```{r message=FALSE, echo=F}
key_cols = c("personID", "name", "symptoms_ever")

obs %>% 
  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) %>% 
  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX=T) )
```





<!-- ======================================================= -->
## Roll-up values {.tabset }


This tab describes:  

1) How to "roll-up" values from multiple rows into just one row, with some variations  
2) Once you have "rolled-up" values, how to overwrite/prioritize the values in each cell  

This tab uses the example dataset from the Preparation tab.  



<!-- ======================================================= -->
### Roll-up values into one row  

The code example below uses `group_by()` and `summarise()` to group rows by person, and then paste together all unique values within the grouped rows. Thus, you get one summary row per person. A few notes:  

* A suffix is appended to all new columns ("_roll" in this example)  
* If you want to show only unique values per cell, then wrap the `na.omit()` with `unique()`  
* `na.omit()` removes `NA` values, but if this is not desired it can be removed `paste0(.x)`...  

*Scroll to the left to see more rows*  

```{r, eval=F}
# "Roll-up" values into one row per group (per "personID") 
cases_rolled <- obs %>% 
  
  # create groups by name
  group_by(personID) %>% 
  
  # order the rows within each group (e.g. by date)
  arrange(date, .by_group = TRUE) %>% 
  
  # For each column, paste together all values within the grouped rows, separated by ";"
  summarise(
    across(everything(),                           # apply to all columns
           ~paste0(na.omit(.x), collapse = "; "))) # function is defined which combines non-NA values
```

The result is one row per group (`ID`), with entries arranged by date and pasted together.  

```{r message=FALSE, echo=F}
# "Roll-up" values into one row per group (per "personID") 
obs %>% 
  
  # create groups by name
  group_by(personID) %>% 
  
  # order the rows within each group (e.g. by date)
  arrange(date, .by_group = TRUE) %>% 
  
  # For each column, paste together all values within the grouped rows, separated by ";"
  summarise(
    across(everything(),                                # apply to all columns
           ~paste0(na.omit(.x), collapse = "; "))) %>%  # function is defined which combines non-NA values

  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX=T))
```

**This variation shows unique values only:**  

```{r}
# Variation - show unique values only 
cases_rolled <- obs %>% 
  group_by(personID) %>% 
  arrange(date, .by_group = TRUE) %>% 
  summarise(
    across(everything(),                                   # apply to all columns
           ~paste0(unique(na.omit(.x)), collapse = "; "))) # function is defined which combines unique non-NA values
```

```{r message=FALSE, echo=F}
# Variation - show unique values only 
obs %>% 
  group_by(personID) %>% 
  arrange(date, .by_group = TRUE) %>% 
  summarise(
    across(everything(),                                   # apply to all columns
           ~paste0(unique(na.omit(.x)), collapse = "; "))) %>%  # function is defined which combines unique non-NA values

  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX=T) )
```


**This variation appends a suffix to each column.**  
In this case "_roll" to signify that it has been rolled:  

```{r, eval=F}
# Variation - suffix added to column names 
cases_rolled <- obs %>% 
  group_by(personID) %>% 
  arrange(date, .by_group = TRUE) %>% 
  summarise(
    across(everything(),                
           list(roll = ~paste0(na.omit(.x), collapse = "; ")))) # _roll is appended to column names
```

```{r message=FALSE, echo=F}
# display the linelist data as a table
# Variation - suffix added to column names 
obs %>% 
  group_by(personID) %>% 
  arrange(date, .by_group = TRUE) %>% 
  summarise(
    across(everything(),                
           list(roll = ~paste0(na.omit(.x), collapse = "; ")))) %>%  # _roll is appended to column names
  DT::datatable(rownames = FALSE, options = list(pageLength = 5, scrollX=T) )
```


<!-- ======================================================= -->
### Overwrite values/hierarchy  


If you then want to evaluate all of the rolled values, and keep only a specific value (e.g. "best" or "maximum" value), you can use `mutate()` across the desired columns, to implement `case_when()`, which uses `str_detect()` from the **stringr** package to sequentially look for string patterns and overwrite the cell content.  

```{r}
# CLEAN CASES
#############
cases_clean <- cases_rolled %>% 
    
    # clean Yes-No-Unknown vars: replace text with "highest" value present in the string
    mutate(across(c(contains("symptoms_ever")),                     # operates on specified columns (Y/N/U)
             list(mod = ~case_when(                                 # adds suffix "_mod" to new cols; implements case_when()
               
               str_detect(.x, "Yes")       ~ "Yes",                 # if "Yes" is detected, then cell value converts to yes
               str_detect(.x, "No")        ~ "No",                  # then, if "No" is detected, then cell value converts to no
               str_detect(.x, "Unknown")   ~ "Unknown",             # then, if "Unknown" is detected, then cell value converts to Unknown
               TRUE                        ~ as.character(.x)))),   # then, if anything else if it kept as is
      .keep = "unused")                                             # old columns removed, leaving only _mod columns
```


Now you can see in the column `symptoms_ever` that if the person EVER said "Yes" to symptoms, then only "Yes" is displayed.  

```{r message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(cases_clean, rownames = FALSE, options = list(pageLength = 10, scrollX=T))
```




<!-- ======================================================= -->
## Resources {.tabset }

Much of the information in this page is adapted from these resources and vignettes online:  

[datanovia](https://www.datanovia.com/en/lessons/identify-and-remove-duplicate-data-in-r/)

[dplyr tidyverse reference](https://dplyr.tidyverse.org/reference/slice.html)  

[cran janitor vignette](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html#explore-records-with-duplicated-values-for-specific-combinations-of-variables-with-get_dupes)  


<!--chapter:end:raw_pages/deduplication.Rmd-->

# (PART) Data Vizualization {-}

<!--chapter:end:raw_pages/cat_data_viz.Rmd-->

# Age pyramids {.tabset .tabset-fade}  

Age pyramids can be useful to show patterns by age group. They can show gender, or the distribution of other characteristics.  
These tabs demonstrate how to produce age pyramids using:  

* Fast & easy:   Using the **apyramid** package  
* More flexible: Using `ggplot()`  
* Having baseline demographics displayed in the background of the pyramid  
* Using pyramid-style plots to show other types of data (e.g responses to Likert-style questions)  


<!-- ======================================================= -->
## Overview {.tabset .tabset-fade}

```{r, out.width = c('50%', '50%'), fig.show='hold', echo=F}
knitr::include_graphics(here::here("images", "pop_pyramid_baseline.png"))

knitr::include_graphics(here::here("images", "likert.png"))
```


Age/gender demographic pyramids in R are generally made with `ggplot()` by creating two barplots (one for each gender), converting one's values to negative values, and flipping the x and y axes to display the barplots vertically. 

Here we offer a quick approach through the **apyramid** package:  

* More customizable code using the raw `ggplot()` commands  
* How to combine case demographic data and compare with that of a baseline population (as shown above)  
* Application of these methods to show other types of data (e.g. responses to Likert-style survey questions)  



<!-- ======================================================= -->
## Preparation {.tabset .tabset-fade}
<h2> Preparation </h2>

For this tab we use the `linelist` dataset that is cleaned in the Cleaning tab.  

To make a traditional age/sex demographic pyramid, the data must first be cleaned in the following ways:  

* The gender column must be cleaned.  
* Age should be in an age category column, and should be an of class Factor (with correctly ordered levels)

**Load packages**  

First, load the packages required for this analysis:  

```{r}
pacman::p_load(rio,       # to import data
               here,      # to locate files
               tidyverse, # to clean, handle, and plot the data (includes ggplot2 package)
               apyramid,  # a package dedicated to creating age pyramids
               stringr)   # working with strings for titles, captions, etc.
```

Load the data  

```{r, echo=F}
linelist <- rio::import(here("data", "linelist_cleaned.rds"))
```

```{r, eval=F}
linelist <- rio::import("linelist_cleaned.csv")
```

**Check class of variables**  

Ensure that the age variable is class Numeric, and check the class and order of levels of `age_cat` and `age_cat5` 

```{r}
class(linelist$age_years)

class(linelist$age_cat)
class(linelist$age_cat5)

table(linelist$age_cat, useNA = "always")
table(linelist$age_cat5, useNA = "always")
```


<!-- ======================================================= -->
## **apyramid** package {.tabset .tabset-fade}
<h2> **apyramid** package </h2>

The package **apyramid** allows you to quickly make an age pyramid. For more nuanced situations, see the tab on using `ggplot()` to make age pyramids. You can read more about the **apyramid** package in its Help page by entering `?age_pyramid` in your R console. 

### Linelist data  
<h3> Linelist data </h3>  


Using the cleaned linelist dataset, we can create an age pyramid with just one simple command. If you need help cleaning your data, see the handbook page on Cleaning data (LINK). In this command:  

* The *data* argument is set as the `linelist` dataframe  
* The *age_group* argument is set to the name (in quotes) of the numeric category variable (in this case `age_cat5`)  
* The *split_by* argument (bar colors) should be a binary column (in this case "gender")  

```{r}
apyramid::age_pyramid(data = linelist,
                      age_group = "age_cat5",
                      split_by = "gender")
```
When using **agepyramid** package, if the `split_by` column is binary (e.g. male/female, or yes/no), then the result will appear as a pyramid. However if there are more than two values in the `split_by` column (not including `NA`), the pyramid will appears as a faceted barplot with empty bars in the background indicating the range of the un-faceted data set for the age group. Values of split_by will appear as labels at top of each facet. For example below if the `split_by` variable is "hospital".  

```{r}
apyramid::age_pyramid(data = linelist,
                      age_group = "age_cat5",
                      split_by = "hospital",
                      na.rm = FALSE)        # show a bar for patients missing age, (note: this changes the pyramid into a faceted barplot)
```

**Missing values**  
Rows missing values for the `split_by` or `age_group` columns, if coded as `NA`, will not trigger the faceting shown above. By default these rows will not be shown. However you can specify that they appear, in an adjacent barplot and as a separate age group at the top, by specifying `na.rm = FALSE`.  

```{r}
apyramid::age_pyramid(data = linelist,
                      age_group = "age_cat5",
                      split_by = "gender",
                      na.rm = FALSE)         # show patients missing age or gender
```

**Proportions, colors, & aesthetics**  

By default, the bars display counts (not %), a dashed mid-line for each group is shown, and the colors are green/purple. Each of these parameters can all be adjusted, as shown below:  

You can also add additional `ggplot()` commands to the plot using the standard `ggplot()` "+" syntax, such as aesthetic themes and label adjustments: 

```{r}
apyramid::age_pyramid(data = linelist,
                      age_group = "age_cat5",
                      split_by = "gender",
                      proportional = TRUE,                  # show percents, not counts
                      show_midpoint = FALSE,                # remove bar mid-point line
                      #pal = c("orange", "purple")          # can specify alt. colors here (but not labels, see below)
                      )+                 
  
  # additional ggplot commands
  theme_minimal()+                                          # simplify the background
  scale_fill_manual(values = c("orange", "purple"),         # to specify colors AND labels
                     labels = c("Male", "Female"))+
  labs(y = "Percent of all cases",                          # note that x and y labels are switched (see ggplot tab)
       x = "Age categories",                          
       fill = "Gender", 
       caption = "My data source and caption here",
       title = "Title of my plot",
       subtitle = "Subtitle with \n a second line...")+
  theme(
    legend.position = "bottom",                             # move legend to bottom
    axis.text = element_text(size = 10, face = "bold"),     # fonts/sizes, see ggplot tips page
    axis.title = element_text(size = 12, face = "bold"))
```



### Aggregated data  
<h3> Aggregated data </h3>

The examples above assume your data are in a linelist-like format, with one row per observation. If your data are already aggregated into counts by age category, you can still use the **apyramid** package, as shown below.  

Let's say that your dataset looks like this, with columns for age category, and male counts, female counts, and missing counts.  
(see the handbook page on Transforming data for tips)

```{r, echo=F}
demo_agg <- linelist %>% 
  group_by(age_cat5, gender) %>% 
  summarize(cases = dplyr::n()) %>% 
  pivot_wider(id_cols = age_cat5, names_from = gender, values_from = cases) %>% 
  rename(`missing_gender` = `NA`)
```

```{r}
# View the aggregated data
DT::datatable(demo_agg, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

`ggplot()` perfers data in "long" format, so first pivot the data to be "long" with the `pivot_longer()` function from **dplyr**.  

```{r}
# pivot the aggregated data into long format
demo_agg_long <- demo_agg %>% 
  pivot_longer(c(f, m, missing_gender),            # cols to elongate
               names_to = "gender",                # name for new col of categories
               values_to = "counts") %>%           # name for new col of counts
  mutate(gender = na_if(gender, "missing_gender")) # convert "missing_gender" to NA
``` 

```{r}
# View the aggregated data
DT::datatable(demo_agg_long, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

Then use the `split_by` and `count` arguments of `age_pyramid()` to specify the respective columns:  

```{r}
apyramid::age_pyramid(data = demo_agg_long,
                      age_group = "age_cat5",
                      split_by = "gender",
                      count = "counts")      # give the column name for the aggregated counts
```

Note in the above, that the factor order of "m" and "f" is different (pyramid reversed). To adjust the order you must re-define gender in the aggredated data as a Factor and order the levels as desired.  




<!-- ======================================================= -->
## `ggplot()` {.tabset .tabset-fade}
<h2> `ggplot()` </h2>

Using `ggplot()` to build your age pyramid allows for more flexibility, but requires more effort and understanding of how `ggplot()` works. It is also easier to accidentally make mistakes.  

**apyramid** uses `ggplot()` in the background (and accepts `ggplot()` commands added), but this page shows how to adjust or recreate a pyramid only using `ggplot()`, if you wish.  



<!-- ======================================================= -->
### Constructing the plot {.tabset .tabset-fade} 
<h3> Constructing the plot </h3>

First, understand that to make such a pyramid using `ggplot()` the approach is to:

* Within the `ggplot()`, create **two** graphs by age category. Create one for each of the two grouping values (in this case gender). See filters applied to the `data` arguments in each `geom_histogram()` commands below.  

* If using `geom_histogram()`, the graphs operate off the numeric column (e.g. `age_years`), whereas if using `geom_barplot()` the graphs operate from an ordered Factor (e.g. `age_cat5`). 

* One graph will have positive count values, while the other will have its counts converted to negative values - this allows both graphs to be seen and compared against each other in the same plot.  

* The command `coord_flip()` switches the X and Y axes, resulting in the graphs turning vertical and creating the pyramid.

* Lastly, the counts-axis labels must be specified so they appear as "positive" counts on both sides of the pyramid (despite the underlying values on one side being negative). 

A **simple** version of this, using `geom_histogram()`, is below:

```{r}
  # begin ggplot
  ggplot(data = linelist, aes(x = age, fill = gender)) +
  
  # female histogram
  geom_histogram(data = filter(linelist, gender == "f"),
                 breaks = seq(0,85,5),
                 colour = "white") +
  
  # male histogram (values converted to negative)
  geom_histogram(data = filter(linelist, gender == "m"),
                 breaks = seq(0,85,5),
                 aes(y=..count..*(-1)),
                 colour = "white") +
  
  # flip the X and Y axes
  coord_flip() +
  
  # adjust counts-axis scale
  scale_y_continuous(limits = c(-600, 900),
                     breaks = seq(-600,900,100),
                     labels = abs(seq(-600, 900, 100)))
```

<span style="color: red;">**_DANGER:_** If the **limits** of your counts axis are set too low, and a counts bar exceeds them, the bar will disappear entirely or be artificially shortened! Watch for this if analyzing data which is routinely updated. Prevent it by having your count-axis limits auto-adjust to your data, as below.</span>  

There are many things you can change/add to this simple version, including:  

* Auto adjust counts-axis count scale to your data (avoid errors discussed in warning below)  
* Manually specify colors and legend labels  


```{r}
# create dataset with proportion of total
pyramid_data <- linelist %>%
  group_by(age_cat5, gender) %>% 
  summarize(counts = n()) %>% 
  ungroup() %>% 
  mutate(percent = round(100*(counts / sum(counts, na.rm=T)),1), 
         percent = case_when(
            gender == "f" ~ percent,
            gender == "m" ~ -percent,
            TRUE          ~ NA_real_))

max_per <- max(pyramid_data$percent, na.rm=T)
min_per <- min(pyramid_data$percent, na.rm=T)


# begin ggplot
  ggplot()+  # default x-axis is age in years;

  # case data graph
  geom_bar(data = pyramid_data,
           stat = "identity",
           aes(x = age_cat5,
               y = percent,
               fill = gender),        # 
           colour = "white")+         # white around each bar
  
  # flip the X and Y axes to make pyramid vertical
  coord_flip()+
  

  # adjust the axes scales (remember they are flipped now!)
  #scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +
  scale_y_continuous(limits = c(min_per, max_per),
                     breaks = seq(floor(min_per), ceiling(max_per), 2),
                     labels = paste0(abs(seq(floor(min_per), ceiling(max_per), 2)), "%"))+

  # designate colors and legend labels manually
  scale_fill_manual(
    values = c("f" = "orange",
               "m" = "darkgreen"),
    labels = c("Female", "Male"),
  ) +
  
  # label values (remember X and Y flipped now)
  labs(
    x = "Age group",
    y = "Percent of total",
    fill = NULL,
    caption = stringr::str_glue("Data are from linelist \nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \nData as of: {format(Sys.Date(), '%d %b %Y')}")) +
  
  # optional aesthetic themes
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    plot.title = element_text(hjust = 0.5), 
    plot.caption = element_text(hjust=0, size=11, face = "italic")) + 
  
  ggtitle(paste0("Age and gender of cases"))
    

```



<!-- ======================================================= -->
### Compare to baseline  
<h3> Compare to baseline </h3>

With the flexibility of `ggplot()`, you can have a second layer of bars in the background that represent the true population pyramid. This can provide a nice visualization to compare the observed counts with the baseline.  

Import and view the population data
```{r echo=F}
# import the population demographics data
pop <- rio::import(here::here("data", "country_demographics.csv"))
```

```{r eval=F}
# import the population demographics data
pop <- rio::import("country_demographics.csv")
```

```{r, message=FALSE}
# display the linelist data as a table
DT::datatable(pop, rownames = FALSE, filter="top", options = list(pageLength = 10, scrollX=T) )
```
First some data management steps:  

Here we record the order of age categories that we want to appear. Due to some quirks the way the `ggplot()` is implemented, it is easiest to store these as a character vector and use them later in the plotting function.  

```{r}
# record correct age cat levels
age_levels <- c("0-4","5-9", "10-14", "15-19", "20-24",
                "25-29","30-34", "35-39", "40-44", "45-49",
                "50-54", "55-59", "60-64", "65-69", "70-74",
                "75-79", "80-84", "85+")
```

Combine the population and case data through the **dplyr** function `bind_rows()`:  

* First, ensure they have the *exact same* column names, age categories values, and gender values  
* Make them have the same data structure: columns of age category, gender, counts, and percent of total  
* Bind them together, one on-top of the other (`bind_rows()`)  



```{r}
# create/transform populaton data, with percent of total
########################################################
pop_data <- pivot_longer(pop, c(m, f), names_to = "gender", values_to = "counts") %>% # pivot gender columns longer
  mutate(data = "population",                                                         # add column designating data source
         percent  = round(100*(counts / sum(counts, na.rm=T)),1),                     # calculate % of total
         percent  = case_when(                                                        # if male, convert % to negative
                            gender == "f" ~ percent,
                            gender == "m" ~ -percent,
                            TRUE          ~ NA_real_))
```

Review the changed population dataset
```{r, message=FALSE}
# display the linelist data as a table
DT::datatable(pop_data, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

Now implement the same for the case linelist.  Slightly different because it begins with case-rows, not counts.  

```{r}
# create case data by age/gender, with percent of total
#######################################################
case_data <- linelist %>%
  group_by(age_cat5, gender) %>%  # aggregate linelist cases into age-gender groups
  summarize(counts = n()) %>%     # calculate counts per age-gender group
  ungroup() %>% 
  mutate(data = "cases",                                          # add column designating data source
         percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculate % of total for age-gender groups
         percent = case_when(                                     # convert % to negative if male
            gender == "f" ~ percent,
            gender == "m" ~ -percent,
            TRUE          ~ NA_real_))
```

Review the changed case dataset  

```{r, message=FALSE}
# display the linelist data as a table
DT::datatable(case_data, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```
Now the two datasets are combined, one on top of the other (same column names)
```{r}
# combine case and population data (same column names, age_cat values, and gender values)
pyramid_data <- bind_rows(case_data, pop_data)
```

Store the maximum and minimum percent values, used in the plotting funtion to define the extent of the plot (and not cut off any bars!)  

```{r}
# Define extent of percent axis, used for plot limits
max_per <- max(pyramid_data$percent, na.rm=T)
min_per <- min(pyramid_data$percent, na.rm=T)
```

Now the plot is made with `ggplot()`: 

* One bar graph of population data (wider, more transparent bars)
* One bar graph of case data (small, more solid bars)  


```{r}

# begin ggplot
##############
ggplot()+  # default x-axis is age in years;

  # population data graph
  geom_bar(data = filter(pyramid_data, data == "population"),
           stat = "identity",
           aes(x = age_cat5,
               y = percent,
               fill = gender),        
           colour = "black",                               # black color around bars
           alpha = 0.2,                                    # more transparent
           width = 1)+                                     # full width
  
  # case data graph
  geom_bar(data = filter(pyramid_data, data == "cases"), 
           stat = "identity",                              # use % as given in data, not counting rows
           aes(x = age_cat5,                               # age categories as original X axis
               y = percent,                                # % as original Y-axis
               fill = gender),                             # fill of bars by gender
           colour = "black",                               # black color around bars
           alpha = 1,                                      # not transparent 
           width = 0.3)+                                   # half width
  
  # flip the X and Y axes to make pyramid vertical
  coord_flip()+
  
  # adjust axes order, scale, and labels (remember X and Y axes are flipped now)
  # manually ensure that age-axis is ordered correctly
  scale_x_discrete(limits = age_levels)+ 
  
  # set percent-axis 
  scale_y_continuous(limits = c(min_per, max_per),                                          # min and max defined above
                     breaks = seq(floor(min_per), ceiling(max_per), by = 2),                # from min% to max% by 2 
                     labels = paste0(                                                       # for the labels, paste together... 
                       abs(seq(floor(min_per), ceiling(max_per), by = 2)),                  # ...rounded absolute values of breaks... 
                       "%"))+                                                               # ... with "%"
                                                                                            # floor(), ceiling() round down and up 

  # designate colors and legend labels manually
  scale_fill_manual(
    values = c("f" = "orange",         # assign colors to values in the data
               "m" = "darkgreen"),
    labels = c("f" = "Female",
               "m"= "Male"),      # change labels that appear in legend, note order
  ) +

  # plot labels, titles, caption    
  labs(
    title = "Case age and gender distribution,\nas compared to baseline population",
    subtitle = "",
    x = "Age category",
    y = "Percent of total",
    fill = NULL,
    caption = stringr::str_glue("Cases shown on top of country demographic baseline\nCase data are from linelist, n = {nrow(linelist)}\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}")) +
  
  # optional aesthetic themes
  theme(
    legend.position = "bottom",                             # move legend to bottom
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"),
    plot.title = element_text(hjust = 0), 
    plot.caption = element_text(hjust=0, size=11, face = "italic"))

```


<!-- ======================================================= -->
## Likert scale {.tabset .tabset-fade}
<h2> Likert scale </h2>

The techniques used to make a population pyramid with `ggplot()` can also be used to make plots of Likert-scale survey data.  

```{r, eval=F, echo=F}
data_raw <- import("P:/Shared/equateur_mve_2020/lessons learned/Ebola After-Action Survey - HQ epi team (form responses).csv")


likert_data <- data_raw %>% 
  select(2, 4:11) %>% 
  rename(status = 1,
         Q1 = 2,
            Q2 = 3,
            Q3 = 4,
            Q4 = 5,
            Q5 = 6,
            Q6 = 7,
            Q7 = 8,
            Q8 = 9) %>% 
  mutate(status = case_when(
           stringr::str_detect(status, "Mar") ~ "Senior",
           stringr::str_detect(status, "Jan") ~ "Intermediate",
           stringr::str_detect(status, "Feb") ~ "Junior",
           TRUE ~ "Senior")) %>% 
  mutate(Q4 = recode(Q4, "Not applicable" = "Very Poor"))

table(likert_data$status)

rio::export(likert_data, here::here("data", "likert_data.csv"))
```

Import the data
```{r echo=F}
# import the likert survey response data
likert_data <- rio::import(here::here("data", "likert_data.csv"))
```

```{r, eval=F}
# import the likert survey response data
likert_data <- rio::import("likert_data.csv")
```

Start with data that looks like this, with a categorical classification of each respondent (`status`) and their answers to 8 questions on a 4-point Likert-type scale ("Very poor", "Poor", "Good", "Very good").  

```{r, message=FALSE}
# display the linelist data as a table
DT::datatable(likert_data, rownames = FALSE, filter="top", options = list(pageLength = 10, scrollX=T) )
```

First, some data management steps:  

* Pivot the data longer  
* Create new column `direction` depending on whether response was generally "positive" or "negative"  
* Set the Factor level order for the `status` column and the `Response` column  
* Store the max count value so limits of plot are appropriate  


```{r}
melted <- pivot_longer(likert_data, Q1:Q8, names_to = "Question", values_to = "Response") %>% 
     mutate(direction = case_when(
               Response %in% c("Poor","Very Poor") ~ "Negative",
               Response %in% c("Good", "Very Good") ~ "Positive",
               TRUE ~ "Unknown"),
            status = factor(status, levels = rev(c(
                 "Senior", "Intermediate", "Junior"))),
            Response = factor(Response, levels = c("Very Good", "Good",
                                             "Very Poor", "Poor"))) # must reverse Very Poor and Poor for ordering to work

melted_max <- melted %>% 
   group_by(status, Question) %>% 
   summarize(n = n())

melted_max <- max(melted_max$n, na.rm=T)

```


Now make the plot:

```{r}
# make plot
ggplot()+
     # bar graph of the "negative" responses 
     geom_bar(data = filter(melted,
                            direction == "Negative"), 
              aes(x = status,
                        y=..count..*(-1),    # counts inverted to negative
                        fill = Response),
                    color = "black",
                    closed = "left", 
                    position = "stack")+
     
     # bar graph of the "positive responses
     geom_bar(data = filter(melted, direction == "Positive"),
              aes(x = status, fill = Response),
              colour = "black",
              closed = "left",
              position = "stack")+
     
     # flip the X and Y axes
     coord_flip()+
  
     # Black vertical line at 0
     geom_hline(yintercept = 0, color = "black", size=1)+
     
    # convert labels to all positive numbers
    scale_y_continuous(limits = c(-ceiling(melted_max/10)*11, ceiling(melted_max/10)*10),   # seq from neg to pos by 10, edges rounded outward to nearest 5
                       breaks = seq(-ceiling(melted_max/10)*10, ceiling(melted_max/10)*10, 10),
                       labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),
                                            seq(0, ceiling(melted_max/10)*10, 10))))) +
     
    # color scales manually assigned 
    scale_fill_manual(values = c("Very Good"  = "green4", # assigns colors
                                  "Good"      = "green3",
                                  "Poor"      = "yellow",
                                  "Very Poor" = "red3"),
                       breaks = c("Very Good", "Good", "Poor", "Very Poor"))+ # orders the legend
     
    
     
    # facet the entire plot so each question is a sub-plot
    facet_wrap(~Question, ncol = 3)+
     
    # labels, titles, caption
    labs(x = "Respondent status",
          y = "Number of responses",
          fill = "")+
     ggtitle(str_glue("Likert-style responses\nn = {nrow(likert_data)}"))+

     # aesthetic settings
     theme_minimal()+
     theme(axis.text = element_text(size = 12),
           axis.title = element_text(size = 14, face = "bold"),
           strip.text = element_text(size = 14, face = "bold"),  # facet sub-titles
           plot.title = element_text(size = 20, face = "bold"),
           panel.background = element_rect(fill = NA, color = "black")) # black box around each facet
```


<!-- ======================================================= -->
## Resources {.tabset .tabset-fade}
<h2> Resources </h2>

This tab should stay with the name "Resources".
Links to other online tutorials or resources.



<!--chapter:end:raw_pages/age_pyramid.Rmd-->

